# Comparing `tmp/tcex-3.0.9.tar.gz` & `tmp/tcex-4.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "tcex-3.0.9.tar", last modified: Wed Jun  7 19:48:12 2023, max compression
+gzip compressed data, was "tcex-4.0.0.tar", last modified: Wed Jul 26 23:47:33 2023, max compression
```

## Comparing `tcex-3.0.9.tar` & `tcex-4.0.0.tar`

### file list

```diff
@@ -1,426 +1,425 @@
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.249093 tcex-3.0.9/
--rw-rw-r--   0 bsummers   (503) staff       (20)    11357 2019-02-12 17:08:25.000000 tcex-3.0.9/LICENSE
--rw-rw-r--   0 bsummers   (503) staff       (20)     3508 2023-06-07 19:48:12.249252 tcex-3.0.9/PKG-INFO
--rw-rw-r--   0 bsummers   (503) staff       (20)     2211 2022-11-14 21:07:06.000000 tcex-3.0.9/README.md
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.610228 tcex-3.0.9/bin/
--rw-rw-r--   0 bsummers   (503) staff       (20)    15774 2023-04-10 17:48:00.000000 tcex-3.0.9/bin/tcex
--rw-rw-r--   0 bsummers   (503) staff       (20)     1006 2023-04-10 17:48:00.000000 tcex-3.0.9/pyproject.toml
--rw-rw-r--   0 bsummers   (503) staff       (20)      772 2023-06-07 19:48:12.250251 tcex-3.0.9/setup.cfg
--rw-rw-r--   0 bsummers   (503) staff       (20)     3081 2023-04-10 17:48:00.000000 tcex-3.0.9/setup.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.614649 tcex-3.0.9/tcex/
--rw-rw-r--   0 bsummers   (503) staff       (20)     1139 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      432 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/__metadata__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.627344 tcex-3.0.9/tcex/api/
--rw-rw-r--   0 bsummers   (503) staff       (20)       76 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      765 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/api.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.648466 tcex-3.0.9/tcex/api/tc/
--rw-rw-r--   0 bsummers   (503) staff       (20)       91 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2052 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/tc.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.664446 tcex-3.0.9/tcex/api/tc/ti_transform/
--rw-rw-r--   0 bsummers   (503) staff       (20)      141 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      196 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/formatters.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.669095 tcex-3.0.9/tcex/api/tc/ti_transform/model/
--rw-rw-r--   0 bsummers   (503) staff       (20)      353 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/model/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7765 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/model/transform_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6377 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/ti_transform.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    25333 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/api/tc/ti_transform/transform_abc.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.698110 tcex-3.0.9/tcex/api/tc/utils/
--rw-rw-r--   0 bsummers   (503) staff       (20)       39 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/utils/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    14736 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/utils/threat_intel_utils.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.704815 tcex-3.0.9/tcex/api/tc/v2/
--rw-rw-r--   0 bsummers   (503) staff       (20)      100 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.756918 tcex-3.0.9/tcex/api/tc/v2/batch/
--rw-rw-r--   0 bsummers   (503) staff       (20)      228 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/batch/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2671 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/batch/attribute.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    44500 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/batch/batch.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    18746 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v2/batch/batch_submit.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    51366 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v2/batch/batch_writer.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    23538 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/batch/group.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    29032 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v2/batch/indicator.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1768 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/batch/security_label.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1161 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/batch/tag.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.764767 tcex-3.0.9/tcex/api/tc/v2/datastore/
--rw-rw-r--   0 bsummers   (503) staff       (20)      114 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/datastore/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7077 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/datastore/cache.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    11000 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/datastore/datastore.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.774834 tcex-3.0.9/tcex/api/tc/v2/metrics/
--rw-rw-r--   0 bsummers   (503) staff       (20)       84 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/metrics/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6543 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/metrics/metrics.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.797834 tcex-3.0.9/tcex/api/tc/v2/notifications/
--rw-rw-r--   0 bsummers   (503) staff       (20)      102 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/notifications/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3187 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/notifications/notifications.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.812399 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/
--rw-rw-r--   0 bsummers   (503) staff       (20)      118 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.852736 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2386 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/filters.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.855627 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3731 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.917885 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8796 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/adversary.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      947 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/attack_pattern.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1625 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/campaign.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      953 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/course_of_action.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4495 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/document.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1112 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/email.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2339 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/event.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2340 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/incident.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      951 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/intrusion_set.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      867 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/malware.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3710 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/report.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1564 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/signature.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      841 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tactic.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      843 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/threat.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      831 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tool.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      947 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/vulnerability.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.921709 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    10357 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.956068 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2166 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/address.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2041 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/email_address.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7612 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/file.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3127 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/host.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2103 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/url.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    22774 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/mappings.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2241 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/owner.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2945 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/security_label.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2545 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/tag.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1249 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/tags.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8676 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/task.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    15032 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/victim.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    57009 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/tcex_ti_tc_request.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    35065 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/threat_intelligence.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7064 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v2/v2.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.975525 tcex-3.0.9/tcex/api/tc/v3/
--rw-rw-r--   0 bsummers   (503) staff       (20)       53 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.021919 tcex-3.0.9/tcex/api/tc/v3/_gen/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     9764 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    19062 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3450 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_args_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    18924 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_filter_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    16667 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_model_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    38886 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_object_abc.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.048371 tcex-3.0.9/tcex/api/tc/v3/_gen/models/
--rw-rw-r--   0 bsummers   (503) staff       (20)      176 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/models/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4059 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/models/_filter_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    14547 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/_gen/models/_property_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.049595 tcex-3.0.9/tcex/api/tc/v3/adversary_assets/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/adversary_assets/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1003 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/api_endpoints.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.063296 tcex-3.0.9/tcex/api/tc/v3/artifact_types/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/artifact_types/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3157 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2770 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2982 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.078235 tcex-3.0.9/tcex/api/tc/v3/artifacts/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/artifacts/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6810 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6061 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8747 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.104121 tcex-3.0.9/tcex/api/tc/v3/attribute_types/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/attribute_types/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3482 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3206 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3261 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.108087 tcex-3.0.9/tcex/api/tc/v3/attributes/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/attributes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2234 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/attributes/attribute_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.116248 tcex-3.0.9/tcex/api/tc/v3/case_attributes/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/case_attributes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4753 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6577 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4834 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.124009 tcex-3.0.9/tcex/api/tc/v3/case_management/
--rw-rw-r--   0 bsummers   (503) staff       (20)       63 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/case_management/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    22368 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/case_management/case_management.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.154033 tcex-3.0.9/tcex/api/tc/v3/cases/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/cases/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    12920 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/cases/case.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    16300 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/cases/case_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    12033 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/cases/case_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.159405 tcex-3.0.9/tcex/api/tc/v3/file_actions/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/api/tc/v3/file_actions/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1797 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/api/tc/v3/file_actions/file_action_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.164123 tcex-3.0.9/tcex/api/tc/v3/file_occurrences/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/api/tc/v3/file_occurrences/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1641 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/api/tc/v3/file_occurrences/file_occurrence_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1371 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/filter_abc.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.179108 tcex-3.0.9/tcex/api/tc/v3/group_attributes/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/group_attributes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4856 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7370 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5255 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.212084 tcex-3.0.9/tcex/api/tc/v3/groups/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/groups/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    15307 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/groups/group.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    22742 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/groups/group_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    16799 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/groups/group_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.225332 tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4980 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/indicator_attribute.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7466 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/indicator_attribute_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5383 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/indicator_attribute_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.255868 tcex-3.0.9/tcex/api/tc/v3/indicators/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/indicators/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    14868 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/indicators/indicator.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    20183 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/indicators/indicator_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    17137 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/indicators/indicator_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.267026 tcex-3.0.9/tcex/api/tc/v3/notes/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/notes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3463 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/notes/note.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4852 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/notes/note_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6026 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/notes/note_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    12632 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/object_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8527 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/object_collection_abc.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.304405 tcex-3.0.9/tcex/api/tc/v3/security/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1393 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/assignee_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      741 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/assignee_user_group_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      716 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/assignee_user_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.318135 tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2878 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/owner_role.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3600 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/owner_role_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3530 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/owner_role_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.330014 tcex-3.0.9/tcex/api/tc/v3/security/owners/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/owners/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2761 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/owners/owner.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    10858 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/owners/owner_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7508 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/owners/owner_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2266 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/security.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.359325 tcex-3.0.9/tcex/api/tc/v3/security/system_roles/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/system_roles/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2905 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/system_roles/system_role.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2052 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/system_roles/system_role_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2697 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/system_roles/system_role_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2650 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/task_assignee_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.373994 tcex-3.0.9/tcex/api/tc/v3/security/user_groups/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/user_groups/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2878 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/user_groups/user_group.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1411 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/user_groups/user_group_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2739 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/user_groups/user_group_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.401226 tcex-3.0.9/tcex/api/tc/v3/security/users/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/users/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2734 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security/users/user.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6970 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/api/tc/v3/security/users/user_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2021 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/security/users/user_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.414277 tcex-3.0.9/tcex/api/tc/v3/security_labels/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/security_labels/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4337 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/security_labels/security_label.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6009 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/security_labels/security_label_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3134 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/security_labels/security_label_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.425752 tcex-3.0.9/tcex/api/tc/v3/tags/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tags/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3980 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/tags/tag.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6091 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/tags/tag_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4349 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tags/tag_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.453058 tcex-3.0.9/tcex/api/tc/v3/tasks/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tasks/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6646 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/tasks/task.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     9537 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/tasks/task_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7442 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/api/tc/v3/tasks/task_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.457931 tcex-3.0.9/tcex/api/tc/v3/threat_intelligence/
--rw-rw-r--   0 bsummers   (503) staff       (20)       67 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/threat_intelligence/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    17553 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/threat_intelligence/threat_intelligence.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.477032 tcex-3.0.9/tcex/api/tc/v3/tql/
--rw-rw-r--   0 bsummers   (503) staff       (20)       51 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tql/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2222 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/tql/tql.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      520 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tql/tql_operator.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      251 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/tql/tql_type.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1321 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/v3.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    18129 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/api/tc/v3/v3_model_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1647 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/v3_types.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.504598 tcex-3.0.9/tcex/api/tc/v3/victim_assets/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/victim_assets/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5821 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5222 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5177 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.516699 tcex-3.0.9/tcex/api/tc/v3/victim_attributes/
--rw-rw-r--   0 bsummers   (503) staff       (20)        0 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/victim_attributes/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4815 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/victim_attributes/victim_attribute.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7027 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/victim_attributes/victim_attribute_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4879 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/api/tc/v3/victim_attributes/victim_attribute_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.529872 tcex-3.0.9/tcex/api/tc/v3/victims/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/victims/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7916 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/victims/victim.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     9140 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/victims/victim_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6561 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/victims/victim_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.562685 tcex-3.0.9/tcex/api/tc/v3/workflow_events/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_events/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4550 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_events/workflow_event.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4075 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_events/workflow_event_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5484 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_events/workflow_event_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.574990 tcex-3.0.9/tcex/api/tc/v3/workflow_templates/
--rw-rw-r--   0 bsummers   (503) staff       (20)       56 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_templates/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3611 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_templates/workflow_template.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3449 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_templates/workflow_template_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5159 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/api/tc/v3/workflow_templates/workflow_template_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.630508 tcex-3.0.9/tcex/app_config/
--rw-rw-r--   0 bsummers   (503) staff       (20)      327 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    21393 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/app_config/app_spec_yml.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     9324 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/app_config/install_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6004 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/app_config/install_json_update.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1485 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/install_json_validate.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2061 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/job_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4484 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/layout_json.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.676131 tcex-3.0.9/tcex/app_config/models/
--rw-rw-r--   0 bsummers   (503) staff       (20)      464 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/app_config/models/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    13834 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/app_config/models/app_spec_yml_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    29279 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/app_config/models/install_json_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2993 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/models/job_json_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2853 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/app_config/models/layout_json_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1833 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/app_config/models/tcex_json_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      914 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/app_config/models/template_config_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    20625 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/app_config/permutation.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2973 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/tcex_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3222 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_config/tcex_json_update.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.698781 tcex-3.0.9/tcex/app_feature/
--rw-rw-r--   0 bsummers   (503) staff       (20)      135 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/app_feature/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5615 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/app_feature/advanced_request.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.705058 tcex-3.0.9/tcex/backports/
--rw-rw-r--   0 bsummers   (503) staff       (20)     1066 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/backports/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.780656 tcex-3.0.9/tcex/bin/
--rw-rw-r--   0 bsummers   (503) staff       (20)      284 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/bin/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6525 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/bin/bin_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    17417 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/bin/dep.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5090 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/bin/deploy.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     9593 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/package.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    11318 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    22766 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_app_input.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8530 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_app_input_static.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    11155 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_app_spec_yml.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5739 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_install_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1587 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_job_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      981 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/bin/spec_tool_layout_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    14062 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/bin/spec_tool_readme_md.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1057 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/bin/spec_tool_tcex_json.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    21485 2023-04-10 17:48:00.000000 tcex-3.0.9/tcex/bin/template.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    21765 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/bin/validate.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.829023 tcex-3.0.9/tcex/decorators/
--rw-rw-r--   0 bsummers   (503) staff       (20)      360 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/decorators/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2335 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/decorators/benchmark.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1558 2020-09-04 22:24:44.000000 tcex-3.0.9/tcex/decorators/debug.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4525 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/decorators/fail_on_output.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3681 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/decorators/on_exception.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1828 2020-09-04 22:24:44.000000 tcex-3.0.9/tcex/decorators/on_success.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3482 2020-09-04 22:24:44.000000 tcex-3.0.9/tcex/decorators/output.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.858251 tcex-3.0.9/tcex/exit/
--rw-rw-r--   0 bsummers   (503) staff       (20)      192 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/exit/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5374 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/exit/error_codes.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6516 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/exit/exit.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.866540 tcex-3.0.9/tcex/input/
--rw-rw-r--   0 bsummers   (503) staff       (20)       92 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:11.954798 tcex-3.0.9/tcex/input/field_types/
--rw-rw-r--   0 bsummers   (503) staff       (20)     1242 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/input/field_types/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3532 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/binary.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3129 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/input/field_types/case_management_entity.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1581 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/choice.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      866 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/datetime.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3764 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/edit_choice.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3073 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/exception.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2995 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/group_entity.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2725 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/indicator_entity.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3505 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/input/field_types/integer.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2336 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/input/field_types/ip_address.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1270 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/key_value.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     5151 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/input/field_types/sensitive.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4111 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/input/field_types/string.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1251 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/field_types/tc_entity.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     8590 2022-03-23 20:18:24.000000 tcex-3.0.9/tcex/input/field_types/validators.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    15693 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/input/input.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.012168 tcex-3.0.9/tcex/input/models/
--rw-rw-r--   0 bsummers   (503) staff       (20)     1012 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2575 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/input/models/advanced_request_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      999 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/aot_execution_enabled_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2935 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/input/models/api_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1525 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/batch_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      893 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/cal_settings_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1567 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/input/models/create_config_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1595 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/logging_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2736 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/input/models/model_map.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      428 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/organization_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1162 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/path_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1577 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/input/models/playbook_common_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      929 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/playbook_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1350 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/proxy_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2716 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/service_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1174 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/input/models/smtp_settings_model.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.025595 tcex-3.0.9/tcex/key_value_store/
--rw-rw-r--   0 bsummers   (503) staff       (20)      224 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/key_value_store/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      873 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/key_value_store/key_value_abc.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2499 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/key_value_store/key_value_api.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1801 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/key_value_store/key_value_mock.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2777 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/key_value_store/key_value_redis.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1860 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/key_value_store/redis_client.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.073325 tcex-3.0.9/tcex/logger/
--rw-rw-r--   0 bsummers   (503) staff       (20)      293 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/logger/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3780 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/logger/api_handler.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      862 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/logger/cache_handler.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    13964 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/logger/logger.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3112 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/logger/pattern_file_handler.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2001 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/logger/rotating_file_handler_custom.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1099 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/logger/sensitive_filter.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1822 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/logger/thread_file_handler.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1206 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/logger/trace_logger.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.106971 tcex-3.0.9/tcex/playbook/
--rw-rw-r--   0 bsummers   (503) staff       (20)       88 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/playbook/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     3467 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/playbook/playbook.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    20899 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/playbook/playbook_create.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1027 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/playbook/playbook_delete.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      668 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/playbook/playbook_output.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    22857 2022-08-26 17:57:26.000000 tcex-3.0.9/tcex/playbook/playbook_read.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.128115 tcex-3.0.9/tcex/pleb/
--rw-rw-r--   0 bsummers   (503) staff       (20)       26 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/pleb/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1599 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/pleb/env_path.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      737 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/pleb/event.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      536 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/pleb/none_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1178 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/pleb/proxies.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7213 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/pleb/registry.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     2311 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/pleb/scoped_property.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      412 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/pleb/singleton.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      731 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/pleb/threading.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.161856 tcex-3.0.9/tcex/services/
--rw-rw-r--   0 bsummers   (503) staff       (20)      324 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/services/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    11874 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/services/api_service.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    16230 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/services/common_service.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    17548 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/services/common_service_trigger.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    10563 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/services/mqtt_message_broker.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    15948 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/services/webhook_trigger_service.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.172666 tcex-3.0.9/tcex/sessions/
--rw-rw-r--   0 bsummers   (503) staff       (20)       40 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/sessions/__init__.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.198304 tcex-3.0.9/tcex/sessions/auth/
--rw-rw-r--   0 bsummers   (503) staff       (20)       31 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/sessions/auth/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1706 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/sessions/auth/hmac_auth.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1539 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/sessions/auth/tc_auth.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1835 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/sessions/auth/token_auth.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    12891 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/sessions/external_session.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4923 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/sessions/rate_limit_handler.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4420 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/sessions/tc_session.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    20160 2023-06-07 19:48:06.000000 tcex-3.0.9/tcex/tcex.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.203927 tcex-3.0.9/tcex/tokens/
--rw-rw-r--   0 bsummers   (503) staff       (20)       80 2020-09-04 22:24:44.000000 tcex-3.0.9/tcex/tokens/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    12245 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/tokens/tokens.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.226880 tcex-3.0.9/tcex/utils/
--rw-rw-r--   0 bsummers   (503) staff       (20)       78 2020-09-04 22:24:44.000000 tcex-3.0.9/tcex/utils/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     1822 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/utils/aes_operations.py
--rw-rw-r--   0 bsummers   (503) staff       (20)    10144 2022-06-29 14:32:21.000000 tcex-3.0.9/tcex/utils/datetime_operations.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7272 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/utils/file_operations.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:12.248646 tcex-3.0.9/tcex/utils/models/
--rw-rw-r--   0 bsummers   (503) staff       (20)      127 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/utils/models/__init__.py
--rw-rw-r--   0 bsummers   (503) staff       (20)      667 2022-03-08 20:24:00.000000 tcex-3.0.9/tcex/utils/models/playbook_variable_model.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     4889 2023-02-02 18:36:54.000000 tcex-3.0.9/tcex/utils/requests_to_curl.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7751 2023-02-07 21:10:46.000000 tcex-3.0.9/tcex/utils/string_operations.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     6165 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/utils/utils.py
--rw-rw-r--   0 bsummers   (503) staff       (20)     7352 2022-11-14 21:07:06.000000 tcex-3.0.9/tcex/utils/variables.py
-drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-06-07 19:48:10.618128 tcex-3.0.9/tcex.egg-info/
--rw-rw-r--   0 bsummers   (503) staff       (20)     3508 2023-06-07 19:48:09.000000 tcex-3.0.9/tcex.egg-info/PKG-INFO
--rw-rw-r--   0 bsummers   (503) staff       (20)    14001 2023-06-07 19:48:10.000000 tcex-3.0.9/tcex.egg-info/SOURCES.txt
--rw-rw-r--   0 bsummers   (503) staff       (20)        1 2023-06-07 19:48:09.000000 tcex-3.0.9/tcex.egg-info/dependency_links.txt
--rw-rw-r--   0 bsummers   (503) staff       (20)     1019 2023-06-07 19:48:09.000000 tcex-3.0.9/tcex.egg-info/requires.txt
--rw-rw-r--   0 bsummers   (503) staff       (20)        5 2023-06-07 19:48:09.000000 tcex-3.0.9/tcex.egg-info/top_level.txt
--rw-rw-r--   0 bsummers   (503) staff       (20)        1 2023-06-07 19:48:09.000000 tcex-3.0.9/tcex.egg-info/zip-safe
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.895238 tcex-4.0.0/
+-rw-rw-r--   0 bsummers   (503) staff       (20)    11357 2023-04-01 00:56:12.000000 tcex-4.0.0/LICENSE
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3078 2023-07-26 23:47:33.894926 tcex-4.0.0/PKG-INFO
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2011 2023-07-26 23:39:14.000000 tcex-4.0.0/README.md
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6522 2023-07-26 23:39:14.000000 tcex-4.0.0/pyproject.toml
+-rw-rw-r--   0 bsummers   (503) staff       (20)       38 2023-07-26 23:47:33.895331 tcex-4.0.0/setup.cfg
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.566178 tcex-4.0.0/tcex/
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1189 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)       77 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/__metadata__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.572811 tcex-4.0.0/tcex/api/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      726 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/api.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.573964 tcex-4.0.0/tcex/api/tc/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2185 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/tc.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.576057 tcex-4.0.0/tcex/api/tc/ti_transform/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      162 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      179 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/formatter.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.577130 tcex-4.0.0/tcex/api/tc/ti_transform/model/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      613 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/model/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7294 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/model/transform_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6246 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/ti_transform.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    25156 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/ti_transform/transform_abc.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.578099 tcex-4.0.0/tcex/api/tc/util/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/util/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    14771 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/util/threat_intel_util.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.579125 tcex-4.0.0/tcex/api/tc/v2/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       94 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/__init__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.585771 tcex-4.0.0/tcex/api/tc/v2/batch/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      311 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2818 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/attribute.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    44913 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/batch.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    18293 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/batch_submit.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    53186 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/batch_writer.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    25062 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/group.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    30344 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/indicator.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1733 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/security_label.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1163 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/batch/tag.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.588067 tcex-4.0.0/tcex/api/tc/v2/datastore/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      121 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/datastore/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7207 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/datastore/cache.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10976 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/datastore/datastore.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.589642 tcex-4.0.0/tcex/api/tc/v2/metric/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       78 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/metric/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6524 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/metric/metric.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.591205 tcex-4.0.0/tcex/api/tc/v2/notification/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       96 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/notification/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3220 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/notification/notification.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.593103 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      114 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/__init__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.598507 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2371 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/filters.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.599600 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3727 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.608764 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8781 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/adversary.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      949 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/attack_pattern.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1621 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/campaign.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      955 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/course_of_action.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4483 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/document.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1113 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/email.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2338 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/event.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2336 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/incident.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      944 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/intrusion_set.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      868 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/malware.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3701 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/report.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1561 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/signature.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      842 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/tactic.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      843 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/threat.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      832 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/tool.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      949 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/vulnerability.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.610303 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10391 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.614525 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2240 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/address.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2110 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/email_address.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7689 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/file.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3204 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/host.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2181 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/url.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    22879 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/mapping.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2223 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/owner.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2929 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/security_label.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2479 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/tag.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1183 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/tags.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8641 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/task.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    15104 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/victim.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    57190 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/tcex_ti_tc_request.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    37126 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/threat_intelligence.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6862 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v2/v2.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.619358 tcex-4.0.0/tcex/api/tc/v3/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/__init__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.624047 tcex-4.0.0/tcex/api/tc/v3/_gen/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9225 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    19154 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3570 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_args_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    19755 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_filter_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    16731 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_model_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    41077 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_object_abc.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.625892 tcex-4.0.0/tcex/api/tc/v3/_gen/model/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      219 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/model/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4773 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/model/_filter_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    14349 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/_gen/model/_property_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.626398 tcex-4.0.0/tcex/api/tc/v3/adversary_assets/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/adversary_assets/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      994 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/api_endpoints.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.628442 tcex-4.0.0/tcex/api/tc/v3/artifact_types/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifact_types/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3186 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifact_types/artifact_type.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4038 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifact_types/artifact_type_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2871 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifact_types/artifact_type_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.631103 tcex-4.0.0/tcex/api/tc/v3/artifacts/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifacts/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7075 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifacts/artifact.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8443 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifacts/artifact_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8720 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/artifacts/artifact_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.634152 tcex-4.0.0/tcex/api/tc/v3/attribute_types/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attribute_types/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3510 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4985 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3145 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.635642 tcex-4.0.0/tcex/api/tc/v3/attributes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attributes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2182 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/attributes/attribute_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.638716 tcex-4.0.0/tcex/api/tc/v3/case_attributes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_attributes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4871 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_attributes/case_attribute.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9497 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_attributes/case_attribute_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4767 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_attributes/case_attribute_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.640232 tcex-4.0.0/tcex/api/tc/v3/case_management/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_management/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    22002 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/case_management/case_management.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.642903 tcex-4.0.0/tcex/api/tc/v3/cases/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/cases/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    13603 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/cases/case.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    23576 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/cases/case_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    12096 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/cases/case_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.643983 tcex-4.0.0/tcex/api/tc/v3/file_actions/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/file_actions/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1690 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/file_actions/file_action_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.644971 tcex-4.0.0/tcex/api/tc/v3/file_occurrences/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/file_occurrences/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1582 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/file_occurrences/file_occurrence_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1713 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/filter_abc.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.647003 tcex-4.0.0/tcex/api/tc/v3/group_attributes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/group_attributes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4898 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/group_attributes/group_attribute.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10290 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/group_attributes/group_attribute_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5205 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/group_attributes/group_attribute_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.648896 tcex-4.0.0/tcex/api/tc/v3/groups/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/groups/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    15892 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/groups/group.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    31396 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/groups/group_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    16794 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/groups/group_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.650776 tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5006 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/indicator_attribute.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10386 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/indicator_attribute_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5325 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/indicator_attribute_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.652555 tcex-4.0.0/tcex/api/tc/v3/indicators/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicators/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    15423 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicators/indicator.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    28915 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicators/indicator_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    17093 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/indicators/indicator_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.654576 tcex-4.0.0/tcex/api/tc/v3/notes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/notes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3500 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/notes/note.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6761 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/notes/note_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5996 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/notes/note_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    12971 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/object_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7716 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/object_collection_abc.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.657317 tcex-4.0.0/tcex/api/tc/v3/security/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1304 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/assignee_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      668 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/assignee_user_group_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      643 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/assignee_user_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.659669 tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2910 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5143 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3422 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.662467 tcex-4.0.0/tcex/api/tc/v3/security/owners/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owners/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2797 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owners/owner.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    18119 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owners/owner_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7344 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/owners/owner_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2262 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/security.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.665415 tcex-4.0.0/tcex/api/tc/v3/security/system_roles/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/system_roles/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2936 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2551 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2599 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2575 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/task_assignee_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.668512 tcex-4.0.0/tcex/api/tc/v3/security/user_groups/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/user_groups/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2910 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2169 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2656 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.671713 tcex-4.0.0/tcex/api/tc/v3/security/users/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/users/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2771 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/users/user.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9703 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/users/user_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1937 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security/users/user_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.674420 tcex-4.0.0/tcex/api/tc/v3/security_labels/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security_labels/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4352 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security_labels/security_label.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8930 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security_labels/security_label_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3038 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/security_labels/security_label_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.677317 tcex-4.0.0/tcex/api/tc/v3/tags/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tags/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4005 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tags/tag.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9676 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tags/tag_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5397 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tags/tag_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.679772 tcex-4.0.0/tcex/api/tc/v3/tasks/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tasks/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6879 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tasks/task.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    14303 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tasks/task_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7371 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tasks/task_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.681240 tcex-4.0.0/tcex/api/tc/v3/threat_intelligence/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/threat_intelligence/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    18524 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/threat_intelligence/threat_intelligence.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.684216 tcex-4.0.0/tcex/api/tc/v3/tql/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tql/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2315 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tql/tql.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      510 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tql/tql_operator.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      245 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/tql/tql_type.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1326 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/v3.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    18514 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/v3_model_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1633 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/v3_types.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.713362 tcex-4.0.0/tcex/api/tc/v3/victim_assets/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_assets/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6065 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7768 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5066 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.716423 tcex-4.0.0/tcex/api/tc/v3/victim_attributes/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_attributes/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4931 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9947 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4808 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.719471 tcex-4.0.0/tcex/api/tc/v3/victims/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victims/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8302 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victims/victim.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    13755 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victims/victim_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6549 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/victims/victim_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.722631 tcex-4.0.0/tcex/api/tc/v3/workflow_events/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_events/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4668 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5713 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5427 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.725735 tcex-4.0.0/tcex/api/tc/v3/workflow_templates/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_templates/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3636 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5477 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5018 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.727354 tcex-4.0.0/tcex/app/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6252 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/app.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.734795 tcex-4.0.0/tcex/app/config/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      331 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    18268 2023-07-26 23:40:09.000000 tcex-4.0.0/tcex/app/config/app_spec_yml.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     9253 2023-07-26 23:40:09.000000 tcex-4.0.0/tcex/app/config/install_json.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6624 2023-07-26 23:40:09.000000 tcex-4.0.0/tcex/app/config/install_json_update.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1558 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/install_json_validate.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1598 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/job_json.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4504 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/layout_json.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.739554 tcex-4.0.0/tcex/app/config/model/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      382 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/model/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    13740 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/model/app_spec_yml_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    30929 2023-07-26 23:40:09.000000 tcex-4.0.0/tcex/app/config/model/install_json_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2942 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/model/job_json_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2921 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/model/layout_json_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1106 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/model/tcex_json_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    24522 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/permutation.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2070 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/config/tcex_json.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2469 2023-07-26 23:40:09.000000 tcex-4.0.0/tcex/app/config/tcex_json_update.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.762132 tcex-4.0.0/tcex/app/decorator/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      437 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2777 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/benchmark.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2039 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/debug.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4858 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/fail_on_output.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3901 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/on_exception.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2241 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/on_success.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3810 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/decorator/output.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.767839 tcex-4.0.0/tcex/app/key_value_store/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      279 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/key_value_store/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      932 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/key_value_store/key_value_abc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2008 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/key_value_store/key_value_api.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1675 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/key_value_store/key_value_mock.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2654 2023-07-26 23:39:48.000000 tcex-4.0.0/tcex/app/key_value_store/key_value_redis.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4137 2023-07-26 23:40:31.000000 tcex-4.0.0/tcex/app/key_value_store/key_value_store.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1860 2023-07-26 23:40:31.000000 tcex-4.0.0/tcex/app/key_value_store/redis_client.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.773847 tcex-4.0.0/tcex/app/playbook/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       83 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/app/playbook/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5956 2023-07-26 23:40:41.000000 tcex-4.0.0/tcex/app/playbook/advanced_request.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3877 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/app/playbook/playbook.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    21692 2023-07-26 23:40:41.000000 tcex-4.0.0/tcex/app/playbook/playbook_create.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      958 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/app/playbook/playbook_delete.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      638 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/app/playbook/playbook_output.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    24162 2023-07-26 23:40:41.000000 tcex-4.0.0/tcex/app/playbook/playbook_read.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.778576 tcex-4.0.0/tcex/app/service/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      406 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    12084 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/api_service.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    15999 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/common_service.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    17206 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/common_service_trigger.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10561 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/mqtt_message_broker.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    15971 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/service/webhook_trigger_service.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.780099 tcex-4.0.0/tcex/app/token/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       75 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/token/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    12649 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/app/token/token.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.782304 tcex-4.0.0/tcex/exit/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      179 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/exit/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5300 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/exit/error_code.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7216 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/exit/exit.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.783689 tcex-4.0.0/tcex/input/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/__init__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.850617 tcex-4.0.0/tcex/input/field_type/
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1930 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2807 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/binary.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2334 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/case_management_entity.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1616 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/choice.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      805 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/datetime.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3707 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/edit_choice.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3228 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/exception.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2435 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/group_entity.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2094 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/indicator_entity.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2847 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/integer.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1666 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/ip_address.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1239 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/key_value.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5635 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/sensitive.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3315 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/string.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1115 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/tc_entity.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     8626 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/field_type/validator.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    19122 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/input.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.866573 tcex-4.0.0/tcex/input/model/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2644 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/advanced_request_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      993 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/aot_execution_enabled_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3019 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/api_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      327 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_api_service_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      163 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_external_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      331 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_feed_api_service_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      252 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_organization_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      328 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_playbook_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      331 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_trigger_service_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      338 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/app_webhook_trigger_service_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1535 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/batch_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      894 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/cal_setting_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      438 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/common_advanced_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      408 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/common_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1605 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/create_config_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1415 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/logging_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2004 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/model_map.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      716 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/module_app_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      439 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/module_requests_session_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      380 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/organization_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1097 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/path_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1411 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/playbook_common_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      833 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/playbook_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1279 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/proxy_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2666 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/service_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1173 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/input/model/smtp_setting_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.871316 tcex-4.0.0/tcex/logger/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3925 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/api_handler.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      893 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/cache_handler.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10370 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/logger.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1934 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/rotating_file_handler_custom.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      969 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/sensitive_filter.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1043 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/logger/trace_logger.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.876114 tcex-4.0.0/tcex/pleb/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      936 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/cached_property.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1647 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/env_path.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      817 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/event.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      758 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/exception_thread.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      285 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/none_model.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1372 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/proxies.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2749 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/scoped_property.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      418 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/pleb/singleton.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7125 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/registry.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.878096 tcex-4.0.0/tcex/requests_external/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      231 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/requests_external/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    13043 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/requests_external/external_session.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5002 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/requests_external/rate_limit_handler.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1866 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/requests_external/requests_external.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.879607 tcex-4.0.0/tcex/requests_tc/
+-rw-rw-r--   0 bsummers   (503) staff       (20)      137 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/__init__.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.883025 tcex-4.0.0/tcex/requests_tc/auth/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/auth/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1606 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/auth/hmac_auth.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1449 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/auth/tc_auth.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1414 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/auth/token_auth.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3416 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/requests_tc.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4417 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/requests_tc/tc_session.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     6432 2023-07-26 23:39:14.000000 tcex-4.0.0/tcex/tcex.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.890599 tcex-4.0.0/tcex/util/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       71 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1827 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/aes_operation.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4044 2023-07-26 23:41:04.000000 tcex-4.0.0/tcex/util/code_operation.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)    10014 2023-07-26 23:41:04.000000 tcex-4.0.0/tcex/util/datetime_operation.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7162 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/file_operation.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.892045 tcex-4.0.0/tcex/util/model/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/model/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      668 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/model/playbook_variable_model.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.894413 tcex-4.0.0/tcex/util/render/
+-rw-rw-r--   0 bsummers   (503) staff       (20)       28 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/render/__init__.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)      455 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/render/render.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     4672 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/render/render_panel.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1243 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/render/render_prompt.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     1855 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/render/render_table.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     5807 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/requests_to_curl.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7034 2023-07-26 23:41:04.000000 tcex-4.0.0/tcex/util/string_operation.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     2856 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/util.py
+-rw-rw-r--   0 bsummers   (503) staff       (20)     7699 2023-07-26 23:39:49.000000 tcex-4.0.0/tcex/util/variable.py
+drwxrwxr-x   0 bsummers   (503) staff       (20)        0 2023-07-26 23:47:33.571573 tcex-4.0.0/tcex.egg-info/
+-rw-rw-r--   0 bsummers   (503) staff       (20)     3078 2023-07-26 23:47:33.000000 tcex-4.0.0/tcex.egg-info/PKG-INFO
+-rw-rw-r--   0 bsummers   (503) staff       (20)    14220 2023-07-26 23:47:33.000000 tcex-4.0.0/tcex.egg-info/SOURCES.txt
+-rw-rw-r--   0 bsummers   (503) staff       (20)        1 2023-07-26 23:47:33.000000 tcex-4.0.0/tcex.egg-info/dependency_links.txt
+-rw-rw-r--   0 bsummers   (503) staff       (20)      290 2023-07-26 23:47:33.000000 tcex-4.0.0/tcex.egg-info/requires.txt
+-rw-rw-r--   0 bsummers   (503) staff       (20)       10 2023-07-26 23:47:33.000000 tcex-4.0.0/tcex.egg-info/top_level.txt
```

### Comparing `tcex-3.0.9/LICENSE` & `tcex-4.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `tcex-3.0.9/PKG-INFO` & `tcex-4.0.0/README.md`

 * *Files 24% similar despite different names*

```diff
@@ -1,95 +1,58 @@
-Metadata-Version: 2.1
-Name: tcex
-Version: 3.0.9
-Summary: ThreatConnect Exchange App Framework
-Home-page: https://github.com/ThreatConnect-Inc/tcex
-Download-URL: https://github.com/ThreatConnect-Inc/tcex/tarball/3.0.9
-Author: ThreatConnect (support@threatconnect.com)
-Author-email: support@threatconnect.com
-License: Apache License, Version 2
-Project-URL: Documentation, https://github.com/ThreatConnect-Inc/tcex
-Project-URL: Source, https://github.com/ThreatConnect-Inc/tcex
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: Natural Language :: English
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Operating System :: OS Independent
-Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: Implementation :: CPython
-Classifier: Programming Language :: Python :: Implementation :: PyPy
-Classifier: Topic :: Security
-Requires-Python: >=3.6
-Description-Content-Type: text/markdown
-Provides-Extra: dev
-Provides-Extra: develop
-Provides-Extra: development
-License-File: LICENSE
-
 # tcex - ThreatConnect Exchange App Framework
 
 The ThreatConnect&trade; TcEx App Framework provides functionality for writing ThreatConnect Exchange Apps.
 
 ## Requirements
 
  * arrow (https://pypi.python.org/pypi/arrow)
- * backports.cached-property (https://pypi.org/project/backports.cached-property/)
- * colorama (https://pypi.python.org/pypi/colorama)
- * future (https://pypi.org/project/future/)
+ * black (https://pypi.org/project/black/)
  * inflect (https://pypi.python.org/pypi/inflect)
+ * isort (https://pypi.org/project/isort/)
  * jmespath (https://pypi.org/project/jmespath/)
  * paho-mqtt (https://pypi.org/project/paho-mqtt/)
  * pyaes (https://pypi.org/project/pyaes/)
  * pydantic (https://pypi.org/project/pydantic/)
  * python-dateutil (https://pypi.python.org/pypi/python-dateutil)
+ * pyyaml (https://pypi.python.org/pypi/pyyaml)
  * redis (https://pypi.python.org/pypi/redis)
- * requests (http://docs.python-requests.org/en/latest)
+ * requests (https://pypi.python.org/pypi/requests)
+ * rich (https://pypi.python.org/pypi/rich)
  * semantic_version (https://pypi.org/project/semantic-version/)
- * stdlib-list (https://pypi.org/project/stdlib-list/)
- * tinydb (https://pypi.python.org/pypi/tinydb)
- * typer (https://pypi.python.org/pypi/typer)
  * wrapt (https://pypi.org/project/wrapt/)
 
 ### Development Requirements
 
  * bandit (https://pypi.org/project/bandit/)
- * black (https://pypi.org/project/black/)
- * codespell (https://pypi.org/project/codespell/)
  * deepdiff (https://pypi.org/project/deepdiff/)
- * flake8 (https://pypi.org/project/flake8/)
- * isort (https://pypi.org/project/isort/)
- * mako (https://pypi.org/project/mako/)
+ * fakeredis (https://pypi.org/project/fakeredis/)
  * pre-commit (https://pypi.org/project/pre-commit/)
  * pydocstyle (https://pypi.org/project/pydocstyle/)
  * pylint (https://pypi.org/project/pylint/)
+ * pyright (https://pypi.org/project/pyright/)
+ * pyupgrade (https://pypi.org/project/pyupgrade/)
+ * typer (https://pypi.python.org/pypi/typer)
+
+### Test Requirements
+
  * pytest (https://pypi.org/project/pytest/)
  * pytest-cov (https://pypi.org/project/pytest-cov/)
  * pytest-html (https://pypi.org/project/pytest-html/)
+ * pytest-ordering (https://pypi.org/project/pytest-ordering/)
  * pytest-xdist (https://pypi.org/project/pytest-xdist/)
- * pyupgrade (https://pypi.org/project/pyupgrade/)
 
 ## Installation
 
-**Using pip**
-
 ```
 pip install tcex
-pip install tcex[development]
 ```
 
-**Manually**
+### Development / Testing
 
-```
-cd tcex
-python setup.py install --force
-```
+pip install tcex[dev,test]
 
 ## Documentation
 
 https://threatconnect.readme.io/docs/overview
 
 ## Release Notes
```

### Comparing `tcex-3.0.9/tcex/api/api.py` & `tcex-4.0.0/tcex/api/api.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,33 +1,27 @@
-"""API"""
-# standard library
-from typing import TYPE_CHECKING
+"""TcEx Framework Module"""
+# third-party
+from requests import Session  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc import TC
-from tcex.backports import cached_property
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
-
-    # first-party
-    from tcex.input.input import Input
+from tcex.api.tc.tc import TC
+from tcex.input.input import Input  # TYPE-CHECKING
+from tcex.pleb.cached_property import cached_property
 
 
 class API:
     """API
 
     Args:
         inputs: An instance of the Input class.
         session_tc: An configured instance of request.Session with TC API Auth.
     """
 
-    def __init__(self, inputs: 'Input', session_tc: 'Session'):
-        """Initialize Class properties."""
+    def __init__(self, inputs: Input, session_tc: Session):
+        """Initialize instance properties."""
         self.inputs = inputs
         self.session_tc = session_tc
 
     @cached_property
-    def tc(self) -> 'TC':
+    def tc(self) -> TC:
         """Return a case management instance."""
         return TC(self.inputs, self.session_tc)
```

### Comparing `tcex-3.0.9/tcex/api/tc/tc.py` & `tcex-4.0.0/tcex/api/tc/tc.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,67 +1,67 @@
-"""API -> TC"""
-# standard library
-from typing import TYPE_CHECKING, Dict, List, Union
+"""TcEx Framework Module"""
+# third-party
+from requests import Session  # TYPE-CHECKING
 
 # first-party
 from tcex.api.tc.ti_transform import TiTransform, TiTransforms
 from tcex.api.tc.ti_transform.model import GroupTransformModel, IndicatorTransformModel
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
 from tcex.api.tc.v2.v2 import V2
 from tcex.api.tc.v3.v3 import V3
-from tcex.backports import cached_property
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
-
-    # first-party
-    from tcex.input.input import Input
+from tcex.input.input import Input  # TYPE-CHECKING
+from tcex.pleb.cached_property import cached_property
 
 
 class TC:
     """API -> TC
 
     Args:
         inputs: An instance of the Input class.
         session_tc: An configured instance of request.Session with TC API Auth.
     """
 
-    def __init__(self, inputs: 'Input', session_tc: 'Session'):
-        """Initialize Class properties."""
+    def __init__(self, inputs: Input, session_tc: Session):
+        """Initialize instance properties."""
         self.inputs = inputs
         self.session_tc = session_tc
 
     @staticmethod
-    def group_transform(transform: Dict) -> 'GroupTransformModel':
+    def group_transform(transform: dict) -> GroupTransformModel:
         """Return a group transform model."""
         return GroupTransformModel(**transform)
 
     @staticmethod
-    def indicator_transform(transform: Dict) -> 'IndicatorTransformModel':
+    def indicator_transform(transform: dict) -> IndicatorTransformModel:
         """Return a indicator transform model."""
         return IndicatorTransformModel(**transform)
 
     @staticmethod
     def ti_transform(
         ti_dict: dict,
-        transforms: List[Union['GroupTransformModel', 'IndicatorTransformModel']],
-    ) -> 'TiTransform':
+        transforms: list[GroupTransformModel | IndicatorTransformModel],
+    ) -> TiTransform:
         """Return an instance of TI Transform class."""
         return TiTransform(ti_dict, transforms)
 
     @staticmethod
     def ti_transforms(
-        ti_dict: List[dict],
-        transforms: List[Union['GroupTransformModel', 'IndicatorTransformModel']],
-    ) -> 'TiTransform':
+        ti_dict: list[dict],
+        transforms: list[GroupTransformModel | IndicatorTransformModel],
+    ) -> TiTransforms:
         """Return an instance of TI Transforms class."""
         return TiTransforms(ti_dict, transforms)
 
     @cached_property
-    def v2(self) -> 'V2':
+    def utils(self) -> ThreatIntelUtil:
+        """Return an instance of TI Transform class."""
+        return ThreatIntelUtil(self.session_tc)
+
+    @cached_property
+    def v2(self) -> V2:
         """Return a case management instance."""
         return V2(self.inputs, self.session_tc)
 
     @cached_property
-    def v3(self) -> 'V3':
+    def v3(self) -> V3:
         """Return a case management instance."""
         return V3(self.session_tc)
```

### Comparing `tcex-3.0.9/tcex/api/tc/ti_transform/ti_transform.py` & `tcex-4.0.0/tcex/api/tc/ti_transform/ti_transform.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-"""Threat Intelligence Transform Module"""
+"""TcEx Framework Module"""
 # standard library
-import traceback
 from datetime import datetime
-from typing import Optional
 
 # first-party
 from tcex.api.tc.ti_transform.model import GroupTransformModel, IndicatorTransformModel
 from tcex.api.tc.ti_transform.transform_abc import TransformABC, TransformsABC
 
 
 class TiTransforms(TransformsABC):
     """Mappings"""
 
     def process(self):
         """Process the mapping."""
-        self.transformed_collection = []
+        self.transformed_collection: list[TiTransform] = []
         for ti_dict in self.ti_dicts:
             self.transformed_collection.append(TiTransform(ti_dict, self.transforms))
 
     @property
     def batch(self) -> dict:
         """Return the data in batch format."""
         self.process()
@@ -31,18 +29,16 @@
         for index, t in enumerate(self.transformed_collection):
             if index and index % 1_000 == 0:
                 self.log.trace(f'feature=ti-transform-batch, items={index}')
 
             # batch must be called so that the transform type is selected
             try:
                 data = t.batch
-            except Exception as ex:
-                # LOG WARNING
-                print(f'feature=ti-transforms, event=transform-error, error="{ex}"')
-                self.log.error(traceback.format_exc())
+            except Exception:
+                self.log.exception('feature=ti-transforms, event=transform-error')
                 continue
 
             # now that batch is called we can identify the ti type
             if isinstance(t.transform, GroupTransformModel):
                 batch['group'].append(data)
             elif isinstance(t.transform, IndicatorTransformModel):
                 batch['indicator'].append(data)
@@ -71,20 +67,20 @@
             associated_group = {'groupXid': group_xid}
             self.transformed_item.setdefault('associatedGroups', []).append(associated_group)
 
     def add_attribute(
         self,
         type_: str,
         value: str,
-        displayed: Optional[bool] = False,
-        source: Optional[str] = None,
+        displayed: bool = False,
+        source: str | None = None,
     ):
         """Add an attribute to the transformed item."""
         if type_ is not None and value is not None:
-            attribute_data = {
+            attribute_data: dict[str, bool | str] = {
                 'type': type_,
                 'value': value,
             }
 
             # displayed is a special case, it only needs to be added if True
             if displayed is True:
                 attribute_data['displayed'] = displayed
@@ -93,32 +89,32 @@
             if source is not None:
                 attribute_data['source'] = source
 
             self.transformed_item.setdefault('attribute', []).append(attribute_data)
 
     def add_file_occurrence(
         self,
-        file_name: Optional[str] = None,
-        path: Optional[str] = None,
-        date: Optional[datetime] = None,
+        file_name: str | None = None,
+        path: str | None = None,
+        date: datetime | None = None,
     ):
         """Abstract method"""
         self.transformed_item.setdefault('fileOccurrence', []).append(
             {
                 k: v
                 for k, v in {
                     'fileName': file_name,
                     'path': path,
                     'date': date,
                 }.items()
                 if v
             }
         )
 
-    def add_confidence(self, confidence: Optional[int]):
+    def add_confidence(self, confidence: int | str | None):
         """Add a rating to the transformed item."""
         if confidence is not None:
             self.transformed_item['confidence'] = int(confidence)
 
     def add_group(self, group_data: dict):
         """Add a group to the transforms.
 
@@ -136,40 +132,40 @@
         self.adhoc_indicators.append(indicator_data)
 
     def add_metadata(self, key: str, value: str):
         """Add name to the transformed item."""
         if all([key, value]):
             self.transformed_item[key] = value
 
-    def add_name(self, name: Optional[str]):
+    def add_name(self, name: str | None):
         """Add name to the transformed item."""
         if name is not None:
             self.transformed_item['name'] = name
 
-    def add_rating(self, rating: Optional[int]):
+    def add_rating(self, rating: float | int | str | None):
         """Add a rating to the transformed item."""
         if rating is not None:
             self.transformed_item['rating'] = float(rating)
 
     def add_security_label(
-        self, name: str, color: Optional[str] = None, description: Optional[str] = None
+        self, name: str, color: str | None = None, description: str | None = None
     ):
         """Add a tag to the transformed item."""
         if name is not None:
             label_data = {'name': name}
 
             if color is not None:
                 label_data['color'] = color
 
             if description is not None:
                 label_data['description'] = description
 
             self.transformed_item.setdefault('securityLabel', []).append(label_data)
 
-    def add_summary(self, value: Optional[str]):
+    def add_summary(self, value: str | None):
         """Add value1 to the transformed item."""
         if value is not None:
             self.transformed_item['summary'] = value
 
     def add_tag(self, name: str):
         """Add a tag to the transformed item."""
         if name is not None:
```

### Comparing `tcex-3.0.9/tcex/api/tc/ti_transform/transform_abc.py` & `tcex-4.0.0/tcex/api/tc/ti_transform/transform_abc.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,151 +1,135 @@
-"""Transform Abstract Base Class"""
+"""TcEx Framework Module"""
 # standard library
 import collections
 import logging
 from abc import ABC, abstractmethod
+from collections.abc import Callable
 from datetime import datetime
 from inspect import signature
-from typing import TYPE_CHECKING, Callable, List, Optional, Union
+from typing import Any
 
 # third-party
 import jmespath
 from jmespath import functions
-from pydantic import ValidationError
 
 # first-party
+from tcex.api.tc.ti_transform.model import AttributeTransformModel  # TYPE-CHECKING
+from tcex.api.tc.ti_transform.model import SecurityLabelTransformModel  # TYPE-CHECKING
+from tcex.api.tc.ti_transform.model import TagTransformModel  # TYPE-CHECKING
 from tcex.api.tc.ti_transform.model import (
     GroupTransformModel,
     IndicatorTransformModel,
     MetadataTransformModel,
 )
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.api.tc.ti_transform.model import (
-        AttributeTransformModel,
-        SecurityLabelTransformModel,
-        TagTransformModel,
-    )
+from tcex.api.tc.ti_transform.model.transform_model import (
+    AssociatedGroupTransform,
+    DatetimeTransformModel,
+    FileOccurrenceTransformModel,
+)
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class TcFunctions(functions.Functions):
     """ThreatConnect custom jmespath functions."""
 
     @functions.signature({'types': ['array']}, {'types': ['string']})
-    def _func_null_leaf(self, arr, search):  # pylint: disable=no-self-use
-        """Return value in array even if they are null.
-
-        Arguments:
-            arr (list) - a list of objects (dict).
-            search (string) - the dict key to retrieve.
-
-        Returns:
-            list - A list of results, including null values.
-
-        """
+    def _func_null_leaf(self, arr: list, search: str) -> list:
+        """Return value in array even if they are null."""
         return [a.get(search) for a in arr]
 
     @functions.signature({'types': ['array']}, {'types': ['string']})
-    def _func_delete(self, arr, search):  # pylint: disable=no-self-use
-        """Return array after popping value at address out.
-
-        Arguments:
-            arr (list) - a list of objects (dict).
-            search (string) - the dict key to delete.
-
-        Returns:
-            list - The provided arr with the keys removed
-
-        """
+    def _func_delete(self, arr: list, search: str) -> list:
+        """Return array after popping value at address out."""
         for a in arr:
             try:
                 a.pop(search)
             except Exception:
-                print('Skipping delete, field not found.')
+                _logger.debug('Skipping delete, field not found.')
         return arr
 
 
 class TransformsABC(ABC):
     """Transform Abstract Base Class"""
 
     def __init__(
         self,
-        ti_dicts: List[dict],
-        transforms: List[Union['GroupTransformModel', 'IndicatorTransformModel']],
+        ti_dicts: list[dict],
+        transforms: list[GroupTransformModel | IndicatorTransformModel],
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.ti_dicts = ti_dicts
-        self.transforms = transforms if isinstance(transforms, list) else [transforms]
+        self.transforms = transforms
 
         # properties
-        self.log = logger
-        self.transformed_collection: List['TransformABC'] = []
+        self.log = _logger
+        self.transformed_collection: list[TransformABC] = []
 
         # validate transforms
         self._validate_transforms()
 
     def _validate_transforms(self):
         """Validate the transform model."""
         if len(self.transforms) > 1:
             for transform in self.transforms:
                 if transform.applies is None:
-                    raise ValidationError(
+                    raise ValueError(
                         'If more than one transform is provided, each '
                         'provided transform must provide an apply field.',
-                        None,
                     )
 
 
 class TransformABC(ABC):
     """Transform Abstract Base Class"""
 
     def __init__(
         self,
         ti_dict: dict,
-        transforms: List[Union['GroupTransformModel', 'IndicatorTransformModel']],
+        transforms: list[GroupTransformModel | IndicatorTransformModel],
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.ti_dict = ti_dict
         self.transforms = transforms if isinstance(transforms, list) else [transforms]
 
         # properties
-        self.adhoc_groups: List[dict] = []
-        self.adhoc_indicators: List[dict] = []
-        self.log = logger
+        self.adhoc_groups: list[dict] = []
+        self.adhoc_indicators: list[dict] = []
+        self.log = _logger
         # the current active transform
-        self.transform: Union['GroupTransformModel', 'IndicatorTransformModel'] = None
+        self.transform: GroupTransformModel | IndicatorTransformModel
         self.transformed_item = {}
-        self.utils = Utils()
+        self.util = Util()
         self.jmespath_options = jmespath.Options(
             custom_functions=TcFunctions(), dict_cls=collections.OrderedDict
         )
 
         # validate transforms
         self._validate_transforms()
 
     @staticmethod
-    def _always_array(value: Union[str, list]) -> list:
+    def _always_array(value: str | list | None) -> list:
         """Ensure value is always an array."""
-        if not isinstance(value, list):
+        if value is None:
+            value = []
+        elif not isinstance(value, list):
             value = [value]
         return value
 
     @staticmethod
     def _build_summary(
-        val1: Optional[str] = None, val2: Optional[str] = None, val3: Optional[str] = None
+        val1: str | None = None, val2: str | None = None, val3: str | None = None
     ) -> str:
         """Build the Indicator summary using available values."""
         return ' : '.join([value for value in [val1, val2, val3] if value is not None])
 
-    def _path_search(self, path: str) -> any:
+    def _path_search(self, path: str) -> Any:
         """Return the value of the provided path.
 
         Path can return any type of data from the TI dict.
         """
         if path is not None:
             value = jmespath.search(path, self.ti_dict, options=self.jmespath_options)
             # self.log.trace(f'feature=transform, action=path-search, path={path}, value={value}')
@@ -177,56 +161,53 @@
 
         # last modified
         self._process_metadata_datetime('lastModified', self.transform.last_modified)
 
         # xid
         self._process_metadata('xid', self.transform.xid)
 
-    def _process_associated_group(self, associations: List['AttributeTransformModel']):
+    def _process_associated_group(self, associations: list[AssociatedGroupTransform]):
         """Process Attribute data"""
         for association in associations or []:
             for value in filter(bool, self._process_metadata_transform_model(association.value)):
-                self.add_associated_group(value)
+                self.add_associated_group(value)  # type: ignore
 
     def _process_metadata_transform_model(
-        self, value: Union['MetadataTransformModel', str], expected_length: Optional[int] = None
-    ) -> List:
+        self, value: bool | MetadataTransformModel | str | None, expected_length: int | None = None
+    ) -> list:
         """Process fields that can be static values or a MetadataTransformModel.
 
         If value is not a MetadataTransformModel (i.e., it's a static value), and expected_length
         is given, "spread" the static value into an array of expected_length length.
 
         """
+        if value is None:
+            if expected_length:
+                return [value] * expected_length
+            return []
+
         if isinstance(value, MetadataTransformModel):
             transformed_value = self._transform_values(value)
 
             if expected_length is not None and len(transformed_value) != expected_length:
                 raise RuntimeError(
                     f'Expected transform value of length {expected_length} for {value}, '
                     f'but length was {len(transformed_value)}'
                 )
 
-            # self.log.trace(
-            #     'feature=transform, action=process-metadata-transform-model, '
-            #     f'value-path={value.path}, transformed-value={transformed_value}'
-            # )
             return transformed_value
 
         if expected_length is not None:
             transformed_value = [value] * expected_length
         else:
             transformed_value = [value]
 
-        # self.log.trace(
-        #     'feature=transform, action=process-metadata-transform-data, '
-        #     f'value={value}, transformed-value={transformed_value}'
-        # )
         return transformed_value
 
-    def _process_attributes(self, attributes: List['AttributeTransformModel']):
+    def _process_attributes(self, attributes: list[AttributeTransformModel]):
         """Process Attribute data"""
         for attribute in attributes or []:
             values = self._process_metadata_transform_model(attribute.value)
             if not values:
                 # self.log.info(f'No values found for attribute transform {attribute.dict()}')
                 continue
 
@@ -234,15 +215,15 @@
             source = self._process_metadata_transform_model(attribute.source, len(values))
             displayed = self._process_metadata_transform_model(attribute.displayed, len(values))
 
             param_keys = ['type_', 'value', 'displayed', 'source']
             params = [dict(zip(param_keys, p)) for p in zip(types, values, displayed, source)]
 
             for param in params:
-                param = self.utils.remove_none(param)
+                param = self.util.remove_none(param)
                 if 'value' not in param:
                     continue
 
                 if 'type_' not in param:
                     self.log.warning(
                         'feature=transform, action=process-attribute, '
                         f'transform={attribute.dict(exclude_unset=True)}, error=no-type'
@@ -255,15 +236,15 @@
                     self.add_attribute(**param)
                 except Exception:
                     self.log.exception(
                         'feature=transform, action=process-attribute, '
                         f'transform={attribute.dict(exclude_unset=True)}'
                     )
 
-    def _process_file_occurrences(self, file_occurrences: List['MetadataTransformModel']):
+    def _process_file_occurrences(self, file_occurrences: list[FileOccurrenceTransformModel]):
         """Process File Occurrences data.
 
         File Occurrences are a bit weird, in that none of the fields are required.  Because of this,
         There may be results where all of the fields are None, in which case we'll skip that result
         and not call add_file_occurrence.
         """
         for file_occurrence in file_occurrences or []:
@@ -287,38 +268,38 @@
             path = self._process_metadata_transform_model(file_occurrence.path, expected_length)
             date = self._process_metadata_transform_model(file_occurrence.date, expected_length)
 
             param_keys = ['file_name', 'path', 'date']
             params = [dict(zip(param_keys, p)) for p in zip(file_name, path, date)]
 
             for kwargs in filter(bool, params):  # get rid of empty dicts
-                self.add_file_occurrence(**self.utils.remove_none(kwargs))
+                self.add_file_occurrence(**self.util.remove_none(kwargs))
 
-    def _process_confidence(self, metadata: 'MetadataTransformModel'):
+    def _process_confidence(self, metadata: MetadataTransformModel | None):
         """Process standard metadata fields."""
         self.add_confidence(self._transform_value(metadata))
 
     def _process_group(self):
         """Process Group Specific data."""
+        if not isinstance(self.transform, GroupTransformModel):
+            return
+
         self._process_name()
 
         if self.transformed_item['type'] == 'Campaign':
-            self._process_metadata('firstSeen', self.transform.first_seen)
+            self._process_metadata_datetime('firstSeen', self.transform.first_seen)
 
         if self.transformed_item['type'] == 'Document':
             self._process_metadata('fileName', self.transform.file_name)
             self._process_metadata('malware', self.transform.malware)
-            self._process_metadata('password', self.transform.confidence)
+            self._process_metadata('password', self.transform.password)
 
         if self.transformed_item['type'] == 'Email':
             self._process_metadata('from', self.transform.from_addr)
             self._process_metadata('to', self.transform.to_addr)
-            self._process_metadata('subject', self.transform.subject)
-            self._process_metadata('body', self.transform.body)
-            self._process_metadata('header', self.transform.header)
 
         if self.transformed_item['type'] in ('Event', 'Incident'):
             self._process_metadata_datetime('eventDate', self.transform.event_date)
             self._process_metadata('status', self.transform.status)
 
         if self.transformed_item['type'] == 'Report':
             self._process_metadata('fileName', self.transform.file_name)
@@ -328,14 +309,17 @@
         if self.transformed_item['type'] == 'Signature':
             self._process_metadata('fileName', self.transform.file_name)
             self._process_metadata('fileType', self.transform.file_type)
             self._process_metadata('fileText', self.transform.file_text)
 
     def _process_indicator(self):
         """Process Indicator Specific data."""
+        if not isinstance(self.transform, IndicatorTransformModel):
+            return
+
         # handle the 3 possible indicator fields
         self._process_indicator_values()
 
         if self.transform.active:
             self._process_metadata('active', self.transform.active)
 
         self._process_confidence(self.transform.confidence)
@@ -346,57 +330,63 @@
             self._process_file_occurrences(self.transform.file_occurrences or [])
 
         if self.transformed_item['type'] == 'Host':
             self._process_metadata('dnsActive', self.transform.dns_active)
             self._process_metadata('whoisActive', self.transform.whois_active)
 
     def _process_indicator_values(self):
+        """Process Indicator value."""
+        if not isinstance(self.transform, IndicatorTransformModel):
+            return
+
         value1 = self._transform_value(self.transform.value1)
         value2 = self._transform_value(self.transform.value2)
         value3 = self._transform_value(self.transform.value3)
 
         if not any([value1, value2, value3]):
             self.log.error(
                 'feature=ti-transform, event=process-indicators, message=no-indicator-value-found, '
-                f'path-value1={self.transform.value1.path}'
-                f'path-value2={self.transform.value2.path}'
-                f'path-value3={self.transform.value3.path}'
+                f'path-value1={value1}, path-value2={value2}, path-value3={value3}'
             )
             raise RuntimeError('At least one indicator value must be provided.')
 
         self.add_summary(self._build_summary(value1, value2, value3))
 
     def _process_name(self):
+        """Process Group Name data."""
+        if not isinstance(self.transform, GroupTransformModel):
+            return
+
         name = self._transform_value(self.transform.name)
 
         if name is None:
             self.log.error(
                 'feature=ti-transform, event=process-group-name, message=no-name-found, '
                 f'path={self.transform.name.path}'
             )
             raise RuntimeError('At least one indicator value must be provided.')
 
         self.add_name(name)
 
-    def _process_metadata(self, key, metadata: 'MetadataTransformModel'):
+    def _process_metadata(self, key: str, metadata: MetadataTransformModel | None):
         """Process standard metadata fields."""
         value = self._transform_value(metadata)
         if value is not None:
             self.add_metadata(key, value)
 
-    def _process_metadata_datetime(self, key, metadata: List['MetadataTransformModel']):
+    def _process_metadata_datetime(self, key: str, metadata: DatetimeTransformModel | None):
         """Process metadata fields that should be a TC datetime."""
-        if metadata is not None:
+        if metadata is not None and metadata.path is not None:
             value = self._path_search(metadata.path)
             if value is not None:
                 self.add_metadata(
-                    key, self.utils.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
+                    key, self.util.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
                 )
 
-    def _process_security_labels(self, labels: List['SecurityLabelTransformModel']):
+    def _process_security_labels(self, labels: list[SecurityLabelTransformModel]):
         """Process Tag data"""
         for label in labels or []:
             names = self._process_metadata_transform_model(label.value)
             if not names:
                 # self.log.info(f'No values found for security label transform {label.dict()}')
                 continue
 
@@ -405,28 +395,28 @@
             )
             colors = self._process_metadata_transform_model(label.color, expected_length=len(names))
 
             param_keys = ['color', 'description', 'name']
             params = [dict(zip(param_keys, p)) for p in zip(colors, descriptions, names)]
 
             for kwargs in params:
-                kwargs = self.utils.remove_none(kwargs)
+                kwargs = self.util.remove_none(kwargs)
                 if 'name' not in kwargs:
                     continue
                 # strip out None params so that required params are enforced and optional
                 # params with default values are respected.
-                self.add_security_label(**kwargs)
+                self.add_security_label(**self.util.remove_none(kwargs))
 
-    def _process_tags(self, tags: List['TagTransformModel']):
+    def _process_tags(self, tags: list[TagTransformModel]):
         """Process Tag data"""
         for tag in tags or []:
             for value in filter(bool, self._process_metadata_transform_model(tag.value)):
-                self.add_tag(name=value)
+                self.add_tag(name=value)  # type: ignore
 
-    def _process_rating(self, metadata: 'MetadataTransformModel'):
+    def _process_rating(self, metadata: MetadataTransformModel | None):
         """Process standard metadata fields."""
         self.add_rating(self._transform_value(metadata))
 
     def _process_type(self):
         """Process standard metadata fields."""
         _type = self._transform_value(self.transform.type)
         if _type is not None:
@@ -443,15 +433,15 @@
         for transform in self.transforms:
             if transform.applies is None or transform.applies(self.ti_dict) is True:
                 self.transform = transform
                 break
         else:
             raise RuntimeError('No transform found for TI data')
 
-    def _transform_value(self, metadata: Optional['MetadataTransformModel']) -> Optional[str]:
+    def _transform_value(self, metadata: MetadataTransformModel | None) -> str | None:
         """Pass value to series transforms."""
         # not all fields are required
         if metadata is None:
             return None
 
         # not all metadata fields have a path, but they must have a path or default
         if metadata.path is None:
@@ -462,33 +452,34 @@
 
         # return default if value of None is returned from Path
         # IMPORTANT: a value of None passed to the transform may cause a failure (lambda x.lower())
         if value is None:
             return metadata.default
 
         for t in metadata.transform or []:
-            # pass value to static_map or callable, but never both
-            if t.filter_map is not None:
-                value = self._transform_value_map(value, t.filter_map, True)
-            elif t.static_map is not None:
-                value = self._transform_value_map(value, t.static_map)
-            elif callable(t.method):
-                value = self._transform_value_callable(value, t.method, t.kwargs)
+            if isinstance(value, str):
+                # pass value to static_map or callable, but never both
+                if t.filter_map is not None:
+                    value = self._transform_value_map(value, t.filter_map, True)
+                elif t.static_map is not None:
+                    value = self._transform_value_map(value, t.static_map)
+                elif callable(t.method):
+                    value = self._transform_value_callable(value, t.method, t.kwargs)
 
         # ensure only a string value or None is returned (set to default if required)
         if value is None:
             value = metadata.default
         elif not isinstance(value, str):
             value = str(value)
 
         return value
 
     def _transform_value_callable(
-        self, value: Union[dict, list, str], c: Callable, kwargs=None
-    ) -> Union[Optional[str], Optional[List[str]]]:
+        self, value: dict | list | str, c: Callable, kwargs=None
+    ) -> str | None | list[str] | None:
         """Transform values in the TI data."""
         # find signature of method and call with correct args
         kwargs = kwargs or {}
         try:
             sig = signature(c, follow_wrapped=True)
             if 'ti_dict' in sig.parameters:
                 kwargs.update({'ti_dict': self.ti_dict})
@@ -509,21 +500,22 @@
         else:
             self.log.warning(
                 f'''feature=ti-transform, action=transform-value, '''
                 f'''message='static-map-requires-str-value", value={value}'''
             )
         return value
 
-    def _transform_values(self, metadata: Optional['MetadataTransformModel']) -> List[str]:
+    def _transform_values(self, metadata: MetadataTransformModel | None) -> list[str]:
         """Pass value to series transforms."""
 
-        def _default() -> str:
+        def _default() -> list:
             """Return default value (as list) if exists, else empty list."""
-            if metadata.default is None:
+            if metadata is None or metadata.default is None:
                 return []
+
             return self._always_array(metadata.default)
 
         # not all items have all metadata fields
         if metadata is None:
             # self.log.trace('feature=transform, action=transform-values, metadata=None')
             return []
 
@@ -558,15 +550,16 @@
                 # when path search returns an array of values, each value is mapped
                 _values = []
                 for v in self._always_array(value):
                     v = self._transform_value_map(v, t.static_map)
                     if v is not None:
                         _values.append(v)
                 value = _values
-            elif callable(t.method):
+            # PYRIGHT-MISS - None check for value already performed above
+            elif callable(t.method) and value is not None:
                 value = self._transform_value_callable(value, t.method, t.kwargs)
             elif callable(t.for_each):
                 value = [
                     self._transform_value_callable(v, t.for_each, t.kwargs) if v is not None else v
                     for v in self._always_array(value)
                 ]
 
@@ -585,65 +578,64 @@
         return _value
 
     def _validate_transforms(self):
         """Validate the transform model."""
         if len(self.transforms) > 1:
             for transform in self.transforms:
                 if transform.applies is None:
-                    raise ValidationError(
+                    raise ValueError(
                         'If more than one transform is provided, each '
                         'provided transform must provide an apply field.',
-                        None,
                     )
 
     @abstractmethod
     def add_associated_group(self, group_xid: str):
         """Abstract method"""
 
     @abstractmethod
     def add_attribute(
         self,
         type_: str,
         value: str,
-        displayed: Optional[bool] = False,
-        source: Optional[str] = None,
+        displayed: bool = False,
+        source: str | None = None,
     ):
         """Abstract method"""
 
     @abstractmethod
     def add_file_occurrence(
         self,
-        file_name: Optional[str] = None,
-        path: Optional[str] = None,
-        date: Optional[datetime] = None,
+        file_name: str | None = None,
+        path: str | None = None,
+        date: datetime | None = None,
     ):
         """Abstract method"""
 
     @abstractmethod
-    def add_confidence(self, confidence: Optional[int]):
+    def add_confidence(self, confidence: int | str | None):
         """Abstract method"""
 
     @abstractmethod
     def add_metadata(self, key: str, value: str):
         """Abstract method"""
 
     @abstractmethod
-    def add_name(self, name: Optional[str]):
+    def add_name(self, name: str | None):
         """Abstract method"""
 
     @abstractmethod
-    def add_rating(self, rating: Optional[int]):
+    def add_rating(self, rating: float | int | str | None):
         """Abstract method"""
 
     @abstractmethod
     def add_security_label(
-        self, name: str, color: Optional[str] = None, description: Optional[str] = None
+        self, name: str, color: str | None = None, description: str | None = None
     ):
         """Abstract method"""
 
     @abstractmethod
-    def add_summary(self, value: Optional[str]):
+    def add_summary(self, value: str | None):
         """Abstract method"""
 
     @abstractmethod
     def add_tag(self, name: str):
         """Abstract method"""
```

### Comparing `tcex-3.0.9/tcex/api/tc/utils/threat_intel_utils.py` & `tcex-4.0.0/tcex/api/tc/util/threat_intel_util.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,42 +1,42 @@
-"""TI Common module."""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import re
-from typing import Dict, List, Optional
 from urllib.parse import quote
 
 # third-party
 import jmespath
 from requests import Session
 
 # first-party
-from tcex.backports import cached_property
-from tcex.exit.error_codes import handle_error
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
-class ThreatIntelUtils:
+class ThreatIntelUtil:
     """Threat Intelligence Common Methods"""
 
     INDICATOR = 'Indicator'
     GROUP = 'Group'
 
     def __init__(self, session_tc: Session):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.session_tc = session_tc
 
         # properties
-        self.log = logger
+        self.log = _logger
         self._ti = None
 
     @property
-    def resolvable_variables(self) -> Dict:
+    def resolvable_variables(self) -> dict:
         """Return a dict of all the supported resolvable variables.
 
         Each entry in the dict has the variables corresponding url and jmespath for their values
         if available. Some variables do not have this data since no api endpoint is supported.
         """
 
         return {
@@ -57,15 +57,15 @@
             },
         }
 
     def _association_types(self):
         """Retrieve Custom Indicator Associations types from the ThreatConnect API."""
 
     @staticmethod
-    def expand_indicators(indicator: str) -> List[str]:
+    def expand_indicators(indicator: str) -> list[str]:
         """Process indicators expanding file hashes/custom indicators into multiple entries.
 
         Args:
             indicator: A " : " delimited string.
 
         Returns:
             A list of indicators split on " : ".
@@ -94,24 +94,24 @@
         else:
             # handle all single valued indicator types (address, host, etc)
             indicator_list = [indicator]
 
         return indicator_list
 
     @property
-    def group_types(self) -> List[str]:
+    def group_types(self) -> list[str]:
         """Return all defined ThreatConnect Group types.
 
         Returns:
             A list of ThreatConnect Group types.
         """
-        return self.group_types_data.keys()
+        return list(self.group_types_data.keys())
 
     @property
-    def group_types_data(self) -> Dict[str, dict]:
+    def group_types_data(self) -> dict[str, dict]:
         """Return supported ThreatConnect Group types."""
         return {
             'Adversary': {'apiBranch': 'adversaries', 'apiEntity': 'adversary'},
             'Attack Pattern': {'apiBranch': 'attackPatterns', 'apiEntity': 'attackPattern'},
             'Campaign': {'apiBranch': 'campaigns', 'apiEntity': 'campaign'},
             'Course of Action': {'apiBranch': 'coursesOfAction', 'apiEntity': 'courseOfAction'},
             'Document': {'apiBranch': 'documents', 'apiEntity': 'document'},
@@ -125,15 +125,15 @@
             'Tactic': {'apiBranch': 'tactics', 'apiEntity': 'tactic'},
             'Task': {'apiBranch': 'tasks', 'apiEntity': 'task'},
             'Threat': {'apiBranch': 'threats', 'apiEntity': 'threat'},
             'Tool': {'apiBranch': 'tools', 'apiEntity': 'tool'},
             'Vulnerability': {'apiBranch': 'vulnerabilities', 'apiEntity': 'vulnerability'},
         }
 
-    def get_type_from_api_entity(self, api_entity: dict) -> Optional[str]:
+    def get_type_from_api_entity(self, api_entity: dict) -> str | None:
         """Return the object type as a string given a api entity.
 
         Args:
             api_entity: A TCEntity object.
 
         Returns:
             str, None: The type value or None.
@@ -143,15 +143,15 @@
         merged.update(self.indicator_types_data)
         for key, value in merged.items():
             if value.get('apiEntity') == api_entity:
                 return key
         return None
 
     @cached_property
-    def indicator_associations_types_data(self) -> Dict[str, dict]:
+    def indicator_associations_types_data(self) -> dict[str, dict]:
         """Return ThreatConnect associations type data.
 
         Retrieve the data from the API if it hasn't already been retrieved.
 
         Returns:
             (dict): A dictionary of ThreatConnect associations types.
         """
@@ -182,25 +182,25 @@
             for association in data.get('data', {}).get('associationType', []):
                 association_types[association.get('name')] = association
         except Exception as e:
             handle_error(code=200, message_values=[e])
         return _association_types
 
     @cached_property
-    def indicator_types(self) -> List[str]:
+    def indicator_types(self) -> list[str]:
         """Return ThreatConnect Indicator types.
 
         Retrieve the data from the API if it hasn't already been retrieved.
 
         Returns:
             (list): A list of ThreatConnect Indicator types.
         """
         return list(self.indicator_types_data.keys())
 
-    def resolve_variables(self, inputs: List[str]) -> List[str]:
+    def resolve_variables(self, inputs: list[str]) -> list[str]:
         """Resolve all of the provided inputs if appropriate.
 
         Args:
             inputs: A list of strings to resolve if string matches a entry in the
             "resolved_variables" dict.
         """
         resolved_inputs = []
@@ -238,15 +238,15 @@
             json_ = r.json()
             for item in jmespath.search(resolvable_variable_details.get('jmspath'), json_):
                 resolved_inputs.append(str(item))
 
         return resolved_inputs
 
     @cached_property
-    def indicator_types_data(self) -> Dict[str, dict]:
+    def indicator_types_data(self) -> dict[str, dict]:
         """Return ThreatConnect indicator types data.
 
         Retrieve the data from the API if it hasn't already been retrieved.
 
         Returns:
             (dict): A dictionary of ThreatConnect Indicator data.
         """
@@ -273,15 +273,15 @@
             (str): The urlencoded string
         """
         if indicator is not None:
             indicator = quote(indicator, safe='~')
         return indicator
 
     @staticmethod
-    def safe_rt(resource_type: str, lower: Optional[bool] = False) -> str:
+    def safe_rt(resource_type: str, lower: bool = False) -> str:
         """Format the Resource Type.
 
         Takes Custom Indicator types with a space character and return a *safe* string.
 
         (e.g. *User Agent* is converted to User_Agent or user_agent.)
 
         Args:
@@ -294,17 +294,15 @@
         if resource_type is not None:
             resource_type = resource_type.replace(' ', '_')
             if lower:
                 resource_type = resource_type.lower()
         return resource_type
 
     @staticmethod
-    def safe_group_name(
-        group_name: str, group_max_length: Optional[int] = 100, ellipsis: Optional[bool] = True
-    ) -> str:
+    def safe_group_name(group_name: str, group_max_length: int = 100, ellipsis: bool = True) -> str:
         """Truncate group name to match limit breaking on space and optionally add an ellipsis.
 
         .. note:: Currently the ThreatConnect group name limit is 100 characters.
 
         Args:
            group_name: The raw group name to be truncated.
            group_max_length: The max length of the group name.
@@ -351,15 +349,15 @@
         Args:
             url (str): The string to URL Encode.
 
         Returns:
             (str): The urlencoded string.
         """
         if url is not None:
-            url: str = quote(url, safe='~')
+            url = quote(url, safe='~')
         return url
 
     @property
     def victim_asset_types(self) -> list:
         """Return all defined ThreatConnect Asset types.
 
         Returns:
@@ -369,15 +367,15 @@
             'EmailAddress',
             'SocialNetwork',
             'NetworkAccount',
             'WebSite',
             'Phone',
         ]
 
-    def validate_intel_types(self, types_list: List[str], restrict_to: Optional[str] = None):
+    def validate_intel_types(self, types_list: list[str], restrict_to: str | None = None):
         """Validate that Types contained in types_list are valid Intel Types.
 
         :param types_list: list of types to validate. An exception is raised if a member of this
         list is not a valid intel type.
 
         :param restrict_to: If None, types_list will be validated to contain valid Indicator
         or Group types. If not None, this value must be set to self.INDICATOR or self.GROUP,
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/attribute.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/attribute.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,37 +1,40 @@
-"""ThreatConnect Batch Import Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import Callable, Optional
+from collections.abc import Callable
+
+# first-party
+from tcex.util import Util
 
 
 class Attribute:
     """ThreatConnect Batch Attribute Object"""
 
-    __slots__ = ['_attribute_data', '_valid']
+    __slots__ = ['_attribute_data', '_valid', 'util']
 
     def __init__(
         self,
         attr_type: str,
         attr_value: str,
-        displayed: Optional[bool] = False,
-        source: Optional[str] = None,
-        formatter: Optional[Callable[[str], str]] = None,
+        displayed: bool = False,
+        source: str | None = None,
+        formatter: Callable[[str], str] | None = None,
     ):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             attr_type: The ThreatConnect defined attribute type.
             attr_value: The value for this attribute.
             displayed: If True the supported attribute will be marked for display.
             source: The source value for this attribute.
             formatter: A callable that take a single attribute
                 value and return a single formatted value.
         """
-        self._attribute_data = {'type': attr_type}
+        self._attribute_data: dict[str, bool | str] = {'type': attr_type}
         if displayed:
             self._attribute_data['displayed'] = displayed
 
         # format the value
         if formatter is not None:
             attr_value = formatter(attr_value)
         self._attribute_data['value'] = attr_value
@@ -43,50 +46,53 @@
         # is attr_value not null or ''
         self._valid = True
 
         # check for None and '' value only.
         if attr_value in [None, '']:
             self._valid = False
 
+        # properties
+        self.util = Util()
+
     @property
     def data(self) -> dict:
         """Return Attribute data."""
         return self._attribute_data
 
     @property
     def displayed(self) -> bool:
         """Return Attribute displayed."""
-        return self._attribute_data.get('displayed')
+        return self.util.to_bool(self._attribute_data.get('displayed') or False)
 
     @displayed.setter
     def displayed(self, displayed: bool):
         """Set Attribute displayed."""
         self._attribute_data['displayed'] = displayed
 
     @property
-    def source(self) -> str:
+    def source(self) -> str | None:
         """Return Attribute source."""
-        return self._attribute_data.get('source')
+        return str(self._attribute_data.get('source'))
 
     @source.setter
     def source(self, source: str):
         """Set Attribute source."""
         self._attribute_data['source'] = source
 
     @property
     def type(self) -> str:
         """Return attribute value."""
-        return self._attribute_data.get('type')
+        return str(self._attribute_data['type'])
 
     @property
     def valid(self) -> bool:
         """Return valid value."""
         return self._valid
 
     @property
-    def value(self) -> str:
+    def value(self) -> bool | str | None:
         """Return attribute value."""
-        return self._attribute_data.get('value')
+        return self._attribute_data['value']
 
     def __str__(self) -> str:
         """Return string representation of object."""
         return json.dumps(self.data, indent=4)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/batch.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/batch.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-"""ThreatConnect Batch Import Module."""
+"""TcEx Framework Module"""
 # standard library
 import gzip
 import json
 import os
+import shelve  # nosec
 import sys
 import threading
 import time
 import traceback
 from collections import deque
-from typing import TYPE_CHECKING, Any, Callable, Optional, Tuple, Union
+from collections.abc import Callable
+from typing import Any
 
 # third-party
 from requests import Response, Session
 
 # first-party
 from tcex.api.tc.v2.batch.batch_submit import BatchSubmit
-from tcex.api.tc.v2.batch.batch_writer import BatchWriter
-from tcex.exit.error_codes import handle_error
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.api.tc.v2.batch.batch_writer import GroupType, IndicatorType
-    from tcex.input import Input
+from tcex.api.tc.v2.batch.batch_writer import BatchWriter, GroupType, IndicatorType
+from tcex.exit.error_code import handle_error
+from tcex.input.input import Input
 
 
 class Batch(BatchWriter, BatchSubmit):
     """ThreatConnect Batch Import Module
 
     Args:
         inputs: The App inputs.
@@ -37,25 +35,25 @@
         playbook_triggers_enabled: If True, Playbook will be triggered when TI data is created.
         security_label_write_type: Write type for labels ['Append', 'Replace'].
         tag_write_type: Write type for tags ['Append', 'Replace'].
     """
 
     def __init__(
         self,
-        inputs: 'Input',
+        inputs: Input,
         session_tc: Session,
         owner: str,
-        action: Optional[str] = 'Create',
-        attribute_write_type: Optional[str] = 'Replace',
-        halt_on_error: Optional[bool] = True,
-        playbook_triggers_enabled: Optional[bool] = False,
-        tag_write_type: Optional[str] = 'Replace',
-        security_label_write_type: Optional[str] = 'Replace',
+        action: str = 'Create',
+        attribute_write_type: str = 'Replace',
+        halt_on_error: bool = True,
+        playbook_triggers_enabled: bool = False,
+        tag_write_type: str = 'Replace',
+        security_label_write_type: str = 'Replace',
     ):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         BatchWriter.__init__(self, inputs=inputs, session_tc=session_tc, output_dir='')
         BatchSubmit.__init__(
             self,
             inputs=inputs,
             session_tc=session_tc,
             owner=owner,
             action=action,
@@ -104,81 +102,79 @@
         self.debug_path = os.path.join(self.inputs.model.tc_temp_path, 'DEBUG')
         self.debug_path_batch = os.path.join(self.debug_path, 'batch_data')
         self.debug_path_group_shelf = os.path.join(self.debug_path, 'groups-saved')
         self.debug_path_indicator_shelf = os.path.join(self.debug_path, 'indicators-saved')
         self.debug_path_files = os.path.join(self.debug_path, 'batch_files')
         self.debug_path_xids = os.path.join(self.debug_path, 'xids-saved')
 
-    def _group(
-        self, group_data: Union[dict, 'GroupType'], store: Optional[bool] = True
-    ) -> Union[dict, 'GroupType']:
+    def _group(self, group_data: dict | GroupType, store: bool = True) -> dict | GroupType:
         """Return previously stored group or new group.
 
         Args:
             group_data: An Group dict or instance of GroupType.
             store: If True the group data will be stored in instance list.
 
         Returns:
             (dict|GroupType): The new Group dict/GroupType or the previously stored dict/GroupType.
         """
         if store is False:
             return group_data
 
         if isinstance(group_data, dict):
             # get xid from dict
-            xid = group_data.get('xid')
+            xid = group_data['xid']
         else:
             # get xid from GroupType
             xid = group_data.xid
 
         if self.groups.get(xid) is not None:
             # return existing group from memory
-            group_data = self.groups.get(xid)
+            group_data = self.groups[xid]
         elif self.groups_shelf.get(xid) is not None:
             # return existing group from shelf
-            group_data = self.groups_shelf.get(xid)
+            group_data = self.groups_shelf[xid]
         else:
             # store new group
             self.groups[xid] = group_data
         return group_data
 
     def _indicator(
-        self, indicator_data: Union[dict, 'IndicatorType'], store: Optional[bool] = True
-    ) -> Union[dict, 'IndicatorType']:
+        self, indicator_data: dict | IndicatorType, store: bool = True
+    ) -> dict | IndicatorType:
         """Return previously stored indicator or new indicator.
 
         Args:
             indicator_data: An Indicator dict or instance of IndicatorType.
             store: If True the indicator data will be stored in instance list.
         """
         if store is False:
             return indicator_data
 
         if isinstance(indicator_data, dict):
             # get xid from dict
-            xid = indicator_data.get('xid')
+            xid = indicator_data['xid']
         else:
             # get xid from IndicatorType
             xid = indicator_data.xid
 
         if self.indicators.get(xid) is not None:
             # return existing indicator from memory
-            indicator_data = self.indicators.get(xid)
+            indicator_data = self.indicators[xid]
         elif self.indicators_shelf.get(xid) is not None:
             # return existing indicator from shelf
-            indicator_data = self.indicators_shelf.get(xid)
+            indicator_data = self.indicators_shelf[xid]
         else:
             # store new indicators
             self.indicators[xid] = indicator_data
         return indicator_data
 
     def close(self):
         """Cleanup batch job."""
         # allow pol thread to complete before wrapping up
-        if hasattr(self._submit_thread, 'is_alive'):
+        if self._submit_thread and hasattr(self._submit_thread, 'is_alive'):
             self._submit_thread.join()
 
         # allow file threads to complete before wrapping up job
         for t in self._file_threads:
             t.join()
 
         self.groups_shelf.close()
@@ -262,15 +258,15 @@
                 tracker['count'] += 1
                 tracker['bytes'] += sys.getsizeof(json.dumps(group_data))
 
                 # extend xids with any groups associated with the same GroupType
                 xids.extend(group_data.get('associatedGroupXid', []))
 
     @staticmethod
-    def data_group_type(group_data: Union[dict, 'GroupType']) -> Tuple[dict, dict]:
+    def data_group_type(group_data: dict | GroupType) -> tuple[dict, dict]:
         """Return dict representation of group data and file data.
 
         Args:
             group_data: The group data dict or GroupType.
 
         Returns:
             Tuple[dict, dict]: A tuple containing file_data and group_data.
@@ -289,15 +285,15 @@
             # get the file data from the GroupType and return dict format of GroupType
             if group_data.data.get('type') in ['Document', 'Report']:
                 file_data = group_data.file_data
             group_data = group_data.data
 
         return file_data, group_data
 
-    def data_groups(self, data: dict, groups: list, tracker: dict) -> bool:
+    def data_groups(self, data: dict, groups: dict | shelve.Shelf[Any], tracker: dict) -> bool:
         """Process Group data.
 
         Args:
             data: The data dict to update with group and file data.
             groups: The list of groups to process.
             tracker: A dict containing total count of all entities collected and
                 the total size in bytes of all entities collected.
@@ -309,34 +305,36 @@
         # the data_group_association function deleting items from the GroupType.
 
         # process the group
         for xid in list(groups.keys()):
             # get association from group data
             self.data_group_association(data, tracker, xid)
 
-            if tracker.get('count') % 2_500 == 0:
+            if tracker['count'] % 2_500 == 0:
                 # log count/size at a sane level
                 self.log.info(
                     '''feature=batch, action=data-groups, '''
                     f'''count={tracker.get('count'):,}, bytes={tracker.get('bytes'):,}'''
                 )
 
             if (
-                tracker.get('count') >= self._batch_max_chunk
-                or tracker.get('bytes') >= self._batch_max_size
+                tracker['count'] >= self._batch_max_chunk
+                or tracker['bytes'] >= self._batch_max_size
             ):
                 # stop processing xid once max limit are reached
                 self.log.info(
                     '''feature=batch, event=max-value-reached, '''
                     f'''count={tracker.get('count'):,}, bytes={tracker.get('bytes'):,}'''
                 )
                 return True
         return False
 
-    def data_indicators(self, data: dict, indicators: list, tracker: dict) -> bool:
+    def data_indicators(
+        self, data: dict, indicators: dict | shelve.Shelf[Any], tracker: dict
+    ) -> bool:
         """Process Indicator data.
 
         Args:
             data: The data dict to update with group and file data.
             indicators: The list of indicators to process.
             tracker: A dict containing total count of all entities collected and
                 the total size in bytes of all entities collected.
@@ -351,24 +349,24 @@
             data['indicator'].append(indicator_data)
             del indicators[xid]
 
             # update entity trackers
             tracker['count'] += 1
             tracker['bytes'] += sys.getsizeof(json.dumps(indicator_data))
 
-            if tracker.get('count') % 2_500 == 0:
+            if tracker['count'] % 2_500 == 0:
                 # log count/size at a sane level
                 self.log.info(
                     '''feature=batch, action=data-indicators, '''
                     f'''count={tracker.get('count'):,}, bytes={tracker.get('bytes'):,}'''
                 )
 
             if (
-                tracker.get('count') >= self._batch_max_chunk
-                or tracker.get('bytes') >= self._batch_max_size
+                tracker['count'] >= self._batch_max_chunk
+                or tracker['bytes'] >= self._batch_max_size
             ):
                 # stop processing xid once max limit are reached
                 self.log.info(
                     '''feature=batch, event=max-value-reached, '''
                     f'''count={tracker.get('count'):,}, bytes={tracker.get('bytes'):,}'''
                 )
                 return True
@@ -395,23 +393,23 @@
                 os.makedirs(self.debug_path_files, exist_ok=True)
                 self._debug = True
         return self._debug
 
     @property
     def halt_on_file_error(self) -> bool:
         """Return halt on file post error value."""
-        return self._halt_on_file_error
+        return self._halt_on_file_error or False
 
     @halt_on_file_error.setter
     def halt_on_file_error(self, value: bool):
         """Set halt on file post error value."""
         if isinstance(value, bool):
             self._halt_on_file_error = value
 
-    def process_all(self, process_files: Optional[bool] = True):
+    def process_all(self, process_files: bool = True):
         """Process Batch request to ThreatConnect API.
 
         Args:
             process_files: Send any document or report attachments to the API.
         """
         while True:
             content = self.data
@@ -421,19 +419,19 @@
 
             # special code for debugging App using batchV2.
             self.write_batch_json(content)
 
             # store the length of the batch data to use for poll interval calculations
             self.log.info(
                 '''feature=batch, event=process-all, type=group, '''
-                f'''count={len(content.get('group')):,}'''
+                f'''count={len(content['group']):,}'''
             )
             self.log.info(
                 '''feature=batch, event=process-all, type=indicator, '''
-                f'''count={len(content.get('indicator')):,}'''
+                f'''count={len(content['indicator']):,}'''
             )
 
         if process_files:
             self.process_files(file_data)
 
     def process_files(self, file_data: dict):
         """Process Files for Documents and Reports to ThreatConnect API.
@@ -526,18 +524,18 @@
     def saved_xids(self, xid: str):
         """Append xid to xids saved file."""
         with open(self.debug_path_xids, 'a') as fh:
             fh.write(f'{xid}\n')
 
     def submit(  # pylint: disable=arguments-differ, arguments-renamed
         self,
-        poll: Optional[bool] = True,
-        errors: Optional[bool] = True,
-        process_files: Optional[bool] = True,
-        halt_on_error: Optional[bool] = True,
+        poll: bool = True,
+        errors: bool = True,
+        process_files: bool = True,
+        halt_on_error: bool = True,
     ) -> dict:
         """Submit Batch request to ThreatConnect API.
 
         By default this method will submit the job request and data and if the size of the data
         is below the value **synchronousBatchSaveLimit** set in System Setting it will process
         the request synchronously and return the batch status.  If the size of the batch is greater
         than the value set the batch job will be queued.
@@ -573,15 +571,15 @@
             self.log.info(f'feature=batch, event=submit, batch-id={batch_id}')
             # job hit queue
             if poll:
                 # poll for status
                 batch_data = (
                     self.poll(batch_id=batch_id, halt_on_error=halt_on_error)
                     .get('data', {})
-                    .get('batchStatus')
+                    .get('batchStatus', {})
                 )
                 if errors:
                     # retrieve errors
                     error_groups = batch_data.get('errorGroupCount', 0)
                     error_indicators = batch_data.get('errorIndicatorCount', 0)
                     if error_groups > 0 or error_indicators > 0:
                         batch_data['errors'] = self.errors(batch_id)
@@ -601,19 +599,19 @@
                     ),
                 )
             )
         return batch_data
 
     def submit_all(
         self,
-        poll: Optional[bool] = True,
-        errors: Optional[bool] = True,
-        process_files: Optional[bool] = True,
-        halt_on_error: Optional[bool] = True,
-    ) -> dict:
+        poll: bool = True,
+        errors: bool = True,
+        process_files: bool = True,
+        halt_on_error: bool = True,
+    ) -> list[dict]:
         """Submit Batch request to ThreatConnect API.
 
         By default this method will submit the job request and data and if the size of the data
         is below the value **synchronousBatchSaveLimit** set in System Setting it will process
         the request synchronously and return the batch status.  If the size of the batch is greater
         than the value set the batch job will be queued.
         Errors are not retrieve automatically and need to be enabled.
@@ -632,16 +630,16 @@
 
         Returns.
             dict: The Batch Status from the ThreatConnect API.
         """
         batch_data_array = []
         file_data = {}
         while True:
-            batch_data = {}
-            batch_id = None
+            batch_data: dict[str, int | list | str] | None = {}
+            batch_id: int | None = None
 
             # get file, group, and indicator data
             content = self.data
 
             # break loop when end of data is reached
             if not content.get('group') and not content.get('indicator'):
                 break
@@ -664,33 +662,38 @@
                 # pop any file content to pass to submit_files
                 file_data = content.pop('file', {})
                 batch_data = (
                     self.submit_create_and_upload(content=content, halt_on_error=halt_on_error)
                     .get('data', {})
                     .get('batchStatus', {})
                 )
-                batch_id = batch_data.get('id')
+                batch_id = batch_data.get('id')  # type: ignore
 
             if batch_id is not None:
                 self.log.info(f'feature=batch, event=status, batch-id={batch_id}')
                 # job hit queue
                 if poll:
                     # poll for status
                     batch_data = (
                         self.poll(batch_id, halt_on_error=halt_on_error)
                         .get('data', {})
-                        .get('batchStatus')
+                        .get('batchStatus', {})
                     )
-                    if errors:
+                    if errors and batch_data is not None:
                         # retrieve errors
                         error_count = batch_data.get('errorCount', 0)
                         error_groups = batch_data.get('errorGroupCount', 0)
                         error_indicators = batch_data.get('errorIndicatorCount', 0)
-                        if error_count > 0 or error_groups > 0 or error_indicators > 0:
-                            batch_data['errors'] = self.errors(batch_id)
+                        if (
+                            isinstance(error_count, int)
+                            and isinstance(error_groups, int)
+                            and isinstance(error_indicators, int)
+                        ):
+                            if error_count > 0 or error_groups > 0 or error_indicators > 0:
+                                batch_data['errors'] = self.errors(batch_id)
                 else:
                     # can't process files if status is unknown (polling must be enabled)
                     process_files = False
 
             if process_files:
                 # submit file data after batch job is complete
                 self._file_threads.append(
@@ -702,36 +705,39 @@
                             halt_on_error,
                         ),
                     )
                 )
             batch_data_array.append(batch_data)
 
             # write errors for debugging
-            self.write_error_json(batch_data.get('errors'))
+            if isinstance(batch_data, dict):
+                batch_errors = batch_data.get('errors', [])
+                if isinstance(batch_errors, list) and len(batch_errors) > 0:
+                    self.write_error_json(batch_errors)
 
         return batch_data_array
 
     def submit_callback(
         self,
         callback: Callable[..., Any],
-        content: Optional[dict] = None,
-        halt_on_error: Optional[bool] = True,
+        content: dict | None = None,
+        halt_on_error: bool = True,
     ) -> bool:
         """Submit batch data to ThreatConnect and poll in a separate thread.
 
         The "normal" submit methods run in serial which will block when the batch poll is running.
         Using this method the submit is done in serial, but the poll method is run in a thread,
         which should allow the App to continue downloading and processing data while the batch
         poll process is running. Only one batch submission is allowed at a time so that any
         critical errors returned from batch can be handled before submitting a new batch job.
 
         Args:
             callback: The callback method that will handle
                 the batch status when polling is complete.
-            content: The dict of groups and indicator data (e.g., {"group": [], "indiciator": []}).
+            content: The dict of groups and indicator data (e.g., {"group": [], "indicator": []}).
             halt_on_error: If True the process should halt if any errors are encountered.
 
         Raises:
             RuntimeError: Raised on invalid callback method.
 
         Returns:
             bool: False when there is not data to process, else True
@@ -745,15 +751,15 @@
         file_data = content.pop('file', {})
 
         # return False when end of data is reached
         if not content.get('group') and not content.get('indicator'):
             return False
 
         # block here is there is already a batch submission being processed
-        if hasattr(self._submit_thread, 'is_alive'):
+        if self._submit_thread and hasattr(self._submit_thread, 'is_alive'):
             self.log.info(
                 'feature=batch, event=progress, status=blocked, '
                 f'is-alive={self._submit_thread.is_alive()}'
             )
             self._submit_thread.join()
             self.log.debug(
                 'feature=batch, event=progress, status=released, '
@@ -775,37 +781,38 @@
             args=(batch_data, callback, file_data),
         )
 
         return True
 
     def submit_callback_thread(
         self,
-        batch_data: int,
+        batch_data: dict,
         callback: Callable[..., Any],
         file_data: dict,
-        halt_on_error: Optional[bool] = True,
+        halt_on_error: bool = True,
     ):
         """Submit data in a thread."""
         batch_id = batch_data.get('id')
         self.log.info(f'feature=batch, event=progress, batch-id={batch_id}')
         if batch_id:
             # when batch_id is None it indicates that batch submission was small enough to be
             # processed inline (without being queued)
 
             # poll for status
             batch_status = (
                 self.poll(batch_id, halt_on_error=halt_on_error).get('data', {}).get('batchStatus')
             )
 
             # retrieve errors
-            error_count = batch_status.get('errorCount', 0)
-            error_groups = batch_status.get('errorGroupCount', 0)
-            error_indicators = batch_status.get('errorIndicatorCount', 0)
-            if error_count > 0 or error_groups > 0 or error_indicators > 0:
-                batch_status['errors'] = self.errors(batch_id)
+            if batch_status is not None:
+                error_count = batch_status.get('errorCount', 0)
+                error_groups = batch_status.get('errorGroupCount', 0)
+                error_indicators = batch_status.get('errorIndicatorCount', 0)
+                if error_count > 0 or error_groups > 0 or error_indicators > 0:
+                    batch_status['errors'] = self.errors(batch_id)
         else:
             batch_status = batch_data
 
         # launch file upload in a thread *after* batch status is returned. while only one batch
         # submission thread is allowed, there is no limit on file upload threads. the upload
         # status returned by file upload will be ignored when running in a thread.
         if file_data:
@@ -824,15 +831,15 @@
         if callable(callback):
             self.log.debug('feature=batch, event=calling-callback')
             try:
                 callback(batch_status)
             except Exception as e:
                 self.log.warning(f'feature=batch, event=callback-error, err="""{e}"""')
 
-    def submit_create_and_upload(self, content: dict, halt_on_error: Optional[bool] = True) -> dict:
+    def submit_create_and_upload(self, content: dict, halt_on_error: bool = True) -> dict:
         """Submit Batch request to ThreatConnect API.
 
         Args:
             content: The dict of groups and indicator data.
             halt_on_error: If True the process should halt if any errors are encountered.
 
         Returns.
@@ -844,19 +851,19 @@
 
         # special code for debugging App using batchV2.
         self.write_batch_json(content)
 
         # store the length of the batch data to use for poll interval calculations
         self.log.info(
             '''feature=batch, event=submit-create-and-upload, type=group, '''
-            f'''count={len(content.get('group')):,}'''
+            f'''count={len(content['group']):,}'''
         )
         self.log.info(
             '''feature=batch, event=submit-create-and-upload, type=indicator, '''
-            f'''count={len(content.get('indicator')):,}'''
+            f'''count={len(content['indicator']):,}'''
         )
 
         try:
             files = (('config', json.dumps(self.settings)), ('content', json.dumps(content)))
             params = {'includeAdditional': 'true'}
             r = self.session_tc.post('/v2/batch/createAndUpload', files=files, params=params)
             if not r.ok or 'application/json' not in r.headers.get('content-type', ''):
@@ -867,15 +874,15 @@
                 )
             return r.json()
         except Exception as e:
             handle_error(code=10505, message_values=[e], raise_error=halt_on_error)
 
         return {}
 
-    def submit_files(self, file_data: dict, halt_on_error: Optional[bool] = True) -> dict:
+    def submit_files(self, file_data: dict, halt_on_error: bool = True) -> list[dict] | None:
         """Submit Files for Documents and Reports to ThreatConnect API.
 
         Critical Errors
 
         * There is insufficient document storage allocated to this account.
 
         Args:
@@ -936,18 +943,24 @@
                         fh.write(content)
 
             # Post File
             url = f'/v2/groups/{api_branch}/{xid}/upload'
             headers = {'Content-Type': 'application/octet-stream'}
             params = {'owner': self._owner, 'updateIfExists': 'true'}
             r = self.submit_file_content('POST', url, content, headers, params, halt_on_error)
+            if r is None:
+                return None
+
             if r.status_code == 401:
                 # use PUT method if file already exists
                 self.log.info('feature=batch, event=401-from-post, action=switch-to-put')
                 r = self.submit_file_content('PUT', url, content, headers, params, halt_on_error)
+                if r is None:
+                    return None
+
             if not r.ok:
                 status = False
                 handle_error(
                     code=585,
                     message_values=[r.status_code, r.text],
                     raise_error=halt_on_error,
                 )
@@ -963,19 +976,19 @@
 
         return upload_status
 
     def submit_file_content(
         self,
         method: str,
         url: str,
-        data: Union[bytes, str],
+        data: bytes | str,
         headers: dict,
         params: dict,
-        halt_on_error: Optional[bool] = True,
-    ) -> Response:
+        halt_on_error: bool = True,
+    ) -> Response | None:
         """Submit File Content for Documents and Reports to ThreatConnect API.
 
         Args:
             method: The HTTP method for the request (POST, PUT).
             url: The URL for the request.
             data: The body (data) for the request.
             headers: The headers for the request.
@@ -988,15 +1001,15 @@
         r = None
         try:
             r = self.session_tc.request(method, url, data=data, headers=headers, params=params)
         except Exception as e:
             handle_error(code=580, message_values=[e], raise_error=halt_on_error)
         return r
 
-    def submit_job(self, halt_on_error: Optional[bool] = True) -> int:
+    def submit_job(self, halt_on_error: bool = True) -> int | None:
         """Submit Batch request to ThreatConnect API.
 
         Args:
             halt_on_error: If True any exception will raise an error.
 
         Returns:
             int: The batch id from the API response.
@@ -1005,14 +1018,15 @@
         if self.halt_on_batch_error is not None:
             halt_on_error = self.halt_on_batch_error
 
         try:
             r = self.session_tc.post('/v2/batch', json=self.settings)
         except Exception as e:
             handle_error(code=10505, message_values=[e], raise_error=halt_on_error)
+            return None
 
         if not r.ok or 'application/json' not in r.headers.get('content-type', ''):
             handle_error(
                 code=10510,
                 message_values=[r.status_code, r.text],
                 raise_error=halt_on_error,
             )
@@ -1025,17 +1039,17 @@
             )
         self.log.debug(f'feature=batch, event=submit-job, status={data}')
         return data.get('data', {}).get('batchId')
 
     def submit_thread(
         self,
         name: str,
-        target: Callable[[], bool],
-        args: Optional[tuple] = None,
-        kwargs: Optional[dict] = None,
+        target: Callable,
+        args: tuple | None = None,
+        kwargs: dict | None = None,
     ):
         """Start a submit thread.
 
         Args:
             name: The name of the thread.
             target: The method to call for the thread.
             args: The args to pass to the target method.
@@ -1086,15 +1100,15 @@
         return len(self.indicators) + len(self.indicators_shelf)
 
     def __len__(self) -> int:
         """Return the number of groups and indicators."""
         return self.group_len + self.indicator_len
 
     def __str__(self) -> str:  # pragma: no cover
-        """Return string represtentation of batch."""
+        """Return string representation of batch."""
         groups = []
         for group_data in self.groups.values():
             if isinstance(group_data, dict):
                 groups.append(group_data)
             else:
                 groups.append(group_data.data)
         for group_data in self.groups_shelf.values():
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/batch_submit.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/batch_submit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,44 @@
-"""ThreatConnect Batch Import Module."""
+"""TcEx Framework Module"""
 # standard library
 import gzip
 import json
 import logging
 import math
 import re
 import time
-from typing import Dict, List, Optional, Union
 
 # third-party
 from requests import Session
 
 # first-party
-from tcex.exit.error_codes import handle_error
+from tcex.exit.error_code import handle_error
 from tcex.input.input import Input
+from tcex.logger.trace_logger import TraceLogger
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class BatchSubmit:
     """ThreatConnect Batch Import Module"""
 
     def __init__(
         self,
         inputs: Input,
         session_tc: Session,
         owner: str,
-        action: Optional[str] = 'Create',
-        attribute_write_type: Optional[str] = 'Replace',
-        halt_on_error: Optional[bool] = True,
-        playbook_triggers_enabled: Optional[bool] = False,
-        tag_write_type: Optional[str] = 'Replace',
-        security_label_write_type: Optional[str] = 'Replace',
+        action: str = 'Create',
+        attribute_write_type: str = 'Replace',
+        halt_on_error: bool = True,
+        playbook_triggers_enabled: bool = False,
+        tag_write_type: str = 'Replace',
+        security_label_write_type: str = 'Replace',
     ):
-        """Initialize Class properties.
+        """Initialize instance properties.
 
         Args:
             inputs: The App inputs.
             session_tc: The ThreatConnect API session.
             owner: The ThreatConnect owner for Batch action.
             action: Action for the batch job ['Create', 'Delete'].
             attribute_write_type: Write type for Indicator attributes ['Append', 'Replace'].
@@ -56,28 +56,28 @@
         self._playbook_triggers_enabled = playbook_triggers_enabled
         self._security_label_write_type = security_label_write_type
         self._tag_write_type = tag_write_type
 
         # properties
         self._file_merge_mode = None
         self._hash_collision_mode = None
-        self.log = logger
+        self.log = _logger
 
         # global overrides on batch/file errors
         self._halt_on_batch_error = None
         self._halt_on_poll_error = None
 
         # default properties
         self._batch_data_count = None
         self._poll_interval = None
         self._poll_interval_times = []
         self._poll_timeout = 3600
 
     @property
-    def _critical_failures(self) -> List[str]:  # pragma: no cover
+    def _critical_failures(self) -> list[str]:  # pragma: no cover
         """Return Batch critical failure messages."""
         return [
             'Encountered an unexpected Exception while processing batch job',
             'would exceed the number of allowed indicators',
         ]
 
     @property
@@ -96,15 +96,15 @@
         return self._attribute_write_type
 
     @attribute_write_type.setter
     def attribute_write_type(self, write_type: str):
         """Set batch attribute write type."""
         self._attribute_write_type = write_type
 
-    def create_job(self, halt_on_error: Optional[bool] = True) -> int:
+    def create_job(self, halt_on_error: bool = True) -> int | None:
         """Submit Batch request to ThreatConnect API.
 
         Args:
             halt_on_error: If True any exception will raise an error.
 
         Returns:
             int: The batch id from the API response.
@@ -113,14 +113,15 @@
         if self.halt_on_batch_error is not None:
             halt_on_error = self.halt_on_batch_error
 
         try:
             r = self.session_tc.post('/v2/batch', json=self.settings)
         except Exception as e:
             handle_error(code=10505, message_values=[e], raise_error=halt_on_error)
+            return None
 
         if not r.ok or 'application/json' not in r.headers.get('content-type', ''):
             handle_error(
                 code=10510,
                 message_values=[r.status_code, r.text],
                 raise_error=halt_on_error,
             )
@@ -133,15 +134,15 @@
                 raise_error=halt_on_error,
             )
 
         self.log.debug(f'feature=batch, event=submit-job, status={data}')
         return data.get('data', {}).get('batchId')
 
     @property
-    def error_codes(self) -> Dict[str, str]:
+    def error_codes(self) -> dict[str, str]:
         """Return static list of Batch error codes and short description"""
         return {
             '0x1001': 'General Error',
             '0x1002': 'Permission Error',
             '0x1003': 'JsonSyntax Error',
             '0x1004': 'Internal Error',
             '0x1005': 'Invalid Indicator Error',
@@ -153,15 +154,15 @@
             '0x100B': 'File IO Error',
             '0x2001': 'Indicator Partial Loss Error',
             '0x2002': 'Group Partial Loss Error',
             '0x2003': 'File Hash Merge Error',
             '0x3001': 'File Hash Merge Error',
         }
 
-    def errors(self, batch_id: int, halt_on_error: Optional[bool] = True) -> list:
+    def errors(self, batch_id: int, halt_on_error: bool = True) -> list:
         """Retrieve Batch errors to ThreatConnect API.
 
         .. code-block:: javascript
 
             [{
                 "errorReason": "Incident incident-001 has an invalid status.",
                 "errorSource": "incident-001 is not valid."
@@ -217,49 +218,49 @@
     def halt_on_error(self, halt_on_error: bool):
         """Set batch halt on error setting."""
         self._halt_on_error = halt_on_error
 
     @property
     def halt_on_batch_error(self) -> bool:
         """Return halt on batch error value."""
-        return self._halt_on_batch_error
+        return self._halt_on_batch_error or False
 
     @halt_on_batch_error.setter
     def halt_on_batch_error(self, value: bool):
         """Set batch halt on batch error value."""
         if isinstance(value, bool):
             self._halt_on_batch_error = value
 
     @property
     def halt_on_poll_error(self) -> bool:
         """Return halt on poll error value."""
-        return self._halt_on_poll_error
+        return self._halt_on_poll_error or False
 
     @halt_on_poll_error.setter
     def halt_on_poll_error(self, value: bool):
         """Set batch halt on poll error value."""
         if isinstance(value, bool):
             self._halt_on_poll_error = value
 
-    def hash_collision_mode(self, value: str) -> str:
+    def hash_collision_mode(self, value: str):
         """Set the file hash collision mode for the entire batch job.
 
         Args:
             value: A value of Split, IgnoreIncoming, IgnoreExisting, FavorIncoming,
                 and FavorExisting.
         """
         self._hash_collision_mode = value
 
     def poll(
         self,
         batch_id: int,
-        retry_seconds: Optional[int] = None,
-        back_off: Optional[float] = None,
-        timeout: Optional[int] = None,
-        halt_on_error: Optional[bool] = True,
+        retry_seconds: int | None = None,
+        back_off: float | None = None,
+        timeout: int | None = None,
+        halt_on_error: bool = True,
     ) -> dict:
         """Poll Batch status to ThreatConnect API.
 
         .. code-block:: javascript
 
             {
                 "status": "Success",
@@ -340,15 +341,15 @@
                 handle_error(code=540, message_values=[e], raise_error=halt_on_error)
 
             if data.get('data', {}).get('batchStatus', {}).get('status') == 'Completed':
                 # store last 5 poll times to use in calculating average poll time
                 modifier = poll_time_total * 0.7
                 self._poll_interval_times = self._poll_interval_times[-4:] + [modifier]
 
-                weights = [1]
+                weights: list[float | int] = [1]
                 poll_interval_time_weighted_sum = 0
                 for poll_interval_time in self._poll_interval_times:
                     poll_interval_time_weighted_sum += poll_interval_time * weights[-1]
                     # weights will be [1, 1.5, 2.25, 3.375, 5.0625] for all 5 poll times depending
                     # on how many poll times are available.
                     weights.append(weights[-1] * 1.5)
 
@@ -391,15 +392,15 @@
 
     @security_label_write_type.setter
     def security_label_write_type(self, write_type: str):
         """Set batch security label write type."""
         self._security_label_write_type = write_type
 
     @property
-    def settings(self) -> Dict[str, str]:
+    def settings(self) -> dict[str, str]:
         """Return batch job settings."""
         _settings = {
             'action': self._action,
             'attributeWriteType': self.attribute_write_type,
             'haltOnError': str(self._halt_on_error).lower(),
             'owner': self._owner,
             'playbookTriggersEnabled': str(self._playbook_triggers_enabled).lower(),
@@ -409,15 +410,15 @@
         }
         if self._hash_collision_mode is not None:
             _settings['hashCollisionMode'] = self._hash_collision_mode
         if self._file_merge_mode is not None:
             _settings['fileMergeMode'] = self._file_merge_mode
         return _settings
 
-    def submit(self, batch_filename: str, halt_on_error: Optional[bool] = True) -> dict:
+    def submit(self, batch_filename: str, halt_on_error: bool = True) -> dict:
         """Submit Batch request to ThreatConnect API.
 
         Args:
             batch_filename: The filename for the batch JSON file.
             halt_on_error: If True the process should halt if any errors are encountered.
 
         Returns.
@@ -425,25 +426,15 @@
         """
         content = gzip.open(batch_filename, 'rt').read()
 
         # check global setting for override
         if self.halt_on_batch_error is not None:
             halt_on_error = self.halt_on_batch_error
 
-        # store the length of the batch data to use for poll interval calculations
-        self.log.info(
-            '''feature=batch, event=submit-create-and-upload, type=group, '''
-            f'''count={len(content.get('group')):,}'''
-        )
-        self.log.info(
-            '''feature=batch, event=submit-create-and-upload, type=indicator, '''
-            f'''count={len(content.get('indicator')):,}'''
-        )
-
-        files = (('config', json.dumps(self.settings)), ('content', json.dumps(content)))
+        files = (('config', json.dumps(self.settings)), ('content', content))
         params = {'includeAdditional': 'true'}
         try:
             r = self.session_tc.post('/v2/batch/createAndUpload', files=files, params=params)
             if not r.ok or 'application/json' not in r.headers.get('content-type', ''):
                 handle_error(
                     code=10510,
                     message_values=[r.status_code, r.text],
@@ -452,22 +443,22 @@
             return r.json()
         except Exception as e:
             handle_error(code=10505, message_values=[e], raise_error=halt_on_error)
 
         return {}
 
     def submit_data(
-        self, batch_id: int, content: Union[dict, str], halt_on_error: Optional[bool] = True
-    ) -> dict:
+        self, batch_id: int, content: dict | str, halt_on_error: bool = True
+    ) -> dict | None:
         """Submit Batch request to ThreatConnect API.
 
         Args:
             batch_id: The batch id of the current job.
             content: The dict of groups and indicator data.
-            halt_on_error (Optional[bool] = True): If True the process
+            halt_on_error (bool = True): If True the process
                 should halt if any errors are encountered.
 
         Returns:
             dict: The response data
         """
         # check global setting for override
         if self.halt_on_batch_error is not None:
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/batch_writer.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/batch_writer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,27 @@
-"""ThreatConnect Batch Import Module."""
+"""TcEx Framework Module"""
 # standard library
 import gzip
 import hashlib
 import json
 import logging
 import os
 import re
 import shelve  # nosec
 import sys
 import time
 import uuid
 from collections import deque
-from typing import TYPE_CHECKING, Optional, Tuple, Union
+from typing import Any
+
+# third-party
+from requests import Session  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
 from tcex.api.tc.v2.batch.group import (
     Adversary,
     AttackPattern,
     Campaign,
     CourseOfAction,
     Document,
     Email,
@@ -44,92 +47,87 @@
     Host,
     Indicator,
     Mutex,
     RegistryKey,
     UserAgent,
     custom_indicator_class_factory,
 )
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
-
-    # first-party
-    from tcex.input.input import Input
+from tcex.input.input import Input  # TYPE-CHECKING
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 # define GroupType
-GroupType = Union[
-    Adversary,
-    AttackPattern,
-    Campaign,
-    CourseOfAction,
-    Document,
-    Email,
-    Event,
-    Group,
-    Incident,
-    IntrusionSet,
-    Malware,
-    Report,
-    Signature,
-    Tactic,
-    Threat,
-    Tool,
-    Vulnerability,
-]
+GroupType = (
+    Adversary
+    | AttackPattern
+    | Campaign
+    | CourseOfAction
+    | Document
+    | Email
+    | Event
+    | Group
+    | Incident
+    | IntrusionSet
+    | Malware
+    | Report
+    | Signature
+    | Tactic
+    | Threat
+    | Tool
+    | Vulnerability
+)
 
 # define IndicatorType
-IndicatorType = Union[
-    ASN,
-    CIDR,
-    URL,
-    Address,
-    EmailAddress,
-    File,
-    Host,
-    Indicator,
-    Mutex,
-    RegistryKey,
-    UserAgent,
-]
+IndicatorType = (
+    ASN
+    | CIDR
+    | URL
+    | Address
+    | EmailAddress
+    | File
+    | Host
+    | Indicator
+    | Mutex
+    | RegistryKey
+    | UserAgent
+)
 
 
 class BatchWriter:
     """ThreatConnect Batch Import Module
 
     Args:
         inputs: The App inputs.
         session_tc: The ThreatConnect API session.
         output_dir: The directory to write the batch JSON data.
     """
 
-    def __init__(self, inputs: 'Input', session_tc: 'Session', output_dir: str, **kwargs):
-        """Initialize Class properties."""
+    def __init__(self, inputs: Input, session_tc: Session, output_dir: str, **kwargs):
+        """Initialize instance properties."""
         self.inputs = inputs
         self.output_dir = output_dir
         self.output_extension = kwargs.get('output_extension')
         self.session_tc = session_tc
         self.write_callback = kwargs.get('write_callback')
         self.write_callback_kwargs = kwargs.get('write_callback_kwargs', {})
 
         # properties
         self._batch_files = []
         self._batch_max_chunk = 100_000
         self._batch_size = 0  # track current batch size
         self._batch_max_size = 75_000_000  # max size in bytes
-        self.log = logger
-        self.tic = ThreatIntelUtils(self.session_tc)
-        self.utils = Utils()
+        self.log = _logger
+        self.tic = ThreatIntelUtil(self.session_tc)
+        self.util = Util()
 
         # shelf settings
         self._group_shelf_fqfn = None
         self._indicator_shelf_fqfn = None
 
         # containers
         self._groups = None
@@ -139,18 +137,18 @@
 
         # build custom indicator classes
         self._gen_indicator_class()
 
     def _gen_indicator_class(self):  # pragma: no cover
         """Generate Custom Indicator Classes."""
         for entry in self.tic.indicator_types_data.values():
-            name = entry.get('name')
+            name = entry['name']
             class_name = name.replace(' ', '')
             # temp fix for API issue where boolean are returned as strings
-            entry['custom'] = self.utils.to_bool(entry.get('custom'))
+            entry['custom'] = self.util.to_bool(entry.get('custom') or False)
 
             if class_name in globals():
                 # skip Indicator Type if a class already exists
                 continue
 
             # Custom Indicator can have 3 values. Only add the value if it is set.
             value_fields = []
@@ -167,15 +165,15 @@
             custom_class = custom_indicator_class_factory(name, Indicator, class_data, value_fields)
             setattr(module, class_name, custom_class)
 
             # Add Custom Indicator Method
             self._gen_indicator_method(name, custom_class, value_count)
 
     def _gen_indicator_method(
-        self, name: str, custom_class: 'IndicatorType', value_count: int
+        self, name: str, custom_class: Any, value_count: int
     ):  # pragma: no cover
         """Dynamically generate custom Indicator methods.
 
         Args:
             name: The name of the method.
             custom_class: The class to add.
             value_count: The number of value parameters to support.
@@ -201,39 +199,37 @@
             """Add Custom Indicator data to Batch"""
             indicator_obj = custom_class(value1, value2, value3, xid, **kwargs)
             return self._indicator(indicator_obj, kwargs.get('store', True))
 
         method = locals()[f'method_{value_count}']
         setattr(self, method_name, method)
 
-    def _group(
-        self, group_data: Union[dict, 'GroupType'], store: Optional[bool] = True
-    ) -> Union[dict, 'GroupType']:
+    def _group(self, group_data: dict | GroupType, store: bool = True) -> dict | GroupType:
         """Return previously stored group or new group.
 
         Args:
             group_data: An Group dict or instance of a GroupType.
             store: If True the group data will be stored in instance list.
         """
         if store is False:
             return group_data
 
         if isinstance(group_data, dict):
             # get xid from dict
-            xid = group_data.get('xid')
+            xid = group_data['xid']
         else:
             # get xid from GroupType
             xid = group_data.xid
 
         if self.groups.get(xid) is not None:
             # return existing group from memory
-            group_data = self.groups.get(xid)
+            group_data = self.groups[xid]
         elif self.groups_shelf.get(xid) is not None:
             # return existing group from shelf
-            group_data = self.groups_shelf.get(xid)
+            group_data = self.groups_shelf[xid]
         else:
             # store new group
             self.groups[xid] = group_data
 
             # track total batch job data size as TI gets added
             if isinstance(group_data, dict):
                 self._batch_size += sys.getsizeof(json.dumps(group_data))
@@ -242,38 +238,38 @@
 
             # max size hit, dump TI to disk
             if self._batch_size > self._batch_max_size:
                 self.dump()
         return group_data
 
     def _indicator(
-        self, indicator_data: Union[dict, 'IndicatorType'], store: Optional[bool] = True
-    ) -> Union[dict, 'IndicatorType']:
+        self, indicator_data: dict | IndicatorType, store: bool = True
+    ) -> dict | IndicatorType:
         """Return previously stored indicator or new indicator.
 
         Args:
             indicator_data: An Indicator dict or instance of IndicatorType.
             store: If True the indicator data will be stored in instance list.
         """
         if store is False:
             return indicator_data
 
         if isinstance(indicator_data, dict):
             # get xid from dict
-            xid = indicator_data.get('xid')
+            xid = indicator_data['xid']
         else:
             # get xid from IndicatorType
             xid = indicator_data.xid
 
         if self.indicators.get(xid) is not None:
             # return existing indicator from memory
-            indicator_data = self.indicators.get(xid)
+            indicator_data = self.indicators[xid]
         elif self.indicators_shelf.get(xid) is not None:
             # return existing indicator from shelf
-            indicator_data = self.indicators_shelf.get(xid)
+            indicator_data = self.indicators_shelf[xid]
         else:
             # store new indicators
             self.indicators[xid] = indicator_data
 
             # track total batch job data size as TI gets added
             if isinstance(indicator_data, dict):
                 self._batch_size += sys.getsizeof(json.dumps(indicator_data))
@@ -314,15 +310,15 @@
 
             indicators = iregx.search(indicator)
             if indicators is not None:
                 indicator_list = list(indicators.groups())
 
         return indicator_list
 
-    def add_group(self, group_data: dict, **kwargs) -> Union[dict, 'GroupType']:
+    def add_group(self, group_data: dict, **kwargs) -> dict | GroupType:
         """Add a group to Batch Job.
 
         .. code-block:: javascript
 
             {
                 "name": "Example Incident",
                 "type": "Incident",
@@ -341,21 +337,22 @@
             }
 
         Args:
             group_data: The full Group data including attributes, labels, tags, and
                 associations.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             (dict|GroupType): The new group dict/GroupType or the previously stored dict/GroupType.
         """
         return self._group(group_data, kwargs.get('store', True))
 
-    def add_indicator(self, indicator_data: dict, **kwargs) -> Union[dict, 'IndicatorType']:
+    def add_indicator(self, indicator_data: dict, **kwargs) -> dict | IndicatorType:
         """Add an indicator to Batch Job.
 
         .. code-block:: javascript
 
             {
                 "type": "File",
                 "rating": 5.00,
@@ -384,146 +381,158 @@
             }
 
         Args:
             indicator_data: The Full Indicator data including attributes, labels, tags,
                 and associations.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             (dict|IndicatorType): The new group dict/IndicatorType
             or the previously stored dict/IndicatorType.
         """
         if indicator_data.get('type') not in ['Address', 'EmailAddress', 'File', 'Host', 'URL']:
             # for custom indicator types the valueX fields are required.
             # using the summary we can build the values
             index = 1
-            for value in self._indicator_values(indicator_data.get('summary')):
+            for value in self._indicator_values(indicator_data['summary']):
                 indicator_data[f'value{index}'] = value
                 index += 1
+
         if indicator_data.get('type') == 'File':
             # convert custom field name to the appropriate value for batch v2
             size = indicator_data.pop('size', None)
             if size is not None:
                 indicator_data['intValue1'] = size
+
         if indicator_data.get('type') == 'Host':
             # convert custom field name to the appropriate value for batch v2
             dns_active = indicator_data.pop('dnsActive', None)
+
             if dns_active is not None:
                 indicator_data['flag1'] = dns_active
             whois_active = indicator_data.pop('whoisActive', None)
+
             if whois_active is not None:
                 indicator_data['flag2'] = whois_active
+
         return self._indicator(indicator_data, kwargs.get('store', True))
 
-    def address(self, ip: str, **kwargs) -> 'Address':
+    def address(self, ip: str, **kwargs) -> Address | dict:
         """Add Address data to Batch.
 
         Args:
             ip: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Address: An instance of the Address class.
         """
         indicator_obj = Address(ip, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def adversary(self, name: str, **kwargs) -> 'Adversary':
+    def adversary(self, name: str, **kwargs) -> Adversary:
         """Add Adversary data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Adversary: An instance of the Adversary class.
         """
         group_obj = Adversary(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def attack_pattern(self, name: str, **kwargs) -> 'AttackPattern':
+    def attack_pattern(self, name: str, **kwargs) -> AttackPattern:
         """Add Attack Pattern data to Batch object.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             AttackPattern: An instance of the AttackPattern class.
         """
         group_obj = AttackPattern(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def asn(self, as_number: str, **kwargs) -> 'ASN':
+    def asn(self, as_number: str, **kwargs) -> ASN:
         """Add ASN data to Batch.
 
         Args:
             as_number: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             ASN: An instance of the ASN class.
         """
         indicator_obj = ASN(as_number, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def campaign(self, name: str, **kwargs) -> 'Campaign':
+    def campaign(self, name: str, **kwargs) -> Campaign:
         """Add Campaign data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             first_seen (str, kwargs): The first seen datetime expression for this Group.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Campaign: An instance of the Campaign class.
         """
         group_obj = Campaign(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def cidr(self, block: str, **kwargs) -> 'CIDR':
+    def cidr(self, block: str, **kwargs) -> CIDR:
         """Add CIDR data to Batch.
 
         Args:
             block: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             CIDR: An instance of the CIDR class.
         """
         indicator_obj = CIDR(block, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
     def close(self):
         """Cleanup batch job."""
         self.dump()
 
         # cleanup shelf files
         try:
@@ -537,29 +546,30 @@
             self.indicators_shelf.close()
             os.unlink(self.indicator_shelf_fqfn)
         except Exception as ex:
             self.log.warning(
                 f'action=batch-close, filename={self.indicator_shelf_fqfn} exception={ex}'
             )
 
-    def course_of_action(self, name: str, **kwargs) -> 'CourseOfAction':
+    def course_of_action(self, name: str, **kwargs) -> CourseOfAction:
         """Add Course Of Action Pattern data to Batch object.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             CourseOfAction: An instance of the CourseOfAction class.
         """
         group_obj = CourseOfAction(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
     @property
     def data(self) -> dict:
         """Return the batch indicator/group and file data to be sent to the ThreatConnect API.
 
         **Processing Order:**
         * Process groups in memory up to max batch size.
@@ -627,15 +637,15 @@
                 # update entity trackers
                 tracker['count'] += 1
 
                 # extend xids with any groups associated with the same GroupType
                 xids.extend(group_data.get('associatedGroupXid', []))
 
     @staticmethod
-    def data_group_type(group_data: Union[dict, 'GroupType']) -> Tuple[dict, dict]:
+    def data_group_type(group_data: dict | GroupType) -> tuple[dict, dict]:
         """Return dict representation of group data and file data.
 
         Args:
             group_data: The group data.
 
         Returns:
             Tuple[dict, dict]: A tuple containing file_data and group_data.
@@ -654,15 +664,15 @@
             # get the file data from the GroupType and return dict format of GroupType
             if group_data.data.get('type') in ['Document', 'Report']:
                 file_data = group_data.file_data
             group_data = group_data.data
 
         return file_data, group_data
 
-    def data_groups(self, data: dict, groups: list, tracker: dict) -> bool:
+    def data_groups(self, data: dict, groups: dict | shelve.Shelf[Any], tracker: dict) -> bool:
         """Process Group data.
 
         Args:
             data: The data dict to update with group and file data.
             groups: The list of groups to process.
             tracker: A dict containing total count of all entities collected.
 
@@ -673,23 +683,25 @@
         # the data_group_association function deleting items from the GroupType.
 
         # process the group
         for xid in list(groups.keys()):
             # get association from group data
             self.data_group_association(data, tracker, xid)
 
-            if tracker.get('count') % 10_000 == 0:
+            if tracker['count'] % 10_000 == 0:
                 # log count/size at a sane level
                 self.log.debug(
                     '''feature=batch, action=data-groups, ''' f'''count={tracker.get('count'):,}'''
                 )
 
         return False
 
-    def data_indicators(self, data: dict, indicators: list, tracker: dict) -> bool:
+    def data_indicators(
+        self, data: dict, indicators: dict | shelve.Shelf[Any], tracker: dict
+    ) -> bool:
         """Process Indicator data.
 
         Args:
             data: The data dict to update with group and file data.
             indicators: The list of indicators to process.
             tracker: A dict containing total count of all entities collected.
 
@@ -702,132 +714,136 @@
                 indicator_data = indicator_data.data
             data['indicator'].append(indicator_data)
             del indicators[xid]
 
             # update entity trackers
             tracker['count'] += 1
 
-            if tracker.get('count') % 10_000 == 0:
+            if tracker['count'] % 10_000 == 0:
                 # log count/size at a sane level
                 self.log.debug(
                     '''feature=batch, action=data-indicators, '''
                     f'''count={tracker.get('count'):,}'''
                 )
 
         return False
 
-    def document(self, name: str, file_name: str, **kwargs) -> 'Document':
+    def document(self, name: str, file_name: str, **kwargs) -> Document:
         """Add Document data to Batch.
 
         Args:
             name: The name for this Group.
             file_name: The name for the attached file for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             file_content (str;method, kwargs): The file contents or
                 callback method to retrieve file content.
             malware (bool, kwargs): If true the file is considered malware.
             password (bool, kwargs): If malware is true a password for the zip archive is
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Document: An instance of the Document class.
         """
         group_obj = Document(name, file_name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
     def dump(self):
         """Process Batch request to ThreatConnect API."""
         content = self.data
         content.pop('file', {})
         if not content.get('group') and not content.get('indicator'):
             return
 
         # special code for debugging App using batchV2.
         self.write_batch_json(content)
 
         # store the length of the batch data to use for poll interval calculations
         self.log.info(
-            '''feature=batch, event=dump, type=group, ''' f'''count={len(content.get('group')):,}'''
+            '''feature=batch, event=dump, type=group, ''' f'''count={len(content['group']):,}'''
         )
         self.log.info(
             '''feature=batch, event=dump, type=indicator, '''
-            f'''count={len(content.get('indicator')):,}'''
+            f'''count={len(content['indicator']):,}'''
         )
         self.log.info(f'''feature=batch, event=dump, type=batch, size={self._batch_size:,}''')
 
         # reset batch size after dump
         self._batch_size = 0
 
-    def email(self, name: str, subject: str, header: str, body: str, **kwargs) -> 'Email':
+    def email(self, name: str, subject: str, header: str, body: str, **kwargs) -> Email:
         """Add Email data to Batch.
 
         Args:
             name: The name for this Group.
             subject: The subject for this Email.
             header: The header for this Email.
             body: The body for this Email.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             from_addr (str, kwargs): The **from** address for this Email.
             to_addr (str, kwargs): The **to** address for this Email.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Email: An instance of the Email class.
         """
         group_obj = Email(name, subject, header, body, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def email_address(self, address: str, **kwargs) -> 'EmailAddress':
+    def email_address(self, address: str, **kwargs) -> EmailAddress:
         """Add Email Address data to Batch.
 
         Args:
             address: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             EmailAddress: An instance of the EmailAddress class.
         """
         indicator_obj = EmailAddress(address, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def event(self, name: str, **kwargs) -> 'Event':
+    def event(self, name: str, **kwargs) -> Event:
         """Add Event data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             event_date (str, kwargs): The event datetime expression for this Group.
             status (str, kwargs): The status for this Group.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Event: An instance of the Event class.
         """
         group_obj = Event(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
     def file(
         self,
-        md5: Optional[str] = None,
-        sha1: Optional[str] = None,
-        sha256: Optional[str] = None,
+        md5: str | None = None,
+        sha1: str | None = None,
+        sha256: str | None = None,
         **kwargs,
-    ) -> 'File':
+    ) -> File:
         """Add File data to Batch.
 
         .. note:: A least one file hash value must be specified.
 
         Args:
             md5: The md5 value for this Indicator.
             sha1: The sha1 value for this Indicator.
@@ -836,53 +852,54 @@
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             size (str, kwargs): The file size for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             File: An instance of the File class.
 
         """
         indicator_obj = File(md5, sha1, sha256, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
     @staticmethod
-    def generate_xid(identifier: Optional[Union[list, str]] = None) -> str:
+    def generate_xid(identifier: list | str | None = None) -> str:
         """Generate xid from provided identifiers.
 
         .. Important::  If no identifier is provided a unique xid will be returned, but it will
                         not be reproducible. If a list of identifiers are provided they must be
                         in the same order to generate a reproducible xid.
 
         Args:
-            identifier:  Optional *string* value(s) to be
-               used to make a unique and reproducible xid.
+            identifier:  Value(s) to be used to make a unique and reproducible xid.
 
         """
         if identifier is None:
             identifier = str(uuid.uuid4())
         elif isinstance(identifier, list):
             identifier = '-'.join([str(i) for i in identifier])
             # IMPORTANT: Do not remove this duplicate line or xids will change.
             identifier = hashlib.sha256(identifier.encode('utf-8')).hexdigest()
         return hashlib.sha256(identifier.encode('utf-8')).hexdigest()
 
-    def group(self, group_type: str, name: str, **kwargs) -> 'GroupType':
+    def group(self, group_type: str, name: str, **kwargs) -> GroupType | dict:
         """Add Group data to Batch.
 
         Args:
             group_type: The ThreatConnect define Group type.
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             GroupType: An instance of one of the Group classes.
         """
         group_obj = Group(group_type, name, **kwargs)
         return self._group(group_obj, kwargs.get('store', True))
 
@@ -900,83 +917,85 @@
             )
         return self._group_shelf_fqfn
 
     @property
     def groups(self) -> dict:
         """Return dictionary of all Groups data."""
         if self._groups is None:
-            # plain dict, but could be something else in future
             self._groups = {}
         return self._groups
 
     @property
-    def groups_shelf(self) -> 'shelve.DbfilenameShelf':
+    def groups_shelf(self) -> shelve.Shelf[Any]:
         """Return dictionary of all Groups data."""
         if self._groups_shelf is None:
             self._groups_shelf = shelve.open(self.group_shelf_fqfn, writeback=False)  # nosec
         return self._groups_shelf
 
-    def host(self, hostname: str, **kwargs) -> 'Host':
+    def host(self, hostname: str, **kwargs) -> Host:
         """Add Host data to Batch.
 
         Args:
             hostname: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             dns_active (bool, kwargs): If True DNS active is enabled for this indicator.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             whois_active (bool, kwargs): If True WhoIs active is enabled for this indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Host: An instance of the Host class.
         """
         indicator_obj = Host(hostname, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def incident(self, name: str, **kwargs) -> 'Incident':
+    def incident(self, name: str, **kwargs) -> Incident:
         """Add Incident data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             event_date (str, kwargs): The event datetime expression for this Group.
             status (str, kwargs): The status for this Group.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Incident: An instance of the Incident class.
         """
         group_obj = Incident(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def indicator(self, indicator_type: str, summary: str, **kwargs) -> 'IndicatorType':
+    def indicator(self, indicator_type: str, summary: str, **kwargs) -> IndicatorType:
         """Add Indicator data to Batch.
 
         Args:
             indicator_type: The ThreatConnect define Indicator type.
             summary: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             IndicatorType: An instance of one of the Indicator classes.
         """
         indicator_obj = Indicator(indicator_type, summary, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
     @property
     def indicator_shelf_fqfn(self) -> str:
         """Return indicator shelf fully qualified filename.
 
         For testing/debugging a previous shelf file can be copied into the tc_temp_path directory
         instead of creating a new shelf file.
@@ -993,117 +1012,122 @@
         """Return dictionary of all Indicator data."""
         if self._indicators is None:
             # plain dict, but could be something else in future
             self._indicators = {}
         return self._indicators
 
     @property
-    def indicators_shelf(self) -> 'shelve.DbfilenameShelf':
+    def indicators_shelf(self) -> shelve.Shelf[Any]:
         """Return dictionary of all Indicator data."""
         if self._indicators_shelf is None:
             self._indicators_shelf = shelve.open(  # nosec
                 self.indicator_shelf_fqfn, writeback=False
             )
         return self._indicators_shelf
 
-    def intrusion_set(self, name: str, **kwargs) -> 'IntrusionSet':
+    def intrusion_set(self, name: str, **kwargs) -> IntrusionSet:
         """Add Intrusion Set data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             IntrusionSet: An instance of the IntrusionSet class.
         """
         group_obj = IntrusionSet(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def malware(self, name: str, **kwargs) -> 'Malware':
+    def malware(self, name: str, **kwargs) -> Malware:
         """Add Malware data to Batch object.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Malware: An instance of the Malware class.
         """
         group_obj = Malware(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def mutex(self, mutex: str, **kwargs) -> 'Mutex':
+    def mutex(self, mutex: str, **kwargs) -> Mutex:
         """Add Mutex data to Batch.
 
         Args:
             mutex: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Mutex: An instance of the Mutex class.
         """
         indicator_obj = Mutex(mutex, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
     def registry_key(
         self, key_name: str, value_name: str, value_type: str, **kwargs
-    ) -> 'RegistryKey':
+    ) -> RegistryKey:
         """Add Registry Key data to Batch.
 
         Args:
             key_name: The key_name value for this Indicator.
             value_name: The value_name value for this Indicator.
             value_type: The value_type value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             RegistryKey: An instance of the Registry Key class.
         """
         indicator_obj = RegistryKey(key_name, value_name, value_type, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def report(self, name: str, **kwargs) -> 'Report':
+    def report(self, name: str, **kwargs) -> Report:
         """Add Report data to Batch.
 
         Args:
             name: The name for this Group.
             file_name (str): The name for the attached file for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             file_content (str;method, kwargs): The file contents or callback method to retrieve
                 file content.
             publish_date (str, kwargs): The publish datetime expression for this Group.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Report: An instance of the Report class.
         """
         group_obj = Report(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def save(self, resource: Union[dict, 'GroupType', 'IndicatorType']):
+    def save(self, resource: dict | GroupType | IndicatorType):
         """Save group|indicator dict, GroupType, or IndicatorTypes to shelve.
 
         Best effort to save group/indicator data to disk.  If for any reason the save fails
         the data will still be accessible from list in memory.
 
         Args:
             resource: The Group or Indicator data.
@@ -1145,15 +1169,15 @@
                         del self.indicators[xid]
                     except KeyError:
                         # if indicator was saved twice it would already be delete
                         pass
 
     def signature(
         self, name: str, file_name: str, file_type: str, file_text: str, **kwargs
-    ) -> 'Signature':
+    ) -> Signature:
         """Add Signature data to Batch.
 
         Valid file_types:
         + Snort 
         + Suricata
         + YARA
         + ClamAV 
@@ -1168,122 +1192,133 @@
             file_name: The name for the attached signature for this Group.
             file_type: The signature type for this Group.
             file_text: The signature content for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Signature: An instance of the Signature class.
         """
         group_obj = Signature(name, file_name, file_type, file_text, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def tactic(self, name: str, **kwargs) -> 'Tactic':
+    def tactic(self, name: str, **kwargs) -> Tactic:
         """Add Tactic data to Batch object.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Tactic: An instance of the Tactic class.
         """
         group_obj = Tactic(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def threat(self, name: str, **kwargs) -> 'Threat':
+    def threat(self, name: str, **kwargs) -> Threat:
         """Add Threat data to Batch.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Threat: An instance of the Threat class.
         """
         group_obj = Threat(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def tool(self, name: str, **kwargs) -> 'Tool':
+    def tool(self, name: str, **kwargs) -> Tool:
         """Add Tool data to Batch object.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             Tool: An instance of the Tool class.
         """
         group_obj = Tool(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
-    def user_agent(self, text: str, **kwargs) -> 'UserAgent':
+    def user_agent(self, text: str, **kwargs) -> UserAgent:
         """Add User Agent data to Batch.
 
         Args:
             text: The value for this Indicator.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
+            **kwargs: Additional keyword arguments.
 
         Returns:
             UserAgent: An instance of the UserAgent class.
         """
         indicator_obj = UserAgent(text, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def url(self, text: str, **kwargs) -> 'URL':
+    def url(self, text: str, **kwargs) -> URL:
         """Add URL Address data to Batch.
 
         Args:
-            text (str): The value for this Indicator.
+            text: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
 
         Returns:
             URL: An instance of the URL class.
         """
         indicator_obj = URL(text, **kwargs)
-        return self._indicator(indicator_obj, kwargs.get('store', True))
+        return self._indicator(indicator_obj, kwargs.get('store', True))  # type: ignore
 
-    def vulnerability(self, name: str, **kwargs) -> 'Vulnerability':
+    def vulnerability(self, name: str, **kwargs) -> Vulnerability:
         """Add Vulnerability data to Batch.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
             store: (bool, kwargs): Advanced - Defaults to True. If True
                 the indicator data will be stored in instance list.
 
         Returns:
             Vulnerability: An instance of the Vulnerability class.
         """
         group_obj = Vulnerability(name, **kwargs)
-        return self._group(group_obj, kwargs.get('store', True))
+        return self._group(group_obj, kwargs.get('store', True))  # type: ignore
 
     def write_batch_json(self, content: dict):
         """Write batch json data to a file."""
         if content:
             # get timestamp as a string without decimal place and consistent length
             filename = f'{str(round(time.time() * 10000000))}.json.gz'
             if self.output_extension is not None:
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/group.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/group.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,18 +1,19 @@
-"""ThreatConnect Batch Import Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import uuid
-from typing import Any, Callable, Optional, Union
+from collections.abc import Callable
+from typing import Any
 
 # first-party
 from tcex.api.tc.v2.batch.attribute import Attribute
 from tcex.api.tc.v2.batch.security_label import SecurityLabel
 from tcex.api.tc.v2.batch.tag import Tag
-from tcex.utils import Utils
+from tcex.util import Util
 
 
 class Group:
     """ThreatConnect Batch Group Object"""
 
     __slots__ = [
         '_attributes',
@@ -23,36 +24,39 @@
         '_processed',
         '_type',
         '_tags',
         'file_content',
         'malware',
         'password',
         'status',
-        'utils',
+        'util',
     ]
 
     def __init__(self, group_type: str, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             group_type (str): The ThreatConnect define Group type.
             name (str): The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             xid (str, kwargs): The external id for this Group.
         """
         self._name = name
-        self._group_data = {'name': name, 'type': group_type}
+        self._group_data: dict[str, bool | int | list | str] = {'name': name, 'type': group_type}
         self._type = group_type
 
         # properties
         self._attributes = []
         self._labels = []
         self._file_content = None
         self._tags = []
         self._processed = False
-        self.utils = Utils()
+        self.util = Util()
 
         # process all kwargs and update metadata field names
         for arg, value in kwargs.items():
             self.add_key_value(arg, value)
         # set xid to random and unique uuid4 value if not provided
         if kwargs.get('xid') is None:
             self._group_data['xid'] = str(uuid.uuid4())
@@ -68,15 +72,15 @@
             'file_type': 'fileType',
             'first_seen': 'firstSeen',
             'from_addr': 'from',
             'publish_date': 'publishDate',
             'to_addr': 'to',
         }
 
-    def add_file(self, filename: str, file_content: Union[bytes, Callable[[str], Any], str]):
+    def add_file(self, filename: str, file_content: bytes | Callable[[str], Any] | str):
         """Add a file for Document and Report types.
 
         Example::
 
             document = tcex.batch.group('Document', 'My Document')
             document.add_file('my_file.txt', 'my contents')
 
@@ -100,39 +104,39 @@
         Args:
             key: The field key to add to the JSON batch data.
             value: The field value to add to the JSON batch data.
         """
         key = self._metadata_map.get(key, key)
         if key in ['dateAdded', 'eventDate', 'firstSeen', 'publishDate']:
             if value is not None:
-                self._group_data[key] = self.utils.any_to_datetime(value).strftime(
+                self._group_data[key] = self.util.any_to_datetime(value).strftime(
                     '%Y-%m-%dT%H:%M:%SZ'
                 )
         elif key == 'file_content':
             # file content arg is not part of Group JSON
             pass
         else:
             self._group_data[key] = value
 
     def association(self, group_xid: str):
         """Add association using xid value.
 
         Args:
             group_xid: The external id of the Group to associate.
         """
-        self._group_data.setdefault('associatedGroupXid', []).append(group_xid)
+        self._group_data.setdefault('associatedGroupXid', []).append(group_xid)  # type: ignore
 
     def attribute(
         self,
         attr_type: str,
         attr_value: str,
-        displayed: Optional[bool] = False,
-        source: Optional[str] = None,
-        unique: Optional[bool] = True,
-        formatter: Optional[Callable[[str], str]] = None,
+        displayed: bool = False,
+        source: str | None = None,
+        unique: bool = True,
+        formatter: Callable[[str], str] | None = None,
     ) -> Attribute:
         """Return instance of Attribute
 
         unique:
             * False - Attribute type:value can be duplicated.
             * 'Type' - Attribute type has to be unique (e.g., only 1 Description Attribute).
             * True - Attribute type:value combo must be unique.
@@ -186,22 +190,22 @@
             self._group_data['tag'] = []
             for tag in self._tags:
                 if tag.valid:
                     self._group_data['tag'].append(tag.data)
         return self._group_data
 
     @property
-    def date_added(self) -> str:
+    def date_added(self) -> str | None:
         """Return Group dateAdded."""
-        return self._group_data.get('dateAdded')
+        return self._group_data.get('dateAdded')  # type: ignore
 
     @date_added.setter
     def date_added(self, date_added: str):
         """Set Indicator dateAdded."""
-        self._group_data['dateAdded'] = self.utils.any_to_datetime(date_added).strftime(
+        self._group_data['dateAdded'] = self.util.any_to_datetime(date_added).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     @property
     def file_data(self) -> dict:
         """Return Group file (only supported for Document and Report)."""
         return {
@@ -209,15 +213,15 @@
             'fileName': self._group_data.get('fileName'),
             'type': self._group_data.get('type'),
         }
 
     @property
     def name(self) -> str:
         """Return Group name."""
-        return self._group_data.get('name')
+        return self._group_data.get('name')  # type: ignore
 
     @property
     def processed(self) -> bool:
         """Return processed value.
 
         .. note:: Processed value indicates that a group with this xid has already been processed.
         """
@@ -225,15 +229,15 @@
 
     @processed.setter
     def processed(self, processed: bool):
         """Set processed."""
         self._processed = processed
 
     def security_label(
-        self, name: str, description: Optional[str] = None, color: Optional[str] = None
+        self, name: str, description: str | None = None, color: str | None = None
     ) -> SecurityLabel:
         """Return instance of SecurityLabel.
 
         .. note:: The provided security label will be create if it doesn't exist. If the security
             label already exists nothing will be changed.
 
         Args:
@@ -249,15 +253,15 @@
             if label_data.name == name:
                 label = label_data
                 break
         else:
             self._labels.append(label)
         return label
 
-    def tag(self, name: str, formatter: Optional[Callable[[str], str]] = None) -> 'Tag':
+    def tag(self, name: str, formatter: Callable[[str], str] | None = None) -> Tag:
         """Return instance of Tag.
 
         Args:
             name: The value for this tag.
             formatter: A callable that take a tag value and returns a formatted tag.
 
         Returns:
@@ -271,117 +275,132 @@
         else:
             self._tags.append(tag)
         return tag
 
     @property
     def type(self) -> str:
         """Return Group type."""
-        return self._group_data.get('type')
+        return self._group_data.get('type')  # type: ignore
 
     @property
     def xid(self) -> str:
         """Return Group xid."""
-        return self._group_data.get('xid')
+        return self._group_data.get('xid')  # type: ignore
 
     def __str__(self) -> str:
         """Return string representation of object."""
         return json.dumps(self.data, indent=4)
 
 
 class Adversary(Group):
     """ThreatConnect Batch Adversary Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Adversary', name, **kwargs)
 
 
 class AttackPattern(Group):
     """ThreatConnect Batch Attack Pattern Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Attack Pattern', name, **kwargs)
 
 
 class Campaign(Group):
     """ThreatConnect Batch Campaign Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             first_seen (str, kwargs): The first seen datetime expression for this Group.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Campaign', name, **kwargs)
 
     @property
     def first_seen(self) -> str:
         """Return Document first seen."""
-        return self._group_data.get('firstSeen')
+        return self._group_data.get('firstSeen')  # type: ignore
 
     @first_seen.setter
     def first_seen(self, first_seen: str):
         """Set Document first seen."""
-        self._group_data['firstSeen'] = self.utils.any_to_datetime(first_seen).strftime(
+        self._group_data['firstSeen'] = self.util.any_to_datetime(first_seen).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
 
 class CourseOfAction(Group):
     """ThreatConnect Batch Course Of Action Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Course of Action', name, **kwargs)
 
 
 class Document(Group):
     """ThreatConnect Batch Document Object"""
 
     __slots__ = ['_file_data']
 
     def __init__(self, name: str, file_name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
             file_name: The name for the attached file for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             file_content (str;method, kwargs): The file contents or callback method to retrieve
-                                               file content.
+                file content.
             malware (bool, kwargs): If true the file is considered malware.
             password (bool, kwargs): If malware is true a password for the zip archive is required.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Document', name, **kwargs)
         self._group_data['fileName'] = file_name
         # file data/content to upload
@@ -395,177 +414,186 @@
             'fileName': self._group_data.get('fileName'),
             'type': self._group_data.get('type'),
         }
 
     @property
     def malware(self) -> bool:
         """Return Document malware."""
-        return self._group_data.get('malware', False)
+        return self._group_data.get('malware', False)  # type: ignore
 
     @malware.setter
     def malware(self, malware: bool):
         """Set Document malware."""
-        self._group_data['malware'] = malware
+        self._group_data['malware'] = malware  # type: ignore
 
     @property
     def password(self) -> str:
         """Return Document password."""
-        return self._group_data.get('password', False)
+        return self._group_data.get('password', False)  # type: ignore
 
     @password.setter
     def password(self, password: str):
         """Set Document password."""
         self._group_data['password'] = password
 
 
 class Email(Group):
     """ThreatConnect Batch Email Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, subject: str, header: str, body: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
             subject: The subject for this Email.
             header: The header for this Email.
             body: The body for this Email.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             from_addr (str, kwargs): The **from** address for this Email.
             to_addr (str, kwargs): The **to** address for this Email.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Email', name, **kwargs)
         self._group_data['subject'] = subject
         self._group_data['header'] = header
         self._group_data['body'] = body
         self._group_data['score'] = 0
 
     @property
     def from_addr(self) -> str:
         """Return Email to."""
-        return self._group_data.get('to')
+        return self._group_data.get('to')  # type: ignore
 
     @from_addr.setter
     def from_addr(self, from_addr: str):
         """Set Email from."""
         self._group_data['from'] = from_addr
 
     @property
     def score(self) -> str:
         """Return Email to."""
-        return self._group_data.get('score')
+        return self._group_data.get('score')  # type: ignore
 
     @score.setter
     def score(self, score: str):
         """Set Email from."""
         self._group_data['score'] = score
 
     @property
     def to_addr(self) -> str:
         """Return Email to."""
-        return self._group_data.get('to')
+        return self._group_data.get('to')  # type: ignore
 
     @to_addr.setter
     def to_addr(self, to_addr: str):
         """Set Email to."""
         self._group_data['to'] = to_addr
 
 
 class Event(Group):
     """ThreatConnect Batch Event Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Valid Values:
         + Escalated
         + False Positive
         + Needs Review
         + No Further Action
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             event_date (str, kwargs): The event datetime expression for this Group.
             status (str, kwargs): The status for this Group.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Event', name, **kwargs)
 
     @property
     def event_date(self) -> str:
         """Return the Events "event date" value."""
-        return self._group_data.get('firstSeen')
+        return self._group_data.get('firstSeen')  # type: ignore
 
     @event_date.setter
     def event_date(self, event_date: str):
         """Set the Events "event date" value."""
-        self._group_data['eventDate'] = self.utils.any_to_datetime(event_date).strftime(
+        self._group_data['eventDate'] = self.util.any_to_datetime(event_date).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     @property
     def status(self) -> str:
         """Return the Events status value."""
-        return self._group_data.get('status')
+        return self._group_data.get('status')  # type: ignore
 
     @status.setter
     def status(self, status: str):
         """Set the Events status value."""
         self._group_data['status'] = status
 
 
 class Incident(Group):
     """ThreatConnect Batch Incident Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Valid Values:
         + Closed
         + Containment Achieved
         + Deleted
         + Incident Reported
         + Open
         + New
         + Rejected
         + Restoration Achieved
         + Stalled
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             event_date (str, kwargs): The event datetime expression for this Group.
             status (str, kwargs): The status for this Group.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Incident', name, **kwargs)
 
     @property
     def event_date(self) -> str:
         """Return Incident event date."""
-        return self._group_data.get('eventDate')
+        return self._group_data.get('eventDate')  # type: ignore
 
     @event_date.setter
     def event_date(self, event_date: str):
         """Set Incident event_date."""
-        self._group_data['eventDate'] = self.utils.any_to_datetime(event_date).strftime(
+        self._group_data['eventDate'] = self.util.any_to_datetime(event_date).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     @property
     def status(self) -> str:
         """Return Incident status."""
-        return self._group_data.get('status')
+        return self._group_data.get('status')  # type: ignore
 
     @status.setter
     def status(self, status: str):
         """Set Incident status.
 
         Valid Values:
         + New
@@ -583,54 +611,63 @@
 
 class IntrusionSet(Group):
     """ThreatConnect Batch Intrusion Set Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Intrusion Set', name, **kwargs)
 
 
 class Malware(Group):
     """ThreatConnect Batch Malware Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Malware', name, **kwargs)
 
 
 class Report(Group):
     """ThreatConnect Batch Report Object"""
 
     __slots__ = []
 
     def __init__(self, name, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             file_name (str, kwargs): The name for the attached file for this Group.
             file_content (str;method, kwargs): The file contents or callback method to retrieve
-                                               file content.
+                file content.
             publish_date (str, kwargs): The publish datetime expression for this Group.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Report', name, **kwargs)
         # file data/content to upload
         self._file_content = kwargs.get('file_content')
 
@@ -642,31 +679,31 @@
             'fileName': self._group_data.get('fileName'),
             'type': self._group_data.get('type'),
         }
 
     @property
     def publish_date(self) -> str:
         """Return Report publish date."""
-        return self._group_data.get('publishDate')
+        return self._group_data.get('publishDate')  # type: ignore
 
     @publish_date.setter
     def publish_date(self, publish_date: str):
         """Set Report publish date"""
-        self._group_data['publishDate'] = self.utils.any_to_datetime(publish_date).strftime(
+        self._group_data['publishDate'] = self.util.any_to_datetime(publish_date).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
 
 class Signature(Group):
     """ThreatConnect Batch Signature Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, file_name: str, file_type: str, file_text: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Valid file_types:
         + Snort 
         + Suricata
         + YARA
         + ClamAV 
         + OpenIOC
@@ -676,14 +713,17 @@
         + SPL - Splunk  Search Processing Language
 
         Args:
             name: The name for this Group.
             file_name: The name for the attached signature for this Group.
             file_type: The signature type for this Group.
             file_text: The signature content for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Signature', name, **kwargs)
         self._group_data['fileName'] = file_name
         self._group_data['fileType'] = file_type
         self._group_data['fileText'] = file_text
@@ -691,63 +731,75 @@
 
 class Tactic(Group):
     """ThreatConnect Batch Tactic Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Tactic', name, **kwargs)
 
 
 class Threat(Group):
     """ThreatConnect Batch Threat Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
             date_added (str, kwargs): The date timestamp the Indicator was created.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Threat', name, **kwargs)
 
 
 class Tool(Group):
     """ThreatConnect Batch Tool Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Tool', name, **kwargs)
 
 
 class Vulnerability(Group):
     """ThreatConnect Batch Vulnerability Object"""
 
     __slots__ = []
 
     def __init__(self, name: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             name: The name for this Group.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             date_added (str, kwargs): The date timestamp the Indicator was created.
             xid (str, kwargs): The external id for this Group.
         """
         super().__init__('Vulnerability', name, **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/indicator.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/indicator.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,23 +1,27 @@
-"""ThreatConnect Batch Import Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import uuid
-from typing import Callable, Optional
+from collections.abc import Callable
+from typing import ForwardRef
 
 # first-party
 from tcex.api.tc.v2.batch.attribute import Attribute
 from tcex.api.tc.v2.batch.security_label import SecurityLabel
 from tcex.api.tc.v2.batch.tag import Tag
-from tcex.utils import Utils
+from tcex.util import Util
+
+FileOccurrences = ForwardRef('FileOccurrences')
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 
+# pylint: disable=unnecessary-dunder-call
 def custom_indicator_class_factory(indicator_type, base_class, class_dict, value_fields):
     """Return internal methods for dynamically building Custom Indicator Class."""
     value_count = len(value_fields)
 
     def init_1(self, tcex, value1, xid, **kwargs):  # pylint: disable=possibly-unused-variable
         """Init method for Custom Indicator Types with one value"""
         summary = self.build_summary(value1)  # build the indicator summary
@@ -41,58 +45,63 @@
         summary = self.build_summary(value1, value2, value3)  # build the indicator summary
         base_class.__init__(self, tcex, indicator_type, summary, xid, **kwargs)
         for k, v in class_dict.items():
             setattr(self, k, v)
 
     class_name = indicator_type.replace(' ', '')
     init_method = locals()[f'init_{value_count}']
-    newclass = type(str(class_name), (base_class,), {'__init__': init_method})
-    return newclass
+    return type(str(class_name), (base_class,), {'__init__': init_method})
 
 
 class Indicator:
     """ThreatConnect Batch Indicator Object"""
 
     __slots__ = [
         '_attributes',
         '_file_actions',
         '_indicator_data',
         '_labels',
         '_occurrences',
         '_summary',
         '_tags',
         '_type',
-        'utils',
+        'util',
     ]
 
     def __init__(self, indicator_type: str, summary: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             indicator_type: The ThreatConnect define Indicator type.
             summary: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
         """
         self._summary = summary
         self._type = indicator_type
-        self._indicator_data = {'summary': summary, 'type': indicator_type}
+        self._indicator_data: dict[str, bool | dict | float | int | list | str] = {
+            'summary': summary,
+            'type': indicator_type,
+        }
 
         # properties
         self._attributes = []
         self._file_actions = []
         self._labels = []
         self._occurrences = []
         self._tags = []
-        self.utils = Utils()
+        self.util = Util()
 
         # process all kwargs and update metadata field names
         for arg, value in kwargs.items():
             self.add_key_value(arg, value)
         # set xid to random and unique uuid4 value if not provided
         if kwargs.get('xid') is None:
             self._indicator_data['xid'] = str(uuid.uuid4())
@@ -123,51 +132,51 @@
 
         Args:
             key: The field key to add to the JSON batch data.
             value: The field value to add to the JSON batch data.
         """
         key = self._metadata_map.get(key, key)
         if key in ['dateAdded', 'lastModified']:
-            self._indicator_data[key] = self.utils.any_to_datetime(value).strftime(
+            self._indicator_data[key] = self.util.any_to_datetime(value).strftime(
                 '%Y-%m-%dT%H:%M:%SZ'
             )
         elif key == 'confidence':
             self._indicator_data[key] = int(value)
         elif key == 'rating':
             self._indicator_data[key] = float(value)
         else:
             self._indicator_data[key] = value
 
     @property
     def active(self) -> bool:
         """Return Indicator active."""
-        return self._indicator_data.get('active')
+        return self._indicator_data.get('active')  # type: ignore
 
     @active.setter
     def active(self, active: bool):
         """Set Indicator active."""
-        self._indicator_data['active'] = self.utils.to_bool(active)
+        self._indicator_data['active'] = self.util.to_bool(active)
 
     def association(self, group_xid: str):
         """Add association using xid value.
 
         Args:
             group_xid (str): The external id of the Group to associate.
         """
         association = {'groupXid': group_xid}
-        self._indicator_data.setdefault('associatedGroups', []).append(association)
+        self._indicator_data.setdefault('associatedGroups', []).append(association)  # type: ignore
 
     def attribute(
         self,
         attr_type: str,
         attr_value: str,
-        displayed: Optional[bool] = False,
-        source: Optional[str] = None,
-        unique: Optional[bool] = True,
-        formatter: Optional[Callable[[str], str]] = None,
+        displayed: bool = False,
+        source: str | None = None,
+        unique: bool = True,
+        formatter: Callable[[str], str] | None = None,
     ) -> Attribute:
         """Return instance of Attribute
 
         unique:
             * False - Attribute type:value can be duplicated.
             * Type - Attribute type has to be unique (e.g., only 1 Description Attribute).
             * True - Attribute type:value combo must be unique.
@@ -201,30 +210,30 @@
                 self._attributes.append(attr)
         elif unique is False:
             self._attributes.append(attr)
         return attr
 
     @staticmethod
     def build_summary(
-        val1: Optional[str] = None, val2: Optional[str] = None, val3: Optional[str] = None
+        val1: str | None = None, val2: str | None = None, val3: str | None = None
     ) -> str:
         """Build the Indicator summary using available values."""
         summary = []
         if val1 is not None:
             summary.append(val1)
         if val2 is not None:
             summary.append(val2)
         if val3 is not None:
             summary.append(val3)
         return ' : '.join(summary)
 
     @property
     def confidence(self) -> int:
         """Return Indicator confidence."""
-        return self._indicator_data.get('confidence')
+        return self._indicator_data.get('confidence')  # type: ignore
 
     @confidence.setter
     def confidence(self, confidence: int):
         """Set Indicator confidence."""
         self._indicator_data['confidence'] = int(confidence)
 
     @property
@@ -235,22 +244,22 @@
             self._indicator_data['attribute'] = []
             for attr in self._attributes:
                 if attr.valid:
                     self._indicator_data['attribute'].append(attr.data)
         # add file actions
         if self._file_actions:
             self._indicator_data.setdefault('fileAction', {})
-            self._indicator_data['fileAction'].setdefault('children', [])
+            self._indicator_data['fileAction'].setdefault('children', [])  # type: ignore
             for action in self._file_actions:
-                self._indicator_data['fileAction']['children'].append(action.data)
+                self._indicator_data['fileAction']['children'].append(action.data)  # type: ignore
         # add file occurrences
         if self._occurrences:
             self._indicator_data.setdefault('fileOccurrence', [])
             for occurrence in self._occurrences:
-                self._indicator_data['fileOccurrence'].append(occurrence.data)
+                self._indicator_data['fileOccurrence'].append(occurrence.data)  # type: ignore
         # add security labels
         if self._labels:
             self._indicator_data['securityLabel'] = []
             for label in self._labels:
                 self._indicator_data['securityLabel'].append(label.data)
         # add tags
         if self._tags:
@@ -259,41 +268,41 @@
                 if tag.valid:
                     self._indicator_data['tag'].append(tag.data)
         return self._indicator_data
 
     @property
     def date_added(self) -> str:
         """Return Indicator dateAdded."""
-        return self._indicator_data.get('dateAdded')
+        return self._indicator_data.get('dateAdded')  # type: ignore
 
     @date_added.setter
     def date_added(self, date_added: str):
         """Set Indicator dateAdded."""
-        self._indicator_data['dateAdded'] = self.utils.any_to_datetime(date_added).strftime(
+        self._indicator_data['dateAdded'] = self.util.any_to_datetime(date_added).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     @property
     def last_modified(self) -> str:
         """Return Indicator lastModified."""
-        return self._indicator_data.get('lastModified')
+        return self._indicator_data.get('lastModified')  # type: ignore
 
     @last_modified.setter
     def last_modified(self, last_modified: str):
         """Set Indicator lastModified."""
-        self._indicator_data['lastModified'] = self.utils.any_to_datetime(last_modified).strftime(
+        self._indicator_data['lastModified'] = self.util.any_to_datetime(last_modified).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     def occurrence(
         self,
-        file_name: Optional[str] = None,
-        path: Optional[str] = None,
-        date: Optional[str] = None,
-    ) -> 'FileOccurrence':
+        file_name: str | None = None,
+        path: str | None = None,
+        date: str | None = None,
+    ) -> 'FileOccurrence | None':
         """Add a file Occurrence.
 
         Args:
             file_name (str, optional): The file name for this occurrence.
             path (str, optional): The file path for this occurrence.
             date (str, optional): The datetime expression for this occurrence.
 
@@ -307,38 +316,38 @@
         occurrence_obj = FileOccurrence(file_name, path, date)
         self._occurrences.append(occurrence_obj)
         return occurrence_obj
 
     @property
     def private_flag(self) -> bool:
         """Return Indicator private flag."""
-        return self._indicator_data.get('privateFlag')
+        return self._indicator_data.get('privateFlag')  # type: ignore
 
     @private_flag.setter
     def private_flag(self, private_flag: bool):
         """Set Indicator private flag."""
-        self._indicator_data['privateFlag'] = self.utils.to_bool(private_flag)
+        self._indicator_data['privateFlag'] = self.util.to_bool(private_flag)
 
     @property
     def rating(self) -> float:
         """Return Indicator rating."""
-        return self._indicator_data.get('rating')
+        return self._indicator_data.get('rating')  # type: ignore
 
     @rating.setter
     def rating(self, rating: float):
         """Set Indicator rating."""
         self._indicator_data['rating'] = float(rating)
 
     @property
     def summary(self) -> str:
         """Return Indicator summary."""
-        return self._indicator_data.get('summary')
+        return self._indicator_data.get('summary')  # type: ignore
 
     def security_label(
-        self, name: str, description: Optional[str] = None, color: Optional[str] = None
+        self, name: str, description: str | None = None, color: str | None = None
     ) -> SecurityLabel:
         """Return instance of SecurityLabel.
 
         .. note:: The provided security label will be create if it doesn't exist. If the security
             label already exists nothing will be changed.
 
         Args:
@@ -354,15 +363,15 @@
             if label_data.name == name:
                 label = label_data
                 break
         else:
             self._labels.append(label)
         return label
 
-    def tag(self, name: str, formatter: Optional[Callable[[str], str]] = None) -> 'Tag':
+    def tag(self, name: str, formatter: Callable[[str], str] | None = None) -> Tag:
         """Return instance of Tag.
 
         Args:
             name: The value for this tag.
             formatter: A method that take a tag value and returns a formatted tag.
 
         Returns:
@@ -376,36 +385,39 @@
         else:
             self._tags.append(tag)
         return tag
 
     @property
     def type(self) -> str:
         """Return Group type."""
-        return self._indicator_data.get('type')
+        return self._indicator_data.get('type')  # type: ignore
 
     @property
     def xid(self) -> str:
         """Return Group xid."""
-        return self._indicator_data.get('xid')
+        return self._indicator_data.get('xid')  # type: ignore
 
     def __str__(self) -> str:
-        """Return string represtentation of object"""
+        """Return string representation of object"""
         return json.dumps(self.data, indent=4)
 
 
 class Address(Indicator):
     """ThreatConnect Batch Address Object"""
 
     __slots__ = []
 
     def __init__(self, ip: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ip: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -415,18 +427,21 @@
 
 class ASN(Indicator):
     """ThreatConnect Batch ASN Object."""
 
     __slots__ = []
 
     def __init__(self, as_number: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             as_number: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -436,18 +451,21 @@
 
 class CIDR(Indicator):
     """ThreatConnect Batch CIDR Object"""
 
     __slots__ = []
 
     def __init__(self, block: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             block: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -457,18 +475,21 @@
 
 class EmailAddress(Indicator):
     """ThreatConnect Batch EmailAddress Object"""
 
     __slots__ = []
 
     def __init__(self, address: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             address: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -479,25 +500,28 @@
 class File(Indicator):
     """ThreatConnect Batch File Object"""
 
     __slots__ = []
 
     def __init__(
         self,
-        md5: Optional[str] = None,
-        sha1: Optional[str] = None,
-        sha256: Optional[str] = None,
+        md5: str | None = None,
+        sha1: str | None = None,
+        sha256: str | None = None,
         **kwargs,
     ):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             md5: The md5 value for this Indicator.
             sha1: The sha1 value for this Indicator.
             sha256: The sha256 value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             size (str, kwargs): The file size for this Indicator.
@@ -505,69 +529,72 @@
         """
         summary = self.build_summary(md5, sha1, sha256)  # build the indicator summary
         super().__init__('File', summary, **kwargs)
         # self._file_action = []
 
     def action(self, relationship: str) -> 'FileAction':
         """Add a File Action."""
-        action_obj = FileAction(self._indicator_data.get('xid'), relationship)
+        action_obj = FileAction(self._indicator_data['xid'], relationship)  # type: ignore
         self._file_actions.append(action_obj)
         return action_obj
 
     @property
     def md5(self) -> str:
         """Return Indicator md5."""
-        return self._indicator_data.get('md5')
+        return self._indicator_data.get('md5')  # type: ignore
 
     @md5.setter
     def md5(self, md5: str):
         """Set Indicator md5."""
         self._indicator_data['md5'] = md5
 
     @property
     def sha1(self) -> str:
         """Return Indicator sha1."""
-        return self._indicator_data.get('sha1')
+        return self._indicator_data.get('sha1')  # type: ignore
 
     @sha1.setter
     def sha1(self, sha1: str):
         """Set Indicator sha1."""
         self._indicator_data['sha1'] = sha1
 
     @property
     def sha256(self) -> str:
         """Return Indicator sha256."""
-        return self._indicator_data.get('sha256')
+        return self._indicator_data.get('sha256')  # type: ignore
 
     @sha256.setter
     def sha256(self, sha256: str):
         """Set Indicator sha256."""
         self._indicator_data['sha256'] = sha256
 
     @property
     def size(self) -> int:
         """Return Indicator size."""
-        return self._indicator_data.get('intValue1')
+        return self._indicator_data.get('intValue1')  # type: ignore
 
     @size.setter
     def size(self, size: int):
         """Set Indicator size."""
         self._indicator_data['intValue1'] = size
 
 
 class Host(Indicator):
     """ThreatConnect Batch Host Object"""
 
     __slots__ = []
 
     def __init__(self, hostname: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             hostname: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             dns_active (bool, kwargs): If True DNS active is enabled for this indicator.
@@ -575,42 +602,45 @@
             xid (str, kwargs): The external id for this Indicator.
         """
         super().__init__('Host', hostname, **kwargs)
 
     @property
     def dns_active(self) -> bool:
         """Return Indicator dns active."""
-        return self._indicator_data.get('flag1')
+        return self._indicator_data.get('flag1')  # type: ignore
 
     @dns_active.setter
     def dns_active(self, dns_active: bool):
         """Set Indicator dns active."""
-        self._indicator_data['flag1'] = self.utils.to_bool(dns_active)
+        self._indicator_data['flag1'] = self.util.to_bool(dns_active)
 
     @property
     def whois_active(self) -> bool:
         """Return Indicator whois active."""
-        return self._indicator_data.get('flag2')
+        return self._indicator_data.get('flag2')  # type: ignore
 
     @whois_active.setter
     def whois_active(self, whois_active: bool):
         """Set Indicator whois active."""
-        self._indicator_data['flag2'] = self.utils.to_bool(whois_active)
+        self._indicator_data['flag2'] = self.util.to_bool(whois_active)
 
 
 class Mutex(Indicator):
     """ThreatConnect Batch Mutex Object"""
 
     __slots__ = []
 
     def __init__(self, mutex: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             mutex: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -620,20 +650,23 @@
 
 class RegistryKey(Indicator):
     """ThreatConnect Batch Registry Key Object"""
 
     __slots__ = []
 
     def __init__(self, key_name: str, value_name: str, value_type: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             key_name: The key_name value for this Indicator.
             value_name: The value_name value for this Indicator.
             value_type: The value_type value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -644,18 +677,21 @@
 
 class URL(Indicator):
     """ThreatConnect Batch URL Object"""
 
     __slots__ = []
 
     def __init__(self, text: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             text: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -665,18 +701,21 @@
 
 class UserAgent(Indicator):
     """ThreatConnect Batch User Agent Object"""
 
     __slots__ = []
 
     def __init__(self, text: str, **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             text: The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
@@ -686,15 +725,15 @@
 
 class FileAction:
     """ThreatConnect Batch FileAction Object"""
 
     __slots__ = ['_action_data', '_children', 'xid']
 
     def __init__(self, parent_xid: str, relationship):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         .. warning:: This code is not complete and may require some update to the API.
 
         Args:
             parent_xid: The external id of the parent Indicator.
             relationship: ???
         """
@@ -716,83 +755,83 @@
 
     def action(self, relationship):
         """Add a nested File Action."""
         action_obj = FileAction(self.xid, relationship)
         self._children.append(action_obj)
 
     def __str__(self) -> str:
-        """Return string represtentation of object."""
+        """Return string representation of object."""
         return json.dumps(self.data, indent=4)
 
 
 class FileOccurrence:
     """ThreatConnect Batch FileAction Object."""
 
-    __slots__ = ['_occurrence_data', 'utils']
+    __slots__ = ['_occurrence_data', 'util']
 
     def __init__(
         self,
-        file_name: Optional[str] = None,
-        path: Optional[str] = None,
-        date: Optional[str] = None,
+        file_name: str | None = None,
+        path: str | None = None,
+        date: str | None = None,
     ):
-        """Initialize Class Properties
+        """Initialize instance properties
 
         Args:
             file_name (str, optional): The file name for this occurrence.
             path (str, optional): The file path for this occurrence.
             date (str, optional): The datetime expression for this occurrence.
         """
         self._occurrence_data = {}
 
         # properties
-        self.utils = Utils()
+        self.util = Util()
 
         if file_name is not None:
             self._occurrence_data['fileName'] = file_name
         if path is not None:
             self._occurrence_data['path'] = path
         if date is not None:
-            self._occurrence_data['date'] = self.utils.any_to_datetime(date).strftime(
+            self._occurrence_data['date'] = self.util.any_to_datetime(date).strftime(
                 '%Y-%m-%dT%H:%M:%SZ'
             )
 
     @property
     def data(self) -> dict:
         """Return File Occurrence data."""
         return self._occurrence_data
 
     @property
     def date(self) -> str:
         """Return File Occurrence date."""
-        return self._occurrence_data.get('date')
+        return self._occurrence_data.get('date')  # type: ignore
 
     @date.setter
     def date(self, date: str):
         """Set File Occurrence date."""
-        self._occurrence_data['date'] = self.utils.any_to_datetime(date).strftime(
+        self._occurrence_data['date'] = self.util.any_to_datetime(date).strftime(
             '%Y-%m-%dT%H:%M:%SZ'
         )
 
     @property
     def file_name(self) -> str:
         """Return File Occurrence file name."""
-        return self._occurrence_data.get('fileName')
+        return self._occurrence_data.get('fileName')  # type: ignore
 
     @file_name.setter
     def file_name(self, file_name: str):
         """Set File Occurrence file name."""
         self._occurrence_data['fileName'] = file_name
 
     @property
     def path(self) -> str:
         """Return File Occurrence path."""
-        return self._occurrence_data.get('path')
+        return self._occurrence_data.get('path')  # type: ignore
 
     @path.setter
     def path(self, path: str):
         """Set File Occurrence path."""
         self._occurrence_data['path'] = path
 
     def __str__(self) -> str:
-        """Return string represtentation of object."""
+        """Return string representation of object."""
         return json.dumps(self.data, indent=4)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/security_label.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/security_label.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,59 +1,58 @@
-"""ThreatConnect SecurityLabel Object"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import Optional
 
 
 class SecurityLabel:
     """ThreatConnect Batch SecurityLabel Object."""
 
     __slots__ = ['_label_data']
 
-    def __init__(self, name: str, description: Optional[str] = None, color: Optional[str] = None):
-        """Initialize Class Properties.
+    def __init__(self, name: str, description: str | None = None, color: str | None = None):
+        """Initialize instance properties.
 
         Args:
             name: The value for this security label.
             description: A description for this security label.
             color: A color (hex value) for this security label.
         """
         self._label_data = {'name': name}
         # add description if provided
         if description is not None:
             self._label_data['description'] = description
         if color is not None:
             self._label_data['color'] = color
 
     @property
-    def color(self) -> str:
+    def color(self) -> str | None:
         """Return Security Label color."""
         return self._label_data.get('color')
 
     @color.setter
     def color(self, color: str):
         """Set Security Label color."""
         self._label_data['color'] = color
 
     @property
     def data(self) -> dict:
         """Return Security Label data."""
         return self._label_data
 
     @property
-    def description(self) -> str:
+    def description(self) -> str | None:
         """Return Security Label description."""
         return self._label_data.get('description')
 
     @description.setter
     def description(self, description: str):
         """Set Security Label description."""
         self._label_data['description'] = description
 
     @property
     def name(self) -> str:
         """Return Security Label name."""
-        return self._label_data.get('name')
+        return self._label_data['name']
 
     def __str__(self) -> str:
-        """Return string represtentation of object."""
+        """Return string representation of object."""
         return json.dumps(self.data, indent=4)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/batch/tag.py` & `tcex-4.0.0/tcex/api/tc/v2/batch/tag.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-"""ThreatConnect Batch Import Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import Callable, Optional
+from collections.abc import Callable
 
 
 class Tag:
     """ThreatConnect Batch Tag Object"""
 
     __slots__ = ['_tag_data', '_valid']
 
-    def __init__(self, name: str, formatter: Optional[Callable[[str], str]] = None):
-        """Initialize Class Properties.
+    def __init__(self, name: str, formatter: Callable[[str], str] | None = None):
+        """Initialize instance properties.
 
         Args:
             name: The value for this tag.
             formatter: A callable that take a tag value and returns a formatted tag.
         """
         if formatter is not None:
             name = formatter(name)
@@ -28,17 +28,17 @@
     def data(self) -> dict:
         """Return Tag data."""
         return self._tag_data
 
     @property
     def name(self) -> str:
         """Return Tag name."""
-        return self._tag_data.get('name')
+        return self._tag_data.get('name')  # type: ignore
 
     @property
     def valid(self) -> bool:
         """Return valid data."""
         return self._valid
 
     def __str__(self) -> str:
-        """Return string represtentation of object."""
+        """Return string representation of object."""
         return json.dumps(self.data, indent=4)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/datastore/cache.py` & `tcex-4.0.0/tcex/api/tc/v2/datastore/cache.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,57 +1,58 @@
-"""Cache"""
+"""TcEx Framework Module"""
 # standard library
 import logging
+from collections.abc import Callable
 from datetime import datetime, timedelta
-from typing import Callable, Optional
 
 # third-party
 import arrow
 from requests import Session
 
 # first-party
 from tcex.api.tc.v2.datastore.datastore import DataStore
-from tcex.utils import Utils
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class Cache:
     """TcEx Cache Class.
 
     Args:
         session: A requests.Session instance with auth configured for the ThreatConnect API.
         domain: A value of system, organization, or local.
         data_type: A free form type name for the data.
         ttl_seconds: Number of seconds the cache is valid.
-        mapping: Elasticsearch mappings data.
+        mapping: Elasticsearch mapping data.
     """
 
     def __init__(
         self,
         session: Session,
         domain: str,
         data_type: str,
-        ttl_seconds: Optional[int] = None,
-        mapping: Optional[dict] = None,
+        ttl_seconds: int | None = None,
+        mapping: dict | None = None,
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
 
         # properties
         self.ds = DataStore(session, domain, data_type, mapping)
-        self.log = logger
-        self.ttl_seconds: Optional[int] = ttl_seconds
-        self.utils = Utils()
+        self.log = _logger
+        self.ttl_seconds = ttl_seconds
+        self.util = Util()
 
         # Warranty void if any of these are changed.  Don't touch.
         self._cache_data_key: str = 'cache-data'
         self._cache_date_key: str = 'cache-date'
 
-    def add(self, rid: str, data: dict, raise_on_error: Optional[bool] = True) -> dict:
+    def add(self, rid: str, data: dict, raise_on_error: bool = True) -> dict | None:
         """Write cache data to the data store.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -73,21 +74,21 @@
             rid: The record identifier.
             data: The record data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The response dict
         """
-        data: dict = {
+        data = {
             self._cache_date_key: datetime.utcnow().isoformat(),
             self._cache_data_key: data,
         }
         return self.ds.post(rid, data, raise_on_error)
 
-    def delete(self, rid: str, raise_on_error: Optional[bool] = True) -> dict:
+    def delete(self, rid: str, raise_on_error: bool = True) -> dict | None:
         """Write cache data to the data store.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -113,17 +114,17 @@
             dict : The response dict.
         """
         return self.ds.delete(rid, raise_on_error)
 
     def get(
         self,
         rid: str,
-        data_callback: Optional[Callable[[str], dict]] = None,
-        raise_on_error: Optional[bool] = True,
-    ) -> dict:
+        data_callback: Callable[[str], dict] | None = None,
+        raise_on_error: bool = True,
+    ) -> dict | None:
         """Get cached data from the data store.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -137,47 +138,47 @@
             rid: The record identifier.
             data_callback: A method that will return the data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict: The cached data.
         """
-        cache_data = None
-        ds_data: dict = self.ds.get(rid, raise_on_error=False)
+        cache_data: dict | None = None
+        ds_data: dict[str, bool | dict | str] | None = self.ds.get(rid, raise_on_error=False)
 
         if ds_data is None:
             # default the response when TC API doesn't return a value
             ds_data = {'found': False}
 
         if ds_data is not None:
             expired = False
             if ds_data.get('found') is True:
-                cache_data: dict = ds_data.get('_source', {})
-                cache_date: str = cache_data.get(self._cache_date_key)
+                cache_data = ds_data.get('_source') or {}  # type: ignore
+                cache_date = cache_data[self._cache_date_key]  # type: ignore
                 if self._is_cache_expired(cache_date):
                     cache_data = None
                     expired = True
                     self.log.debug(f'Cached data is expired for ({rid}).')
 
             if expired or ds_data.get('found') is False:
                 # when cache is expired or does not exist use callback to get data if possible
                 if callable(data_callback):
                     # cache_data = self._encode_data(data_callback(rid))
-                    cache_data: Optional[dict] = data_callback(rid)
+                    cache_data: dict | None = data_callback(rid)
                     self.log.debug(f'Using callback data for ({rid}).')
                     if cache_data:
                         cache_data = self.update(
                             rid, cache_data, raise_on_error
                         )  # update the cache data
             else:
                 self.log.debug(f'Using cached data for ({rid}).')
 
         return cache_data
 
-    def update(self, rid: str, data: dict, raise_on_error: Optional[bool] = True) -> dict:
+    def update(self, rid: str, data: dict, raise_on_error: bool = True) -> dict:
         """Write updated cache data to the DataStore.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -185,15 +186,15 @@
               "cache-data": {
                 "one": 1
               }
             }
 
         Args:
             rid: The record identifier.
-            data): The record data.
+            data: The record data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The cached data.
         """
         cache_date = datetime.utcnow().isoformat()
         # cache_data = self._encode_data(data)
@@ -212,14 +213,14 @@
         """
 
         if self.ttl_seconds is None or self.ttl_seconds == 0:
             return True  # if ttl_is 0 or None, all cached data is always invalid.
 
         # convert the stored time expression to a datetime
         # object (support for different tcex version)
-        cached_datetime = self.utils.any_to_datetime(cached_date).datetime
+        cached_datetime = self.util.any_to_datetime(cached_date).datetime
 
         # calculate the cache expiration time by adding the ttl seconds to the cached time
         cache_expires = cached_datetime + timedelta(seconds=self.ttl_seconds)
 
         # if cache expires is less than "now" then return True/expired
         return cache_expires < arrow.get(datetime.utcnow())
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/datastore/datastore.py` & `tcex-4.0.0/tcex/api/tc/v2/datastore/datastore.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-"""TcEx Framework Module for working with DataStore in the ThreatConnect Platform."""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import TYPE_CHECKING, Optional
 
-# first-party
-from tcex.exit.error_codes import handle_error
+# third-party
+from requests import Response, Session  # TYPE-CHECKING
 
-if TYPE_CHECKING:
-    # third-party
-    from requests import Response, Session
+# first-party
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class DataStore:
     """TcEx DataStore Class.
 
     **domain**
 
@@ -32,28 +31,28 @@
     The URI string after the typeName is assumed to be ElasticSearch relevant information and is
     passed directly to ElasticSearch.
 
     Args:
         session_tc: A requests.Session instance with auth configured for the ThreatConnect API.
         domain: A value of system, organization, or local.
         data_type: A free form type name for the data.
-        mapping: Elasticsearch mappings data.
+        mapping: Elasticsearch mapping data.
     """
 
     def __init__(
-        self, session_tc: 'Session', domain: str, data_type: str, mapping: Optional[dict] = None
+        self, session_tc: Session, domain: str, data_type: str, mapping: dict | None = None
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.domain = domain
         self.data_type = data_type
         self.mapping = mapping or {'dynamic': False}
         self.session_tc = session_tc
 
         # properties
-        self.log = logger
+        self.log = _logger
 
         # setup
         self._create_index()  # create the initial index.
         self._update_mappings()  # update mappings
 
     def _create_index(self):
         """Create index if it doesn't exist."""
@@ -68,15 +67,15 @@
                 error: str = r.text or r.reason
                 handle_error(code=800, message_values=[r.status_code, error])
             self.log.debug(f'creating index. status_code: {r.status_code}, response: "{r.text}".')
             # delete temporary record
             self.delete(rid, False)
 
     def _update_mappings(self):
-        """Update the mappings for the current index."""
+        """Update the mapping for the current index."""
         headers = {'Content-Type': 'application/json', 'DB-Method': 'PUT'}
         url = f'/v2/exchange/db/{self.domain}/{self.data_type}/_mappings'
         r: 'Response' = self.session_tc.post(url, json=self.mapping, headers=headers)
         self.log.debug(f'update mapping. status_code: {r.status_code}, response: "{r.text}".')
 
     @property
     def index_exists(self) -> bool:
@@ -85,28 +84,28 @@
         url = f'/v2/exchange/db/{self.domain}/{self.data_type}/_search'
         r: 'Response' = self.session_tc.post(url, headers=headers)
         if not r.ok:
             self.log.warning(f'The provided index was not found ({r.text}).')
             return False
         return True
 
-    def add(self, rid: str, data: dict, raise_on_error: Optional[bool] = True) -> dict:
+    def add(self, rid: str, data: dict, raise_on_error: bool = True) -> dict | None:
         """Write data to the DataStore. Alias for post() method.
 
         Args:
             rid: The record identifier.
             data: The record data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The response data.
         """
         return self.post(rid, data, raise_on_error)
 
-    def delete(self, rid: str, raise_on_error: Optional[bool] = True) -> dict:
+    def delete(self, rid: str, raise_on_error: bool = True) -> dict | None:
         """Delete a record from the index using provide Id.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -127,36 +126,36 @@
         Args:
             rid: The record identifier.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The response data.
         """
-        response_data = None
+        response_data: dict | None = None
         headers = {'Content-Type': 'application/json', 'DB-Method': 'DELETE'}
         url = f'/v2/exchange/db/{self.domain}/{self.data_type}/{rid}'
         r: 'Response' = self.session_tc.post(url, headers=headers)
         self.log.debug(f'datastore delete status code: {r.status_code}')
         if r.ok and 'application/json' in r.headers.get('content-type', ''):
-            response_data: dict = r.json()
+            response_data = r.json()
         else:
             error: str = r.text or r.reason
             handle_error(
                 code=805,
                 message_values=['delete', r.status_code, error],
                 raise_error=raise_on_error,
             )
         return response_data
 
     def get(
         self,
-        rid: Optional[str] = None,
-        data: Optional[dict] = None,
-        raise_on_error: Optional[bool] = True,
-    ) -> dict:
+        rid: str | None = None,
+        data: dict | None = None,
+        raise_on_error: bool = True,
+    ) -> dict | None:
         """Get data from the DataStore.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -174,26 +173,26 @@
             rid: The record identifier.
             data: The search query.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : Python request response.
         """
-        response_data = None
+        response_data: dict | None = None
         headers = {'Content-Type': 'application/json', 'DB-Method': 'GET'}
-        if rid is None:
-            url = f'/v2/exchange/db/{self.domain}/{self.data_type}/'
-        else:
+        url = f'/v2/exchange/db/{self.domain}/{self.data_type}/'
+        if rid is not None:
             url = f'/v2/exchange/db/{self.domain}/{self.data_type}/{rid}'
-        r: 'Response' = self.session_tc.post(url, json=data, headers=headers)
+
+        r: Response = self.session_tc.post(url, json=data, headers=headers)
         self.log.debug(f'datastore get status code: {r.status_code}')
         if 'application/json' in r.headers.get('content-type', ''):
             # as long as the content is JSON set the value
             try:
-                response_data: dict = r.json()
+                response_data = r.json()
             except Exception as e:  # pragma: no cover
                 # This issue should be addressed by core in a future release.
                 self.log.warning(
                     'DataStore API returned a non-JSON response, even though '
                     f'content-type was application/json: {r.content} error: {e}'
                 )
         if not r.ok:
@@ -201,15 +200,15 @@
             handle_error(
                 code=805,
                 message_values=['get', r.status_code, error],
                 raise_error=raise_on_error,
             )
         return response_data
 
-    def post(self, rid: str, data: str, raise_on_error: Optional[bool] = True) -> dict:
+    def post(self, rid: str, data: dict, raise_on_error: bool = True) -> dict | None:
         """Write data to the DataStore.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -232,35 +231,35 @@
                 search will automatically generate a id.
             data: The record data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The response data.
         """
-        response_data = None
+        response_data: dict | None = None
         headers = {'Content-Type': 'application/json', 'DB-Method': 'POST'}
         url = f'/v2/exchange/db/{self.domain}/{self.data_type}/'
         if rid is not None:
             url = f'{url}{rid}'
 
-        r: 'Response' = self.session_tc.post(url, json=data, headers=headers)
+        r: Response = self.session_tc.post(url, json=data, headers=headers)
         self.log.debug(f'datastore post status code: {r.status_code}')
 
         if r.ok and 'application/json' in r.headers.get('content-type', ''):
-            response_data: dict = r.json()
+            response_data = r.json()
         else:
-            error: str = r.text or r.reason
+            error = r.text or r.reason
             handle_error(
                 code=805,
                 message_values=['post', r.status_code, error],
                 raise_error=raise_on_error,
             )
         return response_data
 
-    def put(self, rid: str, data: dict, raise_on_error: Optional[bool] = True) -> dict:
+    def put(self, rid: str, data: dict, raise_on_error: bool = True) -> dict | None:
         """Update the data for the provided Id.
 
         **Example Response**
 
         .. code-block:: json
 
             {
@@ -282,33 +281,33 @@
             rid: The record identifier.
             data: A search query
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
 
         Returns:
             dict : The response dict.
         """
-        response_data = None
+        response_data: dict | None = None
         headers = {'Content-Type': 'application/json', 'DB-Method': 'PUT'}
         url = f'/v2/exchange/db/{self.domain}/{self.data_type}/{rid}'
 
         r: 'Response' = self.session_tc.post(url, json=data, headers=headers)
         self.log.debug(f'datastore put status code: {r.status_code}')
 
         if r.ok and 'application/json' in r.headers.get('content-type', ''):
-            response_data: dict = r.json()
+            response_data = r.json()
         else:
             error: str = r.text or r.reason
             handle_error(
                 code=805,
                 message_values=['put', r.status_code, error],
                 raise_error=raise_on_error,
             )
         return response_data
 
-    def update(self, rid: str, data: dict, raise_on_error: Optional[bool] = True) -> dict:
+    def update(self, rid: str, data: dict, raise_on_error: bool = True) -> dict | None:
         """Update the for the provided Id. Alias for put() method.
 
         Args:
             rid: The record identifier.
             data: The record data.
             raise_on_error: If True and not r.ok this method will raise a RunTimeError.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/metrics/metrics.py` & `tcex-4.0.0/tcex/api/tc/v2/metric/metric.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,57 +1,56 @@
-"""TcEx Framework Module for working with Metrics in the ThreatConnect Platform."""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import TYPE_CHECKING, Optional
 
-# first-party
-from tcex.exit.error_codes import handle_error
-from tcex.utils import Utils
+# third-party
+from requests import Session  # TYPE-CHECKING
 
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
+# first-party
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
-class Metrics:
+class Metric:
     """TcEx Metrics Class
 
     Args:
         session_tc: An configured instance of request.Session with TC API Auth.
         name: The name for the metric.
         description: The description of the metric.
         data_type: The type of metric: Sum, Count, Min, Max, First, Last, and Average.
         interval: The metric interval: Hourly, Daily, Weekly, Monthly, and Yearly.
         keyed: Indicates whether the data will have a keyed value.
     """
 
     def __init__(
         self,
-        session_tc: 'Session',
+        session_tc: Session,
         name: str,
         description: str,
         data_type: str,
         interval: str,
-        keyed: Optional[bool] = False,
+        keyed: bool = False,
     ):
         """Initialize the Class properties."""
         self.session_tc = session_tc
         self._metric_data_type = data_type
         self._metric_description = description
         self._metric_interval = interval
         self._metric_keyed = keyed
         self._metric_name = name
 
         # properties
         self._metric_id = None
-        self.log = logger
-        self.utils = Utils
+        self.log = _logger
+        self.util = Util
 
         if not self.metric_find():
             self.metric_create()
 
     def metric_create(self):
         """Create the defined metric.
 
@@ -106,54 +105,54 @@
                             "keyedValues": false,
                             "description": "TcEx Metric Testing"
                         }
                     ]
                 }
             }
         """
-        params = {'resultLimit': 50, 'resultStart': 0}
+        params: dict[str, int] = {'resultLimit': 50, 'resultStart': 0}
         while True:
-            if params.get('resultStart') >= params.get('resultLimit'):
+            if params['resultStart'] >= params['resultLimit']:
                 break
             r = self.session_tc.get('/v2/customMetrics', params=params)
             if not r.ok:  # pragma: no cover
                 handle_error(705, [r.status_code, r.text])
             data = r.json()
             for metric in data.get('data', {}).get('customMetricConfig'):
                 if metric.get('name') == self._metric_name:
                     self._metric_id = metric.get('id')
                     self.log.info(
                         f'found metric with name "{self._metric_name}" '
                         f'and Id {self._metric_id}.'
                     )
                     return True
-            params['resultStart'] += params.get('resultLimit')
+            params['resultStart'] += params['resultLimit']
         return False
 
     def add(self, value, date=None, return_value=False, key=None, weight=None):
-        """Add metrics data to collection.
+        """Add metric data to collection.
 
         Args:
             value (str): The value of the metric.
             date (str, optional): The optional date of the metric.
             return_value (bool, default:False): Tell the API to return the updates metric value.
-            key (str, optional): The key value for keyed metrics.
+            key (str, optional): The key value for keyed metric.
             weight (str, optional): The weight value (only needed for averages)
 
         Return:
             dict: If return_value is True a dict with the current value for the time period
                 is returned.
         """
         data = {}
         if self._metric_id is None:  # pragma: no cover
             handle_error(715, [self._metric_name])
 
         body = {'value': value}
         if date is not None:
-            body['date'] = self.utils.any_to_datetime(date).strftime('%Y-%m-%dT%H:%M:%SZ')
+            body['date'] = self.util.any_to_datetime(date).strftime('%Y-%m-%dT%H:%M:%SZ')
 
         if key is not None:
             body['name'] = key
         if weight:
             body['weight'] = weight
         self.log.debug(f'metric data: {body}')
 
@@ -169,19 +168,19 @@
             pass
         else:  # pragma: no cover
             handle_error(710, [r.status_code, r.text])
 
         return data
 
     def add_keyed(self, value, key, date=None, return_value=False, weight=None):
-        """Add keyed metrics data to collection.
+        """Add keyed metric data to collection.
 
         Args:
             value (str): The value of the metric.
-            key (str): The key value for keyed metrics.
+            key (str): The key value for keyed metric.
             date (str, optional): The optional date of the metric.
             return_value (bool, default:False): Tell the API to return the updates metric value.
             weight (str, optional): The weight value (only needed for averages)
 
         Return:
             dict: If return_value is True a dict with the current value for the time period
                 is returned.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/notifications/notifications.py` & `tcex-4.0.0/tcex/api/tc/v2/notification/notification.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,89 +1,88 @@
-"""TcEx Notification Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
-from typing import TYPE_CHECKING
 
-# first-party
-from tcex.exit.error_codes import handle_error
+# third-party
+from requests import Session
 
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
+# first-party
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
-class Notifications:
+class Notification:
     """TcEx Notification Class"""
 
-    def __init__(self, session_tc: 'Session'):
+    def __init__(self, session_tc: Session):
         """Initialize the Class properties.
 
         Args:
             session_tc: An configured instance of request.Session with TC API Auth.
         """
         self.session_tc = session_tc
 
         # properties
         self._is_organization = False
         self._notification_type = None
         self._recipients = None
         self._priority = 'Low'
-        self.log = logger
+        self.log = _logger
 
-    def recipients(self, notification_type, recipients, priority='Low'):
+    def recipients(self, notification_type: str, recipients: str, priority='Low'):
         """Set vars for the passed in data. Used for one or more recipient notification.
 
         .. code-block:: javascript
 
             {
                 "notificationType": notification_type,
                 "priority": priority
                 "isOrganization": false,
                 "recipients": recipients
             }
 
         Args:
-            notification_type (str): The type of notification being sent.
-            recipients (str): A comma delimited string of recipients.
-            priority (str): The priority: Low, Medium, High.
+            notification_type: The type of notification being sent.
+            recipients: A comma delimited string of recipients.
+            priority: The priority: Low, Medium, High.
         """
         self._notification_type = notification_type
         self._recipients = recipients
         self._priority = priority
         self._is_organization = False
 
-    def org(self, notification_type, priority='Low'):
+    def org(self, notification_type: str, priority: str = 'Low'):
         """Set vars for the passed in data. Used for org notification.
 
         .. code-block:: javascript
 
             {
                 "notificationType": notification_type,
                 "priority": priority
                 "isOrganization": true
             }
 
         Args:
-            notification_type (str): The notification type.
-            priority (str): The priority: Low, Medium, High.
+            notification_type: The notification type.
+            priority: The priority: Low, Medium, High.
         """
         self._notification_type = notification_type
         self._recipients = None
         self._priority = priority
         self._is_organization = True
 
-    def send(self, message):
+    def send(self, message: str):
         """Send our message
 
         Args:
-            message (str): The message to be sent.
+            message: The message to be sent.
 
         Returns:
             requests.models.Response: The response from the request.
 
         """
         body = {
             'notificationType': self._notification_type,
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/filters.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/filters.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-"""ThreatConnect Threat Intelligence Filter Module"""
+"""TcEx Framework Module"""
 
 
 class Filters:
     """Filters module for Threat Intelligence"""
 
     def __init__(self):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self._filters = []
 
     @property
     def filters(self):
         """Return filters"""
         return self._filters
 
@@ -31,18 +31,18 @@
             'date_added': 'dateAdded',
             'group.date_added': 'group.dateAdded',
             'document.file_type': 'document.fileType',
             'host.dns_active': 'host.dnsActive',
             'dns_active': 'dnsActive',
             'host.whois_active': 'host.whoisActive',
             'whois_active': 'whoisActive',
-            'address.contry_name': 'address.contryName',
-            'contry_name': 'contryName',
-            'address.contry_code': 'address.contryCode',
-            'contry_code': 'contryCode',
+            'address.country_name': 'address.countryName',
+            'country_name': 'countryName',
+            'address.country_code': 'address.countryCode',
+            'country_code': 'countryCode',
             'indicator.date_added': 'eventDate',
             'indicator.false_positive': 'false_positive',
             'false_positive': 'falsePositive',
             'indicator.threat_assess_score': 'indicator.threatAssessScore',
             'threat_assess_score': 'threatAssessScore',
             'indicator.threat_assess_confidence': 'indicator.threatAssessConfidence',
             'threat_assess_confidence': 'threatAssessConfidence',
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-"""ThreatConnect TI Group"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 from urllib.parse import quote_plus
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.mappings import Mappings
+from tcex.api.tc.v2.threat_intelligence.mapping.mapping import Mapping
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
-class Group(Mappings):
+class Group(Mapping):
     """Unique API calls for Group API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             'Group',
             'groups',
             kwargs.pop('sub_type', None),
             kwargs.pop('api_entity', 'group'),
             kwargs.pop('api_branch', None),
@@ -63,15 +63,15 @@
         """Return True if group can be create."""
         return self.data.get('name') is not None
 
     def add_key_value(self, key, value):
         """Convert the value and adds it as a data field."""
         key = self._metadata_map.get(key, key)
         if key in ['dateAdded', 'eventDate', 'firstSeen', 'publishDate']:
-            self._data[key] = self._utils.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
+            self._data[key] = self.util.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
         elif key == 'file_content':
             # file content arg is not part of Group JSON
             pass
         elif key in ['unique_id', 'id']:
             self._unique_id = quote_plus(str(value))
         else:
             self._data[key] = value
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/adversary.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/adversary.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Adversary"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Adversary(Group):
@@ -16,15 +16,15 @@
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties"""
+        """Initialize instance properties"""
         super().__init__(
             ti, sub_type='Adversary', api_entity='adversary', api_branch='adversaries', **kwargs
         )
 
     def add_asset(self, asset_type, asset_value):
         """Add an asset to the Adversary
 
@@ -46,15 +46,15 @@
 
         # handle invalid input
         if asset_methods.get(asset_type.lower()) is None:
             self._handle_error(
                 925, ['asset_type', 'assets', 'asset_type', 'asset_type', asset_type]
             )
 
-        return asset_methods.get(asset_type.lower())(self.unique_id, asset_value)
+        return asset_methods[asset_type.lower()](self.unique_id, asset_value)
 
     def add_handle_asset(self, value):
         """Add a Handle asset to the adversary.
 
         Args:
             value: The value of the asset
 
@@ -107,15 +107,15 @@
 
         # handle invalid input
         if asset_methods.get(asset_type.lower()) is None:
             self._handle_error(
                 925, ['asset_type', 'assets', 'asset_type', 'asset_type', asset_type]
             )
 
-        return asset_methods.get(asset_type.lower())(self.unique_id, asset_id, action=action)
+        return asset_methods[asset_type.lower()](self.unique_id, asset_id, action=action)
 
     def assets(self, asset_type=None):
         """Retrieve all of the assets of a given asset_type
 
         Args:
             asset_type: (str) Either None, PHONE, HANDLE, or URL
 
@@ -136,15 +136,15 @@
 
         # handle invalid input
         if asset_methods.get(asset_type.lower()) is None:
             self._handle_error(
                 925, ['asset_type', 'assets', 'asset_type', 'asset_type', asset_type]
             )
 
-        return asset_methods.get(asset_type.lower())(self.unique_id)
+        return asset_methods[asset_type.lower()](self.unique_id)
 
     def delete_asset(self, asset_id, asset_type):
         """Delete the asset with the provided asset_id.
 
         Args:
             asset_id: The id of the asset.
             asset_type: The asset type.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/attack_pattern.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/attack_pattern.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class AttackPattern(Group):
@@ -16,15 +16,15 @@
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             sub_type='Attack Pattern',
             api_entity='attackPattern',
             api_branch='attackPatterns',
-            **kwargs
+            **kwargs,
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/campaign.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/campaign.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Campaign"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Campaign(Group):
@@ -17,15 +17,15 @@
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
         first_seen (str, kwargs): The first seen datetime expression for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti, sub_type='Campaign', api_entity='campaign', api_branch='campaigns', **kwargs
         )
 
     def first_seen(self, first_seen):
         """Update the campaign with the new first_seen date.
 
@@ -34,11 +34,11 @@
 
         Returns:
             requests.Response: The response from the API call.
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        first_seen = self._utils.any_to_datetime(first_seen).strftime('%Y-%m-%dT%H:%M:%SZ')
+        first_seen = self.util.any_to_datetime(first_seen).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['firstSeen'] = first_seen
         request = {'firstSeen': first_seen}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/course_of_action.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/course_of_action.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class CourseOfAction(Group):
@@ -16,15 +16,15 @@
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             sub_type='Course of Action',
             api_entity='courseOfAction',
             api_branch='coursesOfAction',
-            **kwargs
+            **kwargs,
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/document.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/document.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Document"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Document(Group):
@@ -19,15 +19,15 @@
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
         file_name (str, kwargs): The name for the attached file for this Group.
         malware (bool, kwargs): If true the file is considered malware.
         password (str, kwargs): If malware is true a password for the zip archive is required.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti, sub_type='Document', api_entity='document', api_branch='documents', **kwargs
         )
 
     def download(self):
         """Download the documents context.
 
@@ -81,15 +81,15 @@
         request = {'fileName': file_name}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
     def file_size(self, file_size):
         """Set or Update the Document file size.
 
         Args:
-            file_name (str): The filename of the document.
+            file_size: The size of the document.
 
         Returns:
             requests.Response
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/email.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/email.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Email(Group):
@@ -21,9 +21,9 @@
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
         subject (str): The subject for this Email.
         to (str, kwargs): The **to** address for this Email.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(ti, sub_type='Email', api_entity='email', api_branch='emails', **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/event.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/event.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Event"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Event(Group):
@@ -24,30 +24,30 @@
         event_date (str, kwargs): The event "event date" datetime expression for this Group.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
         status (str, kwargs): The status for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(ti, sub_type='Event', api_entity='event', api_branch='events', **kwargs)
 
     def event_date(self, event_date):
         """Update the event date for the Event.
 
         Args:
             event_date (str): The event datetime expression for this Group.
 
         Returns:
             requests.Response: The response from the API call.
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        event_date = self._utils.any_to_datetime(event_date).strftime('%Y-%m-%dT%H:%M:%SZ')
+        event_date = self.util.any_to_datetime(event_date).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['eventDate'] = event_date
         request = {'eventDate': event_date}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
     def status(self, status):
         """Update the event date for the Event.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/incident.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/incident.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Incident"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Incident(Group):
@@ -28,29 +28,29 @@
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         event_date (str, kwargs): The incident event date expression for this Group.
         name (str, kwargs): [Required for Create] The name for this Group.
         status (str, kwargs): The status for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti, sub_type='Incident', api_entity='incident', api_branch='incidents', **kwargs
         )
 
     def event_date(self, event_date):
         """Update the event_date.
 
         Args:
             event_date: Converted to %Y-%m-%dT%H:%M:%SZ date format.
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        event_date = self._utils.any_to_datetime(event_date).strftime('%Y-%m-%dT%H:%M:%SZ')
+        event_date = self.util.any_to_datetime(event_date).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['eventDate'] = event_date
         request = {'eventDate': event_date}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
     def status(self, status):
         """Update  the incidents status
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/intrusion_set.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/intrusion_set.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-"""ThreatConnect TI Intrusion Set"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class IntrusionSet(Group):
-    """Unique API calls for IntrustionSet API Endpoints
+    """Unique API calls for IntrusionSet API Endpoints
 
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             sub_type='Intrusion Set',
             api_entity='intrusionSet',
             api_branch='intrusionSets',
-            **kwargs
+            **kwargs,
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/malware.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/malware.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Malware(Group):
@@ -16,11 +16,11 @@
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti, sub_type='Malware', api_entity='malware', api_branch='malware', **kwargs
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/report.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/report.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,35 +1,37 @@
-"""ThreatConnect TI Report"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
-    from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
+    from tcex.api.tc.v2.threat_intelligence.threat_intelligence import (
+        ThreatIntelligence,  # CIRCULAR-IMPORT
+    )
 
 
 class Report(Group):
     """Unique API calls for Report API Endpoints
 
     Args:
-        ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
-        name (str): The name for this Group.
+        ti: An instance of the ThreatIntelligence Class.
+        name (str, kwargs): The name for this Group.
         file_name (str, kwargs): The name for the attached file for this Group.
         publish_date (str, kwargs): The publish datetime expression for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
 
         super().__init__(ti, sub_type='Report', api_entity='report', api_branch='reports', **kwargs)
 
-    def file_content(self, file_content: str, update_if_exists: Optional[bool] = True):
+    def file_content(self, file_content: str, update_if_exists: bool = True):
         """Update the file content."""
         if not self.can_update():
             self._handle_error(910, [self.type])
 
         self._data['fileContent'] = file_content
         return self.tc_requests.upload(
             self.api_type,
@@ -53,15 +55,15 @@
         if not self.can_update():
             self._handle_error(910, [self.type])
 
         self._data['fileSize'] = file_size
         request = {'fileSize': file_size, 'fileName': self._data['fileName']}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
-    def get_file_hash(self, hash_type: Optional[str] = 'sha256'):
+    def get_file_hash(self, hash_type: str = 'sha256'):
         """Get the hash value of attached document"""
         if not self.can_update():
             self._handle_error(910, [self.type])
 
         return self.tc_requests.get_file_hash(
             self.api_type, self.api_branch, self.unique_id, hash_type=hash_type
         )
@@ -86,15 +88,15 @@
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
     def publish_date(self, publish_date):
         """Return Email to."""
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        publish_date = self._utils.any_to_datetime(publish_date).strftime('%Y-%m-%dT%H:%M:%SZ')
+        publish_date = self.util.any_to_datetime(publish_date).strftime('%Y-%m-%dT%H:%M:%SZ')
 
         self._data['publishDate'] = publish_date
         request = {'publishDate': publish_date, 'fileName': self._data['fileName']}
         return self.tc_requests.update(self.api_type, self.api_branch, self.unique_id, request)
 
     def download(self):
         """Download the documents context."""
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/signature.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/signature.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""ThreatConnect TI Signature"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Signature(Group):
@@ -30,15 +30,15 @@
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
         file_name (str, kwargs): The name for the attached signature for this Group.
         file_type (str, kwargs): The signature type for this Group.
         file_text (str, kwargs): The signature content for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti, sub_type='Signature', api_entity='signature', api_branch='signatures', **kwargs
         )
 
     def download(self):
         """Download the signature.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tactic.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/threat.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
-class Tactic(Group):
-    """Unique API calls for Tactic API Endpoints
+class Threat(Group):
+    """Unique API calls for Threat API Endpoints.
 
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
-        super().__init__(ti, sub_type='Tactic', api_entity='tactic', api_branch='tactics', **kwargs)
+        """Initialize instance properties."""
+        super().__init__(ti, sub_type='Threat', api_entity='threat', api_branch='threats', **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tool.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/vulnerability.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,30 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
-class Tool(Group):
-    """Unique API calls for Tool API Endpoints
+class Vulnerability(Group):
+    """Unique API calls for Vulnerability API Endpoints
 
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
-        super().__init__(ti, sub_type='Tool', api_entity='tool', api_branch='tools', **kwargs)
+        """Initialize instance properties."""
+        super().__init__(
+            ti,
+            sub_type='Vulnerability',
+            api_entity='vulnerability',
+            api_branch='vulnerabilities',
+            **kwargs,
+        )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/vulnerability.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/tool.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,30 +1,24 @@
-"""ThreatConnect TI Email"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
-class Vulnerability(Group):
-    """Unique API calls for Vulnerability API Endpoints
+class Tool(Group):
+    """Unique API calls for Tool API Endpoints
 
     Args:
         ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
         name (str, kwargs): [Required for Create] The name for this Group.
         owner (str, kwargs): The name for this Group. Default to default Org when not provided
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties."""
-        super().__init__(
-            ti,
-            sub_type='Vulnerability',
-            api_entity='vulnerability',
-            api_branch='vulnerabilities',
-            **kwargs
-        )
+        """Initialize instance properties."""
+        super().__init__(ti, sub_type='Tool', api_entity='tool', api_branch='tools', **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-"""ThreatConnect TI Indicator"""
+"""TcEx Framework Module"""
 # standard library
 import json
 from typing import TYPE_CHECKING
 from urllib.parse import quote, unquote
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.mappings import Mappings
+from tcex.api.tc.v2.threat_intelligence.mapping.mapping import Mapping
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 
+# pylint: disable=unnecessary-dunder-call
 def custom_indicator_class_factory(
     indicator_type, entity_type, branch_type, base_class, value_fields
 ):
     """Build dynamic Custom Indicator Class."""
 
     @staticmethod
     def _metadata_map_1():
@@ -40,15 +41,15 @@
             api_entity=entity_type,
             api_branch=branch_type,
             **kwargs,
         )
         res = {v: k for k, v in self._metadata_map().items()}
         values = []
         for field in value_fields:
-            value = kwargs.pop(res.get(field), kwargs.pop(field, ''))
+            value = kwargs.pop(res.get(field), kwargs.pop(field, ''))  # type: ignore
             value = quote(self.fully_decode_uri(value), safe='')
             values.append(value)
 
         if len(values) == 1:
             self.unique_id = kwargs.get('unique_id', values[0])
         elif len(values) == 2:
             self.unique_id = kwargs.get('unique_id', self.build_summary(values[0], values[1]))
@@ -92,19 +93,19 @@
             'can_create': can_create_method,
             '_metadata_map': _metadata_map,
         },
     )
     return new_class
 
 
-class Indicator(Mappings):
+class Indicator(Mapping):
     """Unique API calls for Indicator API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             'Indicator',
             'indicators',
             kwargs.pop('sub_type', None),
             kwargs.pop('api_entity', 'indicator'),
             kwargs.pop('api_branch', None),
@@ -115,15 +116,15 @@
             self.add_key_value(arg, value)
 
     @property
     def as_entity(self):
         """Return the entity representation of the Indicator."""
         return {
             'type': self.api_sub_type,
-            'value': unquote(self.unique_id),
+            'value': unquote(self.unique_id),  # type: ignore
             'id': self._data.get('id'),
         }
 
     @staticmethod
     def is_indicator():
         """Return true if object type is an indicator."""
         return True
@@ -155,15 +156,15 @@
             'hostname': 'hostName',
         }
 
     def add_key_value(self, key, value):
         """Convert the value and adds it as a data field."""
         key = self._metadata_map().get(key, key)
         if key in ['dateAdded', 'lastModified']:
-            self._data[key] = self._utils.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
+            self._data[key] = self.util.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
         elif key == 'confidence':
             self._data[key] = int(value)
         elif key == 'rating':
             self._data[key] = float(value)
         elif key == 'unique_id':
             self._unique_id = quote(self.fully_decode_uri(value), safe='')
         else:
@@ -228,17 +229,15 @@
     def add_observers(self, count, date_observed):
         """Add a Indicator Observation."""
         if not self.can_update():
             self._handle_error(910, [self.type])
 
         data = {
             'count': count,
-            'dateObserved': self._utils.any_to_datetime(date_observed).strftime(
-                '%Y-%m-%dT%H:%M:%SZ'
-            ),
+            'dateObserved': self.util.any_to_datetime(date_observed).strftime('%Y-%m-%dT%H:%M:%SZ'),
         }
 
         return self.tc_requests.add_observations(
             self.api_type, self.api_branch, self.unique_id, data, owner=self.owner
         )
 
     def observation_count(self):
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/address.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/address.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,31 @@
-"""ThreatConnect TI Address"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import Indicator
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import Indicator
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Address(Indicator):
     """Unique API calls for Address API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
             ip (str): The value for this Indicator.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
                 modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
@@ -39,15 +42,15 @@
 
     def can_create(self):
         """Return True if address can be created.
 
         If the ip address has been provided returns that the address can be created, otherwise
         returns that the address cannot be created.
         """
-        return not self.data.get('ip') is None
+        return self.data.get('ip') is not None
 
     def dns_resolution(self):
         """Update the DNS resolution."""
         if not self.can_update():
             self._handle_error(910, [self.type])
         return self.tc_requests.dns_resolution(
             self.api_type, self.api_branch, self.unique_id, owner=self.owner
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/email_address.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/email_address.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,50 +1,53 @@
-"""ThreatConnect TI Email Address"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import Indicator
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import Indicator
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class EmailAddress(Indicator):
     """Unique API calls for Email Address API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             address (str): The value for this Indicator.
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): The date timestamp the Indicator was last modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
             xid (str, kwargs): The external id for this Indicator.
         """
         super().__init__(
             ti,
             sub_type='Email Address',
             api_entity='emailAddress',
             api_branch='emailAddresses',
-            **kwargs
+            **kwargs,
         )
         self.unique_id = kwargs.get('unique_id', kwargs.get('address'))
         self._data['address'] = self.unique_id
 
     def can_create(self):
         """Return True if email address can be created.
 
         If the address has been provided returns that the EmailAddress can be created, otherwise
         returns that the EmailAddress cannot be created.
         """
-        return not self.data.get('address') is None
+        return self.data.get('address') is not None
 
     def _set_unique_id(self, json_response: dict):
         """Set the unique_id provided a json response."""
         self.unique_id = json_response.get('address', '')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/file.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/file.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,30 @@
-"""ThreatConnect TI File"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import Indicator
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import Indicator
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class File(Indicator):
     """Unique API calls for File API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             md5 (str, optional): The md5 value for this Indicator.
             sha1 (str, optional): The sha1 value for this Indicator.
             sha256 (str, optional): The sha256 value for this Indicator.
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/host.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/host.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,31 @@
-"""ThreatConnect TI Host"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 from urllib.parse import quote_plus
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import Indicator
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import Indicator
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Host(Indicator):
     """Unique API calls for Host API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             hostname (str): The value for this Indicator.
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
                 modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
@@ -38,15 +41,15 @@
 
     def can_create(self):
         """Return True if file can be create.
 
         If the hostName has been provided returns that the File can be created, otherwise
         returns that the Host cannot be created.
         """
-        return not self.data.get('hostName') is None
+        return self.data.get('hostName') is not None
 
     def _set_unique_id(self, json_response):
         """Set the unique_id provided a json response."""
         self.unique_id = quote_plus(self.fully_decode_uri(json_response.get('hostName', '')))
 
     def dns_resolution(self):
         """Update the Host DNS resolution."""
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/url.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/url.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,31 @@
-"""ThreatConnect TI URL"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 from urllib.parse import quote_plus
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import Indicator
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import Indicator
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class URL(Indicator):
     """Unique API calls for URL API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             text (str, kwargs): [Required for Create] The URL value for this Indicator.
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
                 modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
@@ -37,12 +40,12 @@
 
     def can_create(self):
         """Return True if address can be created.
 
         If the text has been provided returns that the URL can be created, otherwise
         returns that the URL cannot be created.
         """
-        return not self.data.get('text') is None
+        return self.data.get('text') is not None
 
     def _set_unique_id(self, json_response):
         """Set the unique_id provided a json response."""
         self.unique_id = quote_plus(self.fully_decode_uri(json_response.get('text', '')))
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/mappings.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/mapping.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,77 +1,84 @@
-"""ThreatConnect TI Generic Mappings Object"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
 from functools import lru_cache
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING
 from urllib.parse import unquote
 
+# third-party
+from requests import Response
+
 # first-party
 from tcex.api.tc.v2.threat_intelligence.tcex_ti_tc_request import TiTcRequest
-from tcex.exit.error_codes import TcExErrorCodes
-from tcex.utils import Utils
+from tcex.exit.error_code import TcExErrorCode
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 if TYPE_CHECKING:
     # first-party
-    from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
+    from tcex.api.tc.v2.threat_intelligence.threat_intelligence import (
+        ThreatIntelligence,  # CIRCULAR-IMPORT
+    )
+
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
-class Mappings:
+class Mapping:
     """Common API calls for for Indicators/SecurityLabels/Groups and Victims"""
 
     def __init__(
         self,
         ti: 'ThreatIntelligence',
         main_type,
         api_type,
         sub_type,
         api_entity,
         api_branch,
         owner,
     ):
-        """Initialize Class Properties"""
+        """Initialize instance properties"""
         self._api_branch = api_branch
         self._api_entity = api_entity
         self._api_sub_type = sub_type
         self._api_type = api_type
         self._owner = owner
         self._session = ti.session_tc
         self.ti = ti
         self._type = main_type
 
         # properties
         self._data = {}
-        self.log = logger
+        self.log = _logger
+        self.util = Util()
         self._tc_requests = TiTcRequest(ti.session_tc)
         self._unique_id = None
-        self._utils = Utils()
 
     @property
-    @lru_cache()
-    def _error_codes(self) -> 'TcExErrorCodes':  # noqa: F821
+    @lru_cache
+    def _error_codes(self) -> TcExErrorCode:
         """Return TcEx error codes."""
-        return TcExErrorCodes()
+        return TcExErrorCode()
 
     @property
     def _excluded_properties(self):
         """Return a list of properties to exclude when creating the child Class."""
         return ['tcex', 'kwargs', 'api_endpoint']
 
     def _handle_error(
-        self, code: int, message_values: Optional[list] = None, raise_error: Optional[bool] = True
+        self, code: int, message_values: list | None = None, raise_error: bool = True
     ):
         """Raise RuntimeError
 
         Args:
             code: The error code from API or SDK.
-            message: The error message from API or SDK.
+            message_values: The error message from API or SDK.
             raise_error: Raise a Runtime error. Defaults to True.
 
         Raises:
             RuntimeError: Raised a defined error.
         """
         try:
             if message_values is None:
@@ -200,15 +207,15 @@
         if not self.unique_id:
             self._set_unique_id(data)
 
     def set(self, **kwargs):
         """Provide a generic way to update the attributes of a TC data object."""
         for arg, value in kwargs.items():
             if hasattr(self, 'add_key_value'):
-                self.add_key_value(arg, value)  # pylint: disable=no-member
+                self.add_key_value(arg, value)  # type: ignore
             else:
                 self._data[arg] = value
 
     def create(self):
         """Create the Indicator/Group/Victim or Security Label given Owner."""
         if not self.can_create():
             self._handle_error(920, [self.type])
@@ -333,15 +340,15 @@
             self.api_branch,
             self.unique_id,
             owner=self.owner,
             filters=filters,
             params=params,
         )
 
-    def label(self, label, action='ADD', params=None):
+    def label(self, label, action='ADD', params=None) -> Response | None:
         """Add a Security Label to a Indicator/Group or Victim."""
 
         if params is None:
             params = {}
 
         if not label:
             self._handle_error(925, ['label', 'Security Label', 'label', 'label', label])
@@ -658,15 +665,15 @@
         if not self.can_update():
             self._handle_error(910, [self.type])
 
         return self.tc_requests.add_attribute_label(
             self.api_type, self.api_branch, self.unique_id, attribute_id, label, owner=self.owner
         )
 
-    def can_create(self):  # pylint: disable=no-self-use
+    def can_create(self):
         """Determine if the object can be created."""
         return True
 
     def can_delete(self):
         """Determine if the object can be deleted."""
         return self.unique_id is not None
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/owner.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/owner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""ThreatConnect TI Generic Mappings Object"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v2.threat_intelligence.tcex_ti_tc_request import TiTcRequest
 
 if TYPE_CHECKING:
@@ -10,15 +10,15 @@
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Owner:
     """Common API calls for for Indicators/SecurityLabels/Groups and Victims"""
 
     def __init__(self, ti: 'ThreatIntelligence'):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self._data = {}
 
         self._type = 'Owner'
         self._api_type = 'owners'
         self._api_entity = 'owner'
 
         self._tc_requests = TiTcRequest(ti.session_tc)
@@ -75,9 +75,9 @@
         return self.tc_requests.mine()
 
     def members(self):
         """Get all members for my owners."""
         yield from self.tc_requests.many(self.api_type, 'mine/members', 'user')
 
     def metrics(self):
-        """Get all the metrics for owners."""
-        yield from self.tc_requests.many(self.api_type, 'metrics', 'ownerMetric')
+        """Get all the metric for owners."""
+        yield from self.tc_requests.many(self.api_type, 'metric', 'ownerMetric')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/security_label.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/security_label.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-"""ThreatConnect TI Security Label"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.mappings import Mappings
+from tcex.api.tc.v2.threat_intelligence.mapping.mapping import Mapping
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 
-class SecurityLabel(Mappings):
+class SecurityLabel(Mapping):
     """Unique API calls for SecurityLabel API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', name, **kwargs):
         """."""
         super().__init__(
             ti,
             main_type='SecurityLabel',
@@ -80,14 +80,14 @@
 
     def date_added(self, date_added):
         """Update the security labels date_added.
 
         Args:
             date_added: Converted to %Y-%m-%dT%H:%M:%SZ date format
         """
-        date_added = self._utils.any_to_datetime(date_added).strftime('%Y-%m-%dT%H:%M:%SZ')
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%dT%H:%M:%SZ')
 
         self._data['dateAdded'] = date_added
         data = {'dateAdded': date_added}
         return self._tc_requests.update(
             self.api_type, self.api_branch, self.unique_id, data, owner=self.owner
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/tag.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/tag.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-"""ThreatConnect TI Security Label"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v2.threat_intelligence.tcex_ti_tc_request import TiTcRequest
-from tcex.utils import Utils
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Tag:
@@ -17,24 +16,23 @@
     Args:
         group_type (str): The ThreatConnect define Group type.
         name (str): The name for this Group.
         xid (str, kwargs): The external id for this Group.
     """
 
     def __init__(self, ti: 'ThreatIntelligence', name):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         self._name = name
 
         # properties
         self._api_entity = 'tag'
         self._api_sub_type = None
         self._api_type = None
         self._tc_requests = TiTcRequest(ti.session_tc)
         self._type = 'tags'
-        self._utils = Utils()
         self.ti = ti
 
     @staticmethod
     def is_tag():
         """Return true is instance is a tag object."""
         return True
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/tags.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/tags.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,33 +1,31 @@
-"""ThreatConnect TI Security Label"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v2.threat_intelligence.tcex_ti_tc_request import TiTcRequest
-from tcex.utils import Utils
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 class Tags:
     """Unique API calls for Tags API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence'):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
 
         # properties
         self._api_entity = 'tag'
         self._api_sub_type = None
         self._api_type = None
         self._tc_requests = TiTcRequest(ti.session_tc)
         self._type = 'tags'
-        self._utils = Utils()
         self.ti = ti
 
     def many(self, filters=None, owners=None, params=None):
         """Get all the tags."""
         for tag in self.tc_requests.all_tags(filters=filters, owners=owners, params=params):
             yield self.ti.tag(name=tag.get('name'))
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/task.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/task.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-"""ThreatConnect TI Adversary"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 from urllib.parse import quote_plus
 
-from .mappings import Mappings
+from .mapping import Mapping
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
-class Task(Mappings):
+class Task(Mapping):
     """Unique API calls for Tasks API Endpoints.
 
     Valid status:
     + Not Started
     + In Progress
     + Completed
     + Waiting on Someone
@@ -26,15 +26,15 @@
         status (str, kwargs): Not started, In Progress, Completed, Waiting on Someone, Deferred
         due_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
         reminder_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
         escalation_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
     """
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class Properties."""
+        """Initialize instance properties."""
         super().__init__(
             ti,
             main_type='Task',
             api_type='tasks',
             sub_type=None,
             api_entity='task',
             api_branch=None,
@@ -94,15 +94,15 @@
 
     def add_key_value(self, key, value):
         """Convert the value and adds it as a data field."""
         key = self._metadata_map.get(key, key)
         if key in ['unique_id', 'id']:
             self._unique_id = quote_plus(str(value))
         elif key in ['dueDate', 'reminderDate', 'escalationDate']:
-            self._data[key] = self._utils.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
+            self._data[key] = self.util.any_to_datetime(value).strftime('%Y-%m-%dT%H:%M:%SZ')
         else:
             self._data[key] = value
 
     def add_escalatee(self, escalatee):
         """Add the desired escalatee from the Task.
 
         Args:
@@ -175,15 +175,15 @@
 
         Args:
             due_date: Converted to %Y-%m-%dT%H:%M:%SZ date format
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        due_date = self._utils.any_to_datetime(due_date).strftime('%Y-%m-%dT%H:%M:%SZ')
+        due_date = self.util.any_to_datetime(due_date).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['dueDate'] = due_date
         request = {'dueDate': due_date}
         return self.tc_requests.update(self.api_type, self.api_sub_type, self.unique_id, request)
 
     def escalatee(self, escalatee, action='ADD'):
         """General method to perform actions on escalatees
 
@@ -215,17 +215,15 @@
 
         Args:
             escalation_date: Converted to %Y-%m-%dT%H:%M:%SZ date format
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        escalation_date = self._utils.any_to_datetime(escalation_date).strftime(
-            '%Y-%m-%dT%H:%M:%SZ'
-        )
+        escalation_date = self.util.any_to_datetime(escalation_date).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['escalationDate'] = escalation_date
         request = {'escalationDate': escalation_date}
         return self.tc_requests.update(self.api_type, self.api_sub_type, self.unique_id, request)
 
     def get_assignee(self, assignee):
         """Retrieve the desired assignee from the Task.
 
@@ -255,15 +253,15 @@
 
         Args:
             reminder_date: Converted to %Y-%m-%dT%H:%M:%SZ date format
         """
         if not self.can_update():
             self._handle_error(910, [self.type])
 
-        reminder_date = self._utils.any_to_datetime(reminder_date).strftime('%Y-%m-%dT%H:%M:%SZ')
+        reminder_date = self.util.any_to_datetime(reminder_date).strftime('%Y-%m-%dT%H:%M:%SZ')
         self._data['reminderDate'] = reminder_date
         request = {'reminderDate': reminder_date}
         return self.tc_requests.update(self.api_type, self.api_sub_type, self.unique_id, request)
 
     def status(self, status):
         """Update the Task Status
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/mappings/victim.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/mapping/victim.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,31 +1,34 @@
-"""ThreatConnect TI Victim"""
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.mappings import Mappings
+from tcex.api.tc.v2.threat_intelligence.mapping.mapping import Mapping
 
 if TYPE_CHECKING:
     # first-party
     from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
 
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 
-class Victim(Mappings):
+class Victim(Mapping):
     """Unique API calls for Victim API Endpoints"""
 
     def __init__(self, ti: 'ThreatIntelligence', **kwargs):
-        """Initialize Class properties.
+        """Initialize instance properties.
 
         Args:
             ti (ThreatIntelligence): An instance of the ThreatIntelligence Class.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str, kwargs): The owner for this Victim. Default to default Org when not provided
             name (str, kwargs): [Required for Create] The name for this Victim.
         """
         super().__init__(ti, 'Victim', 'victims', None, 'victim', None, kwargs.pop('owner', None))
         self.name = None
         for arg, value in kwargs.items():
             self.add_key_value(arg, value)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/tcex_ti_tc_request.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/tcex_ti_tc_request.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,92 +1,92 @@
-"""ThreatConnect Threat Intelligence Module"""
+"""TcEx Framework Module"""
 # standard library
 import hashlib
 import logging
 from functools import lru_cache
-from typing import Optional
 from urllib.parse import quote
 
 # third-party
 from requests import Session
 
 # first-party
-from tcex.exit.error_codes import TcExErrorCodes
+from tcex.exit.error_code import TcExErrorCode
+from tcex.logger.trace_logger import TraceLogger
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class TiTcRequest:
     """Common API calls to ThreatConnect"""
 
     def __init__(self, session: Session):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self.session = session
 
         # properties
-        self.log = logger
+        self.log = _logger
         self.result_limit = 10000
 
     def _delete(self, url, params=None):
         """Delete data from API."""
         params = params or {}
         params['createActivityLog'] = params.get('createActivityLog') or 'false'
 
         r = self.session.delete(url, params=params)
         self.log.debug(
-            f'Method: ({r.request.method.upper()}), '
+            f'Method: ({r.request.method}), '
             f'Params: ({params}), '
             f'Status Code: {r.status_code}, '
             f'URL: ({r.url})'
         )
         if len(r.content) < 500:
             self.log.trace(f'response: {r.text}')
         if not r.ok:
             err = r.text or r.reason
             self.log.error(f'Error deleting data ({err}')
         return r
 
     @property
-    @lru_cache()
-    def _error_codes(self) -> 'TcExErrorCodes':  # noqa: F821
+    @lru_cache
+    def _error_codes(self) -> TcExErrorCode:
         """Return TcEx error codes."""
-        return TcExErrorCodes()
+        return TcExErrorCode()
 
     def _get(self, url, params=None):
         """Delete data from API."""
         params = params or {}
         params['createActivityLog'] = params.get('createActivityLog') or 'false'
 
         r = self.session.get(url, params=params)
 
         self.log.debug(
-            f'Method: ({r.request.method.upper()}), '
+            f'Method: ({r.request.method}), '
             f'Params: ({params}), '
             f'Status Code: {r.status_code}, '
             f'URL: ({r.url})'
         )
         if len(r.content) < 500:
             self.log.trace(f'response: {r.text}')
         if not r.ok:
             err = r.text or r.reason
             self.log.error(f'Error getting data ({err}')
         return r
 
     def _handle_error(
-        self, code: int, message_values: Optional[list] = None, raise_error: Optional[bool] = True
+        self, code: int, message_values: list | None = None, raise_error: bool = True
     ):
         """Raise RuntimeError
 
         Args:
             code: The error code from API or SDK.
-            message: The error message from API or SDK.
+            message_values: The error message from API or SDK.
             raise_error: Raise a Runtime error. Defaults to True.
 
         Raises:
             RuntimeError: Raised a defined error.
         """
         try:
             if message_values is None:
@@ -135,15 +135,15 @@
     def _post(self, url, data, params=None):
         """Post data to API."""
         params = params or {}
         params['createActivityLog'] = params.get('createActivityLog') or 'false'
 
         r = self.session.post(url, data=data, params=params)
         self.log.debug(
-            f'Method: ({r.request.method.upper()}), '
+            f'Method: ({r.request.method}), '
             f'Params: ({params}), '
             f'Status Code: {r.status_code}, '
             f'URL: ({r.url})'
         )
         if len(data) < 50 and not isinstance(data, bytes):
             self.log.trace(f'body: {data}')
         if len(r.content) < 500:
@@ -156,15 +156,15 @@
     def _post_json(self, url, json_data, params=None):
         """Post JSON data to API."""
         params = params or {}
         params['createActivityLog'] = params.get('createActivityLog') or 'false'
 
         r = self.session.post(url, json=json_data, params=params)
         self.log.debug(
-            f'Method: ({r.request.method.upper()}), '
+            f'Method: ({r.request.method}), '
             f'Params: ({params}), '
             f'Status Code: {r.status_code}, '
             f'URL: ({r.url})'
         )
         self.log.trace(f'body: {json_data}')
         if len(r.content) < 500:
             self.log.trace(f'response: {r.text}')
@@ -176,15 +176,15 @@
     def _put_json(self, url, json_data, params=None):
         """Post JSON data to API."""
         params = params or {}
         params['createActivityLog'] = params.get('createActivityLog') or 'false'
 
         r = self.session.put(url, json=json_data, params=params)
         self.log.debug(
-            f'Method: ({r.request.method.upper()}), '
+            f'Method: ({r.request.method}), '
             f'Params: ({params}), '
             f'Status Code: {r.status_code}, '
             f'URL: ({r.url})'
         )
         if len(json_data) < 50 and not isinstance(json_data, bytes):
             self.log.trace(f'body: {json_data}')
         if len(r.content) < 500:
@@ -385,15 +385,15 @@
 
     def delete(self, main_type, sub_type, unique_id, owner=None):
         """Delete a TI object in the API.
 
         Args:
             main_type (str): The TI type (e.g., groups or indicators).
             sub_type (str): The TI sub type (e.g., adversaries or addresses).
-            data (dict): The body for the POST.
+            unique_id (str): The unique ID of the TI object.
             owner (str): The name of the TC owner.
 
         Returns:
             request.Response: The response from the API call.
         """
         url = f'/v2/{main_type}/{unique_id}'
         if sub_type:
@@ -402,39 +402,39 @@
 
         params = {}
         if owner:
             params['owner'] = owner
         return self._delete(url, params)
 
     def delete_adversary_handle_asset(self, unique_id, asset_id):
-        """Delete Adversary handle assest
+        """Delete Adversary handle asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
 
         Returns:
             requests.Response: A request Response object.
         """
         return self.adversary_handle_asset(unique_id, asset_id, action='DELETE')
 
     def delete_adversary_phone_asset(self, unique_id, asset_id):
-        """Delete Adversary phone assest
+        """Delete Adversary phone asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
 
         Returns:
             requests.Response: A request Response object.
         """
         return self.adversary_phone_asset(unique_id, asset_id, action='DELETE')
 
     def delete_adversary_url_asset(self, unique_id, asset_id):
-        """Delete Adversary URL assest
+        """Delete Adversary URL asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
 
         Returns:
             requests.Response: A request Response object.
@@ -454,43 +454,46 @@
         """
         url = f'/v2/{main_type}/{unique_id}/download'
         if sub_type:
             url = f'/v2/{main_type}/{sub_type}/{unique_id}/download'
         return self._get(url)
 
     def get_adversary_handle_asset(self, unique_id, asset_id, params=None):
-        """Get Adversary handle assest
+        """Get Adversary handle asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
+            params: (dict) Optional query parameters.
 
         Returns:
             requests.Response: A request Response object.
         """
         return self.adversary_handle_asset(unique_id, asset_id, params=params)
 
     def get_adversary_phone_asset(self, unique_id, asset_id, params=None):
-        """Get Adversary phone assest
+        """Get Adversary phone asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
+            params: (dict) Optional query parameters.
 
         Returns:
             requests.Response: A request Response object.
         """
         return self.adversary_phone_asset(unique_id, asset_id, params=params)
 
     def get_adversary_url_asset(self, unique_id, asset_id, params=None):
-        """Get Adversary URL assest
+        """Get Adversary URL asset
 
         Args:
             unique_id (str): The unique ID of the Adversary.
             asset_id: (str) The ID of the asset.
+            params: (dict) Optional query parameters.
 
         Returns:
             requests.Response: A request Response object.
         """
         params = params or {}
 
         return self.adversary_url_asset(unique_id, asset_id, params=params)
@@ -690,15 +693,15 @@
 
         # This is needed because of tasks
         if not sub_type:
             url = f'/v2/{main_type}/{unique_id}/victimAssets'
         else:
             url = f'/v2/{main_type}/{sub_type}/{unique_id}/victimAssets'
         entity_type = 'victimAsset'
-        asset_type = self.victim_asset_type_mapping.get(asset_type)
+        asset_type = self.victim_asset_type_mapping.get(asset_type)  # type: ignore
         if asset_type:
             url += f'/{asset_type}'
         return self._iterate(url, params, entity_type)
 
     def victim_get_asset(self, unique_id, asset_type, asset_id, params=None):
         """Retrieve a Asset from a Victim.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/threat_intelligence/threat_intelligence.py` & `tcex-4.0.0/tcex/api/tc/v2/threat_intelligence/threat_intelligence.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,89 +1,84 @@
-"""ThreatConnect Threat Intelligence Module"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 from functools import lru_cache
-from typing import TYPE_CHECKING, Optional
+from typing import cast
+
+# third-party
+from requests import Response, Session  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc.v2.threat_intelligence.mappings.filters import Filters
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group import Group
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.adversary import Adversary
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.attack_pattern import (
-    AttackPattern,
-)
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.campaign import Campaign
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.course_of_action import (
+from tcex.api.tc.v2.threat_intelligence.mapping.filters import Filters
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group import Group
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.adversary import Adversary
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.attack_pattern import AttackPattern
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.campaign import Campaign
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.course_of_action import (
     CourseOfAction,
 )
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.document import Document
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.email import Email
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.event import Event
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.incident import Incident
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.intrusion_set import IntrusionSet
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.malware import Malware
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.report import Report
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.signature import Signature
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.tactic import Tactic
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.threat import Threat
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.tool import Tool
-from tcex.api.tc.v2.threat_intelligence.mappings.group.group_types.vulnerability import (
-    Vulnerability,
-)
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator import (
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.document import Document
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.email import Email
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.event import Event
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.incident import Incident
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.intrusion_set import IntrusionSet
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.malware import Malware
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.report import Report
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.signature import Signature
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.tactic import Tactic
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.threat import Threat
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.tool import Tool
+from tcex.api.tc.v2.threat_intelligence.mapping.group.group_type.vulnerability import Vulnerability
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator import (
     Indicator,
     custom_indicator_class_factory,
 )
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator_types.address import Address
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator_types.email_address import (
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator_type.address import Address
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator_type.email_address import (
     EmailAddress,
 )
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator_types.file import File
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator_types.host import Host
-from tcex.api.tc.v2.threat_intelligence.mappings.indicator.indicator_types.url import URL
-from tcex.api.tc.v2.threat_intelligence.mappings.owner import Owner
-from tcex.api.tc.v2.threat_intelligence.mappings.tag import Tag
-from tcex.api.tc.v2.threat_intelligence.mappings.tags import Tags
-from tcex.api.tc.v2.threat_intelligence.mappings.task import Task
-from tcex.api.tc.v2.threat_intelligence.mappings.victim import Victim
-from tcex.exit.error_codes import TcExErrorCodes
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
-
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator_type.file import File
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator_type.host import Host
+from tcex.api.tc.v2.threat_intelligence.mapping.indicator.indicator_type.url import URL
+from tcex.api.tc.v2.threat_intelligence.mapping.owner import Owner
+from tcex.api.tc.v2.threat_intelligence.mapping.tag import Tag
+from tcex.api.tc.v2.threat_intelligence.mapping.tags import Tags
+from tcex.api.tc.v2.threat_intelligence.mapping.task import Task
+from tcex.api.tc.v2.threat_intelligence.mapping.victim import Victim
+from tcex.exit.error_code import TcExErrorCode
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util import Util
 
 # import local modules for dynamic reference
 module = __import__(__name__)
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class ThreatIntelligence:
     """ThreatConnect Threat Intelligence Module"""
 
-    def __init__(self, session_tc: 'Session'):
-        """Initialize Class properties."""
+    def __init__(self, session_tc: Session):
+        """Initialize instance properties."""
         self.session_tc = session_tc
 
         # properties
         self._custom_indicator_classes = {}
-        self.log = logger
-        self.utils = Utils()
+        self.log = _logger
+        self.util = Util()
 
         # generate custom ioc classes
         self._gen_indicator_class()
 
     @property
-    @lru_cache()
-    def _error_codes(self) -> 'TcExErrorCodes':  # noqa: F821
+    @lru_cache
+    def _error_codes(self) -> TcExErrorCode:
         """Return TcEx error codes."""
-        return TcExErrorCodes()
+        return TcExErrorCode()
 
     @property
     def _group_types(self) -> list:
         """Return all defined ThreatConnect Group types.
 
         Returns:
             (list): A list of ThreatConnect Group types.
@@ -128,15 +123,15 @@
             'Vulnerability': {'apiBranch': 'vulnerabilities', 'apiEntity': 'vulnerability'},
             'Tactic': {'apiBranch': 'tactics', 'apiEntity': 'tactic'},
             'Tool': {'apiBranch': 'tools', 'apiEntity': 'tool'},
             'Course of Action': {'apiBranch': 'coursesofaction', 'apiEntity': 'courseofAction'},
         }
 
     @property
-    @lru_cache()
+    @lru_cache
     def _indicator_types_data(self) -> dict:
         """Return ThreatConnect indicator types data.
 
         Retrieve the data from the API if it hasn't already been retrieved.
 
         Returns:
             (dict): A dictionary of ThreatConnect Indicator data.
@@ -152,21 +147,21 @@
 
         for itd in r.json().get('data', {}).get('indicatorType'):
             _indicator_types_data[itd.get('name')] = itd
 
         return _indicator_types_data
 
     def _handle_error(
-        self, code: int, message_values: Optional[list] = None, raise_error: Optional[bool] = True
+        self, code: int, message_values: list | None = None, raise_error: bool = True
     ):
         """Raise RuntimeError
 
         Args:
             code: The error code from API or SDK.
-            message: The error message from API or SDK.
+            message_values: The error message from API or SDK.
             raise_error: Raise a Runtime error. Defaults to True.
 
         Raises:
             RuntimeError: Raised a defined error.
         """
         try:
             if message_values is None:
@@ -184,14 +179,17 @@
         if raise_error:
             raise RuntimeError(code, message)
 
     def address(self, **kwargs):
         """Return an Address TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             ip (str, kwargs): [Required for Create] The IP value for this Indicator.
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
                 modified.
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
@@ -202,49 +200,61 @@
         """
         return Address(self, **kwargs)
 
     def url(self, **kwargs):
         """Create the URL TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             text (str, kwargs): [Required for Create] The URL value for this Indicator.
 
         Return:
             obj: An instance of URL.
         """
         return URL(self, **kwargs)
 
     def email_address(self, **kwargs):
         """Create the Email Address TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             address (str, kwargs): [Required for Create] The Email Address value for this Indicator.
 
         Return:
             obj: An instance of EmailAddress.
         """
         return EmailAddress(self, **kwargs)
 
     def file(self, **kwargs):
         """Create the File TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             obj: An instance of File.
         """
         return File(self, **kwargs)
 
     def host(self, **kwargs):
         """Create the Host TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             hostname (str, kwargs): [Required for Create] The Host value for this Indicator.
 
         Return:
             obj: An instance of Host.
         """
         return Host(self, **kwargs)
@@ -254,22 +264,25 @@
         """Create a Filters TI object"""
         return Filters()
 
     def indicator(self, indicator_type=None, owner=None, **kwargs):
         """Return an TI object.
 
         Args:
+            indicator_type (str): The indicator type.
+            owner (str): The name for this Group. Default to default Org when not provided
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): If False the indicator is marked "inactive" in TC.
             confidence (str, kwargs): The threat confidence for this Indicator.
             date_added (str, kwargs): [Read-Only] The date timestamp the Indicator was created.
-            indicator_type (str): The indicator type.
             ip (str, kwargs): [address] The value for this Indicator.
             last_modified (str, kwargs): [Read-Only] The date timestamp the Indicator was last
                 modified.
-            owner (str, kwargs): The name for this Group. Default to default Org when not provided
             private_flag (bool, kwargs): If True the indicator is marked as private in TC.
             rating (str, kwargs): The threat rating for this Indicator.
 
         Returns:
             obj: An instance of Indicator or specific indicator type.
         """
         if not indicator_type:
@@ -293,23 +306,24 @@
         if indicator_type not in indicator_type_map:
             raise RuntimeError(f'Invalid indicator type "{indicator_type}" provided.')
 
         # update kwargs
         kwargs['owner'] = owner
 
         # return correct indicator object
-        indicator_object = indicator_type_map.get(indicator_type)
+        indicator_object = indicator_type_map[indicator_type]
         return indicator_object(self, **kwargs)
 
     def group(self, group_type=None, owner=None, **kwargs):
         """Create the Group TI object.
 
         Args:
-            owner (str): The ThreatConnect owner name.
             group_type: The type of group object.
+            owner (str): The ThreatConnect owner name.
+            **kwargs: Additional keyword arguments.
         """
         if not group_type:
             return Group(self, owner=owner, **kwargs)
 
         group_type_map = {
             'adversary': Adversary,
             'campaign': Campaign,
@@ -337,118 +351,145 @@
         if group_type not in group_type_map:
             raise RuntimeError(f'Invalid group type "{group_type}" provided.')
 
         # update kwargs
         kwargs['owner'] = owner
 
         # return correct group object
-        group_object = group_type_map.get(group_type)
+        group_object = group_type_map[group_type]
         return group_object(self, **kwargs)
 
     def attack_pattern(self, **kwargs):
         """Create the Attack Pattern TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.AttackPattern: An instance of AttackPattern.
         """
         return AttackPattern(self, **kwargs)
 
     def malware(self, **kwargs):
         """Create the Malware TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.Malware: An instance of Malware.
         """
         return Malware(self, **kwargs)
 
     def vulnerability(self, **kwargs):
         """Create the Vulnerability TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.Vulnerability: An instance of Vulnerability.
         """
         return Vulnerability(self, **kwargs)
 
     def tactic(self, **kwargs):
         """Create the Tactic TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.Tactic: An instance of Tactic.
         """
         return Tactic(self, **kwargs)
 
     def tool(self, **kwargs):
         """Create the Tool TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.Tool: An instance of Tool.
         """
         return Tool(self, **kwargs)
 
     def course_of_action(self, **kwargs):
         """Create the Course of Action TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.CourseOfAction: An instance of CourseOfAction.
         """
         return CourseOfAction(self, **kwargs)
 
     def adversary(self, **kwargs):
         """Create the Adversary TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.Adversary: An instance of Adversary.
         """
         return Adversary(self, **kwargs)
 
     def campaign(self, **kwargs):
         """Create the Campaign TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             first_seen (str, kwargs): The first seen datetime expression for this Group.
 
         Return:
             ti.Campaign: An instance of Campaign.
         """
         return Campaign(self, **kwargs)
 
     def document(self, **kwargs):
         """Create the Document TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             file_name (str, kwargs): The name for the attached file for this Group.
             malware (bool, kwargs): If true the file is considered malware.
             password (bool, kwargs): If malware is true a password for the zip archive is required.
 
         Return:
@@ -456,14 +497,17 @@
         """
         return Document(self, **kwargs)
 
     def email(self, **kwargs):
         """Create the Email TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             body (str): The body for this Email.
             from_addr (str, kwargs): The **from** address for this Email.
             header (str): The header for this Email.
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             subject (str): The subject for this Email.
             to (str, kwargs): The **to** address for this Email.
@@ -473,63 +517,78 @@
         """
         return Email(self, **kwargs)
 
     def event(self, **kwargs):
         """Create the Event TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             event_date (str, kwargs): The event "event date" datetime expression for this Group.
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             status (str, kwargs): The status for this Group.
 
         Return:
             ti.Event: An instance of Event.
         """
         return Event(self, **kwargs)
 
     def incident(self, **kwargs):
         """Create the Incident TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             event_date (str, kwargs): The incident event date expression for this Group.
             name (str, kwargs): [Required for Create] The name for this Group.
             status (str, kwargs): The status for this Group.
 
         Return:
             ti.Incident: An instance of Incident.
         """
         return Incident(self, **kwargs)
 
     def intrusion_set(self, **kwargs):
-        """Create the Intrustion Set TI object.
+        """Create the Intrusion Set TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
 
         Return:
             ti.IntrusionSet: An instance of IntrusionSet.
         """
         return IntrusionSet(self, **kwargs)
 
     def report(self, **kwargs):
         """Create the Report TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str): The ThreatConnect owner name.
             name:
             **kwargs:
         """
         return Report(self, **kwargs)
 
     def signature(self, **kwargs):
         """Create the Signature TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str): The ThreatConnect owner name.
             name (str): The name for this Group.
             file_name (str): The name for the attached signature for this Group.
             file_type (str): The signature type for this Group.
             file_text (str): The signature content for this Group.
             **kwargs:
 
@@ -538,14 +597,17 @@
         """
         return Signature(self, **kwargs)
 
     def task(self, **kwargs):
         """Create the Task TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             name (str, kwargs): [Required for Create] The name for this Group.
             owner (str, kwargs): The name for this Group. Default to default Org when not provided
             status (str, kwargs): Not started, In Progress, Completed, Waiting on Someone, Deferred
             due_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
             reminder_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
             escalation_date (str, kwargs): Converted to %Y-%m-%dT%H:%M:%SZ date format
 
@@ -554,28 +616,31 @@
         """
         return Task(self, **kwargs)
 
     def threat(self, **kwargs):
         """Create the Threat TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str): The ThreatConnect owner name.
             name:
-            **kwargs:
         """
         return Threat(self, **kwargs)
 
     def victim(self, **kwargs):
         """Create the Victim TI object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             owner (str): The ThreatConnect owner name.
             name:
-            **kwargs:
-
         """
         return Victim(self, **kwargs)
 
     def tags(self):
         """Create the Tag TI object."""
         return Tags(self)
 
@@ -585,77 +650,79 @@
 
     def owner(self):
         """Create the Owner object."""
         return Owner(self)
 
     def create_entity(self, entity, owner):
         """Given a Entity and a Owner, creates a indicator/group in ThreatConnect"""
-
         attributes = entity.pop('attribute', [])
         associations = entity.pop('associations', [])
         security_labels = entity.pop('securityLabel', [])
         tags = entity.pop('tag', [])
         entity_type = entity.pop('type', '').lower()
         file_content = None
         if entity_type in ['document', 'report']:
             file_content = entity.pop('file_content', None) or entity.pop('fileContent', None)
         try:
-            ti = self.indicator(entity_type, owner, **entity)
+            ti = cast(Indicator, self.indicator(entity_type, owner, **entity))
             if entity.get('falsePositive'):
                 ti.add_false_positive()
         except Exception:
             if entity_type in ['victim']:
                 ti = self.victim(owner=owner, **entity)
             else:
                 entity['name'] = entity.pop('summary', None)
                 if entity_type in ['task']:
                     ti = self.task(owner=owner, **entity)
                 else:
                     ti = self.group(entity_type, owner, **entity)
-        r = ti.create()
-        if entity_type in ['document', 'report']:
+        r = cast(Response, ti.create())
+        if file_content and entity_type in ['document', 'report']:
+            ti = cast(Document | Report, ti)
             ti.file_content(file_content)
 
-        data = {'status_code': r.status_code}
+        data: dict[str, int | list | str] = {'status_code': r.status_code}
         if r.ok:
             data.update(r.json().get('data', {}))
             data['main_type'] = ti.type
             data['sub_type'] = ti.api_sub_type
             data['api_type'] = ti.api_sub_type
             data['api_entity'] = ti.api_entity
             data['api_branch'] = ti.api_branch
             data['owner'] = owner
             data['attributes'] = []
             data['tags'] = []
             data['security_labels'] = []
             data['associations'] = []
+        else:
+            return None
 
         for attribute in attributes:
             r = ti.add_attribute(attribute.get('type'), attribute.get('value'))
             attribute_data = {'status_code': r.status_code}
             if r.ok:
                 attribute_data.update(r.json().get('attribute', {}))
             data['attributes'].append(attribute_data)
         for tag in tags:
-            r = ti.add_tag(tag)
+            r = cast(Response, ti.add_tag(tag))
             tag_response = {'status_code': r.status_code}
             data['tags'].append(tag_response)
         for label in security_labels:
-            r = ti.add_label(label)
+            r = cast(Response, ti.add_label(label))
             label_response = {'status_code': r.status_code}
             data['security_labels'].append(label_response)
         for association in associations:
             association_target = self.indicator(
                 association.pop('type', None), association.pop('owner', None), **association
             )
             if not association_target:
                 association_target = self.group(
                     association.pop('type', None), association.pop('owner', None), **association
                 )
-            r = ti.add_association(association_target)
+            r = cast(Response, ti.add_association(association_target))
             association_response = {'status_code': r.status_code}
             if r.ok:
                 association_response.update(r.json().get('association', {}))
             data['associations'].append(association_response)
 
         return data
 
@@ -751,32 +818,34 @@
         for d in tc_data:
             entity = {'id': d.get('id'), 'webLink': d.get('webLink')}
             values = []
             value = None
             keys = d.keys()
             if resource_type.lower() in map(str.lower, self._group_types):
                 # @bpurdy - is this okay?
-                # r = self.tcex.v2.ti.group(group_type=resource_type, name=d.get('name'))
+                # r = self.tcex.api.tc.v2.ti.group(group_type=resource_type, name=d.get('name'))
                 r = self.group(group_type=resource_type, name=d.get('name'))
                 value = d.get('name')
             elif resource_type.lower() in map(str.lower, self._indicator_types_data):
                 # @bpurdy - is this okay?
-                # r = self.tcex.v2.ti.indicator(indicator_type=resource_type)
+                # r = self.tcex.api.tc.v2.ti.indicator(indicator_type=resource_type)
                 r = self.indicator(indicator_type=resource_type)
                 r._set_unique_id(d)
                 value = r.unique_id
             elif resource_type.lower() in ['victim']:
                 r = self.victim(name=d.get('name'))
                 value = d.get('name')
             else:
                 self._handle_error(925, ['type', 'entities', 'type', 'type', resource_type])
+                continue
 
             if 'summary' in d:
                 values.append(d.get('summary'))
             else:
+                r = cast(Indicator, r)
                 if resource_type.lower() in ['file']:
                     value = r.build_summary(d.get('md5'), d.get('sha1'), d.get('sha256'))
                 values.append(r.fully_decode_uri(value))
             entity['value'] = ' : '.join(values)
 
             if r.is_group() or r.is_indicator():
                 if 'owner' in d:
@@ -836,15 +905,15 @@
                     entity['header'] = d.get('header')
                 if 'body' in keys:
                     entity['body'] = d.get('body')
                 if 'publishDate' in keys:
                     entity['publishDate'] = d.get('publishDate')
                 if r.api_sub_type.lower() in ['signature', 'document', 'report']:
                     r.unique_id = d.get('id')
-                    content_response = r.download()
+                    content_response = r.download()  # type: ignore
                     if content_response.ok:
                         entity['fileContent'] = content_response.text
             # get the entity type
             if d.get('type') is not None:
                 entity['type'] = d.get('type')
             else:
                 entity['type'] = resource_type
@@ -854,15 +923,15 @@
     def _gen_indicator_class(self):
         """Generate Custom Indicator Classes."""
 
         for entry in self._indicator_types_data.values():
             name = entry.get('name')
             class_name = name.replace(' ', '')
             # temp fix for API issue where boolean are returned as strings
-            entry['custom'] = self.utils.to_bool(entry.get('custom'))
+            entry['custom'] = self.util.to_bool(entry.get('custom'))
 
             if class_name in globals():
                 # skip Indicator Type if a class already exists
                 continue
 
             # Custom Indicator can have 3 values. Only add the value if it is set.
             value_fields = []
```

### Comparing `tcex-3.0.9/tcex/api/tc/v2/v2.py` & `tcex-4.0.0/tcex/api/tc/v2/v2.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,52 +1,46 @@
-"""API -> TC -> V2"""
-# standard library
-from typing import TYPE_CHECKING, Optional
+"""TcEx Framework Module"""
+# third-party
+from requests import Session  # TYPE-CHECKING
 
 # first-party
 from tcex.api.tc.v2.batch.batch import Batch
 from tcex.api.tc.v2.batch.batch_submit import BatchSubmit
 from tcex.api.tc.v2.batch.batch_writer import BatchWriter
 from tcex.api.tc.v2.datastore.cache import Cache
 from tcex.api.tc.v2.datastore.datastore import DataStore
-from tcex.api.tc.v2.metrics.metrics import Metrics
-from tcex.api.tc.v2.notifications.notifications import Notifications
+from tcex.api.tc.v2.metric.metric import Metric
+from tcex.api.tc.v2.notification.notification import Notification
 from tcex.api.tc.v2.threat_intelligence.threat_intelligence import ThreatIntelligence
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Session
-
-    # first-party
-    from tcex.input.input import Input
+from tcex.input.input import Input  # TYPE-CHECKING
 
 
 class V2:
     """API -> TC -> V2
 
     Args:
         inputs: An instance of the Input class.
         session_tc: An configured instance of request.Session with TC API Auth.
     """
 
-    def __init__(self, inputs: 'Input', session_tc: 'Session'):
-        """Initialize Class properties."""
+    def __init__(self, inputs: Input, session_tc: Session):
+        """Initialize instance properties."""
         self.inputs = inputs
         self.session_tc = session_tc
 
     def batch(
         self,
         owner: str,
-        action: Optional[str] = 'Create',
-        attribute_write_type: Optional[str] = 'Replace',
-        halt_on_error: Optional[bool] = False,
-        playbook_triggers_enabled: Optional[bool] = False,
-        tag_write_type: Optional[str] = 'Replace',
-        security_label_write_type: Optional[str] = 'Replace',
-    ) -> 'Batch':
+        action: str = 'Create',
+        attribute_write_type: str = 'Replace',
+        halt_on_error: bool = False,
+        playbook_triggers_enabled: bool = False,
+        tag_write_type: str = 'Replace',
+        security_label_write_type: str = 'Replace',
+    ) -> Batch:
         """Return instance of Batch
 
         Args:
             owner: The ThreatConnect owner for Batch action.
             action: Action for the batch job ['Create', 'Delete'].
             attribute_write_type: Write type for TI attributes ['Append', 'Replace'].
             halt_on_error: If True any batch error will halt the batch job.
@@ -65,21 +59,21 @@
             tag_write_type,
             security_label_write_type,
         )
 
     def batch_submit(
         self,
         owner: str,
-        action: Optional[str] = 'Create',
-        attribute_write_type: Optional[str] = 'Replace',
-        halt_on_error: Optional[bool] = False,
-        playbook_triggers_enabled: Optional[bool] = False,
-        tag_write_type: Optional[str] = 'Replace',
-        security_label_write_type: Optional[str] = 'Replace',
-    ) -> 'BatchSubmit':
+        action: str = 'Create',
+        attribute_write_type: str = 'Replace',
+        halt_on_error: bool = False,
+        playbook_triggers_enabled: bool = False,
+        tag_write_type: str = 'Replace',
+        security_label_write_type: str = 'Replace',
+    ) -> BatchSubmit:
         """Return instance of Batch
 
         Args:
             owner: The ThreatConnect owner for Batch action.
             action: Action for the batch job ['Create', 'Delete'].
             attribute_write_type: Write type for TI attributes ['Append', 'Replace'].
             halt_on_error: If True any batch error will halt the batch job.
@@ -95,90 +89,92 @@
             attribute_write_type,
             halt_on_error,
             playbook_triggers_enabled,
             tag_write_type,
             security_label_write_type,
         )
 
-    def batch_writer(self, output_dir: str, **kwargs) -> 'BatchWriter':
+    def batch_writer(self, output_dir: str, **kwargs) -> BatchWriter:
         """Return instance of Batch
 
         Args:
             output_dir: Deprecated input, will not be used.
-            output_extension (kwargs: str): Append this extension to output files.
-            write_callback (kwargs: Callable): A callback method to call when a batch json file
-                is written. The callback will be passed the fully qualified name of the written
-                file.
-            write_callback_kwargs (kwargs: dict): Additional values to send to callback method.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
+            output_extension (str): Append this extension to output files.
+            write_callback (Callable): A callback method to call when a batch json file is
+                written. The callback will be passed the fully qualified name of the written file.
+            write_callback_kwargs (dict): Additional values to send to callback method.
         """
         return BatchWriter(self.inputs, self.session_tc, output_dir, **kwargs)
 
     def cache(
         self,
         domain: str,
         data_type: str,
-        ttl_seconds: Optional[int] = None,
-        mapping: Optional[dict] = None,
+        ttl_seconds: int | None = None,
+        mapping: dict | None = None,
     ) -> Cache:
         """Get instance of the Cache module.
 
         Args:
             domain: The domain can be either "system", "organization", or "local". When using
                 "organization" the data store can be accessed by any Application in the entire org,
                 while "local" access is restricted to the App writing the data. The "system" option
                 should not be used in almost all cases.
             data_type: The data type descriptor (e.g., tc:whois:cache).
             ttl_seconds: The number of seconds the cache is valid.
             mapping: Advanced - The datastore mapping if required.
         """
         return Cache(self.session_tc, domain, data_type, ttl_seconds, mapping)
 
-    def datastore(self, domain: str, data_type: str, mapping: Optional[dict] = None) -> 'DataStore':
+    def datastore(self, domain: str, data_type: str, mapping: dict | None = None) -> DataStore:
         """Return Datastore Module.
 
         Args:
             domain: The domain can be either "system", "organization", or "local". When using
                 "organization" the data store can be accessed by any Application in the entire org,
                 while "local" access is restricted to the App writing the data. The "system" option
                 should not be used in almost all cases.
             data_type: The data type descriptor (e.g., tc:whois:cache).
-            mapping: ElasticSearch mappings data.
+            mapping: ElasticSearch mapping data.
         """
         return DataStore(
             session_tc=self.session_tc, domain=domain, data_type=data_type, mapping=mapping
         )
 
     def metric(
         self,
         name: str,
         description: str,
         data_type: str,
         interval: str,
-        keyed: Optional[bool] = False,
-    ) -> 'Metrics':
+        keyed: bool = False,
+    ) -> Metric:
         """Get instance of the Metrics module.
 
         Args:
             name: The name for the metric.
             description: The description of the metric.
             data_type: The type of metric: Sum, Count, Min, Max, First, Last, and Average.
             interval: The metric interval: Hourly, Daily, Weekly, Monthly, and Yearly.
             keyed: Indicates whether the data will have a keyed value.
         """
-        return Metrics(
+        return Metric(
             session_tc=self.session_tc,
             name=name,
             description=description,
             data_type=data_type,
             interval=interval,
             keyed=keyed,
         )
 
     @property
-    def notification(self) -> 'Notifications':
+    def notification(self) -> Notification:
         """Get instance of the Notification module."""
-        return Notifications(self.session_tc)
+        return Notification(self.session_tc)
 
     @property
-    def ti(self) -> 'ThreatIntelligence':
+    def ti(self) -> ThreatIntelligence:
         """Get instance of the Notification module."""
         return ThreatIntelligence(self.session_tc)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,102 +1,77 @@
-"""Generate Models for ThreatConnect V3 API"""
+"""TcEx Framework Module"""
 # standard library
 import os
-import sys
 from enum import Enum
 from pathlib import Path
 
 # third-party
-import black
-import isort
 import typer
 
 # first-party
 from tcex.api.tc.v3._gen._gen_args_abc import GenerateArgsABC
 from tcex.api.tc.v3._gen._gen_filter_abc import GenerateFilterABC
 from tcex.api.tc.v3._gen._gen_model_abc import GenerateModelABC
 from tcex.api.tc.v3._gen._gen_object_abc import GenerateObjectABC
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
-from tcex.utils import Utils
-from tcex.utils.string_operations import SnakeString
+from tcex.util import Util
+from tcex.util.code_operation import CodeOperation
+from tcex.util.render.render import Render
+from tcex.util.string_operation import SnakeString
 
-# initialize Utils module
-utils = Utils()
+# initialize Util module
+util = Util()
 
 
 def log_server():
     """Log server."""
     _api_server = os.getenv('TC_API_PATH')
-    typer.secho(f'Using server {_api_server}', fg=typer.colors.BRIGHT_MAGENTA)
+    Render.panel.info(f'Using server {_api_server}')
 
 
 class GenerateArgs(GenerateArgsABC):
     """Generate Models for TC API Types"""
 
 
 class GenerateFilter(GenerateFilterABC):
     """Generate Models for TC API Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         _api_endpoint = getattr(ApiEndpoints, type_.upper()).value
         self.api_url = f'{self._api_server}{_api_endpoint}'
 
 
 class GenerateModel(GenerateModelABC):
     """Generate Models for TC API Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         _api_endpoint = getattr(ApiEndpoints, type_.upper()).value
         self.api_url = f'{self._api_server}{_api_endpoint}'
 
 
 class GenerateObject(GenerateObjectABC):
     """Generate Models for TC API Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         _api_endpoint = getattr(ApiEndpoints, type_.upper()).value
         self.api_url = f'{self._api_server}{_api_endpoint}'
 
 
-def format_code(_code):
-    """Return formatted code."""
-
-    # run black formatter on code
-    mode = black.FileMode(line_length=100, string_normalization=False)
-    try:
-        _code = black.format_file_contents(_code, fast=False, mode=mode)
-    except black.InvalidInput as ex:
-        print(f'Formatting of code failed {ex}.')
-        sys.exit(1)
-    except black.NothingChanged:
-        pass
-
-    # run isort on code
-    try:
-        isort_config = isort.Config(settings_file='setup.cfg')
-        _code = isort.code(_code, config=isort_config)
-    except Exception as ex:
-        print(f'Formatting of code failed {ex}.')
-        sys.exit(1)
-
-    return _code
-
-
 def gen_args(type_: SnakeString, indent_blocks: int):
     """Generate args code."""
     # get instance of doc generator
     gen = GenerateArgs(type_)
 
     # run model code first so that requirements can be determined
     i1 = ' ' * (4 * indent_blocks)
@@ -110,114 +85,113 @@
     gen = GenerateFilter(type_)
 
     # set the output filename using the appropriate tcex api path
     out_path = gen.tap(type_).split('.') + [type_, f'{type_.singular()}_filter.py']
     out_file = Path(os.path.join(*out_path))
 
     if not out_file.is_file():
-        typer.secho(f'\nCould not find file {out_file}.', fg=typer.colors.RED)
-        typer.Exit(code=1)
+        Render.panel.failure(f'\nCould not find file {out_file}.')
 
     # generate class methods first so requirements can be updated
     class_methods = gen.gen_class_methods()
 
     _code = gen.gen_doc_string()
     _code += gen.gen_requirements()
     _code += gen.gen_class()
     _code += class_methods
     _code += ''  # newline at the end of the file
 
     with out_file.open(mode='w') as fh:
-        fh.write(format_code(_code))
+        fh.write(CodeOperation.format_code(_code))
 
-    typer.secho(f'Successfully wrote {out_file}.', fg=typer.colors.GREEN)
+    Render.panel.success(f'Successfully wrote {out_file}.')
 
     for msg in gen.messages:
-        typer.secho(msg, fg=typer.colors.YELLOW)
+        Render.panel.warning(msg)
 
 
 def gen_model(type_: SnakeString):
     """Generate model code."""
     # get instance of model generator
     gen = GenerateModel(type_)
 
     # set the output filename using the appropriate tcex api path
     out_path = gen.tap(type_).split('.') + [type_, f'{type_.singular()}_model.py']
     out_file = Path(os.path.join(*out_path))
 
     if not out_file.is_file():
-        typer.secho(f'\nCould not find file {out_file}.', fg=typer.colors.RED)
-        typer.Exit(code=1)
+        Render.panel.failure(f'\nCould not find file {out_file}.')
 
     # generate model fields code first so that requirements can be determined
     container_private_attrs = gen.gen_container_private_attrs()
     model_fields = gen.gen_model_fields()
     model_private_attrs = gen.gen_model_private_attrs()
     validator_methods = gen.gen_validator_methods()
 
     _code = gen.gen_doc_string()
     _code += gen.gen_requirements()
-    # add container model
-    _code += gen.gen_container_class()
-    _code += container_private_attrs
-    _code += gen.gen_container_fields()
-    # add data model
-    _code += gen.gen_data_class()
-    _code += gen.gen_data_fields()
-    # add data model
+    # add generated model class (ArtifactModel, CaseModel, etc.)
     _code += gen.gen_model_class()
     _code += model_private_attrs
     _code += model_fields
-    # add validators
+    # add validators to model class
     _code += validator_methods
+    # add generated "data" model class (ArtifactDataModel, CaseDataModel, etc.)
+    _code += gen.gen_data_class()
+    _code += gen.gen_data_fields()
+    # add generated container model class (ArtifactsModel, CasesModel, etc.)
+    _code += gen.gen_container_class()
+    _code += container_private_attrs
+    _code += gen.gen_container_fields()
     # add forward reference requirements
     _code += gen.gen_requirements_first_party_forward_reference()
     # add forward references
     _code += gen.gen_forward_reference()
 
     with out_file.open(mode='w') as fh:
-        fh.write(format_code(_code))
+        fh.write(CodeOperation.format_code(_code))
 
-    typer.secho(f'Successfully wrote {out_file}.', fg=typer.colors.GREEN)
+    Render.panel.success(f'Successfully wrote {out_file}.')
 
     for msg in gen.messages:
-        typer.secho(msg, fg=typer.colors.YELLOW)
+        Render.panel.warning(msg)
 
 
 def gen_object(type_: SnakeString):
     """Generate object code."""
     # get instance of filter generator
     gen = GenerateObject(type_)
 
     # set the output filename using the appropriate tcex api path
     out_path = gen.tap(type_).split('.') + [type_, f'{type_.singular()}.py']
     out_file = Path(os.path.join(*out_path))
 
     if not out_file.is_file():
-        typer.secho(f'\nCould not find file {out_file}.', fg=typer.colors.RED)
-        typer.Exit(code=1)
+        Render.panel.failure(f'\nCould not find file {out_file}.')
 
     # generate class method code first so that requirements can be determined
     container_methods = gen.gen_container_methods()
     object_methods = gen.gen_object_methods()
 
     _code = gen.gen_doc_string()
     _code += gen.gen_requirements()
-    _code += gen.gen_container_class()
-    _code += container_methods
+    # add generated class (Artifact, Case, etc.)
     _code += gen.gen_object_class()
     _code += object_methods
+    # add generated container class (Artifacts, Cases, etc.)
+    _code += gen.gen_container_class()
+    _code += container_methods
 
     with out_file.open(mode='w') as fh:
-        fh.write(format_code(_code))
+        fh.write(CodeOperation.format_code(_code))
 
-    typer.secho(f'Successfully wrote {out_file}.', fg=typer.colors.GREEN)
+    Render.panel.success(f'Successfully wrote {out_file}.')
 
     for msg in gen.messages:
-        typer.secho(msg, fg=typer.colors.YELLOW)
+        Render.panel.warning(msg)
 
 
 #
 # CLI
 #
 
 
@@ -266,82 +240,82 @@
 def all(  # pylint: disable=redefined-builtin
     gen_type: GenTypes = typer.Option(
         'all', '--gen_type', help='Generate filter, model, or object file.'
     ),
 ):
     """Generate Args."""
     log_server()
-    gen_type = gen_type.value.lower()
+    gen_type_ = gen_type.value.lower()
     for type_ in ObjectTypes:
-        type_ = utils.snake_string(type_.value)
+        type_ = util.snake_string(type_.value)
 
-        if gen_type in ['all', 'filter']:
+        if gen_type_ in ['all', 'filter']:
             gen_filter(type_)
-        if gen_type in ['all', 'model']:
+        if gen_type_ in ['all', 'model']:
             gen_model(type_)
-        if gen_type in ['all', 'object']:
+        if gen_type_ in ['all', 'object']:
             gen_object(type_)
 
 
 @app.command()
 def args(
     type_: ObjectTypes = typer.Option(
         ..., '--type', help='Generate Args for the provided object type.'
     ),
     indent_blocks: int = typer.Option(
         1, help='The number of four space blocks to indent the args.'
     ),
 ):
     """Generate Args."""
     log_server()
-    gen_args(utils.snake_string(type_.value), indent_blocks)
+    gen_args(util.snake_string(type_.value), indent_blocks)
 
 
 @app.command()
 def code(
     type_: ObjectTypes = typer.Option(
         ..., '--type', help='Generate filter, model, and object files for the provided type.'
     ),
 ):
     """Generate Args."""
     log_server()
-    tv = utils.snake_string(type_.value)
+    tv = util.snake_string(type_.value)
     gen_filter(tv)
     gen_model(tv)
     gen_object(tv)
 
 
 @app.command()
 def filter(  # pylint: disable=redefined-builtin
     type_: ObjectTypes = typer.Option(
         ..., '--type', help='Generate filter object file for the provided type.'
     ),
 ):
     """Generate the filter code."""
     log_server()
-    gen_filter(utils.snake_string(type_.value))
+    gen_filter(util.snake_string(type_.value))
 
 
 @app.command()
 def model(
     type_: ObjectTypes = typer.Option(
         ..., '--type', help='Generate model file for the provided type.'
     ),
 ):
     """Generate the model"""
     log_server()
-    gen_model(utils.snake_string(type_.value))
+    gen_model(util.snake_string(type_.value))
 
 
 @app.command()
 def object(  # pylint: disable=redefined-builtin
     type_: ObjectTypes = typer.Option(
         ..., '--type', help='Generate object file for the provided type.'
     ),
 ):
     """Generate the filter class"""
     log_server()
-    gen_object(utils.snake_string(type_.value))
+    gen_object(util.snake_string(type_.value))
 
 
 if __name__ == '__main__':
     app()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_abc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,47 +1,47 @@
-"""Generate Abstract Base Class"""
+"""TcEx Framework Module"""
 # standard library
 import os
 from abc import ABC
+from collections.abc import Generator
 from textwrap import TextWrapper
-from typing import Dict, Iterable, List, Union
 
 # third-party
-import typer
 from pydantic import ValidationError
 from requests import Session
 from requests.exceptions import ProxyError
 
 # first-party
-from tcex.api.tc.v3._gen.models import PropertyModel
-from tcex.backports import cached_property
-from tcex.input.field_types.sensitive import Sensitive
-from tcex.sessions.auth.hmac_auth import HmacAuth
-from tcex.utils import Utils
-from tcex.utils.string_operations import SnakeString
+from tcex.api.tc.v3._gen.model import PropertyModel
+from tcex.input.field_type.sensitive import Sensitive
+from tcex.pleb.cached_property import cached_property
+from tcex.requests_tc.auth.hmac_auth import HmacAuth
+from tcex.util import Util
+from tcex.util.render.render import Render
+from tcex.util.string_operation import SnakeString
 
 
 class GenerateABC(ABC):
     """Generate Abstract Base Class"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.type_ = type_
 
         # properties
         self._api_server = os.getenv('TC_API_PATH')
         self.api_url: str
         self.i1 = ' ' * 4  # indent level 1
         self.i2 = ' ' * 8  # indent level 2
         self.i3 = ' ' * 12  # indent level 3
         self.i4 = ' ' * 16  # indent level 4
         self.i5 = ' ' * 20  # indent level 5
         self.messages = []
         self.requirements = {}
-        self.utils = Utils()
+        self.util = Util()
 
     @staticmethod
     def _format_description(arg: str, description: str, length: int, indent: str) -> str:
         """Format description for field."""
         # fix descriptions coming from core API endpoint
         if description[-1] not in ('.', '?', '!'):
             description += '.'
@@ -63,17 +63,17 @@
             type_ = 'case_attributes'
         elif type_ == 'attributes' and self.type_ == 'groups':
             type_ = 'group_attributes'
         elif type_ == 'attributes' and self.type_ == 'indicators':
             type_ = 'indicator_attributes'
         elif type_ == 'attributes' and self.type_ == 'victims':
             type_ = 'victim_attributes'
-        return self.utils.snake_string(type_)
+        return self.util.snake_string(type_)
 
-    def _module_import_data(self, type_: SnakeString) -> Dict:
+    def _module_import_data(self, type_: SnakeString) -> dict[str, str]:
         """Return the model module map data.
 
         This method provides the logic to build the import module and class dynamically. Using
         the provided type value (e.g., cases, groups, victim_attributes) the module
         (tcex.api.tc.v3.groups.group_filter) and the class (GroupFilter) are returned.
 
         filter -> the filter Class (CaseFilter)
@@ -100,20 +100,19 @@
         _properties = {}
         try:
             r = self.session.options(self.api_url, params={'show': 'readOnly'})
             # print(r.request.method, r.request.url, r.text)
             if r.ok:
                 _properties = r.json()
         except (ConnectionError, ProxyError) as ex:
-            typer.secho(f'Failed getting types properties ({ex}).', fg=typer.colors.RED)
-            typer.Exit(1)
+            Render.panel.failure(f'Failed getting types properties ({ex}).')
 
         return _properties
 
-    def _prop_contents_data(self, properties: dict) -> Iterable[dict]:
+    def _prop_contents_data(self, properties: dict) -> Generator:
         """Yield the appropriate data object.
 
         artifacts": {
             "data": [
                 {
                     "description": "a list of Artifacts corresponding to the Case",
                     "type": "Artifact"
@@ -134,15 +133,15 @@
         for field_name, field_data in sorted(properties.items()):
             if isinstance(field_data, dict):
                 if 'data' in field_data and isinstance(field_data['data'], list):
                     # some properties have a data key with an array of items.
                     field_data = field_data['data'][0]
 
                     # if there is a data array, then the type should always be plural.
-                    field_data['type'] = self.utils.camel_string(field_data['type']).plural()
+                    field_data['type'] = self.util.camel_string(field_data['type']).plural()
             elif isinstance(field_data, list):
                 # in a few instance like attributeType the value of the properties key/value
                 # pair is a list (currently the list only contains a single dict). to be safe
                 # we loop over the list and update the type for each item.
                 field_data = field_data[0]
             else:
                 raise RuntimeError(
@@ -171,15 +170,15 @@
 
         # remove unused fields, if any
         self._prop_content_remove_unused(_properties)
 
         # update "bad" data
         self._prop_content_update(_properties)
 
-        # Temp issue
+        # maybe a temp issue?
         if self.type_ == 'indicators':
             _properties['enrichment']['data'][0]['type'] = 'Enrichment'
 
         # critical fix for breaking API change
         if self.type_ in [
             'case_attributes',
             'group_attributes',
@@ -391,82 +390,85 @@
                 properties['upVoteCount']['readOnly'] = True
 
         if self.type_ in ['victims']:
             # ownerName is readOnly, but readOnly is not defined in response from OPTIONS endpoint
             properties['ownerName']['readOnly'] = True
 
     @property
-    def _prop_models(self) -> List[PropertyModel]:
+    def _prop_models(self) -> list[PropertyModel]:
         """Return a list of PropertyModel objects."""
         properties_models = []
         for field_data in self._prop_contents_data(self._prop_contents_updated):
             try:
                 properties_models.append(PropertyModel(**field_data))
             except ValidationError as ex:
                 # print(field_data)
-                typer.secho(
+                Render.panel.failure(
                     f'Failed generating property model: data={field_data} ({ex}).',
-                    fg=typer.colors.RED,
                 )
-                raise
         return properties_models
 
     def gen_requirements(self):
         """Generate imports string."""
         # add additional imports when required
         if self.requirements.get('type-checking'):
             self.requirements['standard library'].append('from typing import TYPE_CHECKING')
 
         indent = ''
-        _libs: List[Union[dict, str]] = []
+        # _libs: list[dict | str] = []
+        _libs = []
         for from_, libs in self.requirements.items():
             if not libs:
                 # continue if there are no libraries to import
                 continue
 
             if from_ in ['first-party-forward-reference']:
                 # skip forward references
                 continue
 
+            comment = ''
             if from_ == 'type-checking':
                 _libs.append('if TYPE_CHECKING:  # pragma: no cover')
                 indent = self.i1
                 # this should be fine?
                 from_ = 'first-party'
+                comment = '  # CIRCULAR-IMPORT'
 
             _libs.append(f'{indent}# {from_}')
 
             # manage imports as string and dicts
             _imports = []  # temp store for imports so they can be sorted
             for lib in libs:
                 if isinstance(lib, dict):
                     imports = ', '.join(sorted(lib.get('imports')))  # type: ignore
-                    _imports.append(f'''{indent}from {lib.get('module')} import {imports}''')
+                    _imports.append(
+                        f'''{indent}from {lib.get('module')} import {imports}{comment}'''
+                    )
                 elif isinstance(lib, str):
-                    _imports.append(f'{indent}{lib}')
+                    _imports.append(f'{indent}{lib}{comment}')
             _libs.extend(sorted(_imports))  # add imports sorted
 
             _libs.append('')  # add newline
         _libs.append('')  # add newline
 
         # This is the last part of the requirements generated.
         return '\n'.join(_libs)  # type: ignore
 
     @property
-    def session(self) -> 'Session':
+    def session(self) -> Session:
         """Return Session configured for TC API."""
         _session = Session()
         _session.auth = HmacAuth(
             os.getenv('TC_API_ACCESS_ID', ''), Sensitive(os.getenv('TC_API_SECRET_KEY', ''))
         )
         return _session
 
     def tap(self, type_: str):
         """Return the TcEx Api Path."""
-        type_ = self.utils.snake_string(type_)
+        type_ = self.util.snake_string(type_)
         if type_.plural().lower() in [
             'owners',
             'owner_roles',
             'system_roles',
             'users',
             'user_groups',
         ]:
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_args_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_args_abc.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,40 +1,40 @@
-"""Generate Docs for ThreatConnect API"""
+"""TcEx Framework Module"""
 # standard library
 import importlib
-import sys
 from abc import ABC
-from typing import Any, Optional
+from typing import Any
 
 # first-party
 from tcex.api.tc.v3._gen._gen_abc import GenerateABC
+from tcex.util.render.render import Render
 
 
 class GenerateArgsABC(GenerateABC, ABC):
     """Generate docstring for Model."""
 
     def __init__(self, type_: Any):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
     @staticmethod
-    def _import_model(module, class_name) -> Any:
+    def _import_model(module: Any, class_name: str) -> Any:
         """Import the appropriate model."""
         return getattr(importlib.import_module(module), class_name)
 
-    def _prop_type(self, prop_data: dict) -> str:
+    def _prop_type(self, prop_data: dict[str, dict | str | None]) -> str | None:
         """Return the appropriate arg type."""
         prop_type = None
-        if 'type' in prop_data:
-            prop_type = self._prop_type_map(prop_data.get('type'))
+        if 'type' in prop_data and prop_data.get('type') is not None:
+            prop_type = self._prop_type_map(prop_data.get('type'))  # type: ignore
         elif 'allOf' in prop_data and prop_data.get('allOf'):
-            ref = prop_data.get('allOf')[0].get('$ref')
+            ref: str = prop_data.get('allOf')[0].get('$ref')  # type: ignore
             prop_type = ref.split('/')[-1].replace('Model', '')
         elif 'items' in prop_data and prop_data.get('items'):
-            ref = prop_data.get('items').get('$ref')
+            ref: str = prop_data.get('items', {}).get('$ref')  # type: ignore
             prop_type = ref.split('/')[-1].replace('Model', '')
         return prop_type
 
     @staticmethod
     def _prop_type_map(prop_type: str) -> str:
         """Return hint type."""
         _prop_types = {
@@ -42,38 +42,37 @@
             'integer': 'int',
             'string': 'str',
         }
         return _prop_types.get(prop_type, prop_type)
 
     def gen_args(
         self,
-        i1: Optional[str] = None,
-        i2: Optional[str] = None,
-        updatable: Optional[bool] = True,
+        i1: str | None = None,
+        i2: str | None = None,
+        updatable: bool = True,
     ) -> str:
         """Model Map"""
         i1 = i1 or self.i1
         i2 = i2 or self.i2
 
         module_import_data = self._module_import_data(self.type_)
         model = self._import_model(
-            module_import_data.get('model_module'), module_import_data.get('model_class')
+            module_import_data['model_module'], module_import_data['model_class']
         )
         _doc_string = [f'{i1}Args:']
 
         # get properties from schema
         schema = model().schema(by_alias=False)
         if '$ref' in schema:
             model_name = schema.get('$ref').split('/')[-1]
             properties = schema.get('definitions').get(model_name).get('properties')
         elif 'properties' in schema:
             properties = schema.get('properties')
         else:
-            print(model().schema_json(by_alias=False))
-            sys.exit()
+            Render.panel.failure(model().schema_json(by_alias=False))
 
         # iterate over properties to build docstring
         for arg, prop_data in properties.items():
             # for all doc string read-only args should not be included.
             if prop_data.get('read_only', False) is True:
                 continue
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_filter_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_filter_abc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,30 @@
-"""Generate Filters for ThreatConnect API"""
+"""TcEx Framework Module"""
 # standard library
 from abc import ABC
-from typing import Any, Dict, Generator, List
+from collections.abc import Generator
+from typing import Any
 
 # third-party
-import typer
 from pydantic import ValidationError
 from requests.exceptions import ProxyError
 
 # first-party
 from tcex.api.tc.v3._gen._gen_abc import GenerateABC
-from tcex.api.tc.v3._gen.models import FilterModel
-from tcex.backports import cached_property
-from tcex.utils.string_operations import SnakeString
+from tcex.api.tc.v3._gen.model import FilterModel
+from tcex.pleb.cached_property import cached_property
+from tcex.util.render.render import Render
+from tcex.util.string_operation import SnakeString
 
 
 class GenerateFilterABC(GenerateABC, ABC):
     """Generate Models for Case Management Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         self.api_url = ''
         self.requirements = {
             'standard library': [
                 'from enum import Enum',
@@ -44,15 +45,15 @@
                 [
                     'from tcex.api.tc.v3.tql.tql import Tql',
                     'from tcex.api.tc.v3.tql.tql_operator import TqlOperator',
                 ]
             )
 
     @cached_property
-    def _filter_contents(self) -> List[Dict[str, Any]]:
+    def _filter_contents(self) -> list[dict[str, Any]]:
         """Return defined API properties for the current object.
 
         Response:
         {
             "keyword": "analyticsScore",
             "name": "Analytics Score",
             "type": "Integer",
@@ -64,35 +65,35 @@
         _properties = []
         try:
             r = self.session.options(f'{self.api_url}/tql', params={})
             # print(r.request.method, r.request.url, r.text)
             if r.ok:
                 _properties = r.json().get('data', [])
         except (ConnectionError, ProxyError) as ex:
-            typer.secho(f'Failed getting types properties ({ex}).', fg=typer.colors.RED)
-            typer.Exit(1)
+            Render.panel.failure(f'Failed getting types properties ({ex}).')
 
         return _properties
 
     @property
-    def _filter_contents_updated(self) -> List[Dict[str, Any]]:
+    def _filter_contents_updated(self) -> list[dict[str, Any]]:
         """Update the properties contents, fixing issues in core data."""
         filters = self._filter_contents
 
         # Provided invalid type "BigInteger" on tql options call and correcting it to String
         for filter_ in filters:
             if self.type_ == 'indicators':
                 title = 'Indicator Keyword Type'
                 if filter_['keyword'] == 'addressIpval' and filter_['type'] != 'String':
                     self.messages.append(f'- [{self.type_}] - ({title}) - fix required.')
                     filter_['type'] = 'String'
                 else:
                     self.messages.append(f'- [{self.type_}] - ({title}) - fix NOT required.')
 
             if self.type_ == 'cases' and 'description' in filter_:
+                # fix misspelling in core data
                 miss_map = {
                     'occured': 'occurred',
                     'Threatassess': 'ThreatAssess',
                 }
                 for c, w in miss_map.items():
                     if c in filter_['description']:
                         filter_['description'] = filter_['description'].replace(c, w)
@@ -100,19 +101,15 @@
 
     @cached_property
     def _filter_models(self) -> Generator[FilterModel, None, None]:
         for field_data in self._filter_contents_updated:
             try:
                 yield FilterModel(**field_data)
             except ValidationError as ex:
-                typer.secho(
-                    f'Failed generating property model: data={field_data} ({ex}).',
-                    fg=typer.colors.RED,
-                )
-                raise
+                Render.panel.failure(f'Failed generating property model: data={field_data} ({ex}).')
 
     def _gen_code_generic_method(self, filter_data: FilterModel) -> list:
         """Return code for generic TQL filter methods."""
         keyword_description = self._format_description(
             arg=filter_data.keyword.snake_case(),
             description=filter_data.description,
             length=100,
@@ -128,20 +125,41 @@
             '',
             f'{self.i2}Args:',
             f'{self.i3}operator: The operator enum for the filter.',
             f'{self.i3}{keyword_description}',
             f'{self.i2}"""',
         ]
         if filter_data.type.lower() in ['date', 'datetime']:
+            self.requirements['first-party'].extend(
+                [
+                    'from arrow import Arrow',
+                    'from datetime import datetime',
+                ]
+            )
             _code.extend(
                 [
-                    f'''{self.i2}{filter_data.keyword.snake_case()} = self.utils.any_to_datetime'''
+                    f'''{self.i2}{filter_data.keyword.snake_case()} = self.util.any_to_datetime'''
                     f'''({filter_data.keyword.snake_case()}).strftime('%Y-%m-%d %H:%M:%S')'''
                 ]
             )
+
+        if 'list' in filter_data.extra.typing_type:
+            _code.extend(
+                [
+                    (
+                        f'''{self.i2}if isinstance({filter_data.keyword.snake_case()}, list) '''
+                        '''and operator not in self.list_types:'''
+                    ),
+                    f'''{self.i3}raise RuntimeError('''
+                    f'''{self.i5}'Operator must be CONTAINS, NOT_CONTAINS, IN\''''
+                    f'''{self.i5}'or NOT_IN when filtering on a list of values.\''''
+                    f'''{self.i4})''',
+                    '',
+                ]
+            )
         _code.extend(
             [
                 (
                     f'''{self.i2}self._tql.add_filter('{filter_data.keyword}', operator, '''
                     f'''{filter_data.keyword.snake_case()}, '''
                     f'''{filter_data.extra.tql_type})'''
                 ),
@@ -426,15 +444,15 @@
                 '''TqlOperator.EQ, attributes, TqlType.SUB_QUERY)'''
             ),
             f'{self.i2}return attributes',
             '',
         ]
 
     def gen_api_endpoint_method(self) -> str:
-        """Generate private class method/property.
+        r"""Generate private class method/property.
 
         @property
         def _api_endpoint(self) -> str:
             \"\"\"Return the API endpoint.\"\"\"
             return ApiEndpoints.ARTIFACTS.value
         """
         _method = [
@@ -461,15 +479,14 @@
         """Return a Filter Class current object."""
         _filter_class = []
 
         # added _api_endpoint method
         _filter_class.append(self.gen_api_endpoint_method())
 
         for f in self._filter_models:
-
             if f.keyword.snake_case() == 'has_artifact':
                 _filter_class.extend(self._gen_code_has_artifact_method())
             elif f.keyword.snake_case() == 'has_case':
                 _filter_class.extend(self._gen_code_has_case_method())
             elif f.keyword.snake_case() == 'has_group':
                 _filter_class.extend(self._gen_code_has_group_method())
             elif f.keyword.snake_case() == 'has_indicator':
@@ -491,8 +508,9 @@
             else:
                 _filter_class.extend(self._gen_code_generic_method(f))
 
         return '\n'.join(_filter_class)
 
     def gen_doc_string(self) -> str:
         """Generate doc string."""
-        return f'"""{self.type_.singular().title()} TQL Filter"""\n'
+        # return f'"""{self.type_.singular().title()} TQL Filter"""\n'
+        return '"""TcEx Framework Module"""\n'
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_model_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_model_abc.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,32 @@
-"""Generate Models for ThreatConnect API"""
+"""TcEx Framework Module"""
 # standard library
 from abc import ABC
 from textwrap import TextWrapper
-from typing import List
 
 # first-party
 from tcex.api.tc.v3._gen._gen_abc import GenerateABC
-from tcex.utils.string_operations import SnakeString
+from tcex.util.string_operation import SnakeString
 
 
 class GenerateModelABC(GenerateABC, ABC):
     """Generate Models for Case Management Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         self.requirements = {
-            'standard library': [{'module': 'typing', 'imports': ['List', 'Optional']}],
+            'standard library': [],
             'third-party': [
                 {'module': 'pydantic', 'imports': ['BaseModel', 'Extra', 'Field']},
             ],
             'first-party': [
-                {'module': 'tcex.utils', 'imports': ['Utils']},
+                {'module': 'tcex.util', 'imports': ['Util']},
                 {'module': 'tcex.api.tc.v3.v3_model_abc', 'imports': ['V3ModelABC']},
             ],
             'first-party-forward-reference': [],
         }
         self.validators = {}
 
     def _add_module_class(self, from_: str, module: str, class_: str):
@@ -41,32 +40,32 @@
         """Add pydantic validator only when required."""
         self._add_module_class('third-party', 'pydantic', 'validator')
 
     def _add_pydantic_private_attr(self):
         """Add pydantic validator only when required."""
         self._add_module_class('third-party', 'pydantic', 'PrivateAttr')
 
-    def _gen_code_validator_method(self, type_: str, fields: List[str]) -> str:
+    def _gen_code_validator_method(self, type_: str, fields: list[str]) -> str:
         """Return the validator code
 
-        @validator('artifact_type', always=True)
+        @validator('artifact_type', always=True, pre=True)
         def _validate_artifact_type(cls, v):
             if not v:
                 return ArtifactTypeModel()
             return v
         """
-        type_ = self.utils.camel_string(type_)
+        type_ = self.util.camel_string(type_)
 
         fields_string = ', '.join(f'\'{field}\'' for field in fields)
         return '\n'.join(
             [
-                f'''{self.i1}@validator({fields_string}, always=True)''',
+                f'''{self.i1}@validator({fields_string}, always=True, pre=True)''',
                 f'''{self.i1}def _validate_{type_.snake_case()}(cls, v):''',
                 f'''{self.i2}if not v:''',
-                f'''{self.i3}return {type_}Model()''',
+                f'''{self.i3}return {type_}Model()  # type: ignore''',
                 f'''{self.i2}return v''',
                 '',
             ]
         )
 
     # TODO: [low] bsummers - research combining this method with parent method
     # pylint: disable=arguments-differ
@@ -101,59 +100,63 @@
             ]
         )
         _description.append(f'{self.i2})')
         return '\n'.join(_description)
 
     def gen_doc_string(self) -> str:
         """Generate doc string."""
+        # return (
+        #     f'"""{self.type_.singular().title()} / {self.type_.plural().title()} Model"""\n'
+        #     '# pylint: disable=no-member,no-self-argument,wrong-import-position\n'
+        # )
         return (
-            f'"""{self.type_.singular().title()} / {self.type_.plural().title()} Model"""\n'
-            '# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position\n'
+            '"""TcEx Framework Module"""\n'
+            '# pylint: disable=no-member,no-self-argument,wrong-import-position\n'
         )
 
     def gen_container_class(self) -> str:
         """Generate the Container Model
 
         class ArtifactsModel(
             BaseModel,
             title='Artifacts Model',
-            alias_generator=Utils().snake_to_camel,
+            alias_generator=Util().snake_to_camel,
             validate_assignment=True,
         ):
         """
         return '\n'.join(
             [
                 '',
                 f'''class {self.type_.plural().pascal_case()}Model(''',
                 f'''{self.i1}BaseModel,''',
                 f'''{self.i1}title='{self.type_.plural().pascal_case()} Model',''',
-                f'''{self.i1}alias_generator=Utils().snake_to_camel,''',
+                f'''{self.i1}alias_generator=Util().snake_to_camel,''',
                 f'''{self.i1}validate_assignment=True,''',
                 '''):''',
                 f'''{self.i1}"""{self.type_.plural().title()} Model"""''',
                 '',
                 '',
             ]
         )
 
     def gen_container_fields(self) -> str:
         """Generate the Container Model fields
 
-        data: Optional[List['ArtifactModel']] = Field(
+        data: list[ArtifactModel] | None = Field(
             [],
             description='The data of the Cases.',
             methods=['POST', 'PUT'],
             title='data',
         )
         """
         return '\n'.join(
             [
                 (
                     f'''{self.i1}data: '''
-                    f'''Optional[List['{self.type_.singular().pascal_case()}Model']] '''
+                    f'''list[{self.type_.singular().pascal_case()}Model] | None '''
                     '''= Field('''
                 ),
                 f'''{self.i2}[],''',
                 (
                     f'''{self.i2}description='The data for the '''
                     f'''{self.type_.plural().pascal_case()}.','''
                 ),
@@ -206,47 +209,47 @@
 
     def gen_data_class(self) -> str:
         """Generate the Data Class
 
         class ArtifactDataModel(
             BaseModel,
             title='Artifact Data',
-            alias_generator=Utils().snake_to_camel,
+            alias_generator=Util().snake_to_camel,
             validate_assignment=True,
         ):
         """
         return '\n'.join(
             [
                 '',
                 f'''class {self.type_.singular().pascal_case()}DataModel(''',
                 f'''{self.i1}BaseModel,''',
                 f'''{self.i1}title='{self.type_.singular().pascal_case()} Data Model',''',
-                f'''{self.i1}alias_generator=Utils().snake_to_camel,''',
+                f'''{self.i1}alias_generator=Util().snake_to_camel,''',
                 f'''{self.i1}validate_assignment=True,''',
                 '''):''',
                 f'''{self.i1}"""{self.type_.plural().title()} Data Model"""''',
                 '',
                 '',
             ]
         )
 
     def gen_data_fields(self) -> str:
         """Generate the Data Model fields
 
-        data: 'Optional[ArtifactModel]' = Field(
+        data: 'ArtifactModel | None' = Field(
             None,
             description='The data of the Artifact.',
             title='data',
         )
         """
         return '\n'.join(
             [
                 (
                     f'''{self.i1}data: '''
-                    f'''Optional[List['{self.type_.singular().pascal_case()}Model']] '''
+                    f'''list[{self.type_.singular().pascal_case()}Model] | None '''
                     '''= Field('''
                 ),
                 f'''{self.i2}[],''',
                 (
                     f'''{self.i2}description='The data for the '''
                     f'''{self.type_.plural().pascal_case()}.','''
                 ),
@@ -260,24 +263,24 @@
 
     def gen_model_class(self) -> str:
         """Generate the model class
 
         class ArtifactModel(
             BaseModel,
             title='Artifact Model',
-            alias_generator=Utils().snake_to_camel,
+            alias_generator=Util().snake_to_camel,
             validate_assignment=True,
         ):
         """
         return '\n'.join(
             [
                 '',
                 f'''class {self.type_.singular().pascal_case()}Model(''',
                 f'''{self.i1}V3ModelABC,''',
-                f'''{self.i1}alias_generator=Utils().snake_to_camel,''',
+                f'''{self.i1}alias_generator=Util().snake_to_camel,''',
                 f'''{self.i1}extra=Extra.allow,''',
                 f'''{self.i1}title='{self.type_.singular().pascal_case()} Model',''',
                 f'''{self.i1}validate_assignment=True,''',
                 '''):''',
                 f'''{self.i1}"""{self.type_.singular().title()} Model"""''',
                 '',
                 '',
@@ -290,15 +293,15 @@
         Example field_data:
         "analyticsPriority": {
             "readOnly": true,
             "type": "String"
         }
 
         Example Field:
-        analytics_priority: Optional[str] = Field(
+        analytics_priority: str | None = Field(
             None,
             allow_mutation=False,
             description='The **analytics priority** for the Artifact.',
             read_only=True,
             title='analyticsPriority',
         )
         """
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/_gen_object_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/_gen_object_abc.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,31 @@
-"""Generate Object for ThreatConnect API"""
+"""TcEx Framework Module"""
 # standard library
 from abc import ABC
-from typing import List, Optional
 
 # first-party
 from tcex.api.tc.v3._gen._gen_abc import GenerateABC
 from tcex.api.tc.v3._gen._gen_args_abc import GenerateArgsABC
-from tcex.utils.string_operations import SnakeString
+from tcex.util.string_operation import SnakeString
 
 
 class GenerateArgs(GenerateArgsABC):
     """Generate Models for TC API Types"""
 
 
 class GenerateObjectABC(GenerateABC, ABC):
     """Generate Models for Case Management Types"""
 
     def __init__(self, type_: SnakeString):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(type_)
 
         # properties
         self.requirements = {
-            'standard library': ['from typing import Union'],
+            'standard library': [],
             'third-party': [],
             'first-party': [
                 'from tcex.api.tc.v3.api_endpoints import ApiEndpoints',
                 'from tcex.api.tc.v3.object_abc import ObjectABC',
                 'from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC',
             ],
             'first-party-forward-reference': [],
@@ -52,116 +51,162 @@
             ]
         )
 
     def _gen_code_container_init_method(self) -> str:
         """Return the method code.
 
         def __init__(self, **kwargs):
-            '''Initialize Class properties.'''
+            '''Initialize instance properties.'''
             super().__init__(
                 kwargs.pop('session', None),
                 kwargs.pop('tql_filter', None),
                 kwargs.pop('params', None)
             )
             self._model = ArtifactsModel(**kwargs)
         """
         # add method import requirement
         classes = [
             f'{self.type_.singular().pascal_case()}Model',
             f'{self.type_.plural().pascal_case()}Model',
         ]
         self.update_requirements(self.type_, f'{self.type_.singular()}_model', classes)
 
+        model_name = f'{self.type_.plural().pascal_case()}Model'
         return '\n'.join(
             [
                 f'''{self.i1}def __init__(self, **kwargs):''',
-                f'''{self.i2}"""Initialize class properties."""''',
+                f'''{self.i2}"""Initialize instance properties."""''',
                 f'''{self.i2}super().__init__(''',
                 (
                     f'''{self.i3}kwargs.pop('session', None), '''
                     f'''kwargs.pop('tql_filter', None), '''
                     f'''kwargs.pop('params', None)'''
                 ),
                 f'''{self.i2})''',
-                f'''{self.i2}self._model = {self.type_.plural().pascal_case()}Model(**kwargs)''',
+                f'''{self.i2}self._model = {model_name}(**kwargs)''',
                 f'''{self.i2}self.type_ = \'{self.type_.plural()}\'''',
                 '',
                 '',
             ]
         )
 
     def _gen_code_container_iter_method(self) -> str:
         """Return the method code.
 
-        def __iter__(self) -> 'Artifact':
-            '''Iterate over CM objects.'''
+        def __iter__(self) -> Iterator[Artifact]:
+            '''Return CM objects.'''
             return self.iterate(base_class=Artifact)
         """
+        self.requirements['standard library'].append('from collections.abc import Iterator')
         return '\n'.join(
             [
-                f'''{self.i1}def __iter__(self) -> '{self.type_.singular().pascal_case()}':''',
-                f'''{self.i2}"""Iterate over CM objects."""''',
+                (
+                    f'''{self.i1}def __iter__(self) -> '''
+                    f'''Iterator[{self.type_.singular().pascal_case()}]:'''
+                ),
+                f'''{self.i2}"""Return CM objects."""''',
                 (
                     f'''{self.i2}return self.iterate(base_class='''
                     f'''{self.type_.singular().pascal_case()})'''
+                    '''  # type: ignore'''
                 ),
                 '',
                 '',
             ]
         )
 
+    # def _gen_code_container_iter_method(self) -> str:
+    #     """Return the method code.
+
+    #     def __iter__(self) -> Self:
+    #         '''Return CM objects.'''
+    #         return self
+    #     """
+    #     self.requirements['standard library'].append({'module': 'typing', 'imports': ['Self']})
+    #     return '\n'.join(
+    #         [
+    #             f'''{self.i1}def __iter__(self) -> Self:''',
+    #             f'''{self.i2}"""Return CM objects."""''',
+    #             f'''{self.i2}return self''',
+    #             '',
+    #             '',
+    #         ]
+    #     )
+
+    # def _gen_code_container_next_method(self) -> str:
+    #     """Return the method code.
+
+    #     def __next__(self) -> Artifact:
+    #         '''Iterate over CM objects.'''
+    #         return self.iterate(base_class=Artifact)
+    #     """
+    #     return '\n'.join(
+    #         [
+    #             f'''{self.i1}def __next__(self) -> {self.type_.singular().pascal_case()}:''',
+    #             f'''{self.i2}"""Return next CM objects."""''',
+    #             (
+    #                 f'''{self.i2}for i in self.iterate(base_class='''
+    #                 f'''{self.type_.singular().pascal_case()}):'''
+    #             ),
+    #             f'''{self.i3}return i''',
+    #             '',
+    #             f'''{self.i2}raise StopIteration''',
+    #             '',
+    #             '',
+    #         ]
+    #     )
+
     def _gen_code_container_filter_property(self) -> str:
         """Return the method code.
 
         @property
-        def filter(self) -> 'ArtifactFilter':
+        def filter(self) -> ArtifactFilter:
             '''Return the type specific filter object.'''
             return ArtifactFilter(self._session, self.tql)
         """
         filter_class = f'{self.type_.singular().pascal_case()}Filter'
         self.update_requirements(self.type_, f'{self.type_.singular()}_filter', [filter_class])
         return '\n'.join(
             [
                 f'''{self.i1}@property''',
-                f'''{self.i1}def filter(self) -> '{filter_class}':''',
+                f'''{self.i1}def filter(self) -> {filter_class}:''',
                 f'''{self.i2}"""Return the type specific filter object."""''',
                 f'''{self.i2}return {filter_class}(self.tql)''',
                 '',
                 '',
             ]
         )
 
     def _gen_code_deleted_method(self) -> str:
         """Return the method code.
 
         @property
-        def filter(self) -> 'ArtifactFilter':
+        def filter(self) -> ArtifactFilter:
             '''Return the type specific filter object.'''
             return ArtifactFilter(self._session, self.tql)
         """
         self.requirements['first-party'].append({'module': 'datetime', 'imports': ['datetime']})
-        self.requirements['standard library'].append({'module': 'typing', 'imports': ['Optional']})
         return '\n'.join(
             [
                 f'''{self.i1}def deleted(''',
                 f'''{self.i2}self,''',
-                f'''{self.i2}deleted_since: Optional[Union[datetime, str]],''',
-                f'''{self.i2}type_: Optional[str] = None,''',
-                f'''{self.i2}owner: Optional[str] = None''',
+                f'''{self.i2}deleted_since: datetime | str | None,''',
+                f'''{self.i2}type_: str | None = None,''',
+                f'''{self.i2}owner: str | None = None''',
                 f'''{self.i1}):''',
                 f'''{self.i2}"""Return deleted indicators.''',
                 '',
                 f'''{self.i2}This will not use the default params set on the "Indicators" ''',
                 f'''{self.i2}object and instead used the params that are passed in.''',
                 f'''{self.i2}"""''',
                 '',
                 f'''{self.i2}if deleted_since is not None:''',
                 f'''{self.i3}deleted_since = str(''',
                 (
-                    f'''{self.i4}self.utils.any_to_datetime(deleted_since)'''
+                    f'''{self.i4}self.util.any_to_datetime(deleted_since)'''
                     '''.strftime('%Y-%m-%dT%H:%M:%SZ')'''
                 ),
                 f'''{self.i3})''',
                 '',
                 f'''{self.i2}yield from self.iterate(''',
                 f'''{self.i3}base_class=Indicator,''',
                 f'''{self.i3}api_endpoint=f'{{self._api_endpoint}}/deleted',''',
@@ -174,47 +219,48 @@
             ]
         )
 
     def _gen_code_group_methods(self) -> str:
         """Return the method code.
 
         @property
-        def filter(self) -> 'ArtifactFilter':
+        def filter(self) -> ArtifactFilter:
             '''Return the type specific filter object.'''
             return ArtifactFilter(self._session, self.tql)
         """
-        self.requirements['standard library'].append({'module': 'typing', 'imports': ['Optional']})
-        self.requirements['type-checking'].append('''from requests import Response''')
+        # BCS
+        # self.requirements['type-checking'].append('''from requests import Response''')
+        self.requirements['first-party'].append('''from requests import Response''')
         return '\n'.join(
             [
-                f'''{self.i1}def download(self, params: Optional[dict] = None) -> bytes:''',
+                f'''{self.i1}def download(self, params: dict | None = None) -> bytes:''',
                 f'''{self.i2}"""Return the document attachment for Document/Report Types."""''',
                 f'''{self.i2}self._request(''',
                 f'''{self.i3}method='GET',''',
                 f'''{self.i3}url=f\'\'\'{{self.url('GET')}}/download\'\'\',''',
                 f'''{self.i3}headers={{'Accept': 'application/octet-stream'}},''',
                 f'''{self.i3}params=params,''',
                 f'''{self.i2})''',
                 f'''{self.i2}return self.request.content''',
                 '',
-                f'''{self.i1}def pdf(self, params: Optional[dict] = None) -> bytes:''',
+                f'''{self.i1}def pdf(self, params: dict | None = None) -> bytes:''',
                 f'''{self.i2}"""Return the document attachment for Document/Report Types."""''',
                 f'''{self.i2}self._request(''',
                 f'''{self.i3}method='GET',''',
                 f'''{self.i3}body=None,''',
                 f'''{self.i3}url=f\'\'\'{{self.url('GET')}}/pdf\'\'\',''',
                 f'''{self.i3}headers={{'Accept': 'application/octet-stream'}},''',
                 f'''{self.i3}params=params,''',
                 f'''{self.i2})''',
                 '',
                 f'''{self.i2}return self.request.content''',
                 '',
                 (
-                    f'''{self.i1}def upload(self, content: Union[bytes, str], '''
-                    '''params: Optional[dict] = None) -> 'Response':'''
+                    f'''{self.i1}def upload(self, content: bytes | str, '''
+                    '''params: dict | None = None) -> Response:'''
                 ),
                 f'''{self.i2}"""Return the document attachment for Document/Report Types."""''',
                 f'''{self.i2}self._request(''',
                 f'''{self.i3}method='POST',''',
                 f'''{self.i3}url=f\'\'\'{{self.url('GET')}}/upload\'\'\',''',
                 f'''{self.i3}body=content,''',
                 f'''{self.i3}headers={{'content-type': 'application/octet-stream'}},''',
@@ -226,35 +272,36 @@
             ]
         )
 
     def _gen_code_object_init_method(self) -> str:
         """Return the method code.
 
         def __init__(self, **kwargs):
-            '''Initialize Class properties'''
+            '''Initialize instance properties'''
             super().__init__(kwargs.pop('session', None))
             self._model = ArtifactModel(**kwargs)
         """
         # set nested type
-        nested_field_name = self.utils.snake_string(self.type_).camel_case().plural()
+        nested_field_name = self.util.snake_string(self.type_).camel_case().plural()
         if self.type_ in ['indicators', 'groups']:
             nested_field_name = (
-                self.utils.snake_string(f'associated_{self.type_}').camel_case().plural()
+                self.util.snake_string(f'associated_{self.type_}').camel_case().plural()
             )
         elif self.type_ in ['case_attributes', 'group_attributes', 'indicator_attributes']:
             nested_field_name = 'attributes'
 
+        model_name = f'{self.type_.singular().pascal_case()}Model'
         return '\n'.join(
             [
                 f'''{self.i1}def __init__(self, **kwargs):''',
-                f'''{self.i2}"""Initialize class properties."""''',
+                f'''{self.i2}"""Initialize instance properties."""''',
                 f'''{self.i2}super().__init__(kwargs.pop('session', None))''',
                 '',
                 f'''{self.i2}# properties''',
-                f'''{self.i2}self._model = {self.type_.singular().pascal_case()}Model(**kwargs)''',
+                f'''{self.i2}self._model: {model_name} = {model_name}(**kwargs)''',
                 f'''{self.i2}self._nested_field_name = '{nested_field_name}' ''',
                 f'''{self.i2}self._nested_filter = 'has_{self.type_.singular()}' ''',
                 f'''{self.i2}self.type_ = \'{self.type_.singular().space_case()}\'''',
                 '',
                 '',
             ]
         )
@@ -262,41 +309,41 @@
     def _gen_code_object_model_property(self) -> str:
         """Return the method code.
 
         Override the object ABC method so that the correct typing hint return
         type can be used and the IDE will provide full model hinting.
 
         @property
-        def model(self) -> 'CaseModel':
+        def model(self) -> CaseModel:
             '''Return the model data.'''
             return self._model
 
         @model.setter
-        def model(self, data: Union['IndicatorModel', dict]):
+        def model(self, data: dict | IndicatorModel):
             '''Create model using the provided data.'''
             if isinstance(data, type(self.model)):
                 # provided data is already a model, nothing required to change
                 self._model = data
             elif isinstance(data, dict):
                 # provided data is raw response, load the model
                 self._model = type(self.model)(**data)
             else:
                 raise RuntimeError(f'Invalid data type: {type(data)} provided.')
         """
         return '\n'.join(
             [
                 f'''{self.i1}@property''',
-                f'''{self.i1}def model(self) -> '{self.type_.singular().pascal_case()}Model':''',
+                f'''{self.i1}def model(self) -> {self.type_.singular().pascal_case()}Model:''',
                 f'''{self.i2}"""Return the model data."""''',
                 f'''{self.i2}return self._model''',
                 '',
                 f'''{self.i1}@model.setter''',
                 (
-                    f'''{self.i1}def model(self, data: Union'''
-                    f'''['{self.type_.singular().pascal_case()}Model', dict]):'''
+                    f'''{self.i1}def model(self, data: '''
+                    f'''dict | {self.type_.singular().pascal_case()}Model):'''
                 ),
                 f'''{self.i2}"""Create model using the provided data."""''',
                 f'''{self.i2}if isinstance(data, type(self.model)):''',
                 f'''{self.i3}# provided data is already a model, nothing required to change''',
                 f'''{self.i3}self._model = data''',
                 f'''{self.i2}elif isinstance(data, dict):''',
                 f'''{self.i3}# provided data is raw response, load the model''',
@@ -346,35 +393,36 @@
             as_entity_property_method.append(f'''{self.i2}type_ = self.model.type''')
         elif self.type_.lower() in ['victim_assets']:
             value = 'value'
             as_entity_property_method.extend(
                 [
                     f'''{self.i2}value = []''',
                     '',
-                    f'''{self.i2}if self.model.type.lower() == 'phone':''',
-                    f'''{self.i3}if self.model.phone:''',
-                    f'''{self.i4}value.append(self.model.phone)''',
-                    f'''{self.i2}elif self.model.type.lower() == 'socialnetwork':''',
-                    f'''{self.i3}if self.model.social_network:''',
-                    f'''{self.i4}value.append(self.model.social_network)''',
-                    f'''{self.i3}if self.model.account_name:''',
-                    f'''{self.i4}value.append(self.model.account_name)''',
-                    f'''{self.i2}elif self.model.type.lower() == 'networkaccount':''',
-                    f'''{self.i3}if self.model.network_type:''',
-                    f'''{self.i4}value.append(self.model.network_type)''',
-                    f'''{self.i3}if self.model.account_name:''',
-                    f'''{self.i4}value.append(self.model.account_name)''',
-                    f'''{self.i2}elif self.model.type.lower() == 'emailaddress':''',
-                    f'''{self.i3}if self.model.address_type:''',
-                    f'''{self.i4}value.append(self.model.address_type)''',
-                    f'''{self.i3}if self.model.address:''',
-                    f'''{self.i4}value.append(self.model.address)''',
-                    f'''{self.i2}elif self.model.type.lower() == 'website':''',
-                    f'''{self.i3}if self.model.website:''',
-                    f'''{self.i4}value.append(self.model.website)''',
+                    f'''{self.i2}if self.model.type is not None:''',
+                    f'''{self.i3}if self.model.type.lower() == 'phone':''',
+                    f'''{self.i4}if self.model.phone:''',
+                    f'''{self.i5}value.append(self.model.phone)''',
+                    f'''{self.i3}elif self.model.type.lower() == 'socialnetwork':''',
+                    f'''{self.i4}if self.model.social_network:''',
+                    f'''{self.i5}value.append(self.model.social_network)''',
+                    f'''{self.i4}if self.model.account_name:''',
+                    f'''{self.i5}value.append(self.model.account_name)''',
+                    f'''{self.i3}elif self.model.type.lower() == 'networkaccount':''',
+                    f'''{self.i4}if self.model.network_type:''',
+                    f'''{self.i5}value.append(self.model.network_type)''',
+                    f'''{self.i4}if self.model.account_name:''',
+                    f'''{self.i5}value.append(self.model.account_name)''',
+                    f'''{self.i3}elif self.model.type.lower() == 'emailaddress':''',
+                    f'''{self.i4}if self.model.address_type:''',
+                    f'''{self.i5}value.append(self.model.address_type)''',
+                    f'''{self.i4}if self.model.address:''',
+                    f'''{self.i5}value.append(self.model.address)''',
+                    f'''{self.i3}elif self.model.type.lower() == 'website':''',
+                    f'''{self.i4}if self.model.website:''',
+                    f'''{self.i5}value.append(self.model.website)''',
                     '',
                     '',
                     f'''{self.i2}value = ' : '.join(value) if value else \'\'''',
                     f'''{self.i2}type_ = f'Victim Asset : {{self.model.type}}\'''',
                 ]
             )
         else:
@@ -388,56 +436,53 @@
                 ),
                 '',
                 '',
             ]
         )
         return '\n'.join(as_entity_property_method)
 
-    def _gen_code_object_stage_type_method(
-        self, type_: str, model_type: Optional[str] = None
-    ) -> str:
+    def _gen_code_object_stage_type_method(self, type_: str, model_type: str | None = None) -> str:
         """Return the method code.
 
         def stage_artifact(self, **kwargs):
             '''Stage an Artifact on the object.
 
             ...
             '''
             self.model.artifacts.data.append(ArtifactModel(**kwargs))
 
             _code += self._gen_code_object_add_type_method('users', 'user_access')
         """
-        type_ = self.utils.snake_string(type_)
-        model_type = self.utils.snake_string(model_type or type_)
+        type_ = self.util.snake_string(type_)
+        model_type = self.util.snake_string(model_type or type_)
         model_reference = model_type
 
         # Unlike all of the other objects, on the victims model, it references 'assets' not the
         # model name 'VictimAssets'
         if type_.lower() == 'victim_assets' and self.type_.lower() == 'victims':
-            model_reference = self.utils.camel_string('assets')
+            model_reference = self.util.camel_string('assets')
         elif type_.lower() == 'users':
-            model_type = self.utils.camel_string('user_accesses')
+            model_type = self.util.camel_string('user_accesses')
             model_reference = 'user_access'
 
         # get model from map and update requirements
         model_import_data = self._module_import_data(type_)
-        # self.requirements['standard library'].append('''from typing import Union''')
         self.requirements['first-party'].append(
             f'''from {model_import_data.get('model_module')} '''
             f'''import {model_import_data.get('model_class')}'''
         )
         stage_method = [
             (
                 f'''{self.i1}def stage_{model_type.singular()}(self, '''
-                f'''data: Union[dict, 'ObjectABC', '{model_import_data.get('model_class')}'''
-                f'''']):'''
+                f'''data: dict | ObjectABC | {model_import_data.get('model_class')}'''
+                f'''):'''
             ),
             f'''{self.i2}"""Stage {type_.singular()} on the object."""''',
             f'''{self.i2}if isinstance(data, ObjectABC):''',
-            f'''{self.i3}data = data.model''',
+            f'''{self.i3}data = data.model  # type: ignore''',
             f'''{self.i2}elif isinstance(data, dict):''',
             f'''{self.i3}data = {model_import_data.get('model_class')}(**data)''',
             '',
             f'''{self.i2}if not isinstance(data, {model_import_data.get('model_class')}):''',
             (
                 f'''{self.i3}raise RuntimeError('Invalid type '''
                 f'''passed in to stage_{model_type.singular()}')'''
@@ -447,29 +492,28 @@
         if type_.lower() == 'file_actions' and self.type_.lower() == 'indicators':
             # The `indicator` field in the FileActionModel must be staged to be
             # submitted through the API
             stage_method.append(f'''{self.i2}data.indicator._staged = True''')
 
         stage_method.extend(
             [
-                f'''{self.i2}self.model.{model_reference}.data.append(data)''',
+                f'''{self.i2}self.model.{model_reference}.data.append(data)  # type: ignore''',
                 '',
                 '',
             ]
         )
 
         return '\n'.join(stage_method)
 
     def _gen_code_object_remove_method(self) -> str:
         """Return the method code."""
         self.requirements['standard library'].append('import json')
-        self.requirements['standard library'].append({'module': 'typing', 'imports': ['Optional']})
         return '\n'.join(
             [
-                f'''{self.i1}def remove(self, params: Optional[dict] = None):''',
+                f'''{self.i1}def remove(self, params: dict | None = None):''',
                 f'''{self.i2}"""Remove a nested object."""''',
                 f'''{self.i2}method = \'PUT\'''',
                 f'''{self.i2}unique_id = self._calculate_unique_id()''',
                 '',
                 f'''{self.i2}# validate an id is available''',
                 f'''{self.i2}self._validate_id(unique_id.get('value'), '')''',
                 '',
@@ -504,25 +548,25 @@
             ]
         )
 
     def _gen_code_object_stage_assignee(self) -> str:
         """Return the method code.
 
         def stage_assignee(
-            self, type: str, data: Union[dict, 'ObjectABC', 'ArtifactModel']
+            self, type: str, data: dict | ObjectABC | AssigneeModel]
         ):
             '''Stage artifact on the object.'''
             if isinstance(data, ObjectABC):
                 data = data.model
             elif type.lower() == 'user' and isinstance(data, dict):
                 data = UserModel(**data)
             elif type.lower() == 'group' and isinstance(data, dict):
                 data = UserGroupModel(**data)
 
-            if not isinstance(data, (UserModel, UserGroupModel)):
+            if not isinstance(data, UserModel | UserGroupModel):
                 raise RuntimeError('Invalid type passed in to stage_assignee')
             data._staged = True
             self.model.assignee._staged = True
             self.model.assignee.type = type
             self.model.assignee.data = data
         """
         self.requirements['first-party'].extend(
@@ -533,67 +577,78 @@
         )
 
         return '\n'.join(
             [
                 f'''{self.i1}# pylint: disable=redefined-builtin''',
                 (
                     f'''{self.i1}def stage_assignee(self, type: str, data: '''
-                    f'''Union[dict, 'ObjectABC', 'ArtifactModel']):'''
+                    f'''dict | ObjectABC | UserModel | UserGroupModel):'''
                 ),
                 f'''{self.i2}"""Stage artifact on the object."""''',
                 f'''{self.i2}if isinstance(data, ObjectABC):''',
-                f'''{self.i3}data = data.model''',
+                f'''{self.i3}data = data.model  # type: ignore''',
                 f'''{self.i2}elif type.lower() == 'user' and isinstance(data, dict):''',
                 f'''{self.i3}data = UserModel(**data)''',
                 f'''{self.i2}elif type.lower() == 'group' and isinstance(data, dict):''',
                 f'''{self.i3}data = UserGroupModel(**data)''',
                 '',
-                f'''{self.i2}if not isinstance(data, (UserModel, UserGroupModel)):''',
+                f'''{self.i2}if not isinstance(data, UserModel | UserGroupModel):''',
                 f'''{self.i3}raise RuntimeError('Invalid type passed in to stage_assignee')''',
                 f'''{self.i2}data._staged = True''',
                 f'''{self.i2}self.model.assignee._staged = True''',
                 f'''{self.i2}self.model.assignee.type = type''',
-                f'''{self.i2}self.model.assignee.data = data''',
+                # pylance shows a warning on type here, but it in not handling inheritance properly.
+                f'''{self.i2}self.model.assignee.data = data  # type: ignore''',
                 '',
                 '',
             ]
         )
 
     def _gen_code_object_type_property_method(
-        self, type_: str, model_type: Optional[str] = None
+        self, type_: str, model_type: str | None = None
     ) -> str:
         """Return the method code.
 
         @property
         def artifacts(self):
             '''Yield Artifact from Artifacts'''
             from tcex.api.tc.v3.artifacts.model import Artifact, Artifacts
 
             yield from self._iterate_over_sublist(Artifacts)
         """
-        type_ = self.utils.snake_string(type_)
-        model_type = self.utils.snake_string(model_type or type_)
+        type_ = self.util.snake_string(type_)
+        model_type = self.util.snake_string(model_type or type_)
 
         # get model from map and update requirements
         model_import_data = self._module_import_data(type_)
 
-        # Add Iterator to imports:
-        self.requirements['standard library'].append({'module': 'typing', 'imports': ['Iterator']})
+        # Add Generator to imports:
+        self.requirements['standard library'].append(
+            {'module': 'collections.abc', 'imports': ['Generator']}
+        )
 
-        # don't add import if class is in same file
-        if self.type_ != type_:
+        if self.type_ == type_:
+            # set return type to new typing "Self" type and add import
+            return_type = 'Self'
+            self.requirements['standard library'].append(
+                {'module': 'typing', 'imports': [return_type]}
+            )
+        else:
+            # set typing to model class and add import
+            return_type = f'''\'{model_import_data.get('object_class')}\''''
             self.requirements['type-checking'].append(
                 f'''from {model_import_data.get('object_module')} '''
                 f'''import {model_import_data.get('object_class')}'''
             )
+
         _code = [
             f'''{self.i1}@property''',
             (
                 f'''{self.i1}def {model_type.plural()}(self) ->'''
-                f''' Iterator['{model_import_data.get('object_class')}']:'''
+                f''' Generator[{return_type}, None, None]:'''
             ),
             (
                 f'''{self.i2}"""Yield {type_.singular().pascal_case()} '''
                 f'''from {type_.plural().pascal_case()}."""'''
             ),
         ]
 
@@ -616,14 +671,15 @@
         ):
             _code.extend(
                 [
                     f'''{self.i2}# Ensure the current item is not returned as a association''',
                     (
                         f'''{self.i2}for {type_.singular()} in self._iterate_over_sublist'''
                         f'''({model_import_data.get('object_collection_class')}):'''
+                        '''  # type: ignore'''
                     ),
                 ]
             )
             if self.type_ == 'indicator':
                 _code.extend(
                     [
                         (
@@ -634,21 +690,27 @@
                 )
             else:
                 _code.extend(
                     [
                         (f'''{self.i3}if {type_.singular()}.model.id == self.model.id:'''),
                     ]
                 )
-            _code.extend([f'''{self.i4}continue''', f'''{self.i3}yield {type_.singular()}'''])
+            _code.extend(
+                [
+                    f'''{self.i4}continue''',
+                    f'''{self.i3}yield {type_.singular()}  # type: ignore''',
+                ]
+            )
         else:
             _code.extend(
                 [
                     (
                         f'''{self.i2}yield from self._iterate_over_sublist'''
                         f'''({model_import_data.get('object_collection_class')})'''
+                        '''  # type: ignore'''
                     ),
                 ]
             )
         _code.extend(
             [
                 '',
                 '',
@@ -711,31 +773,35 @@
         _code = ''
         # generate __init__ method
         _code += self._gen_code_container_init_method()
 
         # generate __iter__ method
         _code += self._gen_code_container_iter_method()
 
+        # generate __next__ method
+        # _code += self._gen_code_container_next_method()
+
         # generate api_endpoint property method
         _code += self._gen_code_api_endpoint_property()
 
         # generate filter property method
         _code += self._gen_code_container_filter_property()
 
         if self.type_.lower() == 'indicators':
             _code += self._gen_code_deleted_method()
 
         return _code
 
     def gen_doc_string(self) -> str:
         """Generate doc string."""
-        return (
-            f'"""{self.type_.singular().pascal_case()} '
-            f'/ {self.type_.plural().pascal_case()} Object"""\n'
-        )
+        # return (
+        #     f'"""{self.type_.singular().pascal_case()} '
+        #     f'/ {self.type_.plural().pascal_case()} Object"""\n'
+        # )
+        return '"""TcEx Framework Module"""\n'
 
     def gen_object_class(self) -> str:
         """Generate the Object Model
 
         class Artifact(ObjectABC):
             '''Case Management Artifact
 
@@ -949,15 +1015,15 @@
 
         return _code
 
     def update_requirements(
         self,
         type_: SnakeString,
         filename: str,
-        classes: List[str],
-        from_: Optional[str] = 'first-party',
+        classes: list[str],
+        from_: str = 'first-party',
     ):
         """Return the requirements code."""
         class_string = ', '.join(classes)
         self.requirements[from_].append(  # type: ignore
             f'from {self.tap(type_)}.{type_.plural()}.{filename} import {class_string}'
         )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/_gen/models/_property_model.py` & `tcex-4.0.0/tcex/api/tc/v3/_gen/model/_property_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,89 +1,79 @@
-"""Model Definition"""
-
-# standard library
-from typing import Dict, List, Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Extra, Field, validator
 
 # first-party
-from tcex.backports import cached_property
-from tcex.utils import Utils
-from tcex.utils.string_operations import CamelString
+from tcex.pleb.cached_property import cached_property
+from tcex.util import Util
+from tcex.util.string_operation import CamelString
 
 
-# pylint: disable=no-self-argument,no-self-use
+# pylint: disable=no-self-argument
 class ExtraModel(
     BaseModel,
     extra=Extra.forbid,
     title='Extra Model',
     validate_assignment=True,
 ):
     """Model Definition"""
 
     alias: CamelString = Field(..., description='Field alias.')
-    import_data: Optional[str] = Field(None, description='The import data.')
-    import_source: Optional[str] = Field(
+    import_data: str | None = Field(None, description='The import data.')
+    import_source: str | None = Field(
         None, description='The source of the import: standard library, first-party, etc.'
     )
-    methods: List[str] = Field([], description='Field methods.')
-    model: Optional[str] = Field(None, description='The type model.')
+    methods: list[str] = Field([], description='Field methods.')
+    model: str | None = Field(None, description='The type model.')
     type: CamelString = Field(..., description='The type of the property.')
     typing_type: str = Field(..., description='The Python typing hint type.')
 
     @validator('alias', 'type', always=True, pre=True)
     def _camel_string(cls, v):
         """Convert to CamelString."""
         return CamelString(v)
 
 
-# pylint: disable=no-self-argument,no-self-use
+# pylint: disable=no-self-argument
 class PropertyModel(
     BaseModel,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     arbitrary_types_allowed=True,
     extra=Extra.forbid,
     keep_untouched=(cached_property,),
     title='Property Model',
     validate_assignment=True,
 ):
     """Model Definition"""
 
-    applies_to: Optional[List[str]] = Field(None, description='Applies to property.')
-    allowable_values: Optional[List[str]] = Field(
+    applies_to: list[str] | None = Field(None, description='Applies to property.')
+    allowable_values: list[str] | None = Field(
         None, description='Allowable values for the property.'
     )
-    conditional_read_only: Optional[List[str]] = Field(
+    conditional_read_only: list[str] | None = Field(
         None, description='Conditionally read-only property.'
     )
-    conditional_required: Optional[List[str]] = Field(
+    conditional_required: list[str] | None = Field(
         None, description='Conditionally required property.'
     )
-    default: Optional[str] = Field(default=None, description='Default value of the property value.')
-    description: Optional[str] = Field(default=None, description='Description of the property.')
-    max_size: Optional[int] = Field(default=None, description='Maximum size of the property value.')
-    max_length: Optional[int] = Field(
+    default: str | None = Field(default=None, description='Default value of the property value.')
+    description: str | None = Field(default=None, description='Description of the property.')
+    max_size: int | None = Field(default=None, description='Maximum size of the property value.')
+    max_length: int | None = Field(
         default=None, description='Maximum length of the property value.'
     )
-    max_value: Optional[int] = Field(
-        default=None, description='Maximum value of the property value.'
-    )
-    min_length: Optional[int] = Field(
+    max_value: int | None = Field(default=None, description='Maximum value of the property value.')
+    min_length: int | None = Field(
         default=None, description='Minimum length of the property value.'
     )
-    min_value: Optional[int] = Field(
-        default=None, description='Minimum value of the property value.'
-    )
+    min_value: int | None = Field(default=None, description='Minimum value of the property value.')
     name: CamelString = Field(default=None, description='Name of the property.')
     read_only: bool = Field(default=False, description='Read only property.')
     required: bool = Field(default=False, description='Required property.')
-    required_alt_field: Optional[str] = Field(
-        None, description='Required alternative field property.'
-    )
+    required_alt_field: str | None = Field(None, description='Required alternative field property.')
     type: CamelString = Field(..., description='The defined property type.')
     updatable: bool = Field(default=True, description='Updatable property.')
 
     @validator('name', 'type', always=True, pre=True)
     def _came_string(cls, v):
         """Convert to CamelString."""
         if v is None:
@@ -101,15 +91,15 @@
     @cached_property
     def extra(self) -> ExtraModel:
         """Return the extra model."""
         extra_data = self.__extra_data()
         # print(self.name, self.type, extra_data)
         return ExtraModel(**extra_data)  # type: ignore
 
-    def __extra_data(self) -> Dict[str, str]:
+    def __extra_data(self) -> dict[str, str]:
         """Enrich the extra model."""
         # set default value for type
         extra = {
             'alias': self.name,
             # calculate the field methods
             'methods': self.__calculate_methods(),
             # set type to current type value, update later
@@ -131,15 +121,15 @@
 
         # process int types
         self.__process_int_types(self, extra)
 
         # process str types
         self.__process_str_types(self, extra)
 
-        # # process tc types
+        # process tc types
         self.__process_tc_types(self, extra)
 
         # process special types
         self.__process_special_types(self, extra)
 
         if extra.get('typing_type') is None:
             raise RuntimeError(
@@ -159,58 +149,59 @@
             methods.append('POST')
 
             if self.updatable is not False:
                 methods.append('PUT')
         return methods
 
     @classmethod
-    def __process_bool_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_bool_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = ['boolean']
         if pm.type.lower() in types:
             extra.update({'typing_type': 'bool'})
 
     @classmethod
-    def __process_dict_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_dict_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = [
             'AttributeSource',
             'DNSResolutions',
             'Enrichments',
             'GeoLocation',
             'InvestigationLinks',
             'Links',
             'Map',
             'ValidationRule',
+            'Strings',
             'WhoIs',
         ]
         if pm.type in types:
             extra.update({'typing_type': cls.__extra_format_type('dict')})
 
     @classmethod
-    def __process_float_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_float_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = ['Double']
         if pm.type in types:
             extra.update({'typing_type': cls.__extra_format_type('float')})
 
     @classmethod
-    def __process_int_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_int_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = [
             'bigdecimal',  # BigDecimal
             'integer',  # Integer
             'long',  # Long
             'short',  # Short
         ]
         if pm.type.lower() in types:
             extra.update({'typing_type': cls.__extra_format_type('int')})
 
     @classmethod
-    def __process_special_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_special_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         bi = 'from tcex.api.tc.v3.'
 
         if pm.type == 'Assignee':
             bi += 'security.assignee_model'
             extra.update(
                 {
@@ -286,17 +277,16 @@
                     'model': f'{pm.type}Model',
                     'typing_type': cls.__extra_format_type_model(pm.type),
                 }
             )
         elif pm.type == 'JsonNode':
             extra.update(
                 {
-                    'import_data': 'from typing import Union',
                     'import_source': 'standard library',
-                    'typing_type': '''Union[Optional[dict], Optional[List[dict]]]''',
+                    'typing_type': '''dict | list[dict] | None''',
                 }
             )
         elif pm.type == 'TaskAssignees':
             extra.update(
                 {
                     'import_data': (f'{bi}security.task_assignee_model import TaskAssigneesModel'),
                     'import_source': 'first-party-forward-reference',
@@ -312,26 +302,26 @@
                     'import_source': 'first-party-forward-reference',
                     'model': f'{pm.type}Model',
                     'typing_type': cls.__extra_format_type_model(pm.type),
                 }
             )
 
     @classmethod
-    def __process_str_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_str_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = [
             'From',
             'Owner',
             'String',
         ]
         if pm.type in types:
             extra.update({'typing_type': cls.__extra_format_type('str')})
 
     @classmethod
-    def __process_tc_types(cls, pm: 'PropertyModel', extra: Dict[str, str]):
+    def __process_tc_types(cls, pm: 'PropertyModel', extra: dict[str, str]):
         """Process standard type."""
         types = [
             'AdversaryAssets',
             'Artifact',
             'Artifacts',
             'ArtifactType',
             'Case',
@@ -358,41 +348,43 @@
         ]
         if pm.type in types:
             extra.update(cls.__extra_gen_req_code(pm.type))
             extra['model'] = f'{pm.type}Model'
             extra['typing_type'] = cls.__extra_format_type_model(pm.type)
 
     @classmethod
-    def __extra_gen_req_code(cls, type_: CamelString) -> Dict[str, str]:
+    def __extra_gen_req_code(cls, type_: CamelString) -> dict[str, str]:
         """Return the requirements code"""
-        type_ = Utils().camel_string(type_)
+        type_ = Util().camel_string(type_)
         return {
             'import_data': (
                 f'from {cls.__extra_tap(type_)}.{type_.plural().snake_case()}.'
                 f'{type_.singular().snake_case()}_model import {type_}Model'
             ),
             'import_source': 'first-party-forward-reference',
         }
 
     @classmethod
     def __extra_format_type(cls, type_: str, optional: bool = True) -> str:
         """Format type for use in code."""
         if optional:
-            return f'Optional[{type_}]'
+            return f'{type_} | None'
         return type_
 
-    # @classmethod
-    # def __extra_format_type_non_native(cls, type_: str, optional: bool = True) -> str:
-    #     """Format type for use in code."""
-    #     return cls.__extra_format_type(f'\'{type_}\'', optional)
+    @classmethod
+    def __extra_format_type_non_native(cls, type_: str, optional: bool = False) -> str:
+        """Format type for use in code."""
+        if optional:
+            return f'\'{type_} | None\''
+        return f'\'{type_}\''
 
     @classmethod
-    def __extra_format_type_model(cls, type_: str, optional: bool = True) -> str:
+    def __extra_format_type_model(cls, type_: str, optional: bool = False) -> str:
         """Format type for use in code."""
-        return cls.__extra_format_type(f'\'{type_}Model\'', optional)
+        return cls.__extra_format_type_non_native(f'{type_}Model', optional)
 
     @classmethod
     def __extra_tap(cls, type_: CamelString) -> str:
         """Return the TcEx Api Path."""
         if type_.snake_case().plural().lower() in [
             'owners',
             'owner_roles',
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/api_endpoints.py` & `tcex-4.0.0/tcex/api/tc/v3/api_endpoints.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""ThreatConnect V3 API Endpoints"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 
 class ApiEndpoints(Enum):
     """Available API Endpoints"""
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type.py` & `tcex-4.0.0/tcex/api/tc/v3/artifact_types/artifact_type.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,83 +1,44 @@
-"""ArtifactType / ArtifactTypes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifact_types.artifact_type_filter import ArtifactTypeFilter
 from tcex.api.tc.v3.artifact_types.artifact_type_model import ArtifactTypeModel, ArtifactTypesModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 
 
-class ArtifactTypes(ObjectCollectionABC):
-    """ArtifactTypes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = ArtifactTypesModel(**kwargs)
-        self.type_ = 'artifact_types'
-
-    def __iter__(self) -> 'ArtifactType':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=ArtifactType)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.ARTIFACT_TYPES.value
-
-    @property
-    def filter(self) -> 'ArtifactTypeFilter':
-        """Return the type specific filter object."""
-        return ArtifactTypeFilter(self.tql)
-
-
 class ArtifactType(ObjectABC):
     """ArtifactTypes Object."""
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = ArtifactTypeModel(**kwargs)
+        self._model: ArtifactTypeModel = ArtifactTypeModel(**kwargs)
         self._nested_field_name = 'artifactTypes'
         self._nested_filter = 'has_artifact_type'
         self.type_ = 'Artifact Type'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.ARTIFACT_TYPES.value
 
     @property
-    def model(self) -> 'ArtifactTypeModel':
+    def model(self) -> ArtifactTypeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['ArtifactTypeModel', dict]):
+    def model(self, data: dict | ArtifactTypeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -86,7 +47,46 @@
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.name}
+
+
+class ArtifactTypes(ObjectCollectionABC):
+    """ArtifactTypes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = ArtifactTypesModel(**kwargs)
+        self.type_ = 'artifact_types'
+
+    def __iter__(self) -> Iterator[ArtifactType]:
+        """Return CM objects."""
+        return self.iterate(base_class=ArtifactType)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.ARTIFACT_TYPES.value
+
+    @property
+    def filter(self) -> ArtifactTypeFilter:
+        """Return the type specific filter object."""
+        return ArtifactTypeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role_filter.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,80 +1,74 @@
-"""Artifact_Type TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class ArtifactTypeFilter(FilterABC):
-    """Filter Object for ArtifactTypes"""
+class SystemRoleFilter(FilterABC):
+    """Filter Object for SystemRoles"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.ARTIFACT_TYPES.value
+        return ApiEndpoints.SYSTEM_ROLES.value
 
     def active(self, operator: Enum, active: bool):
         """Filter Active based on **active** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            active: The active status of the artifact type.
+            active: The active status of the role.
         """
         self._tql.add_filter('active', operator, active, TqlType.BOOLEAN)
 
-    def data_type(self, operator: Enum, data_type: str):
-        """Filter Data Type based on **dataType** keyword.
+    def assignable(self, operator: Enum, assignable: bool):
+        """Filter Assignable based on **assignable** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            data_type: The data type of the artifact type.
+            assignable: The assignable status of the role.
         """
-        self._tql.add_filter('dataType', operator, data_type, TqlType.STRING)
+        self._tql.add_filter('assignable', operator, assignable, TqlType.BOOLEAN)
 
-    def description(self, operator: Enum, description: str):
-        """Filter Description based on **description** keyword.
+    def displayed(self, operator: Enum, displayed: bool):
+        """Filter Displayed based on **displayed** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the artifact type.
+            displayed: The displayed status of the role.
         """
-        self._tql.add_filter('description', operator, description, TqlType.STRING)
+        self._tql.add_filter('displayed', operator, displayed, TqlType.BOOLEAN)
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the artifact type.
+            id: The ID of the role.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
-
-    def intel_type(self, operator: Enum, intel_type: str):
-        """Filter Intel Type based on **intelType** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            intel_type: The intel type of the artifact type.
-        """
-        self._tql.add_filter('intelType', operator, intel_type, TqlType.STRING)
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def managed(self, operator: Enum, managed: bool):
-        """Filter Managed based on **managed** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            managed: The managed status of the artifact type.
-        """
-        self._tql.add_filter('managed', operator, managed, TqlType.BOOLEAN)
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def name(self, operator: Enum, name: str):
+    def name(self, operator: Enum, name: list | str):
         """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the artifact type.
+            name: The name of the role.
         """
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('name', operator, name, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifact_types/artifact_type_model.py` & `tcex-4.0.0/tcex/api/tc/v3/artifact_types/artifact_type_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,114 +1,111 @@
-"""Artifact_Type / Artifact_Types Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class ArtifactTypesModel(
-    BaseModel,
-    title='ArtifactTypes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Artifact_Types Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['ArtifactTypeModel']] = Field(
-        [],
-        description='The data for the ArtifactTypes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class ArtifactTypeDataModel(
-    BaseModel,
-    title='ArtifactType Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Artifact_Types Data Model"""
-
-    data: Optional[List['ArtifactTypeModel']] = Field(
-        [],
-        description='The data for the ArtifactTypes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class ArtifactTypeModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='ArtifactType Model',
     validate_assignment=True,
 ):
     """Artifact_Type Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    data_type: Optional[str] = Field(
+    data_type: str | None = Field(
         None,
         allow_mutation=False,
         description='The **data type** for the Artifact_Type.',
         read_only=True,
         title='dataType',
     )
     derived_link: bool = Field(
         None,
         allow_mutation=False,
         description='The **derived link** for the Artifact_Type.',
         read_only=True,
         title='derivedLink',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         allow_mutation=False,
         description='The **description** for the Artifact_Type.',
         read_only=True,
         title='description',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    intel_type: Optional[str] = Field(
+    intel_type: str | None = Field(
         None,
         allow_mutation=False,
         description='The **intel type** for the Artifact_Type.',
         read_only=True,
         title='intelType',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
         description='The **name** for the Artifact_Type.',
         read_only=True,
         title='name',
     )
 
 
+class ArtifactTypeDataModel(
+    BaseModel,
+    title='ArtifactType Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Artifact_Types Data Model"""
+
+    data: list[ArtifactTypeModel] | None = Field(
+        [],
+        description='The data for the ArtifactTypes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class ArtifactTypesModel(
+    BaseModel,
+    title='ArtifactTypes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Artifact_Types Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[ArtifactTypeModel] | None = Field(
+        [],
+        description='The data for the ArtifactTypes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 ArtifactTypeDataModel.update_forward_refs()
 ArtifactTypeModel.update_forward_refs()
 ArtifactTypesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact.py` & `tcex-4.0.0/tcex/api/tc/v3/artifacts/artifact.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,65 +1,27 @@
-"""Artifact / Artifacts Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel, ArtifactsModel
 from tcex.api.tc.v3.groups.group_model import GroupModel
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel
 from tcex.api.tc.v3.notes.note_model import NoteModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.groups.group import Group
-    from tcex.api.tc.v3.indicators.indicator import Indicator
-    from tcex.api.tc.v3.notes.note import Note
-
-
-class Artifacts(ObjectCollectionABC):
-    """Artifacts Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = ArtifactsModel(**kwargs)
-        self.type_ = 'artifacts'
-
-    def __iter__(self) -> 'Artifact':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Artifact)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.ARTIFACTS.value
-
-    @property
-    def filter(self) -> 'ArtifactFilter':
-        """Return the type specific filter object."""
-        return ArtifactFilter(self.tql)
+    from tcex.api.tc.v3.groups.group import Group  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.indicators.indicator import Indicator  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.notes.note import Note  # CIRCULAR-IMPORT
 
 
 class Artifact(ObjectABC):
     """Artifacts Object.
 
     Args:
         associated_groups (Groups, kwargs): A list of Groups associated with this Artifact.
@@ -78,35 +40,35 @@
         summary (str, kwargs): The **summary** for the Artifact.
         task_id (int, kwargs): The ID of the task which the Artifact references.
         task_xid (str, kwargs): The XID of the task which the Artifact references.
         type (str, kwargs): The **type** for the Artifact.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = ArtifactModel(**kwargs)
+        self._model: ArtifactModel = ArtifactModel(**kwargs)
         self._nested_field_name = 'artifacts'
         self._nested_filter = 'has_artifact'
         self.type_ = 'Artifact'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.ARTIFACTS.value
 
     @property
-    def model(self) -> 'ArtifactModel':
+    def model(self) -> ArtifactModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['ArtifactModel', dict]):
+    def model(self, data: dict | ArtifactModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -117,65 +79,104 @@
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.summary}
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator['Group', None, None]:
         """Yield Group from Groups."""
         # first-party
         from tcex.api.tc.v3.groups.group import Groups
 
-        yield from self._iterate_over_sublist(Groups)
+        yield from self._iterate_over_sublist(Groups)  # type: ignore
 
     @property
-    def associated_indicators(self) -> Iterator['Indicator']:
+    def associated_indicators(self) -> Generator['Indicator', None, None]:
         """Yield Indicator from Indicators."""
         # first-party
         from tcex.api.tc.v3.indicators.indicator import Indicators
 
-        yield from self._iterate_over_sublist(Indicators)
+        yield from self._iterate_over_sublist(Indicators)  # type: ignore
 
     @property
-    def notes(self) -> Iterator['Note']:
+    def notes(self) -> Generator['Note', None, None]:
         """Yield Note from Notes."""
         # first-party
         from tcex.api.tc.v3.notes.note import Notes
 
-        yield from self._iterate_over_sublist(Notes)
+        yield from self._iterate_over_sublist(Notes)  # type: ignore
 
-    def stage_associated_group(self, data: Union[dict, 'ObjectABC', 'GroupModel']):
+    def stage_associated_group(self, data: dict | ObjectABC | GroupModel):
         """Stage group on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = GroupModel(**data)
 
         if not isinstance(data, GroupModel):
             raise RuntimeError('Invalid type passed in to stage_associated_group')
         data._staged = True
-        self.model.associated_groups.data.append(data)
+        self.model.associated_groups.data.append(data)  # type: ignore
 
-    def stage_associated_indicator(self, data: Union[dict, 'ObjectABC', 'IndicatorModel']):
+    def stage_associated_indicator(self, data: dict | ObjectABC | IndicatorModel):
         """Stage indicator on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = IndicatorModel(**data)
 
         if not isinstance(data, IndicatorModel):
             raise RuntimeError('Invalid type passed in to stage_associated_indicator')
         data._staged = True
-        self.model.associated_indicators.data.append(data)
+        self.model.associated_indicators.data.append(data)  # type: ignore
 
-    def stage_note(self, data: Union[dict, 'ObjectABC', 'NoteModel']):
+    def stage_note(self, data: dict | ObjectABC | NoteModel):
         """Stage note on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = NoteModel(**data)
 
         if not isinstance(data, NoteModel):
             raise RuntimeError('Invalid type passed in to stage_note')
         data._staged = True
-        self.model.notes.data.append(data)
+        self.model.notes.data.append(data)  # type: ignore
+
+
+class Artifacts(ObjectCollectionABC):
+    """Artifacts Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = ArtifactsModel(**kwargs)
+        self.type_ = 'artifacts'
+
+    def __iter__(self) -> Iterator[Artifact]:
+        """Return CM objects."""
+        return self.iterate(base_class=Artifact)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.ARTIFACTS.value
+
+    @property
+    def filter(self) -> ArtifactFilter:
+        """Return the type specific filter object."""
+        return ArtifactFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event_filter.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,169 +1,150 @@
-"""Artifact TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
-from tcex.api.tc.v3.tql.tql import Tql
-from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class ArtifactFilter(FilterABC):
-    """Filter Object for Artifacts"""
+class WorkflowEventFilter(FilterABC):
+    """Filter Object for WorkflowEvents"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.ARTIFACTS.value
-
-    def analytics_score(self, operator: Enum, analytics_score: int):
-        """Filter Analytics Score based on **analyticsScore** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            analytics_score: The intel score of the artifact.
-        """
-        self._tql.add_filter('analyticsScore', operator, analytics_score, TqlType.INTEGER)
+        return ApiEndpoints.WORKFLOW_EVENTS.value
 
-    def case_id(self, operator: Enum, case_id: int):
+    def case_id(self, operator: Enum, case_id: int | list):
         """Filter Case ID based on **caseId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_id: The ID of the case associated with this artifact.
+            case_id: The ID of the case this event is associated with.
         """
+        if isinstance(case_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
 
-    def date_added(self, operator: Enum, date_added: str):
+    def date_added(self, operator: Enum, date_added: Arrow | datetime | int | str):
         """Filter Date Added based on **dateAdded** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_added: The date the artifact was added to the system.
+            date_added: The date the event was added.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
         self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
 
-    @property
-    def has_case(self):
-        """Return **CaseFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.cases.case_filter import CaseFilter
-
-        cases = CaseFilter(Tql())
-        self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
-        return cases
-
-    @property
-    def has_group(self):
-        """Return **GroupFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.groups.group_filter import GroupFilter
-
-        groups = GroupFilter(Tql())
-        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
-        return groups
-
-    @property
-    def has_indicator(self):
-        """Return **IndicatorFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-
-        indicators = IndicatorFilter(Tql())
-        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
-        return indicators
-
-    @property
-    def has_note(self):
-        """Return **NoteFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.notes.note_filter import NoteFilter
-
-        notes = NoteFilter(Tql())
-        self._tql.add_filter('hasNote', TqlOperator.EQ, notes, TqlType.SUB_QUERY)
-        return notes
-
-    @property
-    def has_task(self):
-        """Return **TaskFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.tasks.task_filter import TaskFilter
-
-        tasks = TaskFilter(Tql())
-        self._tql.add_filter('hasTask', TqlOperator.EQ, tasks, TqlType.SUB_QUERY)
-        return tasks
-
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+    def deleted(self, operator: Enum, deleted: bool):
+        """Filter Deleted based on **deleted** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the artifact.
+            deleted: The deletion status of the event.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        self._tql.add_filter('deleted', operator, deleted, TqlType.BOOLEAN)
 
-    def indicator_active(self, operator: Enum, indicator_active: bool):
-        """Filter Active Status based on **indicatorActive** keyword.
+    def deleted_reason(self, operator: Enum, deleted_reason: list | str):
+        """Filter Deleted Reason based on **deletedReason** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            indicator_active: A flag indicating whether or not the artifact is active.
+            deleted_reason: The reason the event was deleted.
         """
-        self._tql.add_filter('indicatorActive', operator, indicator_active, TqlType.BOOLEAN)
+        if isinstance(deleted_reason, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def note_id(self, operator: Enum, note_id: int):
-        """Filter Note ID based on **noteId** keyword.
+        self._tql.add_filter('deletedReason', operator, deleted_reason, TqlType.STRING)
+
+    def event_date(self, operator: Enum, event_date: Arrow | datetime | int | str):
+        """Filter Event Date based on **eventDate** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            note_id: The ID of the note associated with this artifact.
+            event_date: The date the event occurred.
         """
-        self._tql.add_filter('noteId', operator, note_id, TqlType.INTEGER)
+        event_date = self.util.any_to_datetime(event_date).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('eventDate', operator, event_date, TqlType.STRING)
 
-    def source(self, operator: Enum, source: str):
-        """Filter Source based on **source** keyword.
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            source: The source of the artifact.
+            id: The ID of the event.
         """
-        self._tql.add_filter('source', operator, source, TqlType.STRING)
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+
+    def link(self, operator: Enum, link: list | str):
+        """Filter Link based on **link** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            summary: The summary of the artifact.
+            link: The item this event pertains to, in format <type>:<id>.
         """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+        if isinstance(link, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_id(self, operator: Enum, task_id: int):
-        """Filter Task ID based on **taskId** keyword.
+        self._tql.add_filter('link', operator, link, TqlType.STRING)
+
+    def summary(self, operator: Enum, summary: list | str):
+        """Filter Summary based on **summary** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_id: The ID of the task associated with this artifact.
+            summary: Text of the event.
         """
-        self._tql.add_filter('taskId', operator, task_id, TqlType.INTEGER)
+        if isinstance(summary, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def type(self, operator: Enum, type: str):  # pylint: disable=redefined-builtin
-        """Filter typeName based on **type** keyword.
+        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+
+    def system_generated(self, operator: Enum, system_generated: bool):
+        """Filter System Generated based on **systemGenerated** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type: The type name of the artifact.
+            system_generated: Flag determining if this event was created automatically by the
+                system.
         """
-        self._tql.add_filter('type', operator, type, TqlType.STRING)
+        self._tql.add_filter('systemGenerated', operator, system_generated, TqlType.BOOLEAN)
 
-    def type_name(self, operator: Enum, type_name: str):
-        """Filter typeName based on **typeName** keyword.
+    def user_name(self, operator: Enum, user_name: list | str):
+        """Filter User Name based on **userName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type_name: The type name of the artifact.
+            user_name: The username associated with the event.
         """
-        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
+        if isinstance(user_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('userName', operator, user_name, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/artifacts/artifact_model.py` & `tcex-4.0.0/tcex/api/tc/v3/artifacts/artifact_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,148 +1,107 @@
-"""Artifact / Artifacts Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class ArtifactsModel(
-    BaseModel,
-    title='Artifacts Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Artifacts Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['ArtifactModel']] = Field(
-        [],
-        description='The data for the Artifacts.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class ArtifactDataModel(
-    BaseModel,
-    title='Artifact Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Artifacts Data Model"""
-
-    data: Optional[List['ArtifactModel']] = Field(
-        [],
-        description='The data for the Artifacts.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class ArtifactModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Artifact Model',
     validate_assignment=True,
 ):
     """Artifact Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    analytics_priority: Optional[str] = Field(
+    analytics_priority: str | None = Field(
         None,
         allow_mutation=False,
         description='The **analytics priority** for the Artifact.',
         read_only=True,
         title='analyticsPriority',
     )
-    analytics_priority_level: Optional[int] = Field(
+    analytics_priority_level: int | None = Field(
         None,
         allow_mutation=False,
         description='The **analytics priority level** for the Artifact.',
         read_only=True,
         title='analyticsPriorityLevel',
     )
-    analytics_score: Optional[int] = Field(
+    analytics_score: int | None = Field(
         None,
         allow_mutation=False,
         description='The **analytics score** for the Artifact.',
         read_only=True,
         title='analyticsScore',
     )
-    analytics_status: Optional[str] = Field(
+    analytics_status: str | None = Field(
         None,
         allow_mutation=False,
         description='The **analytics status** for the Artifact.',
         read_only=True,
         title='analyticsStatus',
     )
-    analytics_type: Optional[str] = Field(
+    analytics_type: str | None = Field(
         None,
         allow_mutation=False,
         description='The **analytics type** for the Artifact.',
         read_only=True,
         title='analyticsType',
     )
-    artifact_type: Optional['ArtifactTypeModel'] = Field(
+    artifact_type: 'ArtifactTypeModel' = Field(
         None,
         allow_mutation=False,
         description='The **artifact type** for the Artifact.',
         read_only=True,
         title='artifactType',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of Groups associated with this Artifact.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    associated_indicators: Optional['IndicatorsModel'] = Field(
+    associated_indicators: 'IndicatorsModel' = Field(
         None,
         description='A list of Indicators associated with this Artifact.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedIndicators',
     )
-    case_id: Optional[int] = Field(
+    case_id: int | None = Field(
         None,
         description='The **case id** for the Artifact.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseXid',
         title='caseId',
     )
-    case_xid: Optional[str] = Field(
+    case_xid: str | None = Field(
         None,
         description='The **case xid** for the Artifact.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseId',
         title='caseXid',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The **date added** for the Artifact.',
         read_only=True,
         title='dateAdded',
     )
     derived_link: bool = Field(
@@ -151,155 +110,195 @@
             'Flag to specify if this artifact should be used for potentially associated cases or '
             'not.'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='derivedLink',
     )
-    field_name: Optional[str] = Field(
+    field_name: str | None = Field(
         None,
         description='The field name for the artifact.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='fieldName',
     )
-    file_data: Optional[str] = Field(
+    file_data: str | None = Field(
         None,
         description='Base64 encoded file attachment required only for certain artifact types.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='fileData',
     )
-    hash_code: Optional[str] = Field(
+    hash_code: str | None = Field(
         None,
         description='Hashcode of Artifact of type File.',
         methods=['POST'],
         read_only=False,
         title='hashCode',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    intel_type: Optional[str] = Field(
+    intel_type: str | None = Field(
         None,
         allow_mutation=False,
         description='The **intel type** for the Artifact.',
         read_only=True,
         title='intelType',
     )
-    links: Optional[dict] = Field(
+    links: dict | None = Field(
         None,
         allow_mutation=False,
         description='The **links** for the Artifact.',
         read_only=True,
         title='links',
     )
-    notes: Optional['NotesModel'] = Field(
+    notes: 'NotesModel' = Field(
         None,
         description='A list of Notes corresponding to the Artifact.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='notes',
     )
-    parent_case: Optional['CaseModel'] = Field(
+    parent_case: 'CaseModel' = Field(
         None,
         allow_mutation=False,
         description='The **parent case** for the Artifact.',
         read_only=True,
         title='parentCase',
     )
-    source: Optional[str] = Field(
+    source: str | None = Field(
         None,
         description='The **source** for the Artifact.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='source',
     )
-    summary: Optional[str] = Field(
+    summary: str | None = Field(
         None,
         description='The **summary** for the Artifact.',
         methods=['POST', 'PUT'],
         max_length=500,
         min_length=1,
         read_only=False,
         title='summary',
     )
-    task: Optional['TaskModel'] = Field(
+    task: 'TaskModel' = Field(
         None,
         allow_mutation=False,
         description='The **task** for the Artifact.',
         read_only=True,
         title='task',
     )
-    task_id: Optional[int] = Field(
+    task_id: int | None = Field(
         None,
         description='The ID of the task which the Artifact references.',
         methods=['POST'],
         read_only=False,
         title='taskId',
     )
-    task_xid: Optional[str] = Field(
+    task_xid: str | None = Field(
         None,
         description='The XID of the task which the Artifact references.',
         methods=['POST'],
         read_only=False,
         title='taskXid',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The **type** for the Artifact.',
         methods=['POST'],
         read_only=False,
         title='type',
     )
 
-    @validator('artifact_type', always=True)
+    @validator('artifact_type', always=True, pre=True)
     def _validate_artifact_type(cls, v):
         if not v:
-            return ArtifactTypeModel()
+            return ArtifactTypeModel()  # type: ignore
         return v
 
-    @validator('parent_case', always=True)
+    @validator('parent_case', always=True, pre=True)
     def _validate_case(cls, v):
         if not v:
-            return CaseModel()
+            return CaseModel()  # type: ignore
         return v
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
-    @validator('associated_indicators', always=True)
+    @validator('associated_indicators', always=True, pre=True)
     def _validate_indicators(cls, v):
         if not v:
-            return IndicatorsModel()
+            return IndicatorsModel()  # type: ignore
         return v
 
-    @validator('notes', always=True)
+    @validator('notes', always=True, pre=True)
     def _validate_notes(cls, v):
         if not v:
-            return NotesModel()
+            return NotesModel()  # type: ignore
         return v
 
-    @validator('task', always=True)
+    @validator('task', always=True, pre=True)
     def _validate_task(cls, v):
         if not v:
-            return TaskModel()
+            return TaskModel()  # type: ignore
         return v
 
 
+class ArtifactDataModel(
+    BaseModel,
+    title='Artifact Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Artifacts Data Model"""
+
+    data: list[ArtifactModel] | None = Field(
+        [],
+        description='The data for the Artifacts.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class ArtifactsModel(
+    BaseModel,
+    title='Artifacts Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Artifacts Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[ArtifactModel] | None = Field(
+        [],
+        description='The data for the Artifacts.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.artifact_types.artifact_type_model import ArtifactTypeModel
 from tcex.api.tc.v3.cases.case_model import CaseModel
 from tcex.api.tc.v3.groups.group_model import GroupsModel
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorsModel
 from tcex.api.tc.v3.notes.note_model import NotesModel
 from tcex.api.tc.v3.tasks.task_model import TaskModel
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type.py` & `tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,98 +1,98 @@
-"""AttributeType / AttributeTypes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.attribute_types.attribute_type_filter import AttributeTypeFilter
 from tcex.api.tc.v3.attribute_types.attribute_type_model import (
     AttributeTypeModel,
     AttributeTypesModel,
 )
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 
 
-class AttributeTypes(ObjectCollectionABC):
-    """AttributeTypes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = AttributeTypesModel(**kwargs)
-        self.type_ = 'attribute_types'
-
-    def __iter__(self) -> 'AttributeType':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=AttributeType)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.ATTRIBUTE_TYPES.value
-
-    @property
-    def filter(self) -> 'AttributeTypeFilter':
-        """Return the type specific filter object."""
-        return AttributeTypeFilter(self.tql)
-
-
 class AttributeType(ObjectABC):
     """AttributeTypes Object.
 
     Args:
         allow_markdown (bool, kwargs): Flag that enables markdown feature in the attribute value
             field.
         description (str, kwargs): The description of the attribute type.
         error_message (str, kwargs): The error message displayed.
         max_size (int, kwargs): The maximum size of the attribute value.
         name (str, kwargs): The name of the attribute type.
         validation_rule (object, kwargs): The validation rule that governs the attribute value.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = AttributeTypeModel(**kwargs)
+        self._model: AttributeTypeModel = AttributeTypeModel(**kwargs)
         self._nested_field_name = 'attributeTypes'
         self._nested_filter = 'has_attribute_type'
         self.type_ = 'Attribute Type'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.ATTRIBUTE_TYPES.value
 
     @property
-    def model(self) -> 'AttributeTypeModel':
+    def model(self) -> AttributeTypeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['AttributeTypeModel', dict]):
+    def model(self, data: dict | AttributeTypeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
+class AttributeTypes(ObjectCollectionABC):
+    """AttributeTypes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = AttributeTypesModel(**kwargs)
+        self.type_ = 'attribute_types'
+
+    def __iter__(self) -> Iterator[AttributeType]:
+        """Return CM objects."""
+        return self.iterate(base_class=AttributeType)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.ATTRIBUTE_TYPES.value
+
+    @property
+    def filter(self) -> AttributeTypeFilter:
+        """Return the type specific filter object."""
+        return AttributeTypeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group_filter.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,90 +1,62 @@
-"""Attribute_Type TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class AttributeTypeFilter(FilterABC):
-    """Filter Object for AttributeTypes"""
+class UserGroupFilter(FilterABC):
+    """Filter Object for UserGroups"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.ATTRIBUTE_TYPES.value
+        return ApiEndpoints.USER_GROUPS.value
 
-    def associated_type(self, operator: Enum, associated_type: str):
-        """Filter Associated Type based on **associatedType** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            associated_type: The data type(s) that the attribute type can be used for.
-        """
-        self._tql.add_filter('associatedType', operator, associated_type, TqlType.STRING)
-
-    def description(self, operator: Enum, description: str):
+    def description(self, operator: Enum, description: list | str):
         """Filter Description based on **description** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the attribute type.
+            description: The description of the user group.
         """
+        if isinstance(description, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('description', operator, description, TqlType.STRING)
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the attribute type.
+            id: The ID of the user group.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def maxsize(self, operator: Enum, maxsize: int):
-        """Filter Maxsize based on **maxsize** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            maxsize: Max size of the attribute.
-        """
-        self._tql.add_filter('maxsize', operator, maxsize, TqlType.INTEGER)
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def name(self, operator: Enum, name: str):
+    def name(self, operator: Enum, name: list | str):
         """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the attribute type.
-        """
-        self._tql.add_filter('name', operator, name, TqlType.STRING)
-
-    def owner(self, operator: Enum, owner: int):
-        """Filter Owner ID based on **owner** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            owner: The owner ID of the attribute type.
-        """
-        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
-
-    def owner_name(self, operator: Enum, owner_name: str):
-        """Filter Owner Name based on **ownerName** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            owner_name: The owner name of the attribute type.
+            name: The name of the user group.
         """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def system(self, operator: Enum, system: bool):
-        """Filter SystemLevel based on **system** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            system: A flag to show System level attributes (TRUE) or owner-specific ones only
-                (FALSE).
-        """
-        self._tql.add_filter('system', operator, system, TqlType.BOOLEAN)
+        self._tql.add_filter('name', operator, name, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/attribute_types/attribute_type_model.py` & `tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,63 +1,20 @@
-"""Attribute_Type / Attribute_Types Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class AttributeTypesModel(
-    BaseModel,
-    title='AttributeTypes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Attribute_Types Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['AttributeTypeModel']] = Field(
-        [],
-        description='The data for the AttributeTypes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class AttributeTypeDataModel(
-    BaseModel,
-    title='AttributeType Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Attribute_Types Data Model"""
-
-    data: Optional[List['AttributeTypeModel']] = Field(
-        [],
-        description='The data for the AttributeTypes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class AttributeTypeModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='AttributeType Model',
     validate_assignment=True,
 ):
     """Attribute_Type Model"""
 
     _associated_type = PrivateAttr(False)
@@ -68,54 +25,94 @@
     allow_markdown: bool = Field(
         None,
         description='Flag that enables markdown feature in the attribute value field.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='allowMarkdown',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         description='The description of the attribute type.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='description',
     )
-    error_message: Optional[str] = Field(
+    error_message: str | None = Field(
         None,
         description='The error message displayed.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='errorMessage',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    max_size: Optional[int] = Field(
+    max_size: int | None = Field(
         None,
         description='The maximum size of the attribute value.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='maxSize',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='The name of the attribute type.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='name',
     )
-    validation_rule: Optional[dict] = Field(
+    validation_rule: dict | None = Field(
         None,
         description='The validation rule that governs the attribute value.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='validationRule',
     )
 
 
+class AttributeTypeDataModel(
+    BaseModel,
+    title='AttributeType Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Attribute_Types Data Model"""
+
+    data: list[AttributeTypeModel] | None = Field(
+        [],
+        description='The data for the AttributeTypes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class AttributeTypesModel(
+    BaseModel,
+    title='AttributeTypes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Attribute_Types Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[AttributeTypeModel] | None = Field(
+        [],
+        description='The data for the AttributeTypes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 AttributeTypeDataModel.update_forward_refs()
 AttributeTypeModel.update_forward_refs()
 AttributeTypesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute.py` & `tcex-4.0.0/tcex/api/tc/v3/case_attributes/case_attribute.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,64 +1,26 @@
-"""CaseAttribute / CaseAttributes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.case_attributes.case_attribute_filter import CaseAttributeFilter
 from tcex.api.tc.v3.case_attributes.case_attribute_model import (
     CaseAttributeModel,
     CaseAttributesModel,
 )
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-
-
-class CaseAttributes(ObjectCollectionABC):
-    """CaseAttributes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = CaseAttributesModel(**kwargs)
-        self.type_ = 'case_attributes'
-
-    def __iter__(self) -> 'CaseAttribute':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=CaseAttribute)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.CASE_ATTRIBUTES.value
-
-    @property
-    def filter(self) -> 'CaseAttributeFilter':
-        """Return the type specific filter object."""
-        return CaseAttributeFilter(self.tql)
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
 
 
 class CaseAttribute(ObjectABC):
     """CaseAttributes Object.
 
     Args:
         case_id (int, kwargs): Case associated with attribute.
@@ -70,57 +32,96 @@
             the one(s) specified).
         source (str, kwargs): The attribute source.
         type (str, kwargs): The attribute type.
         value (str, kwargs): The attribute value.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = CaseAttributeModel(**kwargs)
+        self._model: CaseAttributeModel = CaseAttributeModel(**kwargs)
         self._nested_field_name = 'attributes'
         self._nested_filter = 'has_case_attribute'
         self.type_ = 'Case Attribute'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.CASE_ATTRIBUTES.value
 
     @property
-    def model(self) -> 'CaseAttributeModel':
+    def model(self) -> CaseAttributeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['CaseAttributeModel', dict]):
+    def model(self, data: dict | CaseAttributeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
+
+
+class CaseAttributes(ObjectCollectionABC):
+    """CaseAttributes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = CaseAttributesModel(**kwargs)
+        self.type_ = 'case_attributes'
+
+    def __iter__(self) -> Iterator[CaseAttribute]:
+        """Return CM objects."""
+        return self.iterate(base_class=CaseAttribute)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.CASE_ATTRIBUTES.value
+
+    @property
+    def filter(self) -> CaseAttributeFilter:
+        """Return the type specific filter object."""
+        return CaseAttributeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/notes/note_filter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,176 +1,178 @@
-"""Case_Attribute TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql import Tql
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class CaseAttributeFilter(FilterABC):
-    """Filter Object for CaseAttributes"""
+class NoteFilter(FilterABC):
+    """Filter Object for Notes"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.CASE_ATTRIBUTES.value
+        return ApiEndpoints.NOTES.value
 
-    def case_id(self, operator: Enum, case_id: int):
-        """Filter Workflow ID based on **caseId** keyword.
+    def artifact_id(self, operator: Enum, artifact_id: int | list):
+        """Filter Artifact ID based on **artifactId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_id: The ID of the case the workflow attribute is applied to.
+            artifact_id: The ID of the artifact this note is associated with.
         """
-        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
+        if isinstance(artifact_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def date_added(self, operator: Enum, date_added: str):
-        """Filter Date Added based on **dateAdded** keyword.
+        self._tql.add_filter('artifactId', operator, artifact_id, TqlType.INTEGER)
+
+    def author(self, operator: Enum, author: list | str):
+        """Filter Author based on **author** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_added: The date the attribute was added to the system.
+            author: The account login of the user who wrote the note.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
+        if isinstance(author, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('author', operator, author, TqlType.STRING)
 
-    def date_val(self, operator: Enum, date_val: str):
-        """Filter Date based on **dateVal** keyword.
+    def case_id(self, operator: Enum, case_id: int | list):
+        """Filter Case ID based on **caseId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_val: The date value of the attribute (only applies to certain types).
+            case_id: The ID of the case this note is associated with.
         """
-        date_val = self.utils.any_to_datetime(date_val).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dateVal', operator, date_val, TqlType.STRING)
+        if isinstance(case_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def displayed(self, operator: Enum, displayed: bool):
-        """Filter Displayed based on **displayed** keyword.
+        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
+
+    def date_added(self, operator: Enum, date_added: Arrow | datetime | int | str):
+        """Filter Date Added based on **dateAdded** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            displayed: Whether or not the attribute is displayed on the item.
+            date_added: The date the note was written.
         """
-        self._tql.add_filter('displayed', operator, displayed, TqlType.BOOLEAN)
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
+
+    @property
+    def has_artifact(self):
+        """Return **ArtifactFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
+
+        artifacts = ArtifactFilter(Tql())
+        self._tql.add_filter('hasArtifact', TqlOperator.EQ, artifacts, TqlType.SUB_QUERY)
+        return artifacts
 
     @property
     def has_case(self):
         """Return **CaseFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.cases.case_filter import CaseFilter
 
         cases = CaseFilter(Tql())
         self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
         return cases
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+    @property
+    def has_task(self):
+        """Return **TaskFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.tasks.task_filter import TaskFilter
 
-        Args:
-            operator: The operator enum for the filter.
-            id: The ID of the attribute.
-        """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        tasks = TaskFilter(Tql())
+        self._tql.add_filter('hasTask', TqlOperator.EQ, tasks, TqlType.SUB_QUERY)
+        return tasks
 
-    def int_val(self, operator: Enum, int_val: int):
-        """Filter Integer Value based on **intVal** keyword.
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            int_val: The integer value of the attribute (only applies to certain types).
+            id: The ID of the case.
         """
-        self._tql.add_filter('intVal', operator, int_val, TqlType.INTEGER)
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def last_modified(self, operator: Enum, last_modified: str):
+    def last_modified(self, operator: Enum, last_modified: Arrow | datetime | int | str):
         """Filter Last Modified based on **lastModified** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_modified: The date the attribute was last modified in the system.
+            last_modified: The date the note was last modified.
         """
-        last_modified = self.utils.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
+        last_modified = self.util.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
         self._tql.add_filter('lastModified', operator, last_modified, TqlType.STRING)
 
-    def max_size(self, operator: Enum, max_size: int):
-        """Filter Max Size based on **maxSize** keyword.
+    def summary(self, operator: Enum, summary: list | str):
+        """Filter Summary based on **summary** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            max_size: The max length of the attribute text.
+            summary: Text of the first 100 characters of the note.
         """
-        self._tql.add_filter('maxSize', operator, max_size, TqlType.INTEGER)
+        if isinstance(summary, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def owner(self, operator: Enum, owner: int):
-        """Filter Owner ID based on **owner** keyword.
+        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            owner: The owner ID of the attribute.
-        """
-        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
-
-    def owner_name(self, operator: Enum, owner_name: str):
-        """Filter Owner Name based on **ownerName** keyword.
+    def task_id(self, operator: Enum, task_id: int | list):
+        """Filter Task ID based on **taskId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name of the attribute.
+            task_id: The ID of the task this note is associated with.
         """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
+        if isinstance(task_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def pinned(self, operator: Enum, pinned: bool):
-        """Filter Pinned based on **pinned** keyword.
+        self._tql.add_filter('taskId', operator, task_id, TqlType.INTEGER)
 
-        Args:
-            operator: The operator enum for the filter.
-            pinned: Whether or not the attribute is pinned with importance.
-        """
-        self._tql.add_filter('pinned', operator, pinned, TqlType.BOOLEAN)
-
-    def source(self, operator: Enum, source: str):
-        """Filter Source based on **source** keyword.
+    def workflow_event_id(self, operator: Enum, workflow_event_id: int | list):
+        """Filter Workflow Event ID based on **workflowEventId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            source: The source text of the attribute.
+            workflow_event_id: The ID of the workflow event this note is associated with.
         """
-        self._tql.add_filter('source', operator, source, TqlType.STRING)
-
-    def text(self, operator: Enum, text: str):
-        """Filter Text based on **text** keyword.
+        if isinstance(workflow_event_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            text: The text of the attribute (only applies to certain types).
-        """
-        self._tql.add_filter('text', operator, text, TqlType.STRING)
-
-    def type(self, operator: Enum, type: int):  # pylint: disable=redefined-builtin
-        """Filter Type ID based on **type** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            type: The ID of the attribute type.
-        """
-        self._tql.add_filter('type', operator, type, TqlType.INTEGER)
-
-    def type_name(self, operator: Enum, type_name: str):
-        """Filter Type Name based on **typeName** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            type_name: The name of the attribute type.
-        """
-        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
-
-    def user(self, operator: Enum, user: str):
-        """Filter User based on **user** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            user: The user who created the attribute.
-        """
-        self._tql.add_filter('user', operator, user, TqlType.STRING)
+        self._tql.add_filter('workflowEventId', operator, workflow_event_id, TqlType.INTEGER)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/case_attributes/case_attribute_model.py` & `tcex-4.0.0/tcex/api/tc/v3/case_attributes/case_attribute_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,90 +1,49 @@
-"""Case_Attribute / Case_Attributes Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class CaseAttributesModel(
-    BaseModel,
-    title='CaseAttributes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Case_Attributes Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['CaseAttributeModel']] = Field(
-        [],
-        description='The data for the CaseAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class CaseAttributeDataModel(
-    BaseModel,
-    title='CaseAttribute Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Case_Attributes Data Model"""
-
-    data: Optional[List['CaseAttributeModel']] = Field(
-        [],
-        description='The data for the CaseAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class CaseAttributeModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='CaseAttribute Model',
     validate_assignment=True,
 ):
     """Case_Attribute Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    case_id: Optional[int] = Field(
+    case_id: int | None = Field(
         None,
         description='Case associated with attribute.',
         methods=['POST'],
         read_only=False,
         title='caseId',
     )
-    created_by: Optional['UserModel'] = Field(
+    created_by: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The **created by** for the Case_Attribute.',
         read_only=True,
         title='createdBy',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
     default: bool = Field(
@@ -93,80 +52,120 @@
             'A flag indicating that this is the default attribute of its type within the object. '
             'Only applies to certain attribute and data types.'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='default',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Attribute was last modified.',
         read_only=True,
         title='lastModified',
     )
     pinned: bool = Field(
         None,
         description='A flag indicating that the attribute has been noted for importance.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='pinned',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    source: Optional[str] = Field(
+    source: str | None = Field(
         None,
         description='The attribute source.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='source',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The attribute type.',
         methods=['POST'],
         read_only=False,
         title='type',
     )
-    value: Optional[str] = Field(
+    value: str | None = Field(
         None,
         description='The attribute value.',
         methods=['POST', 'PUT'],
         min_length=1,
         read_only=False,
         title='value',
     )
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('created_by', always=True)
+    @validator('created_by', always=True, pre=True)
     def _validate_user(cls, v):
         if not v:
-            return UserModel()
+            return UserModel()  # type: ignore
         return v
 
 
+class CaseAttributeDataModel(
+    BaseModel,
+    title='CaseAttribute Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Case_Attributes Data Model"""
+
+    data: list[CaseAttributeModel] | None = Field(
+        [],
+        description='The data for the CaseAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class CaseAttributesModel(
+    BaseModel,
+    title='CaseAttributes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Case_Attributes Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[CaseAttributeModel] | None = Field(
+        [],
+        description='The data for the CaseAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelsModel
 
 # add forward references
 CaseAttributeDataModel.update_forward_refs()
 CaseAttributeModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/case_management/case_management.py` & `tcex-4.0.0/tcex/api/tc/v3/case_management/case_management.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,37 @@
-"""Case Management"""
+"""TcEx Framework Module"""
 # third-party
 from requests import Session
 
 # first-party
 from tcex.api.tc.v3.case_attributes.case_attribute import CaseAttribute, CaseAttributes
-from tcex.api.tc.v3.security.assignee_model import AssigneeModel
 
 
 class CaseManagement:
     """Case Management
 
     Args:
         session: An configured instance of request.Session with TC API Auth.
     """
 
     def __init__(self, session: Session):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self.session = session
 
     def artifact(self, **kwargs) -> 'Artifact':
         """Return a instance of Artifact object.
 
         Model Schema:
-        >>> from tcex.api.tc.v3.case_management.models.artifact_model import ArtifactModel
+        >>> from tcex.api.tc.v3.case_management.model.artifact_model import ArtifactModel
         >>> print(ArtifactModel.schema_json(by_alias=False, indent=2))
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             case_id (int, kwargs): The **case id** for the Artifact.
             case_xid (str, kwargs): The **case xid** for the Artifact.
             derived_link (bool, kwargs): Flag to specify if this artifact should be used for
                 potentially associated cases or not.
             file_data (str, kwargs): Base64 encoded file attachment required only for certain
                 artifact types.
             hash_code (str, kwargs): Hashcode of Artifact of type File.
@@ -53,24 +55,30 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Artifact.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return Artifacts(session=self.session, **kwargs)
 
     def artifact_type(self, **kwargs) -> 'ArtifactType':
         """Return a instance of Artifact Type object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             data_type (str, kwargs): [Read-Only] The **Data Type** for the Artifact Type.
             description (str, kwargs): [Read-Only] The **Description** for the Artifact Type.
             intel_type (str, kwargs): [Read-Only] The **Intel Type** for the Artifact Type.
             name (str, kwargs): [Read-Only] The **Name** for the Artifact Type.
         """
         return ArtifactType(session=self.session, **kwargs)
@@ -86,45 +94,33 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Artifact.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent
                 while retrieving the Artifact Type objects.
         """
         return ArtifactTypes(session=self.session, **kwargs)
 
-    def assignee(self, **kwargs) -> 'AssigneeModel':
-        """Return a instance of Assignee object.
-
-        For User type the user_name or id fields is required and
-        for the Group type the name or id is required.
-
-        Args:
-            first_name (str, kwargs): The first name of the User.
-            id (id, kwargs): The id of the User.
-            name (str, kwargs): The name of the Group.
-            last_name (str, kwargs): The last name of the user.
-            pseudonym (str, kwargs): The pseudonym of the User.
-            role (str, kwargs): The role of the User.
-            user_name (str, kwargs): The user name of the User.
-            type (str, kwargs): The assignee type. Default to User.
-        """
-        return AssigneeModel(session=self.session, **kwargs)
-
     def case(self, **kwargs) -> 'Case':
         """Return a instance of Case object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             artifacts (Artifacts, kwargs): A list of Artifacts corresponding to the Case.
             assignee (Assignee, kwargs): The user or group Assignee object for the Case.
             description (str, kwargs): The **description** for the Case.
             name (str, kwargs): The **name** for the Case.
             notes (Notes, kwargs): A list of Notes corresponding to the Case.
             resolution (str, kwargs): The **resolution** for the Case.
             severity (str, kwargs): The **severity** for the Case.
@@ -138,42 +134,48 @@
                 corresponding to the Case.
             workflow_template (WorkflowTemplate, kwargs): The Template that the Case is populated
                 by.
             xid (str, kwargs): The **xid** for the Case.
         """
         return Case(session=self.session, **kwargs)
 
-    def case_attribute(self, **kwargs) -> 'CaseAttribute':
+    def case_attribute(self, **kwargs) -> CaseAttribute:
         """Return a instance of Case Attributes object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             case_id (int, kwargs): Case associated with attribute.
             default (bool, kwargs): A flag indicating that this is the default attribute of its type
                 within the object. Only applies to certain attribute and data types.
             source (str, kwargs): The attribute source.
             type (str, kwargs): The attribute type.
             value (str, kwargs): Attribute value.
         """
         return CaseAttribute(session=self.session, **kwargs)
 
-    def case_attributes(self, **kwargs) -> 'CaseAttributes':
+    def case_attributes(self, **kwargs) -> CaseAttributes:
         """Return a instance of Case Attributes object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Group.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return CaseAttributes(session=self.session, **kwargs)
 
     def cases(self, **kwargs) -> 'Cases':
@@ -187,24 +189,27 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Artifact.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Case objects.
         """
         return Cases(session=self.session, **kwargs)
 
-    def create_entity(self, entity: dict, owner: str) -> dict:
+    def create_entity(self, entity: dict, owner: str) -> dict | None:
         """Create a CM object provided a dict and owner."""
         entity_type = entity.pop('type').lower()
         entity_type = entity_type.replace(' ', '_')
         try:
             obj = getattr(self, entity_type)(**entity)
         except AttributeError:
             return None
@@ -219,14 +224,17 @@
 
         return data
 
     def note(self, **kwargs) -> 'Note':
         """Return a instance of Note object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             artifact (Artifact, kwargs): [Read-Only] The **Artifact** for the Note.
             artifact_id (int, kwargs): the ID of the Artifact on which to apply the Note
             author (int, kwargs): [Read-Only] The **Author** for the Note.
             case_id (int, kwargs): [Required (alt: caseXid)] The **Case Id** for the Note.
             case_xid (str, kwargs): [Required (alt: caseId)]
             date_added (str, kwargs): [Read-Only] The **Date Added** for the Note.
@@ -254,27 +262,33 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Note.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Notes objects.
         """
         return Notes(session=self.session, **kwargs)
 
     def tag(self, **kwargs) -> 'Tag':
         """Return a instance of Tag object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             cases (Case, kwargs): [Read-Only] The **Cases** for the Tag.
             description (str, kwargs): a brief description of the Tag
             last_used (str, kwargs): [Read-Only] The **Last Used** for the Tag.
             name (str, kwargs): [Required] The **Name** for the Tag.
             owner (str, kwargs): [Read-Only] The **Owner** for the Tag.
         """
@@ -291,27 +305,33 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Tag.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Tag objects.
         """
         return Tags(session=self.session, **kwargs)
 
     def task(self, **kwargs) -> 'Task':
         """Return a instance of Task object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             artifacts (Artifact, kwargs): a list of Artifacts corresponding to the Task
             assignee (Assignee, kwargs): the user or group Assignee object for the Task
             case_id (int, kwargs): [Required (alt: caseXid)] The **Case Id** for the Task.
             case_xid (str, kwargs): [Required (alt: caseId)] The **Case Xid** for the Task.
             completed_by (str, kwargs): [Read-Only] The **Completed By** for the Task.
             completed_date (str, kwargs): the completion date of the Task
@@ -344,50 +364,33 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Task.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Task objects.
         """
         return Tasks(session=self.session, **kwargs)
 
-    # @staticmethod
-    # def user(self, **kwargs) -> 'User':
-    #     """Return a instance of User object.
-    #
-    #     Args:
-    #         first_name (str, kwargs): The first name of the user.
-    #         id (id, kwargs): The id of the user.
-    #         last_name (str, kwargs): The last name of the user.
-    #         pseudonym (str, kwargs): The pseudonym of the user.
-    #         role (str, kwargs): The role of the user.
-    #         user_name (str, kwargs): The user name of the user.
-    #     """
-    #     return User(session=self.session, **kwargs)
-
-    # @staticmethod
-    # def users(users) -> 'Users':
-    #     """Sub class of the Cases object. Used to map the users to.
-
-    #     Args:
-    #         users (list): A array of user data
-    #     """
-    #     return Users(users)
-
     def workflow_event(self, **kwargs) -> 'WorkflowEvent':
         """Return a instance of Workflow Event object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             case_id (int, kwargs): [Required (alt: caseXid)] The **Case Id** for the Workflow Event.
             case_xid (str, kwargs): [Required (alt: caseId)] The **Case Xid**
                 for the Workflow Event.
             date_added (str, kwargs): [Read-Only] The **Date Added** for the Workflow Event.
             deleted (bool, kwargs): [Read-Only] The **Deleted** flag for the Workflow Event.
             deleted_reason (str, kwargs): the reason for deleting the event (required
@@ -415,28 +418,34 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Artifact.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Workflow Event objects.
         """
         return WorkflowEvents(session=self.session, **kwargs)
 
     def workflow_template(self, **kwargs) -> 'WorkflowTemplate':
         """Return a instance of Workflow Template object.
 
         Args:
             tcex (TcEx): An instantiated instance of TcEx object.
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): [Read-Only] The **Active** flag for the Workflow Template.
             assignee (Assignee, kwargs): [Read-Only] The **Assignee** for the Workflow Template.
             cases (Case, kwargs): [Read-Only] The **Cases** for the Workflow Template.
             config_artifact (str, kwargs): [Read-Only] The **Config Artifact** for the Workflow
                 Template.
             config_playbook (str, kwargs): [Read-Only] The **Config Playbook** for the Workflow
                 Template.
@@ -459,26 +468,28 @@
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             tcex (TcEx): An instantiated instance of TcEx object.
             initial_response (dict, optional): Initial data in
                 Case Object for Workflow Template.
             tql_filters (list, optional): List of TQL filters.
             params(dict, optional): Dict of the params to be sent while
                 retrieving the Workflow Event objects.
         """
         return WorkflowTemplates(session=self.session, **kwargs)
 
 
 # first-party
-# TODO: [low] @bsummers - can these be moved to the top?
 # pylint: disable=wrong-import-position
 from tcex.api.tc.v3.artifact_types.artifact_type import ArtifactType, ArtifactTypes
 from tcex.api.tc.v3.artifacts.artifact import Artifact, Artifacts
 from tcex.api.tc.v3.cases.case import Case, Cases
 from tcex.api.tc.v3.notes.note import Note, Notes
 from tcex.api.tc.v3.tags.tag import Tag, Tags
 from tcex.api.tc.v3.tasks.task import Task, Tasks
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/cases/case.py` & `tcex-4.0.0/tcex/api/tc/v3/groups/group.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,331 +1,387 @@
-"""Case / Cases Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+import json
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING, Self
+
+# third-party
+from requests import Response
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
-from tcex.api.tc.v3.case_attributes.case_attribute_model import CaseAttributeModel
-from tcex.api.tc.v3.cases.case_filter import CaseFilter
-from tcex.api.tc.v3.cases.case_model import CaseModel, CasesModel
-from tcex.api.tc.v3.groups.group_model import GroupModel
+from tcex.api.tc.v3.cases.case_model import CaseModel
+from tcex.api.tc.v3.group_attributes.group_attribute_model import GroupAttributeModel
+from tcex.api.tc.v3.groups.group_filter import GroupFilter
+from tcex.api.tc.v3.groups.group_model import GroupModel, GroupsModel
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel
-from tcex.api.tc.v3.notes.note_model import NoteModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
-from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel
-from tcex.api.tc.v3.security.users.user_model import UserModel
+from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 from tcex.api.tc.v3.tags.tag_model import TagModel
-from tcex.api.tc.v3.tasks.task_model import TaskModel
+from tcex.api.tc.v3.victim_assets.victim_asset_model import VictimAssetModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.artifacts.artifact import Artifact
-    from tcex.api.tc.v3.case_attributes.case_attribute import CaseAttribute
-    from tcex.api.tc.v3.groups.group import Group
-    from tcex.api.tc.v3.indicators.indicator import Indicator
-    from tcex.api.tc.v3.notes.note import Note
-    from tcex.api.tc.v3.tags.tag import Tag
-    from tcex.api.tc.v3.tasks.task import Task
-
-
-class Cases(ObjectCollectionABC):
-    """Cases Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = CasesModel(**kwargs)
-        self.type_ = 'cases'
-
-    def __iter__(self) -> 'Case':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Case)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.CASES.value
-
-    @property
-    def filter(self) -> 'CaseFilter':
-        """Return the type specific filter object."""
-        return CaseFilter(self.tql)
+    from tcex.api.tc.v3.artifacts.artifact import Artifact  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.cases.case import Case  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.group_attributes.group_attribute import GroupAttribute  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.indicators.indicator import Indicator  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.tags.tag import Tag  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.victim_assets.victim_asset import VictimAsset  # CIRCULAR-IMPORT
 
 
-class Case(ObjectABC):
-    """Cases Object.
+class Group(ObjectABC):
+    """Groups Object.
 
     Args:
-        artifacts (Artifacts, kwargs): A list of Artifacts corresponding to the Case.
-        assignee (Assignee, kwargs): The user or group Assignee object for the Case.
-        associated_cases (Cases, kwargs): A list of Cases associated with this Case.
-        associated_groups (Groups, kwargs): A list of Groups associated with this Case.
-        associated_indicators (Indicators, kwargs): A list of Indicators associated with this Case.
-        attributes (CaseAttributes, kwargs): A list of Attributes corresponding to the Case.
-        case_close_time (str, kwargs): The date and time that the Case was closed.
-        case_detection_time (str, kwargs): The date and time that ends the user initiated Case
-            duration.
-        case_occurrence_time (str, kwargs): The date and time that starts the user initiated Case
-            duration.
-        case_open_time (str, kwargs): The date and time that the Case was first opened.
-        description (str, kwargs): The description of the Case.
-        name (str, kwargs): The name of the Case.
-        notes (Notes, kwargs): A list of Notes corresponding to the Case.
-        resolution (str, kwargs): The Case resolution.
-        severity (str, kwargs): The Case severity.
-        status (str, kwargs): The Case status.
-        tags (Tags, kwargs): A list of Tags corresponding to the Case (NOTE: Setting this parameter
+        assignments (TaskAssignees, kwargs): A list of assignees and escalatees associated with this
+            group (Task specific).
+        associated_artifacts (Artifacts, kwargs): A list of Artifacts associated with this Group.
+        associated_cases (Cases, kwargs): A list of Cases associated with this Group.
+        associated_groups (Groups, kwargs): A list of groups associated with this group.
+        associated_indicators (Indicators, kwargs): A list of indicators associated with this group.
+        associated_victim_assets (VictimAssets, kwargs): A list of victim assets associated with
+            this group.
+        attributes (GroupAttributes, kwargs): A list of Attributes corresponding to the Group.
+        body (str, kwargs): The email Body.
+        due_date (str, kwargs): The date and time that the Task is due.
+        escalation_date (str, kwargs): The escalation date and time.
+        event_date (str, kwargs): The date and time that the incident or event was first created.
+        file_name (str, kwargs): The document or signature file name.
+        file_text (str, kwargs): The signature file text.
+        file_type (str, kwargs): The signature file type.
+        first_seen (str, kwargs): The date and time that the campaign was first created.
+        from_ (str, kwargs): The email From field.
+        header (str, kwargs): The email Header field.
+        malware (bool, kwargs): Is the document malware?
+        name (str, kwargs): The name of the group.
+        owner_id (int, kwargs): The id of the Organization, Community, or Source that the item
+            belongs to.
+        owner_name (str, kwargs): The name of the Organization, Community, or Source that the item
+            belongs to.
+        password (str, kwargs): The password associated with the document (Required if Malware is
+            true).
+        publish_date (str, kwargs): The date and time that the report was first created.
+        reminder_date (str, kwargs): The reminder date and time.
+        security_labels (SecurityLabels, kwargs): A list of Security Labels corresponding to the
+            Intel item (NOTE: Setting this parameter will replace any existing tag(s) with
+            the one(s) specified).
+        status (str, kwargs): The status associated with this document, event, task, or incident
+            (read only for task, document, and report).
+        subject (str, kwargs): The email Subject section.
+        tags (Tags, kwargs): A list of Tags corresponding to the item (NOTE: Setting this parameter
             will replace any existing tag(s) with the one(s) specified).
-        tasks (Tasks, kwargs): A list of Tasks corresponding to the Case.
-        user_access (Users, kwargs): A list of Users that, when defined, are the only ones allowed
-            to view or edit the Case.
-        workflow_events (WorkflowEvents, kwargs): A list of workflowEvents (timeline) corresponding
-            to the Case.
-        workflow_template (WorkflowTemplate, kwargs): The Template that the Case is populated by.
-        xid (str, kwargs): The **xid** for the Case.
+        type (str, kwargs): The **type** for the Group.
+        up_vote (bool, kwargs): Is the intelligence valid and useful? (0 means downvote, 1 means
+            upvote, and NULL means no vote).
+        xid (str, kwargs): The xid of the item.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = CaseModel(**kwargs)
-        self._nested_field_name = 'cases'
-        self._nested_filter = 'has_case'
-        self.type_ = 'Case'
+        self._model: GroupModel = GroupModel(**kwargs)
+        self._nested_field_name = 'associatedGroups'
+        self._nested_filter = 'has_group'
+        self.type_ = 'Group'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
-        return ApiEndpoints.CASES.value
+        return ApiEndpoints.GROUPS.value
 
     @property
-    def model(self) -> 'CaseModel':
+    def model(self) -> GroupModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['CaseModel', dict]):
+    def model(self, data: dict | GroupModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
-        type_ = self.type_
+        type_ = self.model.type
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.name}
 
+    def remove(self, params: dict | None = None):
+        """Remove a nested object."""
+        method = 'PUT'
+        unique_id = self._calculate_unique_id()
+
+        # validate an id is available
+        self._validate_id(unique_id.get('value'), '')
+
+        body = json.dumps(
+            {
+                self._nested_field_name: {
+                    'data': [{unique_id.get('filter'): unique_id.get('value')}],
+                    'mode': 'delete',
+                }
+            }
+        )
+
+        # get the unique id value for id, xid, summary, etc ...
+        parent_api_endpoint = self._parent_data.get('api_endpoint')
+        parent_unique_id = self._parent_data.get('unique_id')
+        url = f'{parent_api_endpoint}/{parent_unique_id}'
+
+        # validate parent an id is available
+        self._validate_id(parent_unique_id, url)
+
+        self._request(
+            method=method,
+            url=url,
+            body=body,
+            headers={'content-type': 'application/json'},
+            params=params,
+        )
+
+        return self.request
+
+    def download(self, params: dict | None = None) -> bytes:
+        """Return the document attachment for Document/Report Types."""
+        self._request(
+            method='GET',
+            url=f'''{self.url('GET')}/download''',
+            headers={'Accept': 'application/octet-stream'},
+            params=params,
+        )
+        return self.request.content
+
+    def pdf(self, params: dict | None = None) -> bytes:
+        """Return the document attachment for Document/Report Types."""
+        self._request(
+            method='GET',
+            body=None,
+            url=f'''{self.url('GET')}/pdf''',
+            headers={'Accept': 'application/octet-stream'},
+            params=params,
+        )
+
+        return self.request.content
+
+    def upload(self, content: bytes | str, params: dict | None = None) -> Response:
+        """Return the document attachment for Document/Report Types."""
+        self._request(
+            method='POST',
+            url=f'''{self.url('GET')}/upload''',
+            body=content,
+            headers={'content-type': 'application/octet-stream'},
+            params=params,
+        )
+        return self.request
+
     @property
-    def artifacts(self) -> Iterator['Artifact']:
+    def associated_artifacts(self) -> Generator['Artifact', None, None]:
         """Yield Artifact from Artifacts."""
         # first-party
         from tcex.api.tc.v3.artifacts.artifact import Artifacts
 
-        yield from self._iterate_over_sublist(Artifacts)
+        yield from self._iterate_over_sublist(Artifacts)  # type: ignore
 
     @property
-    def associated_cases(self) -> Iterator['Case']:
+    def associated_cases(self) -> Generator['Case', None, None]:
         """Yield Case from Cases."""
-        # Ensure the current item is not returned as a association
-        for case in self._iterate_over_sublist(Cases):
-            if case.model.id == self.model.id:
-                continue
-            yield case
+        # first-party
+        from tcex.api.tc.v3.cases.case import Cases
+
+        yield from self._iterate_over_sublist(Cases)  # type: ignore
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator[Self, None, None]:
         """Yield Group from Groups."""
-        # first-party
-        from tcex.api.tc.v3.groups.group import Groups
-
-        yield from self._iterate_over_sublist(Groups)
+        # Ensure the current item is not returned as a association
+        for group in self._iterate_over_sublist(Groups):  # type: ignore
+            if group.model.id == self.model.id:
+                continue
+            yield group  # type: ignore
 
     @property
-    def associated_indicators(self) -> Iterator['Indicator']:
+    def associated_indicators(self) -> Generator['Indicator', None, None]:
         """Yield Indicator from Indicators."""
         # first-party
         from tcex.api.tc.v3.indicators.indicator import Indicators
 
-        yield from self._iterate_over_sublist(Indicators)
+        yield from self._iterate_over_sublist(Indicators)  # type: ignore
 
     @property
-    def attributes(self) -> Iterator['CaseAttribute']:
-        """Yield Attribute from Attributes."""
+    def associated_victim_assets(self) -> Generator['VictimAsset', None, None]:
+        """Yield VictimAsset from VictimAssets."""
         # first-party
-        from tcex.api.tc.v3.case_attributes.case_attribute import CaseAttributes
+        from tcex.api.tc.v3.victim_assets.victim_asset import VictimAssets
 
-        yield from self._iterate_over_sublist(CaseAttributes)
+        yield from self._iterate_over_sublist(VictimAssets)  # type: ignore
 
     @property
-    def notes(self) -> Iterator['Note']:
-        """Yield Note from Notes."""
+    def attributes(self) -> Generator['GroupAttribute', None, None]:
+        """Yield Attribute from Attributes."""
         # first-party
-        from tcex.api.tc.v3.notes.note import Notes
+        from tcex.api.tc.v3.group_attributes.group_attribute import GroupAttributes
 
-        yield from self._iterate_over_sublist(Notes)
+        yield from self._iterate_over_sublist(GroupAttributes)  # type: ignore
 
     @property
-    def tags(self) -> Iterator['Tag']:
-        """Yield Tag from Tags."""
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
+        """Yield SecurityLabel from SecurityLabels."""
         # first-party
-        from tcex.api.tc.v3.tags.tag import Tags
+        from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(Tags)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
     @property
-    def tasks(self) -> Iterator['Task']:
-        """Yield Task from Tasks."""
+    def tags(self) -> Generator['Tag', None, None]:
+        """Yield Tag from Tags."""
         # first-party
-        from tcex.api.tc.v3.tasks.task import Tasks
+        from tcex.api.tc.v3.tags.tag import Tags
 
-        yield from self._iterate_over_sublist(Tasks)
+        yield from self._iterate_over_sublist(Tags)  # type: ignore
 
-    def stage_artifact(self, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
-        """Stage artifact on the object."""
+    def stage_associated_case(self, data: dict | ObjectABC | CaseModel):
+        """Stage case on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = ArtifactModel(**data)
+            data = CaseModel(**data)
 
-        if not isinstance(data, ArtifactModel):
-            raise RuntimeError('Invalid type passed in to stage_artifact')
+        if not isinstance(data, CaseModel):
+            raise RuntimeError('Invalid type passed in to stage_associated_case')
         data._staged = True
-        self.model.artifacts.data.append(data)
+        self.model.associated_cases.data.append(data)  # type: ignore
 
-    # pylint: disable=redefined-builtin
-    def stage_assignee(self, type: str, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
+    def stage_associated_artifact(self, data: dict | ObjectABC | ArtifactModel):
         """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
-        elif type.lower() == 'user' and isinstance(data, dict):
-            data = UserModel(**data)
-        elif type.lower() == 'group' and isinstance(data, dict):
-            data = UserGroupModel(**data)
-
-        if not isinstance(data, (UserModel, UserGroupModel)):
-            raise RuntimeError('Invalid type passed in to stage_assignee')
-        data._staged = True
-        self.model.assignee._staged = True
-        self.model.assignee.type = type
-        self.model.assignee.data = data
-
-    def stage_associated_case(self, data: Union[dict, 'ObjectABC', 'CaseModel']):
-        """Stage case on the object."""
-        if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = CaseModel(**data)
+            data = ArtifactModel(**data)
 
-        if not isinstance(data, CaseModel):
-            raise RuntimeError('Invalid type passed in to stage_associated_case')
+        if not isinstance(data, ArtifactModel):
+            raise RuntimeError('Invalid type passed in to stage_associated_artifact')
         data._staged = True
-        self.model.associated_cases.data.append(data)
+        self.model.associated_artifacts.data.append(data)  # type: ignore
 
-    def stage_associated_group(self, data: Union[dict, 'ObjectABC', 'GroupModel']):
+    def stage_associated_group(self, data: dict | ObjectABC | GroupModel):
         """Stage group on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = GroupModel(**data)
 
         if not isinstance(data, GroupModel):
             raise RuntimeError('Invalid type passed in to stage_associated_group')
         data._staged = True
-        self.model.associated_groups.data.append(data)
+        self.model.associated_groups.data.append(data)  # type: ignore
+
+    def stage_associated_victim_asset(self, data: dict | ObjectABC | VictimAssetModel):
+        """Stage victim_asset on the object."""
+        if isinstance(data, ObjectABC):
+            data = data.model  # type: ignore
+        elif isinstance(data, dict):
+            data = VictimAssetModel(**data)
 
-    def stage_associated_indicator(self, data: Union[dict, 'ObjectABC', 'IndicatorModel']):
+        if not isinstance(data, VictimAssetModel):
+            raise RuntimeError('Invalid type passed in to stage_associated_victim_asset')
+        data._staged = True
+        self.model.associated_victim_assets.data.append(data)  # type: ignore
+
+    def stage_associated_indicator(self, data: dict | ObjectABC | IndicatorModel):
         """Stage indicator on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = IndicatorModel(**data)
 
         if not isinstance(data, IndicatorModel):
             raise RuntimeError('Invalid type passed in to stage_associated_indicator')
         data._staged = True
-        self.model.associated_indicators.data.append(data)
+        self.model.associated_indicators.data.append(data)  # type: ignore
 
-    def stage_attribute(self, data: Union[dict, 'ObjectABC', 'CaseAttributeModel']):
+    def stage_attribute(self, data: dict | ObjectABC | GroupAttributeModel):
         """Stage attribute on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = CaseAttributeModel(**data)
+            data = GroupAttributeModel(**data)
 
-        if not isinstance(data, CaseAttributeModel):
+        if not isinstance(data, GroupAttributeModel):
             raise RuntimeError('Invalid type passed in to stage_attribute')
         data._staged = True
-        self.model.attributes.data.append(data)
+        self.model.attributes.data.append(data)  # type: ignore
 
-    def stage_note(self, data: Union[dict, 'ObjectABC', 'NoteModel']):
-        """Stage note on the object."""
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
+        """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = NoteModel(**data)
+            data = SecurityLabelModel(**data)
 
-        if not isinstance(data, NoteModel):
-            raise RuntimeError('Invalid type passed in to stage_note')
+        if not isinstance(data, SecurityLabelModel):
+            raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.notes.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
 
-    def stage_tag(self, data: Union[dict, 'ObjectABC', 'TagModel']):
+    def stage_tag(self, data: dict | ObjectABC | TagModel):
         """Stage tag on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = TagModel(**data)
 
         if not isinstance(data, TagModel):
             raise RuntimeError('Invalid type passed in to stage_tag')
         data._staged = True
-        self.model.tags.data.append(data)
+        self.model.tags.data.append(data)  # type: ignore
 
-    def stage_task(self, data: Union[dict, 'ObjectABC', 'TaskModel']):
-        """Stage task on the object."""
-        if isinstance(data, ObjectABC):
-            data = data.model
-        elif isinstance(data, dict):
-            data = TaskModel(**data)
 
-        if not isinstance(data, TaskModel):
-            raise RuntimeError('Invalid type passed in to stage_task')
-        data._staged = True
-        self.model.tasks.data.append(data)
+class Groups(ObjectCollectionABC):
+    """Groups Collection.
 
-    def stage_user_access(self, data: Union[dict, 'ObjectABC', 'UserModel']):
-        """Stage user on the object."""
-        if isinstance(data, ObjectABC):
-            data = data.model
-        elif isinstance(data, dict):
-            data = UserModel(**data)
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
 
-        if not isinstance(data, UserModel):
-            raise RuntimeError('Invalid type passed in to stage_user_access')
-        data._staged = True
-        self.model.user_access.data.append(data)
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = GroupsModel(**kwargs)
+        self.type_ = 'groups'
+
+    def __iter__(self) -> Iterator[Group]:
+        """Return CM objects."""
+        return self.iterate(base_class=Group)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.GROUPS.value
+
+    @property
+    def filter(self) -> GroupFilter:
+        """Return the type specific filter object."""
+        return GroupFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/cases/case_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owners/owner_filter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,419 +1,441 @@
-"""Case TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
-from tcex.api.tc.v3.tql.tql import Tql
-from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class CaseFilter(FilterABC):
-    """Filter Object for Cases"""
+class OwnerFilter(FilterABC):
+    """Filter Object for Owners"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.CASES.value
+        return ApiEndpoints.OWNERS.value
 
-    def assigned_to_user_or_group(self, operator: Enum, assigned_to_user_or_group: str):
-        """Filter Assigned To User or Group based on **assignedToUserOrGroup** keyword.
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            assigned_to_user_or_group: A value of User, Group, or None depending on the assignee.
+            id: The ID of the Community Membership.
         """
-        self._tql.add_filter(
-            'assignedToUserOrGroup', operator, assigned_to_user_or_group, TqlType.STRING
-        )
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def assignee_name(self, operator: Enum, assignee_name: str):
-        """Filter Assignee based on **assigneeName** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            assignee_name: The user or group name assigned to the Case.
-        """
-        self._tql.add_filter('assigneeName', operator, assignee_name, TqlType.STRING)
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def attribute(self, operator: Enum, attribute: str):
-        """Filter attribute based on **attribute** keyword.
+    def owner_id(self, operator: Enum, owner_id: int | list):
+        """Filter Owner ID based on **ownerId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            attribute: No description provided.
+            owner_id: The ID of the Owner.
         """
-        self._tql.add_filter('attribute', operator, attribute, TqlType.STRING)
+        if isinstance(owner_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def cal_score(self, operator: Enum, cal_score: int):
-        """Filter CalScore based on **calScore** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            cal_score: Cal score of the case.
-        """
-        self._tql.add_filter('calScore', operator, cal_score, TqlType.INTEGER)
+        self._tql.add_filter('ownerId', operator, owner_id, TqlType.INTEGER)
 
-    def case_close_date(self, operator: Enum, case_close_date: str):
-        """Filter Cases Closed based on **caseCloseDate** keyword.
+    def owner_name(self, operator: Enum, owner_name: list | str):
+        """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_close_date: The date/time the case was closed.
+            owner_name: The name of the Owner.
         """
-        case_close_date = self.utils.any_to_datetime(case_close_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('caseCloseDate', operator, case_close_date, TqlType.STRING)
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def case_close_time(self, operator: Enum, case_close_time: str):
-        """Filter Case Close Time based on **caseCloseTime** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            case_close_time: The date/time the case was closed.
-        """
-        case_close_time = self.utils.any_to_datetime(case_close_time).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('caseCloseTime', operator, case_close_time, TqlType.STRING)
+        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def case_close_user(self, operator: Enum, case_close_user: str):
-        """Filter Case Close User based on **caseCloseUser** keyword.
+    def perm_apps(self, operator: Enum, perm_apps: list | str):
+        """Filter Apps Permission based on **permApps** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_close_user: The user who closed the case.
+            perm_apps: The User's Apps permission in the Owner.
         """
-        self._tql.add_filter('caseCloseUser', operator, case_close_user, TqlType.STRING)
+        if isinstance(perm_apps, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def case_detection_time(self, operator: Enum, case_detection_time: str):
-        """Filter Case Detection Time based on **caseDetectionTime** keyword.
+        self._tql.add_filter('permApps', operator, perm_apps, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            case_detection_time: The date/time the case was detected.
-        """
-        case_detection_time = self.utils.any_to_datetime(case_detection_time).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('caseDetectionTime', operator, case_detection_time, TqlType.STRING)
-
-    def case_detection_user(self, operator: Enum, case_detection_user: str):
-        """Filter Case Detection User based on **caseDetectionUser** keyword.
+    def perm_artifact(self, operator: Enum, perm_artifact: list | str):
+        """Filter Artifact Permission based on **permArtifact** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_detection_user: The user who logged the case detection time.
+            perm_artifact: The User's Artifact permission in the Owner.
         """
-        self._tql.add_filter('caseDetectionUser', operator, case_detection_user, TqlType.STRING)
+        if isinstance(perm_artifact, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def case_occurrence_time(self, operator: Enum, case_occurrence_time: str):
-        """Filter Case Occurrence Time based on **caseOccurrenceTime** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            case_occurrence_time: The date/time the case occurred.
-        """
-        case_occurrence_time = self.utils.any_to_datetime(case_occurrence_time).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('caseOccurrenceTime', operator, case_occurrence_time, TqlType.STRING)
+        self._tql.add_filter('permArtifact', operator, perm_artifact, TqlType.STRING)
 
-    def case_occurrence_user(self, operator: Enum, case_occurrence_user: str):
-        """Filter Case Occurrence User based on **caseOccurrenceUser** keyword.
+    def perm_attribute(self, operator: Enum, perm_attribute: list | str):
+        """Filter Attribute Permission based on **permAttribute** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_occurrence_user: The user who logged the case occurrence time.
+            perm_attribute: The User's Attribute permission in the Owner.
         """
-        self._tql.add_filter('caseOccurrenceUser', operator, case_occurrence_user, TqlType.STRING)
+        if isinstance(perm_attribute, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def case_open_date(self, operator: Enum, case_open_date: str):
-        """Filter Cases Created based on **caseOpenDate** keyword.
+        self._tql.add_filter('permAttribute', operator, perm_attribute, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            case_open_date: The date/time the case was opened.
-        """
-        case_open_date = self.utils.any_to_datetime(case_open_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('caseOpenDate', operator, case_open_date, TqlType.STRING)
-
-    def case_open_time(self, operator: Enum, case_open_time: str):
-        """Filter Case Open Time based on **caseOpenTime** keyword.
+    def perm_attribute_type(self, operator: Enum, perm_attribute_type: list | str):
+        """Filter AttributeType Permission based on **permAttributeType** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_open_time: The date/time the case was opened.
+            perm_attribute_type: The User's AttributeType permission in the Owner.
         """
-        case_open_time = self.utils.any_to_datetime(case_open_time).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('caseOpenTime', operator, case_open_time, TqlType.STRING)
+        if isinstance(perm_attribute_type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def case_open_user(self, operator: Enum, case_open_user: str):
-        """Filter Case Opening User based on **caseOpenUser** keyword.
+        self._tql.add_filter('permAttributeType', operator, perm_attribute_type, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            case_open_user: The user who opened the case.
-        """
-        self._tql.add_filter('caseOpenUser', operator, case_open_user, TqlType.STRING)
-
-    def created_by(self, operator: Enum, created_by: str):
-        """Filter Creator based on **createdBy** keyword.
+    def perm_case_tag(self, operator: Enum, perm_case_tag: list | str):
+        """Filter CaseTag Permission based on **permCaseTag** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            created_by: The account login of the user who created the case.
+            perm_case_tag: The User's CaseTag permission in the Owner.
         """
-        self._tql.add_filter('createdBy', operator, created_by, TqlType.STRING)
+        if isinstance(perm_case_tag, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permCaseTag', operator, perm_case_tag, TqlType.STRING)
 
-    def created_by_id(self, operator: Enum, created_by_id: int):
-        """Filter Creator ID based on **createdById** keyword.
+    def perm_comment(self, operator: Enum, perm_comment: list | str):
+        """Filter Comment Permission based on **permComment** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            created_by_id: The user ID for the creator of the case.
+            perm_comment: The User's Comment permission in the Owner.
         """
-        self._tql.add_filter('createdById', operator, created_by_id, TqlType.INTEGER)
+        if isinstance(perm_comment, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def date_added(self, operator: Enum, date_added: str):
-        """Filter Date Added based on **dateAdded** keyword.
+        self._tql.add_filter('permComment', operator, perm_comment, TqlType.STRING)
+
+    def perm_copy_data(self, operator: Enum, perm_copy_data: list | str):
+        """Filter CopyData Permission based on **permCopyData** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_added: The date the case was added to the system.
+            perm_copy_data: The User's CopyData permission in the Owner.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
+        if isinstance(perm_copy_data, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permCopyData', operator, perm_copy_data, TqlType.STRING)
 
-    def description(self, operator: Enum, description: str):
-        """Filter Description based on **description** keyword.
+    def perm_group(self, operator: Enum, perm_group: list | str):
+        """Filter Group Permission based on **permGroup** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the case.
+            perm_group: The User's Group permission in the Owner.
         """
-        self._tql.add_filter('description', operator, description, TqlType.STRING)
+        if isinstance(perm_group, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    @property
-    def has_artifact(self):
-        """Return **ArtifactFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
-
-        artifacts = ArtifactFilter(Tql())
-        self._tql.add_filter('hasArtifact', TqlOperator.EQ, artifacts, TqlType.SUB_QUERY)
-        return artifacts
-
-    @property
-    def has_case(self):
-        """Return **CaseFilter** for further filtering."""
-        cases = CaseFilter(Tql())
-        self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
-        return cases
-
-    @property
-    def has_group(self):
-        """Return **GroupFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.groups.group_filter import GroupFilter
-
-        groups = GroupFilter(Tql())
-        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
-        return groups
-
-    @property
-    def has_indicator(self):
-        """Return **IndicatorFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-
-        indicators = IndicatorFilter(Tql())
-        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
-        return indicators
-
-    @property
-    def has_note(self):
-        """Return **NoteFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.notes.note_filter import NoteFilter
-
-        notes = NoteFilter(Tql())
-        self._tql.add_filter('hasNote', TqlOperator.EQ, notes, TqlType.SUB_QUERY)
-        return notes
-
-    @property
-    def has_tag(self):
-        """Return **TagFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.tags.tag_filter import TagFilter
-
-        tags = TagFilter(Tql())
-        self._tql.add_filter('hasTag', TqlOperator.EQ, tags, TqlType.SUB_QUERY)
-        return tags
-
-    @property
-    def has_task(self):
-        """Return **TaskFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.tasks.task_filter import TaskFilter
+        self._tql.add_filter('permGroup', operator, perm_group, TqlType.STRING)
 
-        tasks = TaskFilter(Tql())
-        self._tql.add_filter('hasTask', TqlOperator.EQ, tasks, TqlType.SUB_QUERY)
-        return tasks
-
-    def has_workflow_template(self, operator: Enum, has_workflow_template: int):
-        """Filter Associated Workflow Template based on **hasWorkflowTemplate** keyword.
+    def perm_indicator(self, operator: Enum, perm_indicator: list | str):
+        """Filter Indicator Permission based on **permIndicator** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            has_workflow_template: A nested query for association to workflow templates.
+            perm_indicator: The User's Indicator permission in the Owner.
         """
-        self._tql.add_filter(
-            'hasWorkflowTemplate', operator, has_workflow_template, TqlType.INTEGER
-        )
+        if isinstance(perm_indicator, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+        self._tql.add_filter('permIndicator', operator, perm_indicator, TqlType.STRING)
+
+    def perm_invite(self, operator: Enum, perm_invite: list | str):
+        """Filter Invite Permission based on **permInvite** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the case.
+            perm_invite: The User's Invite permission in the Owner.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        if isinstance(perm_invite, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permInvite', operator, perm_invite, TqlType.STRING)
 
-    def id_as_string(self, operator: Enum, id_as_string: str):
-        """Filter ID As String based on **idAsString** keyword.
+    def perm_members(self, operator: Enum, perm_members: list | str):
+        """Filter Members Permission based on **permMembers** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id_as_string: The ID of the case as a String.
+            perm_members: The User's Members permission in the Owner.
         """
-        self._tql.add_filter('idAsString', operator, id_as_string, TqlType.STRING)
+        if isinstance(perm_members, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def last_updated(self, operator: Enum, last_updated: str):
-        """Filter Last Updated based on **lastUpdated** keyword.
+        self._tql.add_filter('permMembers', operator, perm_members, TqlType.STRING)
+
+    def perm_playbooks(self, operator: Enum, perm_playbooks: list | str):
+        """Filter Playbooks Permission based on **permPlaybooks** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_updated: The date the case was last updated in the system.
+            perm_playbooks: The User's Playbooks permission in the Owner.
         """
-        last_updated = self.utils.any_to_datetime(last_updated).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('lastUpdated', operator, last_updated, TqlType.STRING)
+        if isinstance(perm_playbooks, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permPlaybooks', operator, perm_playbooks, TqlType.STRING)
 
-    def missing_artifact_count(self, operator: Enum, missing_artifact_count: int):
-        """Filter Missing Artifact Count For Tasks based on **missingArtifactCount** keyword.
+    def perm_playbooks_execute(self, operator: Enum, perm_playbooks_execute: list | str):
+        """Filter PlaybooksExecute Permission based on **permPlaybooksExecute** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            missing_artifact_count: Missing Artifact Count for Case Tasks.
+            perm_playbooks_execute: The User's PlaybooksExecute permission in the Owner.
         """
+        if isinstance(perm_playbooks_execute, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter(
-            'missingArtifactCount', operator, missing_artifact_count, TqlType.INTEGER
+            'permPlaybooksExecute', operator, perm_playbooks_execute, TqlType.STRING
         )
 
-    def name(self, operator: Enum, name: str):
-        """Filter Name based on **name** keyword.
+    def perm_post(self, operator: Enum, perm_post: list | str):
+        """Filter Post Permission based on **permPost** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the case.
+            perm_post: The User's Post permission in the Owner.
         """
-        self._tql.add_filter('name', operator, name, TqlType.STRING)
+        if isinstance(perm_post, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def owner(self, operator: Enum, owner: int):
-        """Filter Owner ID based on **owner** keyword.
+        self._tql.add_filter('permPost', operator, perm_post, TqlType.STRING)
+
+    def perm_publish(self, operator: Enum, perm_publish: list | str):
+        """Filter Publish Permission based on **permPublish** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner: The Owner ID for the case.
+            perm_publish: The User's Publish permission in the Owner.
         """
-        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
+        if isinstance(perm_publish, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def owner_name(self, operator: Enum, owner_name: str):
-        """Filter Owner Name based on **ownerName** keyword.
+        self._tql.add_filter('permPublish', operator, perm_publish, TqlType.STRING)
+
+    def perm_security_label(self, operator: Enum, perm_security_label: list | str):
+        """Filter SecurityLabel Permission based on **permSecurityLabel** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name for the case.
+            perm_security_label: The User's SecurityLabel permission in the Owner.
         """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
+        if isinstance(perm_security_label, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permSecurityLabel', operator, perm_security_label, TqlType.STRING)
 
-    def resolution(self, operator: Enum, resolution: str):
-        """Filter Resolution based on **resolution** keyword.
+    def perm_settings(self, operator: Enum, perm_settings: list | str):
+        """Filter Settings Permission based on **permSettings** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            resolution: The resolution of the case.
+            perm_settings: The User's Settings permission in the Owner.
         """
-        self._tql.add_filter('resolution', operator, resolution, TqlType.STRING)
+        if isinstance(perm_settings, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def severity(self, operator: Enum, severity: str):
-        """Filter Severity based on **severity** keyword.
+        self._tql.add_filter('permSettings', operator, perm_settings, TqlType.STRING)
+
+    def perm_tag(self, operator: Enum, perm_tag: list | str):
+        """Filter Tag Permission based on **permTag** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            severity: The severity of the case.
+            perm_tag: The User's Tag permission in the Owner.
         """
-        self._tql.add_filter('severity', operator, severity, TqlType.STRING)
+        if isinstance(perm_tag, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permTag', operator, perm_tag, TqlType.STRING)
 
-    def status(self, operator: Enum, status: str):
-        """Filter Status based on **status** keyword.
+    def perm_task(self, operator: Enum, perm_task: list | str):
+        """Filter Task Permission based on **permTask** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            status: The status of the case.
+            perm_task: The User's Task permission in the Owner.
         """
-        self._tql.add_filter('status', operator, status, TqlType.STRING)
+        if isinstance(perm_task, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def tag(self, operator: Enum, tag: str):
-        """Filter Tag based on **tag** keyword.
+        self._tql.add_filter('permTask', operator, perm_task, TqlType.STRING)
+
+    def perm_timeline(self, operator: Enum, perm_timeline: list | str):
+        """Filter Timeline Permission based on **permTimeline** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag: The name of a tag applied to a case.
+            perm_timeline: The User's Timeline permission in the Owner.
         """
-        self._tql.add_filter('tag', operator, tag, TqlType.STRING)
+        if isinstance(perm_timeline, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permTimeline', operator, perm_timeline, TqlType.STRING)
 
-    def target_id(self, operator: Enum, target_id: int):
-        """Filter Assignee ID based on **targetId** keyword.
+    def perm_track(self, operator: Enum, perm_track: list | str):
+        """Filter Track Permission based on **permTrack** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            target_id: The assigned user or group ID for the case.
+            perm_track: The User's Track permission in the Owner.
         """
-        self._tql.add_filter('targetId', operator, target_id, TqlType.INTEGER)
+        if isinstance(perm_track, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permTrack', operator, perm_track, TqlType.STRING)
 
-    def target_type(self, operator: Enum, target_type: str):
-        """Filter Target Type based on **targetType** keyword.
+    def perm_users(self, operator: Enum, perm_users: list | str):
+        """Filter Users Permission based on **permUsers** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            target_type: The target type for this case (either User or Group).
+            perm_users: The User's Users permission in the Owner.
         """
-        self._tql.add_filter('targetType', operator, target_type, TqlType.STRING)
+        if isinstance(perm_users, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def threat_assess_score(self, operator: Enum, threat_assess_score: int):
-        """Filter ThreatAssessScore based on **threatAssessScore** keyword.
+        self._tql.add_filter('permUsers', operator, perm_users, TqlType.STRING)
+
+    def perm_victim(self, operator: Enum, perm_victim: list | str):
+        """Filter Victim Permission based on **permVictim** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            threat_assess_score: ThreatAssess score of the case.
+            perm_victim: The User's Victim permission in the Owner.
         """
-        self._tql.add_filter('threatAssessScore', operator, threat_assess_score, TqlType.INTEGER)
+        if isinstance(perm_victim, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('permVictim', operator, perm_victim, TqlType.STRING)
 
-    def type_name(self, operator: Enum, type_name: str):
-        """Filter Name based on **typeName** keyword.
+    def perm_workflow_template(self, operator: Enum, perm_workflow_template: list | str):
+        """Filter WorkflowTemplate Permission based on **permWorkflowTemplate** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type_name: The name of the case.
+            perm_workflow_template: The User's WorkflowTemplate permission in the Owner.
         """
-        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
+        if isinstance(perm_workflow_template, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def xid(self, operator: Enum, xid: str):
-        """Filter XID based on **xid** keyword.
+        self._tql.add_filter(
+            'permWorkflowTemplate', operator, perm_workflow_template, TqlType.STRING
+        )
+
+    def user_id(self, operator: Enum, user_id: int | list):
+        """Filter User ID based on **userId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            xid: The XID of the case.
+            user_id: The ID of the user.
         """
-        self._tql.add_filter('xid', operator, xid, TqlType.STRING)
+        if isinstance(user_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('userId', operator, user_id, TqlType.INTEGER)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/cases/case_model.py` & `tcex-4.0.0/tcex/api/tc/v3/cases/case_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,404 +1,404 @@
-"""Case / Cases Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class CasesModel(
-    BaseModel,
-    title='Cases Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Cases Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['CaseModel']] = Field(
-        [],
-        description='The data for the Cases.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class CaseDataModel(
-    BaseModel,
-    title='Case Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Cases Data Model"""
-
-    data: Optional[List['CaseModel']] = Field(
-        [],
-        description='The data for the Cases.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class CaseModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Case Model',
     validate_assignment=True,
 ):
     """Case Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    artifacts: Optional['ArtifactsModel'] = Field(
+    artifacts: 'ArtifactsModel' = Field(
         None,
         description='A list of Artifacts corresponding to the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='artifacts',
     )
-    assignee: Optional['AssigneeModel'] = Field(
+    assignee: 'AssigneeModel' = Field(
         None,
         description='The user or group Assignee object for the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='assignee',
     )
-    associated_cases: Optional['CasesModel'] = Field(
+    associated_cases: 'CasesModel' = Field(
         None,
         description='A list of Cases associated with this Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedCases',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of Groups associated with this Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    associated_indicators: Optional['IndicatorsModel'] = Field(
+    associated_indicators: 'IndicatorsModel' = Field(
         None,
         description='A list of Indicators associated with this Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedIndicators',
     )
-    attributes: Optional['CaseAttributesModel'] = Field(
+    attributes: 'CaseAttributesModel' = Field(
         None,
         description='A list of Attributes corresponding to the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='attributes',
     )
-    case_close_time: Optional[datetime] = Field(
+    case_close_time: datetime | None = Field(
         None,
         description='The date and time that the Case was closed.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='caseCloseTime',
     )
-    case_close_user: Optional['UserModel'] = Field(
+    case_close_user: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The user that closed the Case.',
         read_only=True,
         title='caseCloseUser',
     )
-    case_detection_time: Optional[datetime] = Field(
+    case_detection_time: datetime | None = Field(
         None,
         description='The date and time that ends the user initiated Case duration.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='caseDetectionTime',
     )
-    case_detection_user: Optional['UserModel'] = Field(
+    case_detection_user: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The user that stopped the clock on Case duration.',
         read_only=True,
         title='caseDetectionUser',
     )
-    case_occurrence_time: Optional[datetime] = Field(
+    case_occurrence_time: datetime | None = Field(
         None,
         description='The date and time that starts the user initiated Case duration.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='caseOccurrenceTime',
     )
-    case_occurrence_user: Optional['UserModel'] = Field(
+    case_occurrence_user: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The user that started the clock on Case duration.',
         read_only=True,
         title='caseOccurrenceUser',
     )
-    case_open_time: Optional[datetime] = Field(
+    case_open_time: datetime | None = Field(
         None,
         description='The date and time that the Case was first opened.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='caseOpenTime',
     )
-    case_open_user: Optional['UserModel'] = Field(
+    case_open_user: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The user that opened the Case.',
         read_only=True,
         title='caseOpenUser',
     )
-    created_by: Optional['UserModel'] = Field(
+    created_by: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The **created by** for the Case.',
         read_only=True,
         title='createdBy',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Case was first created.',
         read_only=True,
         title='dateAdded',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         description='The description of the Case.',
         methods=['POST', 'PUT'],
         max_length=1500,
         min_length=0,
         read_only=False,
         title='description',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    last_updated: Optional[datetime] = Field(
+    last_updated: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Case was last updated.',
         read_only=True,
         title='lastUpdated',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='The name of the Case.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='name',
     )
-    notes: Optional['NotesModel'] = Field(
+    notes: 'NotesModel' = Field(
         None,
         description='A list of Notes corresponding to the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='notes',
     )
-    owner: Optional[str] = Field(
+    owner: str | None = Field(
         None,
         allow_mutation=False,
         description='The name of the Owner of the Case.',
         read_only=True,
         title='owner',
     )
-    owner_id: Optional[int] = Field(
+    owner_id: int | None = Field(
         None,
         allow_mutation=False,
         description='The id of the Owner of the Case.',
         read_only=True,
         title='ownerId',
     )
-    related: Optional['CasesModel'] = Field(
+    related: 'CasesModel' = Field(
         None,
         allow_mutation=False,
         description='The **related** for the Case.',
         read_only=True,
         title='related',
     )
-    resolution: Optional[str] = Field(
+    resolution: str | None = Field(
         None,
         description='The Case resolution.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='resolution',
     )
-    severity: Optional[str] = Field(
+    severity: str | None = Field(
         None,
         description='The Case severity.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='severity',
     )
-    status: Optional[str] = Field(
+    status: str | None = Field(
         None,
         description='The Case status.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='status',
     )
-    tags: Optional['TagsModel'] = Field(
+    tags: 'TagsModel' = Field(
         None,
         description=(
             'A list of Tags corresponding to the Case (NOTE: Setting this parameter will replace '
             'any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='tags',
     )
-    tasks: Optional['TasksModel'] = Field(
+    tasks: 'TasksModel' = Field(
         None,
         description='A list of Tasks corresponding to the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='tasks',
     )
-    user_access: Optional['UsersModel'] = Field(
+    user_access: 'UsersModel' = Field(
         None,
         description=(
             'A list of Users that, when defined, are the only ones allowed to view or edit the '
             'Case.'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='userAccess',
     )
-    workflow_events: Optional['WorkflowEventsModel'] = Field(
+    workflow_events: 'WorkflowEventsModel' = Field(
         None,
         description='A list of workflowEvents (timeline) corresponding to the Case.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='workflowEvents',
     )
-    workflow_template: Optional['WorkflowTemplateModel'] = Field(
+    workflow_template: 'WorkflowTemplateModel' = Field(
         None,
         description='The Template that the Case is populated by.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='workflowTemplate',
     )
-    xid: Optional[str] = Field(
+    xid: str | None = Field(
         None,
         description='The **xid** for the Case.',
         methods=['POST'],
         max_length=100,
         min_length=10,
         read_only=False,
         title='xid',
     )
 
-    @validator('artifacts', always=True)
+    @validator('artifacts', always=True, pre=True)
     def _validate_artifacts(cls, v):
         if not v:
-            return ArtifactsModel()
+            return ArtifactsModel()  # type: ignore
         return v
 
-    @validator('assignee', always=True)
+    @validator('assignee', always=True, pre=True)
     def _validate_assignee(cls, v):
         if not v:
-            return AssigneeModel()
+            return AssigneeModel()  # type: ignore
         return v
 
-    @validator('attributes', always=True)
+    @validator('attributes', always=True, pre=True)
     def _validate_case_attributes(cls, v):
         if not v:
-            return CaseAttributesModel()
+            return CaseAttributesModel()  # type: ignore
         return v
 
-    @validator('associated_cases', 'related', always=True)
+    @validator('associated_cases', 'related', always=True, pre=True)
     def _validate_cases(cls, v):
         if not v:
-            return CasesModel()
+            return CasesModel()  # type: ignore
         return v
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
-    @validator('associated_indicators', always=True)
+    @validator('associated_indicators', always=True, pre=True)
     def _validate_indicators(cls, v):
         if not v:
-            return IndicatorsModel()
+            return IndicatorsModel()  # type: ignore
         return v
 
-    @validator('notes', always=True)
+    @validator('notes', always=True, pre=True)
     def _validate_notes(cls, v):
         if not v:
-            return NotesModel()
+            return NotesModel()  # type: ignore
         return v
 
-    @validator('tags', always=True)
+    @validator('tags', always=True, pre=True)
     def _validate_tags(cls, v):
         if not v:
-            return TagsModel()
+            return TagsModel()  # type: ignore
         return v
 
-    @validator('tasks', always=True)
+    @validator('tasks', always=True, pre=True)
     def _validate_tasks(cls, v):
         if not v:
-            return TasksModel()
+            return TasksModel()  # type: ignore
         return v
 
     @validator(
         'case_close_user',
         'case_detection_user',
         'case_occurrence_user',
         'case_open_user',
         'created_by',
         always=True,
+        pre=True,
     )
     def _validate_user(cls, v):
         if not v:
-            return UserModel()
+            return UserModel()  # type: ignore
         return v
 
-    @validator('user_access', always=True)
+    @validator('user_access', always=True, pre=True)
     def _validate_users(cls, v):
         if not v:
-            return UsersModel()
+            return UsersModel()  # type: ignore
         return v
 
-    @validator('workflow_events', always=True)
+    @validator('workflow_events', always=True, pre=True)
     def _validate_workflow_events(cls, v):
         if not v:
-            return WorkflowEventsModel()
+            return WorkflowEventsModel()  # type: ignore
         return v
 
-    @validator('workflow_template', always=True)
+    @validator('workflow_template', always=True, pre=True)
     def _validate_workflow_template(cls, v):
         if not v:
-            return WorkflowTemplateModel()
+            return WorkflowTemplateModel()  # type: ignore
         return v
 
 
+class CaseDataModel(
+    BaseModel,
+    title='Case Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Cases Data Model"""
+
+    data: list[CaseModel] | None = Field(
+        [],
+        description='The data for the Cases.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class CasesModel(
+    BaseModel,
+    title='Cases Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Cases Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[CaseModel] | None = Field(
+        [],
+        description='The data for the Cases.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactsModel
 from tcex.api.tc.v3.case_attributes.case_attribute_model import CaseAttributesModel
 from tcex.api.tc.v3.groups.group_model import GroupsModel
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorsModel
 from tcex.api.tc.v3.notes.note_model import NotesModel
 from tcex.api.tc.v3.security.assignee_model import AssigneeModel
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/file_actions/file_action_model.py` & `tcex-4.0.0/tcex/api/tc/v3/file_actions/file_action_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,50 +1,21 @@
-"""File Actions Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class FileActionsModel(
-    BaseModel,
-    title='File Actions Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """File Actions Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    count: Optional[int] = Field(None, description='The number of file actions.')
-
-    data: Optional[List['FileActionModel']] = Field(
-        [],
-        description='The data for the File Actions.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
+from tcex.util import Util
 
 
 class FileActionModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='File Action Model',
     validate_assignment=True,
 ):
     """File Action Model"""
 
     relationship: str = Field(
@@ -59,12 +30,39 @@
         description='The **indicator** related to the FileAction.',
         methods=['POST', 'PUT'],
         title='indicator',
         read_only=False,
     )
 
 
+class FileActionsModel(
+    BaseModel,
+    title='File Actions Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """File Actions Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    count: int | None = Field(None, description='The number of file actions.')
+
+    data: list[FileActionModel] | None = Field(
+        [],
+        description='The data for the File Actions.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
-from tcex.api.tc.v3.indicators.indicator import IndicatorModel  # pylint: disable=unused-import
+from tcex.api.tc.v3.indicators.indicator import IndicatorModel
 
 FileActionModel.update_forward_refs()
 FileActionsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/file_occurrences/file_occurrence_model.py` & `tcex-4.0.0/tcex/api/tc/v3/file_occurrences/file_occurrence_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,71 +1,70 @@
-"""File Occurrences Model"""
+"""TcEx Framework Module"""
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class FileOccurrencesModel(
-    BaseModel,
-    title='File Occurrences Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """File Occurrences Data Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    count: Optional[int] = Field(None, description='The number of occurrences.')
-
-    data: Optional[List['FileOccurrenceModel']] = Field(
-        [],
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
+from tcex.util import Util
 
 
 class FileOccurrenceModel(
     V3ModelABC,
     title='File Occurrence Model',
     extra=Extra.allow,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """File Occurrences Model"""
 
-    date: Optional[datetime] = Field(
+    date: datetime | None = Field(
         None,
         methods=['POST', 'PUT'],
         title='date',
     )
-    file_name: Optional[str] = Field(
+    file_name: str | None = Field(
         None,
         methods=['POST', 'PUT'],
         title='fileName',
     )
-    path: Optional[str] = Field(
+    path: str | None = Field(
         None,
         methods=['POST', 'PUT'],
         title='path',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         title='id',
     )
 
 
+class FileOccurrencesModel(
+    BaseModel,
+    title='File Occurrences Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """File Occurrences Data Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    count: int | None = Field(None, description='The number of occurrences.')
+
+    data: list[FileOccurrenceModel] | None = Field(
+        [],
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 FileOccurrenceModel.update_forward_refs()
 FileOccurrencesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/filter_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/filter_abc.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,46 +1,57 @@
-"""Case Management Filter Abstract Base Class"""
+"""TcEx Framework Module"""
 # standard library
 from abc import ABC
-from typing import TYPE_CHECKING, List
+from typing import TYPE_CHECKING
 
 # first-party
-from tcex.utils.utils import Utils
+from tcex.api.tc.v3.tql.tql_operator import TqlOperator
+from tcex.util.util import Util
 
 if TYPE_CHECKING:
     # first-party
-    from tcex.api.tc.v3.tql.tql import Tql
+    from tcex.api.tc.v3.tql.tql import Tql  # CIRCULAR-IMPORT
 
 
 class FilterABC(ABC):
     """Case Management Filter Abstract Base Class"""
 
     def __init__(self, tql: 'Tql'):
-        """Initialize Class properties"""
+        """Initialize instance properties"""
         self._tql = tql
 
         # properties
-        self.utils = Utils()
+        self.util = Util()
 
     @property
     def _api_endpoint(self):
         raise NotImplementedError('Child class must implement this method.')
 
     @property
-    def implemented_keywords(self) -> List[str]:
+    def implemented_keywords(self) -> list[str]:
         """Return implemented TQL keywords."""
         keywords = []
         for prop in dir(self):
             if prop.startswith('_') or prop in ['tql']:
                 continue
             keywords.append(prop)
 
         return keywords
 
     @property
+    def list_types(self) -> list[TqlOperator]:
+        """Return list of implemented TQL keywords that are list types."""
+        return [
+            TqlOperator.IN,
+            TqlOperator.NOT_IN,
+            TqlOperator.CONTAINS,
+            TqlOperator.NOT_CONTAINS,
+        ]
+
+    @property
     def tql(self) -> 'Tql':
         """Return the current TQL instance."""
         return self._tql
 
     @tql.setter
     def tql(self, tql: str):
         """Filter objects based on TQL expression.
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute.py` & `tcex-4.0.0/tcex/api/tc/v3/group_attributes/group_attribute.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,127 +1,127 @@
-"""GroupAttribute / GroupAttributes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.group_attributes.group_attribute_filter import GroupAttributeFilter
 from tcex.api.tc.v3.group_attributes.group_attribute_model import (
     GroupAttributeModel,
     GroupAttributesModel,
 )
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-
-
-class GroupAttributes(ObjectCollectionABC):
-    """GroupAttributes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = GroupAttributesModel(**kwargs)
-        self.type_ = 'group_attributes'
-
-    def __iter__(self) -> 'GroupAttribute':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=GroupAttribute)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.GROUP_ATTRIBUTES.value
-
-    @property
-    def filter(self) -> 'GroupAttributeFilter':
-        """Return the type specific filter object."""
-        return GroupAttributeFilter(self.tql)
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
 
 
 class GroupAttribute(ObjectABC):
     """GroupAttributes Object.
 
     Args:
         default (bool, kwargs): A flag indicating that this is the default attribute of its type
             within the object. Only applies to certain attribute and data types.
-        group (Group, kwargs): Details of group associated with attribute.
         group_id (int, kwargs): Group associated with attribute.
         pinned (bool, kwargs): A flag indicating that the attribute has been noted for importance.
         security_labels (SecurityLabels, kwargs): A list of Security Labels corresponding to the
             Intel item (NOTE: Setting this parameter will replace any existing tag(s) with
             the one(s) specified).
         source (str, kwargs): The attribute source.
         type (str, kwargs): The attribute type.
         value (str, kwargs): The attribute value.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = GroupAttributeModel(**kwargs)
+        self._model: GroupAttributeModel = GroupAttributeModel(**kwargs)
         self._nested_field_name = 'attributes'
         self._nested_filter = 'has_group_attribute'
         self.type_ = 'Group Attribute'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.GROUP_ATTRIBUTES.value
 
     @property
-    def model(self) -> 'GroupAttributeModel':
+    def model(self) -> GroupAttributeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['GroupAttributeModel', dict]):
+    def model(self, data: dict | GroupAttributeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
+
+
+class GroupAttributes(ObjectCollectionABC):
+    """GroupAttributes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = GroupAttributesModel(**kwargs)
+        self.type_ = 'group_attributes'
+
+    def __iter__(self) -> Iterator[GroupAttribute]:
+        """Return CM objects."""
+        return self.iterate(base_class=GroupAttribute)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.GROUP_ATTRIBUTES.value
+
+    @property
+    def filter(self) -> GroupAttributeFilter:
+        """Return the type specific filter object."""
+        return GroupAttributeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/group_attributes/group_attribute_filter.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,11 +1,15 @@
-"""Group_Attribute TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql import Tql
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
@@ -23,50 +27,56 @@
 
         Args:
             operator: The operator enum for the filter.
             associable: A flag to include an attribute in group associations.
         """
         self._tql.add_filter('associable', operator, associable, TqlType.BOOLEAN)
 
-    def date_added(self, operator: Enum, date_added: str):
+    def date_added(self, operator: Enum, date_added: Arrow | datetime | int | str):
         """Filter Date Added based on **dateAdded** keyword.
 
         Args:
             operator: The operator enum for the filter.
             date_added: The date the attribute was added to the system.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
         self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
 
-    def date_val(self, operator: Enum, date_val: str):
+    def date_val(self, operator: Enum, date_val: Arrow | datetime | int | str):
         """Filter Date based on **dateVal** keyword.
 
         Args:
             operator: The operator enum for the filter.
             date_val: The date value of the attribute (only applies to certain types).
         """
-        date_val = self.utils.any_to_datetime(date_val).strftime('%Y-%m-%d %H:%M:%S')
+        date_val = self.util.any_to_datetime(date_val).strftime('%Y-%m-%d %H:%M:%S')
         self._tql.add_filter('dateVal', operator, date_val, TqlType.STRING)
 
     def displayed(self, operator: Enum, displayed: bool):
         """Filter Displayed based on **displayed** keyword.
 
         Args:
             operator: The operator enum for the filter.
             displayed: Whether or not the attribute is displayed on the item.
         """
         self._tql.add_filter('displayed', operator, displayed, TqlType.BOOLEAN)
 
-    def group_id(self, operator: Enum, group_id: int):
+    def group_id(self, operator: Enum, group_id: int | list):
         """Filter Group ID based on **groupId** keyword.
 
         Args:
             operator: The operator enum for the filter.
             group_id: The ID of the group the group attribute is applied to.
         """
+        if isinstance(group_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('groupId', operator, group_id, TqlType.INTEGER)
 
     @property
     def has_group(self):
         """Return **GroupFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.groups.group_filter import GroupFilter
@@ -81,115 +91,175 @@
         # first-party
         from tcex.api.tc.v3.security_labels.security_label_filter import SecurityLabelFilter
 
         security_labels = SecurityLabelFilter(Tql())
         self._tql.add_filter('hasSecurityLabel', TqlOperator.EQ, security_labels, TqlType.SUB_QUERY)
         return security_labels
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
             id: The ID of the attribute.
         """
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def int_val(self, operator: Enum, int_val: int):
+    def int_val(self, operator: Enum, int_val: int | list):
         """Filter Integer Value based on **intVal** keyword.
 
         Args:
             operator: The operator enum for the filter.
             int_val: The integer value of the attribute (only applies to certain types).
         """
+        if isinstance(int_val, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('intVal', operator, int_val, TqlType.INTEGER)
 
-    def last_modified(self, operator: Enum, last_modified: str):
+    def last_modified(self, operator: Enum, last_modified: Arrow | datetime | int | str):
         """Filter Last Modified based on **lastModified** keyword.
 
         Args:
             operator: The operator enum for the filter.
             last_modified: The date the attribute was last modified in the system.
         """
-        last_modified = self.utils.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
+        last_modified = self.util.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
         self._tql.add_filter('lastModified', operator, last_modified, TqlType.STRING)
 
-    def max_size(self, operator: Enum, max_size: int):
+    def max_size(self, operator: Enum, max_size: int | list):
         """Filter Max Size based on **maxSize** keyword.
 
         Args:
             operator: The operator enum for the filter.
             max_size: The max length of the attribute text.
         """
+        if isinstance(max_size, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('maxSize', operator, max_size, TqlType.INTEGER)
 
-    def owner(self, operator: Enum, owner: int):
+    def owner(self, operator: Enum, owner: int | list):
         """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
             owner: The owner ID of the attribute.
         """
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-    def owner_name(self, operator: Enum, owner_name: str):
+    def owner_name(self, operator: Enum, owner_name: list | str):
         """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
             owner_name: The owner name of the attribute.
         """
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
     def pinned(self, operator: Enum, pinned: bool):
         """Filter Pinned based on **pinned** keyword.
 
         Args:
             operator: The operator enum for the filter.
             pinned: Whether or not the attribute is pinned with importance.
         """
         self._tql.add_filter('pinned', operator, pinned, TqlType.BOOLEAN)
 
-    def source(self, operator: Enum, source: str):
+    def source(self, operator: Enum, source: list | str):
         """Filter Source based on **source** keyword.
 
         Args:
             operator: The operator enum for the filter.
             source: The source text of the attribute.
         """
+        if isinstance(source, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('source', operator, source, TqlType.STRING)
 
-    def text(self, operator: Enum, text: str):
+    def text(self, operator: Enum, text: list | str):
         """Filter Text based on **text** keyword.
 
         Args:
             operator: The operator enum for the filter.
             text: The text of the attribute (only applies to certain types).
         """
+        if isinstance(text, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('text', operator, text, TqlType.STRING)
 
-    def type(self, operator: Enum, type: int):  # pylint: disable=redefined-builtin
+    def type(self, operator: Enum, type: int | list):  # pylint: disable=redefined-builtin
         """Filter Type ID based on **type** keyword.
 
         Args:
             operator: The operator enum for the filter.
             type: The ID of the attribute type.
         """
+        if isinstance(type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('type', operator, type, TqlType.INTEGER)
 
-    def type_name(self, operator: Enum, type_name: str):
+    def type_name(self, operator: Enum, type_name: list | str):
         """Filter Type Name based on **typeName** keyword.
 
         Args:
             operator: The operator enum for the filter.
             type_name: The name of the attribute type.
         """
+        if isinstance(type_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
 
-    def user(self, operator: Enum, user: str):
+    def user(self, operator: Enum, user: list | str):
         """Filter User based on **user** keyword.
 
         Args:
             operator: The operator enum for the filter.
             user: The user who created the attribute.
         """
+        if isinstance(user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('user', operator, user, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/group_attributes/group_attribute_model.py` & `tcex-4.0.0/tcex/api/tc/v3/notes/note_model.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,187 +1,225 @@
-"""Group_Attribute / Group_Attributes Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
-class GroupAttributesModel(
-    BaseModel,
-    title='GroupAttributes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Group_Attributes Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['GroupAttributeModel']] = Field(
-        [],
-        description='The data for the GroupAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class GroupAttributeDataModel(
-    BaseModel,
-    title='GroupAttribute Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Group_Attributes Data Model"""
-
-    data: Optional[List['GroupAttributeModel']] = Field(
-        [],
-        description='The data for the GroupAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-
-class GroupAttributeModel(
+class NoteModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
-    title='GroupAttribute Model',
+    title='Note Model',
     validate_assignment=True,
 ):
-    """Group_Attribute Model"""
+    """Note Model"""
 
     _associated_type = PrivateAttr(False)
-    _cm_type = PrivateAttr(False)
+    _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    created_by: Optional['UserModel'] = Field(
+    artifact: 'ArtifactModel' = Field(
         None,
         allow_mutation=False,
-        description='The **created by** for the Group_Attribute.',
+        description='The **artifact** for the Note.',
         read_only=True,
-        title='createdBy',
+        title='artifact',
+    )
+    artifact_id: int | None = Field(
+        None,
+        description='The ID of the Artifact on which to apply the Note.',
+        methods=['POST'],
+        read_only=False,
+        title='artifactId',
     )
-    date_added: Optional[datetime] = Field(
+    author: str | None = Field(
         None,
         allow_mutation=False,
-        description='The date and time that the item was first created.',
+        description='The **author** for the Note.',
         read_only=True,
-        title='dateAdded',
+        title='author',
     )
-    default: bool = Field(
+    case_id: int | None = Field(
         None,
-        description=(
-            'A flag indicating that this is the default attribute of its type within the object. '
-            'Only applies to certain attribute and data types.'
-        ),
-        methods=['POST', 'PUT'],
+        description='The **case id** for the Note.',
+        methods=['POST'],
         read_only=False,
-        title='default',
+        required_alt_field='caseXid',
+        title='caseId',
     )
-    group: Optional['GroupModel'] = Field(
+    case_xid: str | None = Field(
         None,
-        description='Details of group associated with attribute.',
+        description='The **case xid** for the Note.',
         methods=['POST'],
         read_only=False,
-        title='group',
+        required_alt_field='caseId',
+        title='caseXid',
     )
-    group_id: Optional[int] = Field(
+    date_added: datetime | None = Field(
         None,
-        description='Group associated with attribute.',
-        methods=['POST'],
-        read_only=False,
-        title='groupId',
+        allow_mutation=False,
+        description='The **date added** for the Note.',
+        read_only=True,
+        title='dateAdded',
+    )
+    edited: bool = Field(
+        None,
+        allow_mutation=False,
+        description='The **edited** for the Note.',
+        read_only=True,
+        title='edited',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
-        description='The date and time that the Attribute was last modified.',
+        description='The **last modified** for the Note.',
         read_only=True,
         title='lastModified',
     )
-    pinned: bool = Field(
+    parent_case: 'CaseModel' = Field(
         None,
-        description='A flag indicating that the attribute has been noted for importance.',
-        methods=['POST', 'PUT'],
-        read_only=False,
-        title='pinned',
+        allow_mutation=False,
+        description='The **parent case** for the Note.',
+        read_only=True,
+        title='parentCase',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    summary: str | None = Field(
         None,
-        description=(
-            'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
-            'parameter will replace any existing tag(s) with the one(s) specified).'
-        ),
-        methods=['POST', 'PUT'],
-        read_only=False,
-        title='securityLabels',
+        allow_mutation=False,
+        description='The **summary** for the Note.',
+        read_only=True,
+        title='summary',
     )
-    source: Optional[str] = Field(
+    task: 'TaskModel' = Field(
         None,
-        description='The attribute source.',
-        methods=['POST', 'PUT'],
+        allow_mutation=False,
+        description='The **task** for the Note.',
+        read_only=True,
+        title='task',
+    )
+    task_id: int | None = Field(
+        None,
+        description='The ID of the Task on which to apply the Note.',
+        methods=['POST'],
         read_only=False,
-        title='source',
+        title='taskId',
     )
-    type: Optional[str] = Field(
+    task_xid: str | None = Field(
         None,
-        description='The attribute type.',
+        description='The XID of the Task on which to apply the Note.',
         methods=['POST'],
         read_only=False,
-        title='type',
+        title='taskXid',
     )
-    value: Optional[str] = Field(
+    text: str | None = Field(
         None,
-        description='The attribute value.',
+        description='The **text** for the Note.',
         methods=['POST', 'PUT'],
+        max_length=65500,
         min_length=1,
         read_only=False,
-        title='value',
+        title='text',
+    )
+    workflow_event: 'WorkflowEventModel' = Field(
+        None,
+        allow_mutation=False,
+        description='The **workflow event** for the Note.',
+        read_only=True,
+        title='workflowEvent',
+    )
+    workflow_event_id: int | None = Field(
+        None,
+        description='The ID of the Event on which to apply the Note.',
+        methods=['POST'],
+        read_only=False,
+        title='workflowEventId',
     )
 
-    @validator('group', always=True)
-    def _validate_group(cls, v):
+    @validator('artifact', always=True, pre=True)
+    def _validate_artifact(cls, v):
+        if not v:
+            return ArtifactModel()  # type: ignore
+        return v
+
+    @validator('parent_case', always=True, pre=True)
+    def _validate_case(cls, v):
         if not v:
-            return GroupModel()
+            return CaseModel()  # type: ignore
         return v
 
-    @validator('security_labels', always=True)
-    def _validate_security_labels(cls, v):
+    @validator('task', always=True, pre=True)
+    def _validate_task(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return TaskModel()  # type: ignore
         return v
 
-    @validator('created_by', always=True)
-    def _validate_user(cls, v):
+    @validator('workflow_event', always=True, pre=True)
+    def _validate_workflow_event(cls, v):
         if not v:
-            return UserModel()
+            return WorkflowEventModel()  # type: ignore
         return v
 
 
+class NoteDataModel(
+    BaseModel,
+    title='Note Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Notes Data Model"""
+
+    data: list[NoteModel] | None = Field(
+        [],
+        description='The data for the Notes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class NotesModel(
+    BaseModel,
+    title='Notes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Notes Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[NoteModel] | None = Field(
+        [],
+        description='The data for the Notes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
-from tcex.api.tc.v3.groups.group_model import GroupModel
-from tcex.api.tc.v3.security.users.user_model import UserModel
-from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelsModel
+from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
+from tcex.api.tc.v3.cases.case_model import CaseModel
+from tcex.api.tc.v3.tasks.task_model import TaskModel
+from tcex.api.tc.v3.workflow_events.workflow_event_model import WorkflowEventModel
 
 # add forward references
-GroupAttributeDataModel.update_forward_refs()
-GroupAttributeModel.update_forward_refs()
-GroupAttributesModel.update_forward_refs()
+NoteDataModel.update_forward_refs()
+NoteModel.update_forward_refs()
+NotesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/groups/group.py` & `tcex-4.0.0/tcex/api/tc/v3/indicators/indicator.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,148 +1,112 @@
-"""Group / Groups Object"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import TYPE_CHECKING, Iterator, Optional, Union
+from collections.abc import Generator, Iterator
+from datetime import datetime
+from typing import TYPE_CHECKING, Self
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
 from tcex.api.tc.v3.cases.case_model import CaseModel
-from tcex.api.tc.v3.group_attributes.group_attribute_model import GroupAttributeModel
-from tcex.api.tc.v3.groups.group_filter import GroupFilter
-from tcex.api.tc.v3.groups.group_model import GroupModel, GroupsModel
-from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel
+from tcex.api.tc.v3.file_actions.file_action_model import FileActionModel
+from tcex.api.tc.v3.file_occurrences.file_occurrence_model import FileOccurrenceModel
+from tcex.api.tc.v3.groups.group_model import GroupModel
+from tcex.api.tc.v3.indicator_attributes.indicator_attribute_model import IndicatorAttributeModel
+from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
+from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel, IndicatorsModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 from tcex.api.tc.v3.tags.tag_model import TagModel
-from tcex.api.tc.v3.victim_assets.victim_asset_model import VictimAssetModel
 
 if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from requests import Response
-
     # first-party
-    from tcex.api.tc.v3.artifacts.artifact import Artifact
-    from tcex.api.tc.v3.cases.case import Case
-    from tcex.api.tc.v3.group_attributes.group_attribute import GroupAttribute
-    from tcex.api.tc.v3.indicators.indicator import Indicator
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-    from tcex.api.tc.v3.tags.tag import Tag
-    from tcex.api.tc.v3.victim_assets.victim_asset import VictimAsset
-
-
-class Groups(ObjectCollectionABC):
-    """Groups Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = GroupsModel(**kwargs)
-        self.type_ = 'groups'
-
-    def __iter__(self) -> 'Group':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Group)
+    from tcex.api.tc.v3.artifacts.artifact import Artifact  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.cases.case import Case  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.groups.group import Group  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.indicator_attributes.indicator_attribute import (  # CIRCULAR-IMPORT
+        IndicatorAttribute,
+    )
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.tags.tag import Tag  # CIRCULAR-IMPORT
 
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.GROUPS.value
-
-    @property
-    def filter(self) -> 'GroupFilter':
-        """Return the type specific filter object."""
-        return GroupFilter(self.tql)
 
-
-class Group(ObjectABC):
-    """Groups Object.
+class Indicator(ObjectABC):
+    """Indicators Object.
 
     Args:
-        assignments (TaskAssignees, kwargs): A list of assignees and escalatees associated with this
-            group (Task specific).
-        associated_artifacts (Artifacts, kwargs): A list of Artifacts associated with this Group.
-        associated_cases (Cases, kwargs): A list of Cases associated with this Group.
-        associated_groups (Groups, kwargs): A list of groups associated with this group.
-        associated_indicators (Indicators, kwargs): A list of indicators associated with this group.
-        associated_victim_assets (VictimAssets, kwargs): A list of victim assets associated with
-            this group.
-        attributes (GroupAttributes, kwargs): A list of Attributes corresponding to the Group.
-        body (str, kwargs): The email Body.
-        due_date (str, kwargs): The date and time that the Task is due.
-        escalation_date (str, kwargs): The escalation date and time.
-        event_date (str, kwargs): The date and time that the incident or event was first created.
-        file_name (str, kwargs): The document or signature file name.
-        file_text (str, kwargs): The signature file text.
-        file_type (str, kwargs): The signature file type.
-        first_seen (str, kwargs): The date and time that the campaign was first created.
-        from_ (str, kwargs): The email From field.
-        header (str, kwargs): The email Header field.
-        malware (bool, kwargs): Is the document malware?
-        name (str, kwargs): The name of the group.
+        active (bool, kwargs): Is the indicator active?
+        active_locked (bool, kwargs): Lock the indicator active value?
+        address (str, kwargs): The email address associated with this indicator (EmailAddress
+            specific summary field).
+        associated_artifacts (Artifacts, kwargs): A list of Artifacts associated with this
+            Indicator.
+        associated_cases (Cases, kwargs): A list of Cases associated with this Indicator.
+        associated_groups (Groups, kwargs): A list of groups that this indicator is associated with.
+        associated_indicators (Indicators, kwargs): A list of indicators associated with this
+            indicator.
+        attributes (IndicatorAttributes, kwargs): A list of Attributes corresponding to the
+            Indicator.
+        confidence (int, kwargs): The indicator threat confidence.
+        dns_active (bool, kwargs): Is dns active for the indicator?
+        file_actions (FileActions, kwargs): The type of file action associated with this indicator.
+        file_occurrences (FileOccurrences, kwargs): A list of file occurrences associated with this
+            indicator.
+        host_name (str, kwargs): The host name of the indicator (Host specific summary field).
+        ip (str, kwargs): The ip address associated with this indicator (Address specific summary
+            field).
+        md5 (str, kwargs): The md5 associated with this indicator (File specific summary field).
+        mode (str, kwargs): The operation to perform on the file hashes (delete | merge).
         owner_id (int, kwargs): The id of the Organization, Community, or Source that the item
             belongs to.
         owner_name (str, kwargs): The name of the Organization, Community, or Source that the item
             belongs to.
-        password (str, kwargs): The password associated with the document (Required if Malware is
-            true).
-        publish_date (str, kwargs): The date and time that the report was first created.
-        reminder_date (str, kwargs): The reminder date and time.
+        private_flag (bool, kwargs): Is this indicator private?
+        rating (int, kwargs): The indicator threat rating.
         security_labels (SecurityLabels, kwargs): A list of Security Labels corresponding to the
             Intel item (NOTE: Setting this parameter will replace any existing tag(s) with
             the one(s) specified).
-        status (str, kwargs): The status associated with this document, event, task, or incident
-            (read only for task, document, and report).
-        subject (str, kwargs): The email Subject section.
+        sha1 (str, kwargs): The sha1 associated with this indicator (File specific summary field).
+        sha256 (str, kwargs): The sha256 associated with this indicator (File specific summary
+            field).
+        size (int, kwargs): The size of the file.
         tags (Tags, kwargs): A list of Tags corresponding to the item (NOTE: Setting this parameter
             will replace any existing tag(s) with the one(s) specified).
-        type (str, kwargs): The **type** for the Group.
-        up_vote (bool, kwargs): Is the intelligence valid and useful? (0 means downvote, 1 means
-            upvote, and NULL means no vote).
-        xid (str, kwargs): The xid of the item.
+        text (str, kwargs): The url text value of the indicator (Url specific summary field).
+        type (str, kwargs): The **type** for the Indicator.
+        value1 (str, kwargs): Custom Indicator summary field value1.
+        value2 (str, kwargs): Custom Indicator summary field value2.
+        value3 (str, kwargs): Custom Indicator summary field value3.
+        whois_active (bool, kwargs): Is whois active for the indicator?
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = GroupModel(**kwargs)
-        self._nested_field_name = 'associatedGroups'
-        self._nested_filter = 'has_group'
-        self.type_ = 'Group'
+        self._model: IndicatorModel = IndicatorModel(**kwargs)
+        self._nested_field_name = 'associatedIndicators'
+        self._nested_filter = 'has_indicator'
+        self.type_ = 'Indicator'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
-        return ApiEndpoints.GROUPS.value
+        return ApiEndpoints.INDICATORS.value
 
     @property
-    def model(self) -> 'GroupModel':
+    def model(self) -> IndicatorModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['GroupModel', dict]):
+    def model(self, data: dict | IndicatorModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -150,17 +114,17 @@
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.model.type
 
-        return {'type': type_, 'id': self.model.id, 'value': self.model.name}
+        return {'type': type_, 'id': self.model.id, 'value': self.model.summary}
 
-    def remove(self, params: Optional[dict] = None):
+    def remove(self, params: dict | None = None):
         """Remove a nested object."""
         method = 'PUT'
         unique_id = self._calculate_unique_id()
 
         # validate an id is available
         self._validate_id(unique_id.get('value'), '')
 
@@ -187,200 +151,222 @@
             body=body,
             headers={'content-type': 'application/json'},
             params=params,
         )
 
         return self.request
 
-    def download(self, params: Optional[dict] = None) -> bytes:
-        """Return the document attachment for Document/Report Types."""
-        self._request(
-            method='GET',
-            url=f'''{self.url('GET')}/download''',
-            headers={'Accept': 'application/octet-stream'},
-            params=params,
-        )
-        return self.request.content
-
-    def pdf(self, params: Optional[dict] = None) -> bytes:
-        """Return the document attachment for Document/Report Types."""
-        self._request(
-            method='GET',
-            body=None,
-            url=f'''{self.url('GET')}/pdf''',
-            headers={'Accept': 'application/octet-stream'},
-            params=params,
-        )
-
-        return self.request.content
-
-    def upload(self, content: Union[bytes, str], params: Optional[dict] = None) -> 'Response':
-        """Return the document attachment for Document/Report Types."""
-        self._request(
-            method='POST',
-            url=f'''{self.url('GET')}/upload''',
-            body=content,
-            headers={'content-type': 'application/octet-stream'},
-            params=params,
-        )
-        return self.request
-
     @property
-    def associated_artifacts(self) -> Iterator['Artifact']:
+    def associated_artifacts(self) -> Generator['Artifact', None, None]:
         """Yield Artifact from Artifacts."""
         # first-party
         from tcex.api.tc.v3.artifacts.artifact import Artifacts
 
-        yield from self._iterate_over_sublist(Artifacts)
+        yield from self._iterate_over_sublist(Artifacts)  # type: ignore
 
     @property
-    def associated_cases(self) -> Iterator['Case']:
+    def associated_cases(self) -> Generator['Case', None, None]:
         """Yield Case from Cases."""
         # first-party
         from tcex.api.tc.v3.cases.case import Cases
 
-        yield from self._iterate_over_sublist(Cases)
+        yield from self._iterate_over_sublist(Cases)  # type: ignore
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator['Group', None, None]:
         """Yield Group from Groups."""
-        # Ensure the current item is not returned as a association
-        for group in self._iterate_over_sublist(Groups):
-            if group.model.id == self.model.id:
-                continue
-            yield group
-
-    @property
-    def associated_indicators(self) -> Iterator['Indicator']:
-        """Yield Indicator from Indicators."""
         # first-party
-        from tcex.api.tc.v3.indicators.indicator import Indicators
+        from tcex.api.tc.v3.groups.group import Groups
 
-        yield from self._iterate_over_sublist(Indicators)
+        yield from self._iterate_over_sublist(Groups)  # type: ignore
 
     @property
-    def associated_victim_assets(self) -> Iterator['VictimAsset']:
-        """Yield VictimAsset from VictimAssets."""
-        # first-party
-        from tcex.api.tc.v3.victim_assets.victim_asset import VictimAssets
-
-        yield from self._iterate_over_sublist(VictimAssets)
+    def associated_indicators(self) -> Generator[Self, None, None]:
+        """Yield Indicator from Indicators."""
+        # Ensure the current item is not returned as a association
+        for indicator in self._iterate_over_sublist(Indicators):  # type: ignore
+            if indicator.model.id == self.model.id:
+                continue
+            yield indicator  # type: ignore
 
     @property
-    def attributes(self) -> Iterator['GroupAttribute']:
+    def attributes(self) -> Generator['IndicatorAttribute', None, None]:
         """Yield Attribute from Attributes."""
         # first-party
-        from tcex.api.tc.v3.group_attributes.group_attribute import GroupAttributes
+        from tcex.api.tc.v3.indicator_attributes.indicator_attribute import IndicatorAttributes
 
-        yield from self._iterate_over_sublist(GroupAttributes)
+        yield from self._iterate_over_sublist(IndicatorAttributes)  # type: ignore
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
     @property
-    def tags(self) -> Iterator['Tag']:
+    def tags(self) -> Generator['Tag', None, None]:
         """Yield Tag from Tags."""
         # first-party
         from tcex.api.tc.v3.tags.tag import Tags
 
-        yield from self._iterate_over_sublist(Tags)
+        yield from self._iterate_over_sublist(Tags)  # type: ignore
 
-    def stage_associated_case(self, data: Union[dict, 'ObjectABC', 'CaseModel']):
+    def stage_associated_case(self, data: dict | ObjectABC | CaseModel):
         """Stage case on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = CaseModel(**data)
 
         if not isinstance(data, CaseModel):
             raise RuntimeError('Invalid type passed in to stage_associated_case')
         data._staged = True
-        self.model.associated_cases.data.append(data)
+        self.model.associated_cases.data.append(data)  # type: ignore
 
-    def stage_associated_artifact(self, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
+    def stage_associated_artifact(self, data: dict | ObjectABC | ArtifactModel):
         """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = ArtifactModel(**data)
 
         if not isinstance(data, ArtifactModel):
             raise RuntimeError('Invalid type passed in to stage_associated_artifact')
         data._staged = True
-        self.model.associated_artifacts.data.append(data)
+        self.model.associated_artifacts.data.append(data)  # type: ignore
 
-    def stage_associated_group(self, data: Union[dict, 'ObjectABC', 'GroupModel']):
+    def stage_associated_group(self, data: dict | ObjectABC | GroupModel):
         """Stage group on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = GroupModel(**data)
 
         if not isinstance(data, GroupModel):
             raise RuntimeError('Invalid type passed in to stage_associated_group')
         data._staged = True
-        self.model.associated_groups.data.append(data)
+        self.model.associated_groups.data.append(data)  # type: ignore
 
-    def stage_associated_victim_asset(self, data: Union[dict, 'ObjectABC', 'VictimAssetModel']):
-        """Stage victim_asset on the object."""
+    def stage_attribute(self, data: dict | ObjectABC | IndicatorAttributeModel):
+        """Stage attribute on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = VictimAssetModel(**data)
+            data = IndicatorAttributeModel(**data)
 
-        if not isinstance(data, VictimAssetModel):
-            raise RuntimeError('Invalid type passed in to stage_associated_victim_asset')
+        if not isinstance(data, IndicatorAttributeModel):
+            raise RuntimeError('Invalid type passed in to stage_attribute')
         data._staged = True
-        self.model.associated_victim_assets.data.append(data)
+        self.model.attributes.data.append(data)  # type: ignore
 
-    def stage_associated_indicator(self, data: Union[dict, 'ObjectABC', 'IndicatorModel']):
-        """Stage indicator on the object."""
+    def stage_file_action(self, data: dict | ObjectABC | FileActionModel):
+        """Stage file_action on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = IndicatorModel(**data)
+            data = FileActionModel(**data)
 
-        if not isinstance(data, IndicatorModel):
-            raise RuntimeError('Invalid type passed in to stage_associated_indicator')
+        if not isinstance(data, FileActionModel):
+            raise RuntimeError('Invalid type passed in to stage_file_action')
         data._staged = True
-        self.model.associated_indicators.data.append(data)
+        data.indicator._staged = True
+        self.model.file_actions.data.append(data)  # type: ignore
 
-    def stage_attribute(self, data: Union[dict, 'ObjectABC', 'GroupAttributeModel']):
-        """Stage attribute on the object."""
+    def stage_file_occurrence(self, data: dict | ObjectABC | FileOccurrenceModel):
+        """Stage file_occurrence on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = GroupAttributeModel(**data)
+            data = FileOccurrenceModel(**data)
 
-        if not isinstance(data, GroupAttributeModel):
-            raise RuntimeError('Invalid type passed in to stage_attribute')
+        if not isinstance(data, FileOccurrenceModel):
+            raise RuntimeError('Invalid type passed in to stage_file_occurrence')
         data._staged = True
-        self.model.attributes.data.append(data)
+        self.model.file_occurrences.data.append(data)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
 
-    def stage_tag(self, data: Union[dict, 'ObjectABC', 'TagModel']):
+    def stage_tag(self, data: dict | ObjectABC | TagModel):
         """Stage tag on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = TagModel(**data)
 
         if not isinstance(data, TagModel):
             raise RuntimeError('Invalid type passed in to stage_tag')
         data._staged = True
-        self.model.tags.data.append(data)
+        self.model.tags.data.append(data)  # type: ignore
+
+
+class Indicators(ObjectCollectionABC):
+    """Indicators Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = IndicatorsModel(**kwargs)
+        self.type_ = 'indicators'
+
+    def __iter__(self) -> Iterator[Indicator]:
+        """Return CM objects."""
+        return self.iterate(base_class=Indicator)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.INDICATORS.value
+
+    @property
+    def filter(self) -> IndicatorFilter:
+        """Return the type specific filter object."""
+        return IndicatorFilter(self.tql)
+
+    def deleted(
+        self,
+        deleted_since: datetime | str | None,
+        type_: str | None = None,
+        owner: str | None = None,
+    ):
+        """Return deleted indicators.
+
+        This will not use the default params set on the "Indicators"
+        object and instead used the params that are passed in.
+        """
+
+        if deleted_since is not None:
+            deleted_since = str(
+                self.util.any_to_datetime(deleted_since).strftime('%Y-%m-%dT%H:%M:%SZ')
+            )
+
+        yield from self.iterate(
+            base_class=Indicator,
+            api_endpoint=f'{self._api_endpoint}/deleted',
+            params={'deletedSince': deleted_since, 'owner': owner, 'type': type_},
+        )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/groups/group_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/cases/case_filter.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,571 +1,589 @@
-"""Group TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql import Tql
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class GroupFilter(FilterABC):
-    """Filter Object for Groups"""
+class CaseFilter(FilterABC):
+    """Filter Object for Cases"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.GROUPS.value
+        return ApiEndpoints.CASES.value
 
-    def associated_indicator(self, operator: Enum, associated_indicator: int):
-        """Filter associatedIndicator based on **associatedIndicator** keyword.
+    def assigned_to_user_or_group(self, operator: Enum, assigned_to_user_or_group: list | str):
+        """Filter Assigned To User or Group based on **assignedToUserOrGroup** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            associated_indicator: No description provided.
+            assigned_to_user_or_group: A value of User, Group, or None depending on the assignee.
         """
-        self._tql.add_filter('associatedIndicator', operator, associated_indicator, TqlType.INTEGER)
+        if isinstance(assigned_to_user_or_group, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def attribute(self, operator: Enum, attribute: str):
-        """Filter attribute based on **attribute** keyword.
+        self._tql.add_filter(
+            'assignedToUserOrGroup', operator, assigned_to_user_or_group, TqlType.STRING
+        )
+
+    def assignee_name(self, operator: Enum, assignee_name: list | str):
+        """Filter Assignee based on **assigneeName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            attribute: No description provided.
+            assignee_name: The user or group name assigned to the Case.
         """
-        self._tql.add_filter('attribute', operator, attribute, TqlType.STRING)
+        if isinstance(assignee_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def child_group(self, operator: Enum, child_group: int):
-        """Filter childGroup based on **childGroup** keyword.
+        self._tql.add_filter('assigneeName', operator, assignee_name, TqlType.STRING)
+
+    def attribute(self, operator: Enum, attribute: list | str):
+        """Filter attribute based on **attribute** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            child_group: No description provided.
+            attribute: No description provided.
         """
-        self._tql.add_filter('childGroup', operator, child_group, TqlType.INTEGER)
+        if isinstance(attribute, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('attribute', operator, attribute, TqlType.STRING)
 
-    def created_by(self, operator: Enum, created_by: str):
-        """Filter Created By based on **createdBy** keyword.
+    def cal_score(self, operator: Enum, cal_score: int | list):
+        """Filter CalScore based on **calScore** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            created_by: The user who created the group.
+            cal_score: Cal score of the case.
         """
-        self._tql.add_filter('createdBy', operator, created_by, TqlType.STRING)
+        if isinstance(cal_score, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def date_added(self, operator: Enum, date_added: str):
-        """Filter Date Added based on **dateAdded** keyword.
+        self._tql.add_filter('calScore', operator, cal_score, TqlType.INTEGER)
+
+    def case_close_date(self, operator: Enum, case_close_date: Arrow | datetime | int | str):
+        """Filter Cases Closed based on **caseCloseDate** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_added: The date the group was added to the system.
+            case_close_date: The date/time the case was closed.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
+        case_close_date = self.util.any_to_datetime(case_close_date).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('caseCloseDate', operator, case_close_date, TqlType.STRING)
 
-    def document_date_added(self, operator: Enum, document_date_added: str):
-        """Filter Date Added (Document) based on **documentDateAdded** keyword.
+    def case_close_time(self, operator: Enum, case_close_time: Arrow | datetime | int | str):
+        """Filter Case Close Time based on **caseCloseTime** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            document_date_added: The date the document was added.
+            case_close_time: The date/time the case was closed.
         """
-        document_date_added = self.utils.any_to_datetime(document_date_added).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('documentDateAdded', operator, document_date_added, TqlType.STRING)
+        case_close_time = self.util.any_to_datetime(case_close_time).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('caseCloseTime', operator, case_close_time, TqlType.STRING)
 
-    def document_filename(self, operator: Enum, document_filename: str):
-        """Filter Filename (Document) based on **documentFilename** keyword.
+    def case_close_user(self, operator: Enum, case_close_user: list | str):
+        """Filter Case Close User based on **caseCloseUser** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            document_filename: The file name of the document.
+            case_close_user: The user who closed the case.
         """
-        self._tql.add_filter('documentFilename', operator, document_filename, TqlType.STRING)
+        if isinstance(case_close_user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('caseCloseUser', operator, case_close_user, TqlType.STRING)
 
-    def document_filesize(self, operator: Enum, document_filesize: int):
-        """Filter File Size (Document) based on **documentFilesize** keyword.
+    def case_detection_time(
+        self, operator: Enum, case_detection_time: Arrow | datetime | int | str
+    ):
+        """Filter Case Detection Time based on **caseDetectionTime** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            document_filesize: The filesize of the document.
+            case_detection_time: The date/time the case was detected.
         """
-        self._tql.add_filter('documentFilesize', operator, document_filesize, TqlType.INTEGER)
+        case_detection_time = self.util.any_to_datetime(case_detection_time).strftime(
+            '%Y-%m-%d %H:%M:%S'
+        )
+        self._tql.add_filter('caseDetectionTime', operator, case_detection_time, TqlType.STRING)
 
-    def document_status(self, operator: Enum, document_status: str):
-        """Filter Status (Document) based on **documentStatus** keyword.
+    def case_detection_user(self, operator: Enum, case_detection_user: list | str):
+        """Filter Case Detection User based on **caseDetectionUser** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            document_status: The status of the document.
+            case_detection_user: The user who logged the case detection time.
         """
-        self._tql.add_filter('documentStatus', operator, document_status, TqlType.STRING)
+        if isinstance(case_detection_user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('caseDetectionUser', operator, case_detection_user, TqlType.STRING)
 
-    def document_type(self, operator: Enum, document_type: str):
-        """Filter Type (Document) based on **documentType** keyword.
+    def case_occurrence_time(
+        self, operator: Enum, case_occurrence_time: Arrow | datetime | int | str
+    ):
+        """Filter Case Occurrence Time based on **caseOccurrenceTime** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            document_type: The type of document.
+            case_occurrence_time: The date/time the case occurred.
         """
-        self._tql.add_filter('documentType', operator, document_type, TqlType.STRING)
+        case_occurrence_time = self.util.any_to_datetime(case_occurrence_time).strftime(
+            '%Y-%m-%d %H:%M:%S'
+        )
+        self._tql.add_filter('caseOccurrenceTime', operator, case_occurrence_time, TqlType.STRING)
 
-    def downvote_count(self, operator: Enum, downvote_count: int):
-        """Filter Downvote Count based on **downvoteCount** keyword.
+    def case_occurrence_user(self, operator: Enum, case_occurrence_user: list | str):
+        """Filter Case Occurrence User based on **caseOccurrenceUser** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            downvote_count: The number of downvotes the group has received.
+            case_occurrence_user: The user who logged the case occurrence time.
         """
-        self._tql.add_filter('downvoteCount', operator, downvote_count, TqlType.INTEGER)
+        if isinstance(case_occurrence_user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def email_date(self, operator: Enum, email_date: str):
-        """Filter Date (Email) based on **emailDate** keyword.
+        self._tql.add_filter('caseOccurrenceUser', operator, case_occurrence_user, TqlType.STRING)
+
+    def case_open_date(self, operator: Enum, case_open_date: Arrow | datetime | int | str):
+        """Filter Cases Created based on **caseOpenDate** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            email_date: The date of the email.
+            case_open_date: The date/time the case was opened.
         """
-        email_date = self.utils.any_to_datetime(email_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('emailDate', operator, email_date, TqlType.STRING)
+        case_open_date = self.util.any_to_datetime(case_open_date).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('caseOpenDate', operator, case_open_date, TqlType.STRING)
 
-    def email_from(self, operator: Enum, email_from: str):
-        """Filter From (Email) based on **emailFrom** keyword.
+    def case_open_time(self, operator: Enum, case_open_time: Arrow | datetime | int | str):
+        """Filter Case Open Time based on **caseOpenTime** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            email_from: The 'from' field of the email.
+            case_open_time: The date/time the case was opened.
         """
-        self._tql.add_filter('emailFrom', operator, email_from, TqlType.STRING)
+        case_open_time = self.util.any_to_datetime(case_open_time).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('caseOpenTime', operator, case_open_time, TqlType.STRING)
 
-    def email_score(self, operator: Enum, email_score: int):
-        """Filter Score (Email) based on **emailScore** keyword.
+    def case_open_user(self, operator: Enum, case_open_user: list | str):
+        """Filter Case Opening User based on **caseOpenUser** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            email_score: The score of the email.
+            case_open_user: The user who opened the case.
         """
-        self._tql.add_filter('emailScore', operator, email_score, TqlType.INTEGER)
+        if isinstance(case_open_user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('caseOpenUser', operator, case_open_user, TqlType.STRING)
 
-    def email_score_includes_body(self, operator: Enum, email_score_includes_body: bool):
-        """Filter Score Includes Body (Email) based on **emailScoreIncludesBody** keyword.
+    def created_by(self, operator: Enum, created_by: list | str):
+        """Filter Creator based on **createdBy** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            email_score_includes_body: A true/false indicating if the body was included in the
-                scoring of the email.
+            created_by: The account login of the user who created the case.
         """
-        self._tql.add_filter(
-            'emailScoreIncludesBody', operator, email_score_includes_body, TqlType.BOOLEAN
-        )
+        if isinstance(created_by, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('createdBy', operator, created_by, TqlType.STRING)
 
-    def email_subject(self, operator: Enum, email_subject: str):
-        """Filter Subject (Email) based on **emailSubject** keyword.
+    def created_by_id(self, operator: Enum, created_by_id: int | list):
+        """Filter Creator ID based on **createdById** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            email_subject: The subject of the email.
+            created_by_id: The user ID for the creator of the case.
         """
-        self._tql.add_filter('emailSubject', operator, email_subject, TqlType.STRING)
+        if isinstance(created_by_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def event_date(self, operator: Enum, event_date: str):
-        """Filter Event Date based on **eventDate** keyword.
+        self._tql.add_filter('createdById', operator, created_by_id, TqlType.INTEGER)
+
+    def date_added(self, operator: Enum, date_added: Arrow | datetime | int | str):
+        """Filter Date Added based on **dateAdded** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            event_date: The event date of the group.
+            date_added: The date the case was added to the system.
         """
-        event_date = self.utils.any_to_datetime(event_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('eventDate', operator, event_date, TqlType.STRING)
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
 
-    def generated_report(self, operator: Enum, generated_report: bool):
-        """Filter Generated (Report) based on **generatedReport** keyword.
+    def description(self, operator: Enum, description: list | str):
+        """Filter Description based on **description** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            generated_report: Boolean flag indicating if the Report was auto-generated.
+            description: The description of the case.
         """
-        self._tql.add_filter('generatedReport', operator, generated_report, TqlType.BOOLEAN)
+        if isinstance(description, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('description', operator, description, TqlType.STRING)
 
     @property
     def has_artifact(self):
         """Return **ArtifactFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
 
         artifacts = ArtifactFilter(Tql())
         self._tql.add_filter('hasArtifact', TqlOperator.EQ, artifacts, TqlType.SUB_QUERY)
         return artifacts
 
     @property
-    def has_attribute(self):
-        """Return **GroupAttributeFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.group_attributes.group_attribute_filter import GroupAttributeFilter
-
-        attributes = GroupAttributeFilter(Tql())
-        self._tql.add_filter('hasAttribute', TqlOperator.EQ, attributes, TqlType.SUB_QUERY)
-        return attributes
-
-    @property
     def has_case(self):
         """Return **CaseFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.cases.case_filter import CaseFilter
-
         cases = CaseFilter(Tql())
         self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
         return cases
 
     @property
     def has_group(self):
         """Return **GroupFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.groups.group_filter import GroupFilter
+
         groups = GroupFilter(Tql())
         self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
         return groups
 
     @property
     def has_indicator(self):
         """Return **IndicatorFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
 
         indicators = IndicatorFilter(Tql())
         self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
         return indicators
 
-    def has_intel_query(self, operator: Enum, has_intel_query: int):
-        """Filter Associated User Queries based on **hasIntelQuery** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            has_intel_query: A nested query for association to User Queries.
-        """
-        self._tql.add_filter('hasIntelQuery', operator, has_intel_query, TqlType.INTEGER)
-
     @property
-    def has_security_label(self):
-        """Return **SecurityLabel** for further filtering."""
+    def has_note(self):
+        """Return **NoteFilter** for further filtering."""
         # first-party
-        from tcex.api.tc.v3.security_labels.security_label_filter import SecurityLabelFilter
+        from tcex.api.tc.v3.notes.note_filter import NoteFilter
 
-        security_labels = SecurityLabelFilter(Tql())
-        self._tql.add_filter('hasSecurityLabel', TqlOperator.EQ, security_labels, TqlType.SUB_QUERY)
-        return security_labels
+        notes = NoteFilter(Tql())
+        self._tql.add_filter('hasNote', TqlOperator.EQ, notes, TqlType.SUB_QUERY)
+        return notes
 
     @property
     def has_tag(self):
         """Return **TagFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.tags.tag_filter import TagFilter
 
         tags = TagFilter(Tql())
         self._tql.add_filter('hasTag', TqlOperator.EQ, tags, TqlType.SUB_QUERY)
         return tags
 
     @property
-    def has_victim(self):
-        """Return **VictimFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
-
-        victims = VictimFilter(Tql())
-        self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
-        return victims
-
-    @property
-    def has_victim_asset(self):
-        """Return **VictimAssetFilter** for further filtering."""
+    def has_task(self):
+        """Return **TaskFilter** for further filtering."""
         # first-party
-        from tcex.api.tc.v3.victim_assets.victim_asset_filter import VictimAssetFilter
+        from tcex.api.tc.v3.tasks.task_filter import TaskFilter
 
-        victim_assets = VictimAssetFilter(Tql())
-        self._tql.add_filter('hasVictimAsset', TqlOperator.EQ, victim_assets, TqlType.SUB_QUERY)
-        return victim_assets
+        tasks = TaskFilter(Tql())
+        self._tql.add_filter('hasTask', TqlOperator.EQ, tasks, TqlType.SUB_QUERY)
+        return tasks
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+    def has_workflow_template(self, operator: Enum, has_workflow_template: int | list):
+        """Filter Associated Workflow Template based on **hasWorkflowTemplate** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the group.
+            has_workflow_template: A nested query for association to workflow templates.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
-
-    def is_group(self, operator: Enum, is_group: bool):
-        """Filter isGroup based on **isGroup** keyword.
+        if isinstance(has_workflow_template, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            is_group: No description provided.
-        """
-        self._tql.add_filter('isGroup', operator, is_group, TqlType.BOOLEAN)
+        self._tql.add_filter(
+            'hasWorkflowTemplate', operator, has_workflow_template, TqlType.INTEGER
+        )
 
-    def last_modified(self, operator: Enum, last_modified: str):
-        """Filter Last Modified based on **lastModified** keyword.
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_modified: The date the group was last modified.
+            id: The ID of the case.
         """
-        last_modified = self.utils.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('lastModified', operator, last_modified, TqlType.STRING)
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def owner(self, operator: Enum, owner: int):
-        """Filter Owner ID based on **owner** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            owner: The Owner ID for the group.
-        """
-        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def owner_name(self, operator: Enum, owner_name: str):
-        """Filter Owner Name based on **ownerName** keyword.
+    def id_as_string(self, operator: Enum, id_as_string: list | str):
+        """Filter ID As String based on **idAsString** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name for the group.
+            id_as_string: The ID of the case as a String.
         """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
-
-    def parent_group(self, operator: Enum, parent_group: int):
-        """Filter parentGroup based on **parentGroup** keyword.
+        if isinstance(id_as_string, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            parent_group: No description provided.
-        """
-        self._tql.add_filter('parentGroup', operator, parent_group, TqlType.INTEGER)
+        self._tql.add_filter('idAsString', operator, id_as_string, TqlType.STRING)
 
-    def security_label(self, operator: Enum, security_label: str):
-        """Filter Security Label based on **securityLabel** keyword.
+    def last_updated(self, operator: Enum, last_updated: Arrow | datetime | int | str):
+        """Filter Last Updated based on **lastUpdated** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            security_label: The name of a security label applied to the group.
+            last_updated: The date the case was last updated in the system.
         """
-        self._tql.add_filter('securityLabel', operator, security_label, TqlType.STRING)
+        last_updated = self.util.any_to_datetime(last_updated).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('lastUpdated', operator, last_updated, TqlType.STRING)
 
-    def signature_date_added(self, operator: Enum, signature_date_added: str):
-        """Filter Date Added (Signature) based on **signatureDateAdded** keyword.
+    def missing_artifact_count(self, operator: Enum, missing_artifact_count: int | list):
+        """Filter Missing Artifact Count For Tasks based on **missingArtifactCount** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            signature_date_added: The date the signature was added.
+            missing_artifact_count: Missing Artifact Count for Case Tasks.
         """
-        signature_date_added = self.utils.any_to_datetime(signature_date_added).strftime(
-            '%Y-%m-%d %H:%M:%S'
+        if isinstance(missing_artifact_count, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter(
+            'missingArtifactCount', operator, missing_artifact_count, TqlType.INTEGER
         )
-        self._tql.add_filter('signatureDateAdded', operator, signature_date_added, TqlType.STRING)
 
-    def signature_filename(self, operator: Enum, signature_filename: str):
-        """Filter Filename (Signature) based on **signatureFilename** keyword.
+    def name(self, operator: Enum, name: list | str):
+        """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            signature_filename: The file name of the signature.
+            name: The name of the case.
         """
-        self._tql.add_filter('signatureFilename', operator, signature_filename, TqlType.STRING)
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def signature_type(self, operator: Enum, signature_type: str):
-        """Filter Type (Signature) based on **signatureType** keyword.
+        self._tql.add_filter('name', operator, name, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            signature_type: The type of signature.
-        """
-        self._tql.add_filter('signatureType', operator, signature_type, TqlType.STRING)
-
-    def status(self, operator: Enum, status: str):
-        """Filter Status based on **status** keyword.
+    def owner(self, operator: Enum, owner: int | list):
+        """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            status: Status of the group.
+            owner: The Owner ID for the case.
         """
-        self._tql.add_filter('status', operator, status, TqlType.STRING)
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            summary: The summary (name) of the group.
-        """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-    def tag(self, operator: Enum, tag: str):
-        """Filter Tag based on **tag** keyword.
+    def owner_name(self, operator: Enum, owner_name: list | str):
+        """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag: The name of a tag applied to the group.
+            owner_name: The owner name for the case.
         """
-        self._tql.add_filter('tag', operator, tag, TqlType.STRING)
-
-    def tag_owner(self, operator: Enum, tag_owner: int):
-        """Filter Tag Owner ID based on **tagOwner** keyword.
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            tag_owner: The ID of the owner of a tag.
-        """
-        self._tql.add_filter('tagOwner', operator, tag_owner, TqlType.INTEGER)
+        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def tag_owner_name(self, operator: Enum, tag_owner_name: str):
-        """Filter Tag Owner Name based on **tagOwnerName** keyword.
+    def resolution(self, operator: Enum, resolution: list | str):
+        """Filter Resolution based on **resolution** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag_owner_name: The name of the owner of a tag.
+            resolution: The resolution of the case.
         """
-        self._tql.add_filter('tagOwnerName', operator, tag_owner_name, TqlType.STRING)
+        if isinstance(resolution, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_assignee(self, operator: Enum, task_assignee: str):
-        """Filter Assignee (Task) based on **taskAssignee** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            task_assignee: The assignee of the task.
-        """
-        self._tql.add_filter('taskAssignee', operator, task_assignee, TqlType.STRING)
+        self._tql.add_filter('resolution', operator, resolution, TqlType.STRING)
 
-    def task_assignee_pseudo(self, operator: Enum, task_assignee_pseudo: str):
-        """Filter Assignee Pseudonym (Task) based on **taskAssigneePseudo** keyword.
+    def severity(self, operator: Enum, severity: list | str):
+        """Filter Severity based on **severity** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_assignee_pseudo: The pseudonym of the assignee of the task.
+            severity: The severity of the case.
         """
-        self._tql.add_filter('taskAssigneePseudo', operator, task_assignee_pseudo, TqlType.STRING)
+        if isinstance(severity, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_date_added(self, operator: Enum, task_date_added: str):
-        """Filter Date Added (Task) based on **taskDateAdded** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            task_date_added: The date the task was added.
-        """
-        task_date_added = self.utils.any_to_datetime(task_date_added).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('taskDateAdded', operator, task_date_added, TqlType.STRING)
+        self._tql.add_filter('severity', operator, severity, TqlType.STRING)
 
-    def task_due_date(self, operator: Enum, task_due_date: str):
-        """Filter Due Date (Task) based on **taskDueDate** keyword.
+    def status(self, operator: Enum, status: list | str):
+        """Filter Status based on **status** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_due_date: The due date of a task.
+            status: The status of the case.
         """
-        task_due_date = self.utils.any_to_datetime(task_due_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('taskDueDate', operator, task_due_date, TqlType.STRING)
+        if isinstance(status, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_escalated(self, operator: Enum, task_escalated: bool):
-        """Filter Escalated (Task) based on **taskEscalated** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            task_escalated: A flag indicating if a task has been escalated.
-        """
-        self._tql.add_filter('taskEscalated', operator, task_escalated, TqlType.BOOLEAN)
+        self._tql.add_filter('status', operator, status, TqlType.STRING)
 
-    def task_escalation_date(self, operator: Enum, task_escalation_date: str):
-        """Filter Escalation Date (Task) based on **taskEscalationDate** keyword.
+    def tag(self, operator: Enum, tag: list | str):
+        """Filter Tag based on **tag** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_escalation_date: The escalation date of a task.
+            tag: The name of a tag applied to a case.
         """
-        task_escalation_date = self.utils.any_to_datetime(task_escalation_date).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('taskEscalationDate', operator, task_escalation_date, TqlType.STRING)
+        if isinstance(tag, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_last_modified(self, operator: Enum, task_last_modified: str):
-        """Filter Last Modified based on **taskLastModified** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            task_last_modified: The date the group was last modified.
-        """
-        task_last_modified = self.utils.any_to_datetime(task_last_modified).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('taskLastModified', operator, task_last_modified, TqlType.STRING)
+        self._tql.add_filter('tag', operator, tag, TqlType.STRING)
 
-    def task_overdue(self, operator: Enum, task_overdue: bool):
-        """Filter Overdue (Task) based on **taskOverdue** keyword.
+    def target_id(self, operator: Enum, target_id: int | list):
+        """Filter Assignee ID based on **targetId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_overdue: A flag indicating if a task has become overdue.
+            target_id: The assigned user or group ID for the case.
         """
-        self._tql.add_filter('taskOverdue', operator, task_overdue, TqlType.BOOLEAN)
-
-    def task_reminded(self, operator: Enum, task_reminded: bool):
-        """Filter Reminded (Task) based on **taskReminded** keyword.
+        if isinstance(target_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            task_reminded: A flag indicating if a task has been reminded.
-        """
-        self._tql.add_filter('taskReminded', operator, task_reminded, TqlType.BOOLEAN)
+        self._tql.add_filter('targetId', operator, target_id, TqlType.INTEGER)
 
-    def task_reminder_date(self, operator: Enum, task_reminder_date: str):
-        """Filter Reminder Date (Task) based on **taskReminderDate** keyword.
+    def target_type(self, operator: Enum, target_type: list | str):
+        """Filter Target Type based on **targetType** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_reminder_date: The reminder date of a task.
+            target_type: The target type for this case (either User or Group).
         """
-        task_reminder_date = self.utils.any_to_datetime(task_reminder_date).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('taskReminderDate', operator, task_reminder_date, TqlType.STRING)
+        if isinstance(target_type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_status(self, operator: Enum, task_status: str):
-        """Filter Status (Task) based on **taskStatus** keyword.
+        self._tql.add_filter('targetType', operator, target_type, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            task_status: The status of the task.
-        """
-        self._tql.add_filter('taskStatus', operator, task_status, TqlType.STRING)
-
-    def type(self, operator: Enum, type: int):  # pylint: disable=redefined-builtin
-        """Filter Type based on **type** keyword.
+    def threat_assess_score(self, operator: Enum, threat_assess_score: int | list):
+        """Filter ThreatAssessScore based on **threatAssessScore** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type: The ID of the group type.
+            threat_assess_score: ThreatAssess score of the case.
         """
-        self._tql.add_filter('type', operator, type, TqlType.INTEGER)
+        if isinstance(threat_assess_score, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def type_name(self, operator: Enum, type_name: str):
-        """Filter Type Name based on **typeName** keyword.
+        self._tql.add_filter('threatAssessScore', operator, threat_assess_score, TqlType.INTEGER)
+
+    def type_name(self, operator: Enum, type_name: list | str):
+        """Filter Name based on **typeName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type_name: The name of the group type.
+            type_name: The name of the case.
         """
+        if isinstance(type_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
 
-    def upvote_count(self, operator: Enum, upvote_count: int):
-        """Filter Upvote Count based on **upvoteCount** keyword.
+    def xid(self, operator: Enum, xid: list | str):
+        """Filter XID based on **xid** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            upvote_count: The number of upvotes the group has received.
+            xid: The XID of the case.
         """
-        self._tql.add_filter('upvoteCount', operator, upvote_count, TqlType.INTEGER)
+        if isinstance(xid, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def victim_asset(self, operator: Enum, victim_asset: str):
-        """Filter victimAsset based on **victimAsset** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            victim_asset: No description provided.
-        """
-        self._tql.add_filter('victimAsset', operator, victim_asset, TqlType.STRING)
+        self._tql.add_filter('xid', operator, xid, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/groups/group_model.py` & `tcex-4.0.0/tcex/api/tc/v3/groups/group_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,182 +1,141 @@
-"""Group / Groups Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class GroupsModel(
-    BaseModel,
-    title='Groups Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Groups Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['GroupModel']] = Field(
-        [],
-        description='The data for the Groups.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class GroupDataModel(
-    BaseModel,
-    title='Group Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Groups Data Model"""
-
-    data: Optional[List['GroupModel']] = Field(
-        [],
-        description='The data for the Groups.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class GroupModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Group Model',
     validate_assignment=True,
 ):
     """Group Model"""
 
     _associated_type = PrivateAttr(True)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    assignments: Optional['TaskAssigneesModel'] = Field(
+    assignments: 'TaskAssigneesModel' = Field(
         None,
         description=(
             'A list of assignees and escalatees associated with this group (Task specific).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='assignments',
     )
-    associated_artifacts: Optional['ArtifactsModel'] = Field(
+    associated_artifacts: 'ArtifactsModel' = Field(
         None,
         description='A list of Artifacts associated with this Group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedArtifacts',
     )
-    associated_cases: Optional['CasesModel'] = Field(
+    associated_cases: 'CasesModel' = Field(
         None,
         description='A list of Cases associated with this Group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedCases',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of groups associated with this group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    associated_indicators: Optional['IndicatorsModel'] = Field(
+    associated_indicators: 'IndicatorsModel' = Field(
         None,
         description='A list of indicators associated with this group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedIndicators',
     )
-    associated_victim_assets: Optional['VictimAssetsModel'] = Field(
+    associated_victim_assets: 'VictimAssetsModel' = Field(
         None,
         description='A list of victim assets associated with this group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedVictimAssets',
     )
-    attributes: Optional['GroupAttributesModel'] = Field(
+    attributes: 'GroupAttributesModel' = Field(
         None,
         description='A list of Attributes corresponding to the Group.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='attributes',
     )
-    body: Optional[str] = Field(
+    body: str | None = Field(
         None,
         applies_to=['Email'],
         description='The email Body.',
         methods=['POST', 'PUT'],
         max_length=65535,
         min_length=0,
         read_only=False,
         title='body',
     )
-    created_by: Optional['UserModel'] = Field(
+    created_by: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The **created by** for the Group.',
         read_only=True,
         title='createdBy',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
-    document_date_added: Optional[datetime] = Field(
+    document_date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Document', 'Report'],
         description='The date and time that the document was first created.',
         read_only=True,
         title='documentDateAdded',
     )
-    document_type: Optional[str] = Field(
+    document_type: str | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Document', 'Report'],
         description='The document type.',
         read_only=True,
         title='documentType',
     )
-    down_vote_count: Optional[int] = Field(
+    down_vote_count: int | None = Field(
         None,
         allow_mutation=False,
         description='The total number of users who find the intel not helpful.',
         read_only=True,
         title='downVoteCount',
     )
-    due_date: Optional[datetime] = Field(
+    due_date: datetime | None = Field(
         None,
         applies_to=['Task'],
         description='The date and time that the Task is due.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='dueDate',
     )
-    email_date: Optional[datetime] = Field(
+    email_date: datetime | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Email'],
         description='The date and time that the email was first created.',
         read_only=True,
         title='emailDate',
     )
@@ -184,74 +143,74 @@
         None,
         allow_mutation=False,
         applies_to=['Task'],
         description='Flag indicating whether or not the task has been escalated.',
         read_only=True,
         title='escalated',
     )
-    escalation_date: Optional[datetime] = Field(
+    escalation_date: datetime | None = Field(
         None,
         applies_to=['Task'],
         description='The escalation date and time.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='escalationDate',
     )
-    event_date: Optional[datetime] = Field(
+    event_date: datetime | None = Field(
         None,
         applies_to=['Incident', 'Event'],
         description='The date and time that the incident or event was first created.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='eventDate',
     )
-    file_name: Optional[str] = Field(
+    file_name: str | None = Field(
         None,
         applies_to=['Document', 'Report', 'Signature'],
         conditional_required=['Document', 'Report', 'Signature'],
         description='The document or signature file name.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=0,
         read_only=False,
         title='fileName',
     )
-    file_size: Optional[int] = Field(
+    file_size: int | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Document', 'Report'],
         description='The document file size.',
         read_only=True,
         title='fileSize',
     )
-    file_text: Optional[str] = Field(
+    file_text: str | None = Field(
         None,
         applies_to=['Signature'],
         description='The signature file text.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='fileText',
     )
-    file_type: Optional[str] = Field(
+    file_type: str | None = Field(
         None,
         applies_to=['Signature'],
         description='The signature file type.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='fileType',
     )
-    first_seen: Optional[datetime] = Field(
+    first_seen: datetime | None = Field(
         None,
         applies_to=['Campaign'],
         description='The date and time that the campaign was first created.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='firstSeen',
     )
-    from_: Optional[str] = Field(
+    from_: str | None = Field(
         None,
         alias='from',
         applies_to=['Email'],
         description='The email From field.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
@@ -261,53 +220,53 @@
     generated_report: bool = Field(
         None,
         allow_mutation=False,
         description='Is the report auto-generated?',
         read_only=True,
         title='generatedReport',
     )
-    header: Optional[str] = Field(
+    header: str | None = Field(
         None,
         applies_to=['Email'],
         description='The email Header field.',
         methods=['POST', 'PUT'],
         max_length=65535,
         min_length=0,
         read_only=False,
         title='header',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Entity was last modified.',
         read_only=True,
         title='lastModified',
     )
-    legacy_link: Optional[str] = Field(
+    legacy_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the legacy ThreatConnect details page for this entity.',
         read_only=True,
         title='legacyLink',
     )
     malware: bool = Field(
         None,
         applies_to=['Document'],
         description='Is the document malware?',
         methods=['POST', 'PUT'],
         read_only=False,
         title='malware',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='The name of the group.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='name',
@@ -316,37 +275,37 @@
         None,
         allow_mutation=False,
         applies_to=['Task'],
         description='Flag indicating whether or not the task is overdue.',
         read_only=True,
         title='overdue',
     )
-    owner_id: Optional[int] = Field(
+    owner_id: int | None = Field(
         None,
         description='The id of the Organization, Community, or Source that the item belongs to.',
         methods=['POST'],
         read_only=False,
         title='ownerId',
     )
-    owner_name: Optional[str] = Field(
+    owner_name: str | None = Field(
         None,
         description='The name of the Organization, Community, or Source that the item belongs to.',
         methods=['POST'],
         read_only=False,
         title='ownerName',
     )
-    password: Optional[str] = Field(
+    password: str | None = Field(
         None,
         applies_to=['Document'],
         description='The password associated with the document (Required if Malware is true).',
         methods=['POST', 'PUT'],
         read_only=False,
         title='password',
     )
-    publish_date: Optional[datetime] = Field(
+    publish_date: datetime | None = Field(
         None,
         applies_to=['Report'],
         description='The date and time that the report was first created.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='publishDate',
     )
@@ -354,31 +313,31 @@
         None,
         allow_mutation=False,
         applies_to=['Task'],
         description='Flag indicating whether or not the task reminders have been sent.',
         read_only=True,
         title='reminded',
     )
-    reminder_date: Optional[datetime] = Field(
+    reminder_date: datetime | None = Field(
         None,
         applies_to=['Task'],
         description='The reminder date and time.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='reminderDate',
     )
-    score: Optional[int] = Field(
+    score: int | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Email'],
         description='The score value for this email.',
         read_only=True,
         title='score',
     )
-    score_breakdown: Optional[str] = Field(
+    score_breakdown: str | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Email'],
         description='The email score breakdown.',
         read_only=True,
         title='scoreBreakdown',
     )
@@ -386,72 +345,72 @@
         None,
         allow_mutation=False,
         applies_to=['Email'],
         description='Is the Body included in the email score?',
         read_only=True,
         title='scoreIncludesBody',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    signature_date_added: Optional[datetime] = Field(
+    signature_date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Signature'],
         description='The date and time that the signature was first created.',
         read_only=True,
         title='signatureDateAdded',
     )
-    status: Optional[str] = Field(
+    status: str | None = Field(
         None,
         applies_to=['Document', 'Report', 'Event', 'Task', 'Incident'],
         description=(
             'The status associated with this document, event, task, or incident (read only for '
             'task, document, and report).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='status',
     )
-    subject: Optional[str] = Field(
+    subject: str | None = Field(
         None,
         applies_to=['Email'],
         description='The email Subject section.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=0,
         read_only=False,
         title='subject',
     )
-    tags: Optional['TagsModel'] = Field(
+    tags: 'TagsModel' = Field(
         None,
         description=(
             'A list of Tags corresponding to the item (NOTE: Setting this parameter will replace '
             'any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='tags',
     )
-    to: Optional[str] = Field(
+    to: str | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Email'],
         description='The email To field .',
         read_only=True,
         title='to',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The **type** for the Group.',
         methods=['POST', 'PUT'],
         min_length=1,
         read_only=False,
         title='type',
     )
@@ -461,97 +420,137 @@
             'Is the intelligence valid and useful? (0 means downvote, 1 means upvote, and NULL '
             'means no vote).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='upVote',
     )
-    up_vote_count: Optional[int] = Field(
+    up_vote_count: int | None = Field(
         None,
         allow_mutation=False,
         description='The total number of users who find the intel useful.',
         read_only=True,
         title='upVoteCount',
     )
-    web_link: Optional[str] = Field(
+    web_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the ThreatConnect details page for this entity.',
         read_only=True,
         title='webLink',
     )
-    xid: Optional[str] = Field(
+    xid: str | None = Field(
         None,
         description='The xid of the item.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='xid',
     )
 
-    @validator('associated_artifacts', always=True)
+    @validator('associated_artifacts', always=True, pre=True)
     def _validate_artifacts(cls, v):
         if not v:
-            return ArtifactsModel()
+            return ArtifactsModel()  # type: ignore
         return v
 
-    @validator('associated_cases', always=True)
+    @validator('associated_cases', always=True, pre=True)
     def _validate_cases(cls, v):
         if not v:
-            return CasesModel()
+            return CasesModel()  # type: ignore
         return v
 
-    @validator('attributes', always=True)
+    @validator('attributes', always=True, pre=True)
     def _validate_group_attributes(cls, v):
         if not v:
-            return GroupAttributesModel()
+            return GroupAttributesModel()  # type: ignore
         return v
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
-    @validator('associated_indicators', always=True)
+    @validator('associated_indicators', always=True, pre=True)
     def _validate_indicators(cls, v):
         if not v:
-            return IndicatorsModel()
+            return IndicatorsModel()  # type: ignore
         return v
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('tags', always=True)
+    @validator('tags', always=True, pre=True)
     def _validate_tags(cls, v):
         if not v:
-            return TagsModel()
+            return TagsModel()  # type: ignore
         return v
 
-    @validator('assignments', always=True)
+    @validator('assignments', always=True, pre=True)
     def _validate_task_assignees(cls, v):
         if not v:
-            return TaskAssigneesModel()
+            return TaskAssigneesModel()  # type: ignore
         return v
 
-    @validator('created_by', always=True)
+    @validator('created_by', always=True, pre=True)
     def _validate_user(cls, v):
         if not v:
-            return UserModel()
+            return UserModel()  # type: ignore
         return v
 
-    @validator('associated_victim_assets', always=True)
+    @validator('associated_victim_assets', always=True, pre=True)
     def _validate_victim_assets(cls, v):
         if not v:
-            return VictimAssetsModel()
+            return VictimAssetsModel()  # type: ignore
         return v
 
 
+class GroupDataModel(
+    BaseModel,
+    title='Group Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Groups Data Model"""
+
+    data: list[GroupModel] | None = Field(
+        [],
+        description='The data for the Groups.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class GroupsModel(
+    BaseModel,
+    title='Groups Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Groups Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[GroupModel] | None = Field(
+        [],
+        description='The data for the Groups.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactsModel
 from tcex.api.tc.v3.cases.case_model import CasesModel
 from tcex.api.tc.v3.group_attributes.group_attribute_model import GroupAttributesModel
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorsModel
 from tcex.api.tc.v3.security.task_assignee_model import TaskAssigneesModel
 from tcex.api.tc.v3.security.users.user_model import UserModel
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/indicator_attribute.py` & `tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/indicator_attribute.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,127 +1,127 @@
-"""IndicatorAttribute / IndicatorAttributes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.indicator_attributes.indicator_attribute_filter import IndicatorAttributeFilter
 from tcex.api.tc.v3.indicator_attributes.indicator_attribute_model import (
     IndicatorAttributeModel,
     IndicatorAttributesModel,
 )
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-
-
-class IndicatorAttributes(ObjectCollectionABC):
-    """IndicatorAttributes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = IndicatorAttributesModel(**kwargs)
-        self.type_ = 'indicator_attributes'
-
-    def __iter__(self) -> 'IndicatorAttribute':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=IndicatorAttribute)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.INDICATOR_ATTRIBUTES.value
-
-    @property
-    def filter(self) -> 'IndicatorAttributeFilter':
-        """Return the type specific filter object."""
-        return IndicatorAttributeFilter(self.tql)
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
 
 
 class IndicatorAttribute(ObjectABC):
     """IndicatorAttributes Object.
 
     Args:
         default (bool, kwargs): A flag indicating that this is the default attribute of its type
             within the object. Only applies to certain attribute and data types.
-        indicator (Indicator, kwargs): Details of indicator associated with attribute.
         indicator_id (int, kwargs): Indicator associated with attribute.
         pinned (bool, kwargs): A flag indicating that the attribute has been noted for importance.
         security_labels (SecurityLabels, kwargs): A list of Security Labels corresponding to the
             Intel item (NOTE: Setting this parameter will replace any existing tag(s) with
             the one(s) specified).
         source (str, kwargs): The attribute source.
         type (str, kwargs): The attribute type.
         value (str, kwargs): The attribute value.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = IndicatorAttributeModel(**kwargs)
+        self._model: IndicatorAttributeModel = IndicatorAttributeModel(**kwargs)
         self._nested_field_name = 'attributes'
         self._nested_filter = 'has_indicator_attribute'
         self.type_ = 'Indicator Attribute'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.INDICATOR_ATTRIBUTES.value
 
     @property
-    def model(self) -> 'IndicatorAttributeModel':
+    def model(self) -> IndicatorAttributeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['IndicatorAttributeModel', dict]):
+    def model(self, data: dict | IndicatorAttributeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
+
+
+class IndicatorAttributes(ObjectCollectionABC):
+    """IndicatorAttributes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = IndicatorAttributesModel(**kwargs)
+        self.type_ = 'indicator_attributes'
+
+    def __iter__(self) -> Iterator[IndicatorAttribute]:
+        """Return CM objects."""
+        return self.iterate(base_class=IndicatorAttribute)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.INDICATOR_ATTRIBUTES.value
+
+    @property
+    def filter(self) -> IndicatorAttributeFilter:
+        """Return the type specific filter object."""
+        return IndicatorAttributeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/indicator_attributes/indicator_attribute_model.py` & `tcex-4.0.0/tcex/api/tc/v3/indicator_attributes/indicator_attribute_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,83 +1,42 @@
-"""Indicator_Attribute / Indicator_Attributes Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class IndicatorAttributesModel(
-    BaseModel,
-    title='IndicatorAttributes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Indicator_Attributes Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['IndicatorAttributeModel']] = Field(
-        [],
-        description='The data for the IndicatorAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class IndicatorAttributeDataModel(
-    BaseModel,
-    title='IndicatorAttribute Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Indicator_Attributes Data Model"""
-
-    data: Optional[List['IndicatorAttributeModel']] = Field(
-        [],
-        description='The data for the IndicatorAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class IndicatorAttributeModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='IndicatorAttribute Model',
     validate_assignment=True,
 ):
     """Indicator_Attribute Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    created_by: Optional['UserModel'] = Field(
+    created_by: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The **created by** for the Indicator_Attribute.',
         read_only=True,
         title='createdBy',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
     default: bool = Field(
@@ -86,100 +45,140 @@
             'A flag indicating that this is the default attribute of its type within the object. '
             'Only applies to certain attribute and data types.'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='default',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    indicator: Optional['IndicatorModel'] = Field(
+    indicator: 'IndicatorModel' = Field(
         None,
+        allow_mutation=False,
         description='Details of indicator associated with attribute.',
-        methods=['POST'],
-        read_only=False,
+        read_only=True,
         title='indicator',
     )
-    indicator_id: Optional[int] = Field(
+    indicator_id: int | None = Field(
         None,
         description='Indicator associated with attribute.',
         methods=['POST'],
         read_only=False,
         title='indicatorId',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Attribute was last modified.',
         read_only=True,
         title='lastModified',
     )
     pinned: bool = Field(
         None,
         description='A flag indicating that the attribute has been noted for importance.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='pinned',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    source: Optional[str] = Field(
+    source: str | None = Field(
         None,
         description='The attribute source.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='source',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The attribute type.',
         methods=['POST'],
         read_only=False,
         title='type',
     )
-    value: Optional[str] = Field(
+    value: str | None = Field(
         None,
         description='The attribute value.',
         methods=['POST', 'PUT'],
         min_length=1,
         read_only=False,
         title='value',
     )
 
-    @validator('indicator', always=True)
+    @validator('indicator', always=True, pre=True)
     def _validate_indicator(cls, v):
         if not v:
-            return IndicatorModel()
+            return IndicatorModel()  # type: ignore
         return v
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('created_by', always=True)
+    @validator('created_by', always=True, pre=True)
     def _validate_user(cls, v):
         if not v:
-            return UserModel()
+            return UserModel()  # type: ignore
         return v
 
 
+class IndicatorAttributeDataModel(
+    BaseModel,
+    title='IndicatorAttribute Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Indicator_Attributes Data Model"""
+
+    data: list[IndicatorAttributeModel] | None = Field(
+        [],
+        description='The data for the IndicatorAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class IndicatorAttributesModel(
+    BaseModel,
+    title='IndicatorAttributes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Indicator_Attributes Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[IndicatorAttributeModel] | None = Field(
+        [],
+        description='The data for the IndicatorAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel
 from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelsModel
 
 # add forward references
 IndicatorAttributeDataModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/indicators/indicator.py` & `tcex-4.0.0/tcex/api/tc/v3/cases/case.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,369 +1,332 @@
-"""Indicator / Indicators Object"""
+"""TcEx Framework Module"""
 # standard library
-import json
-from datetime import datetime
-from typing import TYPE_CHECKING, Iterator, Optional, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING, Self
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
-from tcex.api.tc.v3.cases.case_model import CaseModel
-from tcex.api.tc.v3.file_actions.file_action_model import FileActionModel
-from tcex.api.tc.v3.file_occurrences.file_occurrence_model import FileOccurrenceModel
+from tcex.api.tc.v3.case_attributes.case_attribute_model import CaseAttributeModel
+from tcex.api.tc.v3.cases.case_filter import CaseFilter
+from tcex.api.tc.v3.cases.case_model import CaseModel, CasesModel
 from tcex.api.tc.v3.groups.group_model import GroupModel
-from tcex.api.tc.v3.indicator_attributes.indicator_attribute_model import IndicatorAttributeModel
-from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel, IndicatorsModel
+from tcex.api.tc.v3.indicators.indicator_model import IndicatorModel
+from tcex.api.tc.v3.notes.note_model import NoteModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
-from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
+from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel
+from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.tags.tag_model import TagModel
+from tcex.api.tc.v3.tasks.task_model import TaskModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.artifacts.artifact import Artifact
-    from tcex.api.tc.v3.cases.case import Case
-    from tcex.api.tc.v3.groups.group import Group
-    from tcex.api.tc.v3.indicator_attributes.indicator_attribute import IndicatorAttribute
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-    from tcex.api.tc.v3.tags.tag import Tag
+    from tcex.api.tc.v3.artifacts.artifact import Artifact  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.case_attributes.case_attribute import CaseAttribute  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.groups.group import Group  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.indicators.indicator import Indicator  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.notes.note import Note  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.tags.tag import Tag  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.tasks.task import Task  # CIRCULAR-IMPORT
 
 
-class Indicators(ObjectCollectionABC):
-    """Indicators Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
+class Case(ObjectABC):
+    """Cases Object.
 
     Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = IndicatorsModel(**kwargs)
-        self.type_ = 'indicators'
-
-    def __iter__(self) -> 'Indicator':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Indicator)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.INDICATORS.value
-
-    @property
-    def filter(self) -> 'IndicatorFilter':
-        """Return the type specific filter object."""
-        return IndicatorFilter(self.tql)
-
-    def deleted(
-        self,
-        deleted_since: Optional[Union[datetime, str]],
-        type_: Optional[str] = None,
-        owner: Optional[str] = None,
-    ):
-        """Return deleted indicators.
-
-        This will not use the default params set on the "Indicators"
-        object and instead used the params that are passed in.
-        """
-
-        if deleted_since is not None:
-            deleted_since = str(
-                self.utils.any_to_datetime(deleted_since).strftime('%Y-%m-%dT%H:%M:%SZ')
-            )
-
-        yield from self.iterate(
-            base_class=Indicator,
-            api_endpoint=f'{self._api_endpoint}/deleted',
-            params={'deletedSince': deleted_since, 'owner': owner, 'type': type_},
-        )
-
-
-class Indicator(ObjectABC):
-    """Indicators Object.
-
-    Args:
-        active (bool, kwargs): Is the indicator active?
-        active_locked (bool, kwargs): Lock the indicator active value?
-        address (str, kwargs): The email address associated with this indicator (EmailAddress
-            specific summary field).
-        associated_artifacts (Artifacts, kwargs): A list of Artifacts associated with this
-            Indicator.
-        associated_cases (Cases, kwargs): A list of Cases associated with this Indicator.
-        associated_groups (Groups, kwargs): A list of groups that this indicator is associated with.
-        associated_indicators (Indicators, kwargs): A list of indicators associated with this
-            indicator.
-        attributes (IndicatorAttributes, kwargs): A list of Attributes corresponding to the
-            Indicator.
-        confidence (int, kwargs): The indicator threat confidence.
-        dns_active (bool, kwargs): Is dns active for the indicator?
-        file_actions (FileActions, kwargs): The type of file action associated with this indicator.
-        file_occurrences (FileOccurrences, kwargs): A list of file occurrences associated with this
-            indicator.
-        host_name (str, kwargs): The host name of the indicator (Host specific summary field).
-        ip (str, kwargs): The ip address associated with this indicator (Address specific summary
-            field).
-        md5 (str, kwargs): The md5 associated with this indicator (File specific summary field).
-        mode (str, kwargs): The operation to perform on the file hashes (delete | merge).
-        owner_id (int, kwargs): The id of the Organization, Community, or Source that the item
-            belongs to.
-        owner_name (str, kwargs): The name of the Organization, Community, or Source that the item
-            belongs to.
-        private_flag (bool, kwargs): Is this indicator private?
-        rating (int, kwargs): The indicator threat rating.
-        security_labels (SecurityLabels, kwargs): A list of Security Labels corresponding to the
-            Intel item (NOTE: Setting this parameter will replace any existing tag(s) with
-            the one(s) specified).
-        sha1 (str, kwargs): The sha1 associated with this indicator (File specific summary field).
-        sha256 (str, kwargs): The sha256 associated with this indicator (File specific summary
-            field).
-        size (int, kwargs): The size of the file.
-        tags (Tags, kwargs): A list of Tags corresponding to the item (NOTE: Setting this parameter
+        artifacts (Artifacts, kwargs): A list of Artifacts corresponding to the Case.
+        assignee (Assignee, kwargs): The user or group Assignee object for the Case.
+        associated_cases (Cases, kwargs): A list of Cases associated with this Case.
+        associated_groups (Groups, kwargs): A list of Groups associated with this Case.
+        associated_indicators (Indicators, kwargs): A list of Indicators associated with this Case.
+        attributes (CaseAttributes, kwargs): A list of Attributes corresponding to the Case.
+        case_close_time (str, kwargs): The date and time that the Case was closed.
+        case_detection_time (str, kwargs): The date and time that ends the user initiated Case
+            duration.
+        case_occurrence_time (str, kwargs): The date and time that starts the user initiated Case
+            duration.
+        case_open_time (str, kwargs): The date and time that the Case was first opened.
+        description (str, kwargs): The description of the Case.
+        name (str, kwargs): The name of the Case.
+        notes (Notes, kwargs): A list of Notes corresponding to the Case.
+        resolution (str, kwargs): The Case resolution.
+        severity (str, kwargs): The Case severity.
+        status (str, kwargs): The Case status.
+        tags (Tags, kwargs): A list of Tags corresponding to the Case (NOTE: Setting this parameter
             will replace any existing tag(s) with the one(s) specified).
-        text (str, kwargs): The url text value of the indicator (Url specific summary field).
-        type (str, kwargs): The **type** for the Indicator.
-        value1 (str, kwargs): Custom Indicator summary field value1.
-        value2 (str, kwargs): Custom Indicator summary field value2.
-        value3 (str, kwargs): Custom Indicator summary field value3.
-        whois_active (bool, kwargs): Is whois active for the indicator?
+        tasks (Tasks, kwargs): A list of Tasks corresponding to the Case.
+        user_access (Users, kwargs): A list of Users that, when defined, are the only ones allowed
+            to view or edit the Case.
+        workflow_events (WorkflowEvents, kwargs): A list of workflowEvents (timeline) corresponding
+            to the Case.
+        workflow_template (WorkflowTemplate, kwargs): The Template that the Case is populated by.
+        xid (str, kwargs): The **xid** for the Case.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = IndicatorModel(**kwargs)
-        self._nested_field_name = 'associatedIndicators'
-        self._nested_filter = 'has_indicator'
-        self.type_ = 'Indicator'
+        self._model: CaseModel = CaseModel(**kwargs)
+        self._nested_field_name = 'cases'
+        self._nested_filter = 'has_case'
+        self.type_ = 'Case'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
-        return ApiEndpoints.INDICATORS.value
+        return ApiEndpoints.CASES.value
 
     @property
-    def model(self) -> 'IndicatorModel':
+    def model(self) -> CaseModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['IndicatorModel', dict]):
+    def model(self, data: dict | CaseModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
-        type_ = self.model.type
-
-        return {'type': type_, 'id': self.model.id, 'value': self.model.summary}
+        type_ = self.type_
 
-    def remove(self, params: Optional[dict] = None):
-        """Remove a nested object."""
-        method = 'PUT'
-        unique_id = self._calculate_unique_id()
-
-        # validate an id is available
-        self._validate_id(unique_id.get('value'), '')
-
-        body = json.dumps(
-            {
-                self._nested_field_name: {
-                    'data': [{unique_id.get('filter'): unique_id.get('value')}],
-                    'mode': 'delete',
-                }
-            }
-        )
-
-        # get the unique id value for id, xid, summary, etc ...
-        parent_api_endpoint = self._parent_data.get('api_endpoint')
-        parent_unique_id = self._parent_data.get('unique_id')
-        url = f'{parent_api_endpoint}/{parent_unique_id}'
-
-        # validate parent an id is available
-        self._validate_id(parent_unique_id, url)
-
-        self._request(
-            method=method,
-            url=url,
-            body=body,
-            headers={'content-type': 'application/json'},
-            params=params,
-        )
-
-        return self.request
+        return {'type': type_, 'id': self.model.id, 'value': self.model.name}
 
     @property
-    def associated_artifacts(self) -> Iterator['Artifact']:
+    def artifacts(self) -> Generator['Artifact', None, None]:
         """Yield Artifact from Artifacts."""
         # first-party
         from tcex.api.tc.v3.artifacts.artifact import Artifacts
 
-        yield from self._iterate_over_sublist(Artifacts)
+        yield from self._iterate_over_sublist(Artifacts)  # type: ignore
 
     @property
-    def associated_cases(self) -> Iterator['Case']:
+    def associated_cases(self) -> Generator[Self, None, None]:
         """Yield Case from Cases."""
-        # first-party
-        from tcex.api.tc.v3.cases.case import Cases
-
-        yield from self._iterate_over_sublist(Cases)
+        # Ensure the current item is not returned as a association
+        for case in self._iterate_over_sublist(Cases):  # type: ignore
+            if case.model.id == self.model.id:
+                continue
+            yield case  # type: ignore
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator['Group', None, None]:
         """Yield Group from Groups."""
         # first-party
         from tcex.api.tc.v3.groups.group import Groups
 
-        yield from self._iterate_over_sublist(Groups)
+        yield from self._iterate_over_sublist(Groups)  # type: ignore
 
     @property
-    def associated_indicators(self) -> Iterator['Indicator']:
+    def associated_indicators(self) -> Generator['Indicator', None, None]:
         """Yield Indicator from Indicators."""
-        # Ensure the current item is not returned as a association
-        for indicator in self._iterate_over_sublist(Indicators):
-            if indicator.model.id == self.model.id:
-                continue
-            yield indicator
+        # first-party
+        from tcex.api.tc.v3.indicators.indicator import Indicators
+
+        yield from self._iterate_over_sublist(Indicators)  # type: ignore
 
     @property
-    def attributes(self) -> Iterator['IndicatorAttribute']:
+    def attributes(self) -> Generator['CaseAttribute', None, None]:
         """Yield Attribute from Attributes."""
         # first-party
-        from tcex.api.tc.v3.indicator_attributes.indicator_attribute import IndicatorAttributes
+        from tcex.api.tc.v3.case_attributes.case_attribute import CaseAttributes
 
-        yield from self._iterate_over_sublist(IndicatorAttributes)
+        yield from self._iterate_over_sublist(CaseAttributes)  # type: ignore
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
-        """Yield SecurityLabel from SecurityLabels."""
+    def notes(self) -> Generator['Note', None, None]:
+        """Yield Note from Notes."""
         # first-party
-        from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
+        from tcex.api.tc.v3.notes.note import Notes
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(Notes)  # type: ignore
 
     @property
-    def tags(self) -> Iterator['Tag']:
+    def tags(self) -> Generator['Tag', None, None]:
         """Yield Tag from Tags."""
         # first-party
         from tcex.api.tc.v3.tags.tag import Tags
 
-        yield from self._iterate_over_sublist(Tags)
+        yield from self._iterate_over_sublist(Tags)  # type: ignore
 
-    def stage_associated_case(self, data: Union[dict, 'ObjectABC', 'CaseModel']):
-        """Stage case on the object."""
+    @property
+    def tasks(self) -> Generator['Task', None, None]:
+        """Yield Task from Tasks."""
+        # first-party
+        from tcex.api.tc.v3.tasks.task import Tasks
+
+        yield from self._iterate_over_sublist(Tasks)  # type: ignore
+
+    def stage_artifact(self, data: dict | ObjectABC | ArtifactModel):
+        """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = CaseModel(**data)
+            data = ArtifactModel(**data)
 
-        if not isinstance(data, CaseModel):
-            raise RuntimeError('Invalid type passed in to stage_associated_case')
+        if not isinstance(data, ArtifactModel):
+            raise RuntimeError('Invalid type passed in to stage_artifact')
         data._staged = True
-        self.model.associated_cases.data.append(data)
+        self.model.artifacts.data.append(data)  # type: ignore
 
-    def stage_associated_artifact(self, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
+    # pylint: disable=redefined-builtin
+    def stage_assignee(self, type: str, data: dict | ObjectABC | UserModel | UserGroupModel):
         """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
+        elif type.lower() == 'user' and isinstance(data, dict):
+            data = UserModel(**data)
+        elif type.lower() == 'group' and isinstance(data, dict):
+            data = UserGroupModel(**data)
+
+        if not isinstance(data, UserModel | UserGroupModel):
+            raise RuntimeError('Invalid type passed in to stage_assignee')
+        data._staged = True
+        self.model.assignee._staged = True
+        self.model.assignee.type = type
+        self.model.assignee.data = data  # type: ignore
+
+    def stage_associated_case(self, data: dict | ObjectABC | CaseModel):
+        """Stage case on the object."""
+        if isinstance(data, ObjectABC):
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = ArtifactModel(**data)
+            data = CaseModel(**data)
 
-        if not isinstance(data, ArtifactModel):
-            raise RuntimeError('Invalid type passed in to stage_associated_artifact')
+        if not isinstance(data, CaseModel):
+            raise RuntimeError('Invalid type passed in to stage_associated_case')
         data._staged = True
-        self.model.associated_artifacts.data.append(data)
+        self.model.associated_cases.data.append(data)  # type: ignore
 
-    def stage_associated_group(self, data: Union[dict, 'ObjectABC', 'GroupModel']):
+    def stage_associated_group(self, data: dict | ObjectABC | GroupModel):
         """Stage group on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = GroupModel(**data)
 
         if not isinstance(data, GroupModel):
             raise RuntimeError('Invalid type passed in to stage_associated_group')
         data._staged = True
-        self.model.associated_groups.data.append(data)
+        self.model.associated_groups.data.append(data)  # type: ignore
+
+    def stage_associated_indicator(self, data: dict | ObjectABC | IndicatorModel):
+        """Stage indicator on the object."""
+        if isinstance(data, ObjectABC):
+            data = data.model  # type: ignore
+        elif isinstance(data, dict):
+            data = IndicatorModel(**data)
+
+        if not isinstance(data, IndicatorModel):
+            raise RuntimeError('Invalid type passed in to stage_associated_indicator')
+        data._staged = True
+        self.model.associated_indicators.data.append(data)  # type: ignore
 
-    def stage_attribute(self, data: Union[dict, 'ObjectABC', 'IndicatorAttributeModel']):
+    def stage_attribute(self, data: dict | ObjectABC | CaseAttributeModel):
         """Stage attribute on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = IndicatorAttributeModel(**data)
+            data = CaseAttributeModel(**data)
 
-        if not isinstance(data, IndicatorAttributeModel):
+        if not isinstance(data, CaseAttributeModel):
             raise RuntimeError('Invalid type passed in to stage_attribute')
         data._staged = True
-        self.model.attributes.data.append(data)
+        self.model.attributes.data.append(data)  # type: ignore
 
-    def stage_file_action(self, data: Union[dict, 'ObjectABC', 'FileActionModel']):
-        """Stage file_action on the object."""
+    def stage_note(self, data: dict | ObjectABC | NoteModel):
+        """Stage note on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = FileActionModel(**data)
+            data = NoteModel(**data)
 
-        if not isinstance(data, FileActionModel):
-            raise RuntimeError('Invalid type passed in to stage_file_action')
+        if not isinstance(data, NoteModel):
+            raise RuntimeError('Invalid type passed in to stage_note')
         data._staged = True
-        data.indicator._staged = True
-        self.model.file_actions.data.append(data)
+        self.model.notes.data.append(data)  # type: ignore
 
-    def stage_file_occurrence(self, data: Union[dict, 'ObjectABC', 'FileOccurrenceModel']):
-        """Stage file_occurrence on the object."""
+    def stage_tag(self, data: dict | ObjectABC | TagModel):
+        """Stage tag on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = FileOccurrenceModel(**data)
+            data = TagModel(**data)
 
-        if not isinstance(data, FileOccurrenceModel):
-            raise RuntimeError('Invalid type passed in to stage_file_occurrence')
+        if not isinstance(data, TagModel):
+            raise RuntimeError('Invalid type passed in to stage_tag')
         data._staged = True
-        self.model.file_occurrences.data.append(data)
+        self.model.tags.data.append(data)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
-        """Stage security_label on the object."""
+    def stage_task(self, data: dict | ObjectABC | TaskModel):
+        """Stage task on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = SecurityLabelModel(**data)
+            data = TaskModel(**data)
 
-        if not isinstance(data, SecurityLabelModel):
-            raise RuntimeError('Invalid type passed in to stage_security_label')
+        if not isinstance(data, TaskModel):
+            raise RuntimeError('Invalid type passed in to stage_task')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.tasks.data.append(data)  # type: ignore
 
-    def stage_tag(self, data: Union[dict, 'ObjectABC', 'TagModel']):
-        """Stage tag on the object."""
+    def stage_user_access(self, data: dict | ObjectABC | UserModel):
+        """Stage user on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
-            data = TagModel(**data)
+            data = UserModel(**data)
 
-        if not isinstance(data, TagModel):
-            raise RuntimeError('Invalid type passed in to stage_tag')
+        if not isinstance(data, UserModel):
+            raise RuntimeError('Invalid type passed in to stage_user_access')
         data._staged = True
-        self.model.tags.data.append(data)
+        self.model.user_access.data.append(data)  # type: ignore
+
+
+class Cases(ObjectCollectionABC):
+    """Cases Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = CasesModel(**kwargs)
+        self.type_ = 'cases'
+
+    def __iter__(self) -> Iterator[Case]:
+        """Return CM objects."""
+        return self.iterate(base_class=Case)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.CASES.value
+
+    @property
+    def filter(self) -> CaseFilter:
+        """Return the type specific filter object."""
+        return CaseFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/indicators/indicator_model.py` & `tcex-4.0.0/tcex/api/tc/v3/indicators/indicator_model.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,64 +1,23 @@
-"""Indicator / Indicators Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class IndicatorsModel(
-    BaseModel,
-    title='Indicators Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Indicators Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['IndicatorModel']] = Field(
-        [],
-        description='The data for the Indicators.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class IndicatorDataModel(
-    BaseModel,
-    title='Indicator Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Indicators Data Model"""
-
-    data: Optional[List['IndicatorModel']] = Field(
-        [],
-        description='The data for the Indicators.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class IndicatorModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Indicator Model',
     validate_assignment=True,
 ):
     """Indicator Model"""
 
     _associated_type = PrivateAttr(True)
@@ -76,407 +35,407 @@
     active_locked: bool = Field(
         None,
         description='Lock the indicator active value?',
         methods=['POST', 'PUT'],
         read_only=False,
         title='activeLocked',
     )
-    address: Optional[str] = Field(
+    address: str | None = Field(
         None,
         applies_to=['EmailAddress'],
         conditional_required=['EmailAddress'],
         description=(
             'The email address associated with this indicator (EmailAddress specific summary '
             'field).'
         ),
         methods=['POST'],
         read_only=False,
         title='address',
     )
-    associated_artifacts: Optional['ArtifactsModel'] = Field(
+    associated_artifacts: 'ArtifactsModel' = Field(
         None,
         description='A list of Artifacts associated with this Indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedArtifacts',
     )
-    associated_cases: Optional['CasesModel'] = Field(
+    associated_cases: 'CasesModel' = Field(
         None,
         description='A list of Cases associated with this Indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedCases',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of groups that this indicator is associated with.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    associated_indicators: Optional['IndicatorsModel'] = Field(
+    associated_indicators: 'IndicatorsModel' = Field(
         None,
         description='A list of indicators associated with this indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedIndicators',
     )
-    attributes: Optional['IndicatorAttributesModel'] = Field(
+    attributes: 'IndicatorAttributesModel' = Field(
         None,
         description='A list of Attributes corresponding to the Indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='attributes',
     )
-    confidence: Optional[int] = Field(
+    confidence: int | None = Field(
         None,
         description='The indicator threat confidence.',
         methods=['POST', 'PUT'],
         maximum=100,
         minimum=0,
         read_only=False,
         title='confidence',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         allow_mutation=False,
         description='The indicator description text.',
         read_only=True,
         title='description',
     )
     dns_active: bool = Field(
         None,
         applies_to=['Host'],
         description='Is dns active for the indicator?',
         methods=['POST', 'PUT'],
         read_only=False,
         title='dnsActive',
     )
-    dns_resolution: Optional[dict] = Field(
+    dns_resolution: dict | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Host', 'Address'],
         conditional_required=['Host', 'Address'],
         description='Dns resolution data for the Host or Address indicator.',
         read_only=True,
         title='dnsResolution',
     )
-    enrichment: Optional[dict] = Field(
+    enrichment: dict | None = Field(
         None,
         allow_mutation=False,
         description='Enrichment data.',
         read_only=True,
         title='enrichment',
     )
     false_positive_reported_by_user: bool = Field(
         None,
         allow_mutation=False,
         description='Has a false positive been reported by this user for this indicator today?',
         read_only=True,
         title='falsePositiveReportedByUser',
     )
-    false_positives: Optional[int] = Field(
+    false_positives: int | None = Field(
         None,
         allow_mutation=False,
         description='The number of false positives reported for this indicator.',
         read_only=True,
         title='falsePositives',
     )
-    file_actions: Optional['FileActionsModel'] = Field(
+    file_actions: 'FileActionsModel' = Field(
         None,
         description='The type of file action associated with this indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='fileActions',
     )
-    file_occurrences: Optional['FileOccurrencesModel'] = Field(
+    file_occurrences: 'FileOccurrencesModel' = Field(
         None,
         description='A list of file occurrences associated with this indicator.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='fileOccurrences',
     )
-    geo_location: Optional[dict] = Field(
+    geo_location: dict | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Host', 'Address'],
         conditional_required=['Host', 'Address'],
         description='Geographical localization of the Host or Address indicator.',
         read_only=True,
         title='geoLocation',
     )
-    host_name: Optional[str] = Field(
+    host_name: str | None = Field(
         None,
         applies_to=['Host'],
         conditional_required=['Host'],
         description='The host name of the indicator (Host specific summary field).',
         methods=['POST'],
         read_only=False,
         title='hostName',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    investigation_links: Optional[dict] = Field(
+    investigation_links: dict | None = Field(
         None,
         allow_mutation=False,
         description=(
             'Resource links that provide additional information to assist in investigation.'
         ),
         read_only=True,
         title='investigationLinks',
     )
-    ip: Optional[str] = Field(
+    ip: str | None = Field(
         None,
         applies_to=['Address'],
         conditional_required=['Address'],
         description=(
             'The ip address associated with this indicator (Address specific summary field).'
         ),
         methods=['POST'],
         read_only=False,
         title='ip',
     )
-    last_false_positive: Optional[datetime] = Field(
+    last_false_positive: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time of the last false positive reported for this indicator.',
         read_only=True,
         title='lastFalsePositive',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the indicator was last modified.',
         read_only=True,
         title='lastModified',
     )
-    last_observed: Optional[datetime] = Field(
+    last_observed: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the indicator was last observed.',
         read_only=True,
         title='lastObserved',
     )
-    legacy_link: Optional[str] = Field(
+    legacy_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the legacy ThreatConnect details page for this entity.',
         read_only=True,
         title='legacyLink',
     )
-    md5: Optional[str] = Field(
+    md5: str | None = Field(
         None,
         applies_to=['File'],
         description='The md5 associated with this indicator (File specific summary field).',
         methods=['POST', 'PUT'],
         read_only=False,
         title='md5',
     )
-    mode: Optional[str] = Field(
+    mode: str | None = Field(
         None,
         applies_to=['File'],
         description='The operation to perform on the file hashes (delete | merge).',
         methods=['POST', 'PUT'],
         read_only=False,
         title='mode',
     )
-    observations: Optional[int] = Field(
+    observations: int | None = Field(
         None,
         allow_mutation=False,
         description='The number of times this indicator has been observed.',
         read_only=True,
         title='observations',
     )
-    owner_id: Optional[int] = Field(
+    owner_id: int | None = Field(
         None,
         description='The id of the Organization, Community, or Source that the item belongs to.',
         methods=['POST'],
         read_only=False,
         title='ownerId',
     )
-    owner_name: Optional[str] = Field(
+    owner_name: str | None = Field(
         None,
         description='The name of the Organization, Community, or Source that the item belongs to.',
         methods=['POST'],
         read_only=False,
         title='ownerName',
     )
     private_flag: bool = Field(
         None,
         description='Is this indicator private?',
         methods=['POST', 'PUT'],
         read_only=False,
         title='privateFlag',
     )
-    rating: Optional[int] = Field(
+    rating: int | None = Field(
         None,
         description='The indicator threat rating.',
         methods=['POST', 'PUT'],
         maximum=5,
         minimum=0,
         read_only=False,
         title='rating',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    sha1: Optional[str] = Field(
+    sha1: str | None = Field(
         None,
         applies_to=['File'],
         description='The sha1 associated with this indicator (File specific summary field).',
         methods=['POST', 'PUT'],
         read_only=False,
         title='sha1',
     )
-    sha256: Optional[str] = Field(
+    sha256: str | None = Field(
         None,
         applies_to=['File'],
         description='The sha256 associated with this indicator (File specific summary field).',
         methods=['POST', 'PUT'],
         read_only=False,
         title='sha256',
     )
-    size: Optional[int] = Field(
+    size: int | None = Field(
         None,
         applies_to=['File'],
         description='The size of the file.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='size',
     )
-    source: Optional[str] = Field(
+    source: str | None = Field(
         None,
         allow_mutation=False,
         description='The source for this indicator.',
         read_only=True,
         title='source',
     )
-    summary: Optional[str] = Field(
+    summary: str | None = Field(
         None,
         allow_mutation=False,
         description='The indicator summary.',
         read_only=True,
         title='summary',
     )
-    tags: Optional['TagsModel'] = Field(
+    tags: 'TagsModel' = Field(
         None,
         description=(
             'A list of Tags corresponding to the item (NOTE: Setting this parameter will replace '
             'any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='tags',
     )
-    text: Optional[str] = Field(
+    text: str | None = Field(
         None,
         applies_to=['URL'],
         conditional_required=['URL'],
         description='The url text value of the indicator (Url specific summary field).',
         methods=['POST'],
         read_only=False,
         title='text',
     )
-    threat_assess_confidence: Optional[float] = Field(
+    threat_assess_confidence: float | None = Field(
         None,
         allow_mutation=False,
         description='The Threat Assess confidence for this indicator.',
         read_only=True,
         title='threatAssessConfidence',
     )
-    threat_assess_rating: Optional[float] = Field(
+    threat_assess_rating: float | None = Field(
         None,
         allow_mutation=False,
         description='The Threat Assess rating for this indicator.',
         read_only=True,
         title='threatAssessRating',
     )
-    threat_assess_score: Optional[int] = Field(
+    threat_assess_score: int | None = Field(
         None,
         allow_mutation=False,
         description='The Threat Assess score for this indicator.',
         read_only=True,
         title='threatAssessScore',
     )
-    threat_assess_score_false_positive: Optional[int] = Field(
+    threat_assess_score_false_positive: int | None = Field(
         None,
         allow_mutation=False,
         description='The Threat Assess score for false positives related to this indicator.',
         read_only=True,
         title='threatAssessScoreFalsePositive',
     )
-    threat_assess_score_observed: Optional[int] = Field(
+    threat_assess_score_observed: int | None = Field(
         None,
         allow_mutation=False,
         description='The Threat Assess score observed for this indicator.',
         read_only=True,
         title='threatAssessScoreObserved',
     )
-    tracked_users: Optional[dict] = Field(
+    tracked_users: dict | None = Field(
         None,
         allow_mutation=False,
         description='List of tracked users and their observation and false positive stats.',
         read_only=True,
         title='trackedUsers',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The **type** for the Indicator.',
         methods=['POST', 'PUT'],
         min_length=1,
         read_only=False,
         title='type',
     )
-    value1: Optional[str] = Field(
+    value1: str | None = Field(
         None,
         description='Custom Indicator summary field value1.',
         methods=['POST'],
         read_only=False,
         title='value1',
     )
-    value2: Optional[str] = Field(
+    value2: str | None = Field(
         None,
         description='Custom Indicator summary field value2.',
         methods=['POST'],
         read_only=False,
         title='value2',
     )
-    value3: Optional[str] = Field(
+    value3: str | None = Field(
         None,
         description='Custom Indicator summary field value3.',
         methods=['POST'],
         read_only=False,
         title='value3',
     )
-    web_link: Optional[str] = Field(
+    web_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the ThreatConnect details page for this entity.',
         read_only=True,
         title='webLink',
     )
-    whois: Optional[dict] = Field(
+    whois: dict | None = Field(
         None,
         allow_mutation=False,
         applies_to=['Host'],
         conditional_required=['Host'],
         description='The whois data for the indicator.',
         read_only=True,
         title='whois',
@@ -486,69 +445,109 @@
         applies_to=['Host'],
         description='Is whois active for the indicator?',
         methods=['POST', 'PUT'],
         read_only=False,
         title='whoisActive',
     )
 
-    @validator('associated_artifacts', always=True)
+    @validator('associated_artifacts', always=True, pre=True)
     def _validate_artifacts(cls, v):
         if not v:
-            return ArtifactsModel()
+            return ArtifactsModel()  # type: ignore
         return v
 
-    @validator('associated_cases', always=True)
+    @validator('associated_cases', always=True, pre=True)
     def _validate_cases(cls, v):
         if not v:
-            return CasesModel()
+            return CasesModel()  # type: ignore
         return v
 
-    @validator('file_actions', always=True)
+    @validator('file_actions', always=True, pre=True)
     def _validate_file_actions(cls, v):
         if not v:
-            return FileActionsModel()
+            return FileActionsModel()  # type: ignore
         return v
 
-    @validator('file_occurrences', always=True)
+    @validator('file_occurrences', always=True, pre=True)
     def _validate_file_occurrences(cls, v):
         if not v:
-            return FileOccurrencesModel()
+            return FileOccurrencesModel()  # type: ignore
         return v
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
-    @validator('attributes', always=True)
+    @validator('attributes', always=True, pre=True)
     def _validate_indicator_attributes(cls, v):
         if not v:
-            return IndicatorAttributesModel()
+            return IndicatorAttributesModel()  # type: ignore
         return v
 
-    @validator('associated_indicators', always=True)
+    @validator('associated_indicators', always=True, pre=True)
     def _validate_indicators(cls, v):
         if not v:
-            return IndicatorsModel()
+            return IndicatorsModel()  # type: ignore
         return v
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('tags', always=True)
+    @validator('tags', always=True, pre=True)
     def _validate_tags(cls, v):
         if not v:
-            return TagsModel()
+            return TagsModel()  # type: ignore
         return v
 
 
+class IndicatorDataModel(
+    BaseModel,
+    title='Indicator Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Indicators Data Model"""
+
+    data: list[IndicatorModel] | None = Field(
+        [],
+        description='The data for the Indicators.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class IndicatorsModel(
+    BaseModel,
+    title='Indicators Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Indicators Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[IndicatorModel] | None = Field(
+        [],
+        description='The data for the Indicators.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactsModel
 from tcex.api.tc.v3.cases.case_model import CasesModel
 from tcex.api.tc.v3.file_actions.file_action_model import FileActionsModel
 from tcex.api.tc.v3.file_occurrences.file_occurrence_model import FileOccurrencesModel
 from tcex.api.tc.v3.groups.group_model import GroupsModel
 from tcex.api.tc.v3.indicator_attributes.indicator_attribute_model import IndicatorAttributesModel
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/notes/note.py` & `tcex-4.0.0/tcex/api/tc/v3/notes/note.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,93 +1,54 @@
-"""Note / Notes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.notes.note_filter import NoteFilter
 from tcex.api.tc.v3.notes.note_model import NoteModel, NotesModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 
 
-class Notes(ObjectCollectionABC):
-    """Notes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = NotesModel(**kwargs)
-        self.type_ = 'notes'
-
-    def __iter__(self) -> 'Note':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Note)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.NOTES.value
-
-    @property
-    def filter(self) -> 'NoteFilter':
-        """Return the type specific filter object."""
-        return NoteFilter(self.tql)
-
-
 class Note(ObjectABC):
     """Notes Object.
 
     Args:
         artifact_id (int, kwargs): The ID of the Artifact on which to apply the Note.
         case_id (int, kwargs): The **case id** for the Note.
         case_xid (str, kwargs): The **case xid** for the Note.
         task_id (int, kwargs): The ID of the Task on which to apply the Note.
         task_xid (str, kwargs): The XID of the Task on which to apply the Note.
         text (str, kwargs): The **text** for the Note.
         workflow_event_id (int, kwargs): The ID of the Event on which to apply the Note.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = NoteModel(**kwargs)
+        self._model: NoteModel = NoteModel(**kwargs)
         self._nested_field_name = 'notes'
         self._nested_filter = 'has_note'
         self.type_ = 'Note'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.NOTES.value
 
     @property
-    def model(self) -> 'NoteModel':
+    def model(self) -> NoteModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['NoteModel', dict]):
+    def model(self, data: dict | NoteModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -96,7 +57,46 @@
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.summary}
+
+
+class Notes(ObjectCollectionABC):
+    """Notes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = NotesModel(**kwargs)
+        self.type_ = 'notes'
+
+    def __iter__(self) -> Iterator[Note]:
+        """Return CM objects."""
+        return self.iterate(base_class=Note)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.NOTES.value
+
+    @property
+    def filter(self) -> NoteFilter:
+        """Return the type specific filter object."""
+        return NoteFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/notes/note_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/attribute_types/attribute_type_filter.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,132 +1,132 @@
-"""Note TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
-from tcex.api.tc.v3.tql.tql import Tql
-from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class NoteFilter(FilterABC):
-    """Filter Object for Notes"""
+class AttributeTypeFilter(FilterABC):
+    """Filter Object for AttributeTypes"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.NOTES.value
+        return ApiEndpoints.ATTRIBUTE_TYPES.value
 
-    def artifact_id(self, operator: Enum, artifact_id: int):
-        """Filter Artifact ID based on **artifactId** keyword.
+    def associated_type(self, operator: Enum, associated_type: list | str):
+        """Filter Associated Type based on **associatedType** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            artifact_id: The ID of the artifact this note is associated with.
+            associated_type: The data type(s) that the attribute type can be used for.
         """
-        self._tql.add_filter('artifactId', operator, artifact_id, TqlType.INTEGER)
+        if isinstance(associated_type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def author(self, operator: Enum, author: str):
-        """Filter Author based on **author** keyword.
+        self._tql.add_filter('associatedType', operator, associated_type, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            author: The account login of the user who wrote the note.
-        """
-        self._tql.add_filter('author', operator, author, TqlType.STRING)
-
-    def case_id(self, operator: Enum, case_id: int):
-        """Filter Case ID based on **caseId** keyword.
+    def description(self, operator: Enum, description: list | str):
+        """Filter Description based on **description** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_id: The ID of the case this note is associated with.
+            description: The description of the attribute type.
         """
-        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
+        if isinstance(description, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def date_added(self, operator: Enum, date_added: str):
-        """Filter Date Added based on **dateAdded** keyword.
+        self._tql.add_filter('description', operator, description, TqlType.STRING)
+
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            date_added: The date the note was written.
+            id: The ID of the attribute type.
         """
-        date_added = self.utils.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
-
-    @property
-    def has_artifact(self):
-        """Return **ArtifactFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
-
-        artifacts = ArtifactFilter(Tql())
-        self._tql.add_filter('hasArtifact', TqlOperator.EQ, artifacts, TqlType.SUB_QUERY)
-        return artifacts
-
-    @property
-    def has_case(self):
-        """Return **CaseFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.cases.case_filter import CaseFilter
-
-        cases = CaseFilter(Tql())
-        self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
-        return cases
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    @property
-    def has_task(self):
-        """Return **TaskFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.tasks.task_filter import TaskFilter
-
-        tasks = TaskFilter(Tql())
-        self._tql.add_filter('hasTask', TqlOperator.EQ, tasks, TqlType.SUB_QUERY)
-        return tasks
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+    def maxsize(self, operator: Enum, maxsize: int | list):
+        """Filter Maxsize based on **maxsize** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the case.
+            maxsize: Max size of the attribute.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        if isinstance(maxsize, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def last_modified(self, operator: Enum, last_modified: str):
-        """Filter Last Modified based on **lastModified** keyword.
+        self._tql.add_filter('maxsize', operator, maxsize, TqlType.INTEGER)
+
+    def name(self, operator: Enum, name: list | str):
+        """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_modified: The date the note was last modified.
+            name: The name of the attribute type.
         """
-        last_modified = self.utils.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('lastModified', operator, last_modified, TqlType.STRING)
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('name', operator, name, TqlType.STRING)
 
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
+    def owner(self, operator: Enum, owner: int | list):
+        """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            summary: Text of the first 100 characters of the note.
+            owner: The owner ID of the attribute type.
         """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def task_id(self, operator: Enum, task_id: int):
-        """Filter Task ID based on **taskId** keyword.
+        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
+
+    def owner_name(self, operator: Enum, owner_name: list | str):
+        """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            task_id: The ID of the task this note is associated with.
+            owner_name: The owner name of the attribute type.
         """
-        self._tql.add_filter('taskId', operator, task_id, TqlType.INTEGER)
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def workflow_event_id(self, operator: Enum, workflow_event_id: int):
-        """Filter Workflow Event ID based on **workflowEventId** keyword.
+    def system(self, operator: Enum, system: bool):
+        """Filter SystemLevel based on **system** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            workflow_event_id: The ID of the workflow event this note is associated with.
+            system: A flag to show System level attributes (TRUE) or owner-specific ones only
+                (FALSE).
         """
-        self._tql.add_filter('workflowEventId', operator, workflow_event_id, TqlType.INTEGER)
+        self._tql.add_filter('system', operator, system, TqlType.BOOLEAN)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/notes/note_model.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,226 +1,199 @@
-"""Note / Notes Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
-class NotesModel(
-    BaseModel,
-    title='Notes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Notes Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['NoteModel']] = Field(
-        [],
-        description='The data for the Notes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class NoteDataModel(
-    BaseModel,
-    title='Note Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Notes Data Model"""
-
-    data: Optional[List['NoteModel']] = Field(
-        [],
-        description='The data for the Notes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-
-class NoteModel(
+class WorkflowEventModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
-    title='Note Model',
+    title='WorkflowEvent Model',
     validate_assignment=True,
 ):
-    """Note Model"""
+    """Workflow_Event Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    artifact: Optional['ArtifactModel'] = Field(
-        None,
-        allow_mutation=False,
-        description='The **artifact** for the Note.',
-        read_only=True,
-        title='artifact',
-    )
-    artifact_id: Optional[int] = Field(
-        None,
-        description='The ID of the Artifact on which to apply the Note.',
-        methods=['POST'],
-        read_only=False,
-        title='artifactId',
-    )
-    author: Optional[str] = Field(
-        None,
-        allow_mutation=False,
-        description='The **author** for the Note.',
-        read_only=True,
-        title='author',
-    )
-    case_id: Optional[int] = Field(
+    case_id: int | None = Field(
         None,
-        description='The **case id** for the Note.',
+        description='The **case id** for the Workflow_Event.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseXid',
         title='caseId',
     )
-    case_xid: Optional[str] = Field(
+    case_xid: str | None = Field(
         None,
-        description='The **case xid** for the Note.',
+        description='The **case xid** for the Workflow_Event.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseId',
         title='caseXid',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
-        description='The **date added** for the Note.',
+        description='The **date added** for the Workflow_Event.',
         read_only=True,
         title='dateAdded',
     )
-    edited: bool = Field(
+    deleted: bool = Field(
         None,
         allow_mutation=False,
-        description='The **edited** for the Note.',
+        description='The **deleted** for the Workflow_Event.',
         read_only=True,
-        title='edited',
+        title='deleted',
     )
-    id: Optional[int] = Field(
+    deleted_reason: str | None = Field(
         None,
-        description='The ID of the item.',
-        read_only=True,
-        title='id',
+        description='The reason for deleting the event (required input for DELETE operation only).',
+        methods=['DELETE'],
+        max_length=255,
+        min_length=1,
+        read_only=False,
+        title='deletedReason',
     )
-    last_modified: Optional[datetime] = Field(
+    event_date: datetime | None = Field(
         None,
-        allow_mutation=False,
-        description='The **last modified** for the Note.',
-        read_only=True,
-        title='lastModified',
+        description='The time that the Event is logged.',
+        methods=['POST', 'PUT'],
+        read_only=False,
+        title='eventDate',
     )
-    parent_case: Optional['CaseModel'] = Field(
+    id: int | None = Field(
         None,
-        allow_mutation=False,
-        description='The **parent case** for the Note.',
+        description='The ID of the item.',
         read_only=True,
-        title='parentCase',
+        title='id',
     )
-    summary: Optional[str] = Field(
+    link: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **summary** for the Note.',
+        description='The **link** for the Workflow_Event.',
         read_only=True,
-        title='summary',
+        title='link',
     )
-    task: Optional['TaskModel'] = Field(
+    link_text: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **task** for the Note.',
+        description='The **link text** for the Workflow_Event.',
         read_only=True,
-        title='task',
+        title='linkText',
     )
-    task_id: Optional[int] = Field(
+    notes: 'NotesModel' = Field(
         None,
-        description='The ID of the Task on which to apply the Note.',
-        methods=['POST'],
+        description='A list of Notes corresponding to the Event.',
+        methods=['POST', 'PUT'],
         read_only=False,
-        title='taskId',
+        title='notes',
     )
-    task_xid: Optional[str] = Field(
+    parent_case: 'CaseModel' = Field(
         None,
-        description='The XID of the Task on which to apply the Note.',
-        methods=['POST'],
-        read_only=False,
-        title='taskXid',
+        allow_mutation=False,
+        description='The **parent case** for the Workflow_Event.',
+        read_only=True,
+        title='parentCase',
     )
-    text: Optional[str] = Field(
+    summary: str | None = Field(
         None,
-        description='The **text** for the Note.',
+        description='The **summary** for the Workflow_Event.',
         methods=['POST', 'PUT'],
-        max_length=65500,
+        max_length=255,
         min_length=1,
         read_only=False,
-        title='text',
+        title='summary',
     )
-    workflow_event: Optional['WorkflowEventModel'] = Field(
+    system_generated: bool = Field(
         None,
         allow_mutation=False,
-        description='The **workflow event** for the Note.',
+        description='The **system generated** for the Workflow_Event.',
         read_only=True,
-        title='workflowEvent',
+        title='systemGenerated',
     )
-    workflow_event_id: Optional[int] = Field(
+    user: 'UserModel' = Field(
         None,
-        description='The ID of the Event on which to apply the Note.',
-        methods=['POST'],
-        read_only=False,
-        title='workflowEventId',
+        allow_mutation=False,
+        description='The **user** for the Workflow_Event.',
+        read_only=True,
+        title='user',
     )
 
-    @validator('artifact', always=True)
-    def _validate_artifact(cls, v):
-        if not v:
-            return ArtifactModel()
-        return v
-
-    @validator('parent_case', always=True)
+    @validator('parent_case', always=True, pre=True)
     def _validate_case(cls, v):
         if not v:
-            return CaseModel()
+            return CaseModel()  # type: ignore
         return v
 
-    @validator('task', always=True)
-    def _validate_task(cls, v):
+    @validator('notes', always=True, pre=True)
+    def _validate_notes(cls, v):
         if not v:
-            return TaskModel()
+            return NotesModel()  # type: ignore
         return v
 
-    @validator('workflow_event', always=True)
-    def _validate_workflow_event(cls, v):
+    @validator('user', always=True, pre=True)
+    def _validate_user(cls, v):
         if not v:
-            return WorkflowEventModel()
+            return UserModel()  # type: ignore
         return v
 
 
+class WorkflowEventDataModel(
+    BaseModel,
+    title='WorkflowEvent Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Workflow_Events Data Model"""
+
+    data: list[WorkflowEventModel] | None = Field(
+        [],
+        description='The data for the WorkflowEvents.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class WorkflowEventsModel(
+    BaseModel,
+    title='WorkflowEvents Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Workflow_Events Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[WorkflowEventModel] | None = Field(
+        [],
+        description='The data for the WorkflowEvents.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
-from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
 from tcex.api.tc.v3.cases.case_model import CaseModel
-from tcex.api.tc.v3.tasks.task_model import TaskModel
-from tcex.api.tc.v3.workflow_events.workflow_event_model import WorkflowEventModel
+from tcex.api.tc.v3.notes.note_model import NotesModel
+from tcex.api.tc.v3.security.users.user_model import UserModel
 
 # add forward references
-NoteDataModel.update_forward_refs()
-NoteModel.update_forward_refs()
-NotesModel.update_forward_refs()
+WorkflowEventDataModel.update_forward_refs()
+WorkflowEventModel.update_forward_refs()
+WorkflowEventsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/object_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/object_abc.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,93 +1,93 @@
-"""Case Management Abstract Base Class"""
+"""TcEx Framework Module"""
 # standard library
 import logging
-
-# import inspect
-# import re
 from abc import ABC
-from typing import TYPE_CHECKING, Dict, List, Optional, Union
+from collections.abc import Generator
+from typing import Self
 
 # third-party
-from requests import Response
+from requests import Response, Session
 from requests.exceptions import ProxyError, RetryError
 
 # first-party
+from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
-from tcex.backports import cached_property
-from tcex.exit.error_codes import handle_error
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.api.tc.v3.v3_types import V3Type
+from tcex.api.tc.v3.v3_model_abc import V3ModelABC
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class ObjectABC(ABC):
     """Object Abstract Base Class
 
     This class is a base class for Object classes that use
     multi-inheritance with a pydantic BaseModel class. To ensure
     properties are not added to the model both @property and @setter
     methods are used.
     """
 
-    def __init__(self, session):
-        """Initialize class properties."""
-        self._session = session
+    def __init__(self, session: Session):
+        """Initialize instance properties."""
+        self._session: Session = session
 
         # properties
         self._parent_data = {}
         self._remove_objects = {
             'associations': [],
             'attributes': [],
             'securityLabels': [],
             'tags': [],
         }
-        self.utils = Utils()
-        self.log = logger
-        self.request = None
+        self.util = Util()
+        self.log = _logger
+        self.request: Response
 
         # define/overwritten in child class
-        self._model = None
-        self._nested_field_name = None
-        self._nested_filter = None
-        self.type_ = None
+        self._model: V3ModelABC
+        self._nested_field_name: str | None = None
+        self._nested_filter: str | None = None
+        self.type_: str
 
     @property
-    def _api_endpoint(self) -> dict:  # pragma: no cover
+    def _api_endpoint(self) -> str:  # pragma: no cover
         """Return the type specific API endpoint."""
         raise NotImplementedError('Child class must implement this property.')
 
-    def _calculate_unique_id(self):
+    def _calculate_unique_id(self) -> dict[str, int | str]:
         if self.model.id:
             return {'filter': 'id', 'value': self.model.id}
 
-        if hasattr(self.model, 'xid') and self.model.xid:
-            return {'filter': 'xid', 'value': self.model.xid}
+        if hasattr(self.model, 'xid') and self.model.xid:  # type: ignore
+            return {'filter': 'xid', 'value': self.model.xid}  # type: ignore
 
         if self.type_.lower() in ['indicator']:
-            return {'filter': 'summary', 'value': self.model.summary}
+            return {'filter': 'summary', 'value': self.model.summary}  # type: ignore
 
         return {}
 
-    def _iterate_over_sublist(self, sublist_type: object) -> 'V3Type':
+    def _iterate_over_sublist(
+        self, sublist_type: ObjectCollectionABC
+    ) -> Generator[Self, None, None]:
         """Iterate over any nested collections."""
-        sublist = sublist_type(session=self._session)
+        sublist = sublist_type(session=self._session)  # type: ignore
 
         # determine the filter type and value based on the available object fields.
         unique_id_data = self._calculate_unique_id()
 
         # add the filter (e.g., group.has_indicator.id(TqlOperator.EQ, 123)) for the parent object.
-        getattr(getattr(sublist.filter, self._nested_filter), unique_id_data.get('filter'))(
-            TqlOperator.EQ, unique_id_data.get('value')
-        )
+        getattr(
+            getattr(sublist.filter, self._nested_filter),  # type: ignore
+            unique_id_data.get('filter'),  # type: ignore
+        )(TqlOperator.EQ, unique_id_data.get('value'))
 
         # return the sub object, injecting the parent data
         for obj in sublist:
             obj._parent_data = {
                 'api_endpoint': self._api_endpoint,
                 'type': self.type_,
                 'unique_id': unique_id_data.get('value'),
@@ -95,18 +95,18 @@
             yield obj
         self.request = sublist.request
 
     def _request(
         self,
         method: str,
         url: str,
-        body: Optional[Union[bytes, str]] = None,
-        params: Optional[dict] = None,
-        headers: Optional[dict] = None,
-    ) -> 'Response':
+        body: bytes | str | None = None,
+        params: dict | None = None,
+        headers: dict | None = None,
+    ):
         """Handle standard request with error checking."""
         try:
             self.request = self._session.request(
                 method, url, data=body, headers=headers, params=params
             )
             if isinstance(self.request.request.body, str) and len(self.request.request.body) < 1000:
                 self.log.debug(f'feature=api-tc-v3, request-body={self.request.request.body}')
@@ -123,51 +123,50 @@
 
         content_type = self.request.headers.get('Content-Type')
         if content_type == 'application/json' and not self.success(self.request):
             err = self.request.text or self.request.reason
             handle_error(
                 code=952,
                 message_values=[
-                    self.request.request.method.upper(),
+                    (self.request.request.method or '').upper(),
                     self.request.status_code,
                     err,
                     self.request.url,
                 ],
             )
 
         # log content for debugging
         if content_type == 'application/json':
             self.log_response_text(self.request)
 
     @staticmethod
-    def _validate_id(id_: int, url: str):
+    def _validate_id(id_: int | str | None, url: str):
         """Raise exception is id is not provided."""
         if not id_:  # pragma: no cover
             message = '{"message": "No ID provided.", "status": "Error"}'
             handle_error(code=952, message_values=['GET', '404', message, url])
 
     @property
-    def as_entity(self) -> Dict[str, str]:  # pragma: no cover
+    def as_entity(self) -> dict[str, str]:  # pragma: no cover
         """Return the entity representation of the object."""
         raise NotImplementedError('Child class must implement this property.')
 
     @property
-    def available_fields(self) -> List[str]:
+    def available_fields(self) -> list[str]:
         """Return the available query param field names for this object."""
-        return [fd.get('name') for fd in self.fields]
+        return [fd['name'] for fd in self.fields]
 
-    def create(self, params: Optional[dict] = None) -> 'Response':
+    def create(self, params: dict | None = None) -> Response:
         """Create or Update the Case Management object.
 
         This is determined based on if the id is already present in the object.
         """
         method = 'POST'
         body = self.model.gen_body_json(method=method)
-
-        params = self.gen_params(params or {})
+        params = self.gen_params(params) if params else None
         self._request(
             method,
             self.url(method),
             body,
             headers={'content-type': 'application/json'},
             params=params,
         )
@@ -176,15 +175,15 @@
         response_json = self.request.json()
 
         # update the model with the response from the API
         self.model = type(self.model)(**response_json.get('data'))
 
         return self.request
 
-    def delete(self, params: Optional[dict] = None):
+    def delete(self, params: dict | None = None):
         """Delete the object."""
         method = 'DELETE'
         body = self.model.gen_body_json(method)
 
         # get the unique id value for id, xid, summary, etc ...
         unique_id = self._calculate_unique_id().get('value')
 
@@ -192,43 +191,43 @@
         self._validate_id(unique_id, self.url(method, unique_id))
 
         self._request(method, self.url(method, unique_id), body, params=params)
 
         return self.request
 
     @cached_property
-    def fields(self) -> Dict[str, str]:
+    def fields(self) -> list[dict[str, str]]:
         """Return the field data for this object."""
-        _fields = {}
+        _fields = []
         r = self._session.options(f'{self._api_endpoint}/fields', params={})
         if r.ok:
-            _fields = r.json().get('data', {})
+            _fields = r.json().get('data', [])
         return _fields
 
-    def gen_params(self, params: List[dict]) -> List[dict]:
+    def gen_params(self, params: dict) -> dict:
         """Return appropriate params values."""
         # convert all keys to camel case
-        params = {self.utils.snake_to_camel(k): v for k, v in params.items()}
+        params = {self.util.snake_to_camel(k): v for k, v in params.items()}
 
         # special parameter for indicators to enable the return the the indicator fields
         # (value1, value2, value3) on std-custom/custom-custom indicator types.
         if self.type_ == 'Indicator':
             params.setdefault('fields', []).append('genericCustomIndicatorValues')
 
         # add fields parameter if provided
         if '_all_' in params.get('fields', []):
             params['fields'] = list(self.available_fields)
 
         return params
 
     def get(
         self,
-        object_id: Optional[int] = None,
-        params: Optional[dict] = None,
-    ) -> 'V3Type':
+        object_id: int | None = None,
+        params: dict | None = None,
+    ) -> Response:
         """Get the Case Management Object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
@@ -240,24 +239,23 @@
 
         Args:
             object_id: The unique id of the object to be returned.
             params: Dict of the params to be sent while retrieving the Artifacts objects.
         """
         method = 'GET'
         object_id = object_id or self.model.id
-        params = params or {}
+        params = self.gen_params(params) if params else None
 
         # get the unique id value for id, xid, summary, etc ...
         unique_id = self._calculate_unique_id().get('value')
 
         # validate an id is available
         self._validate_id(unique_id, self.url(method, unique_id))
 
         body = self.model.gen_body_json(method)
-        params = self.gen_params(params)
         self._request(method, self.url(method, unique_id), body, params)
 
         # update model
         self.model = self.request.json().get('data')
 
         return self.request
 
@@ -265,37 +263,37 @@
         """Log the response text."""
         response_text = 'response text: (text to large to log)'
         if len(response.content) < 5000:  # check size of content for performance
             response_text = response.text
         self.log.debug(f'feature=api-tc-v3, response-body={response_text}')
 
     @property
-    def model(self) -> 'V3Type':
+    def model(self) -> V3ModelABC:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['V3Type', dict]):
+    def model(self, data: dict | V3ModelABC):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @cached_property
-    def properties(self) -> dict:
+    def properties(self) -> dict[str, dict | list]:
         """Return defined API properties for the current object.
 
         This property is used in testing API consistency.
         """
-        _properties = []
+        _properties = {}
         try:
             r = self._session.options(
                 self._api_endpoint,
                 params={'show': 'readOnly'},
                 headers={'content-type': 'application/json'},
             )
             if r.ok:
@@ -329,29 +327,29 @@
                     status = False
             except Exception:  # pragma: no cover
                 status = False
         else:
             status = False
         return status
 
-    def update(self, mode: Optional[str] = None, params: Optional[dict] = None) -> 'Response':
+    def update(self, mode: str | None = None, params: dict | None = None) -> Response:
         """Create or Update the Case Management object.
 
         This is determined based on if the id is already present in the object.
         """
         method = 'PUT'
         body = self.model.gen_body_json(method=method, mode=mode)
+        params = self.gen_params(params) if params else None
 
         # get the unique id value for id, xid, summary, etc ...
         unique_id = self._calculate_unique_id().get('value')
 
         # validate an id is available
         self._validate_id(unique_id, self.url(method))
 
-        params = self.gen_params(params or {})
         self._request(
             method,
             self.url(method, unique_id=unique_id),
             body,
             headers={'content-type': 'application/json'},
             params=params,
         )
@@ -359,13 +357,13 @@
         # get the response data from nested data object or full response
         response_json = self.request.json()
 
         self.model = type(self.model)(**response_json.get('data'))
 
         return self.request
 
-    def url(self, method: str, unique_id: Optional[str] = None) -> str:
+    def url(self, method: str, unique_id: int | str | None = None) -> str:
         """Return the proper URL."""
         unique_id = unique_id or self._calculate_unique_id().get('value')
         if method in ['DELETE', 'GET', 'PUT']:
             return f'{self._api_endpoint}/{unique_id}'
         return self._api_endpoint
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/object_collection_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/object_collection_abc.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,91 +1,71 @@
-"""Case Management Collection Abstract Base Class"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 from abc import ABC
-from typing import TYPE_CHECKING, Optional, Union
+from collections.abc import Generator
+from typing import Any
 
 # third-party
-from requests import Response
+from requests import Response, Session
 from requests.exceptions import ProxyError, RetryError
 
 # first-party
 from tcex.api.tc.v3.tql.tql import Tql
-from tcex.backports import cached_property
-from tcex.exit.error_codes import handle_error
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # third-party
-    from pydantic import BaseModel
-
-    # first-party
-    from tcex.api.tc.v3.artifacts.artifact import Artifact
-    from tcex.api.tc.v3.cases.case import Case
-    from tcex.api.tc.v3.notes.note import Note
-    from tcex.api.tc.v3.tags.tag import Tag
-    from tcex.api.tc.v3.tasks.task import Task
-    from tcex.api.tc.v3.workflow_events.workflow_event import WorkflowEvent
-
-    # Case Management Types
-    CaseManagementType = Union[
-        Artifact,
-        Case,
-        Note,
-        Tag,
-        Task,
-        WorkflowEvent,
-    ]
+from tcex.exit.error_code import handle_error
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class ObjectCollectionABC(ABC):
     """Case Management Collection Abstract Base Class
 
     This class is a base class for Case Management collections that use
     multi-inheritance with a pydantic BaseModel class. To ensure
     properties are not added to the model both @property and @setter
     methods are used.
     """
 
     def __init__(
         self,
-        session,
-        tql_filters: Optional[list] = None,  # This will be removed!
-        params: Optional[dict] = None,
+        session: Session,
+        tql_filters: list | None = None,  # This will be removed!
+        params: dict | None = None,
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self._params = params or {}
         self._tql_filters = tql_filters or []
 
         # properties
         self._session = session
-        self.log = logger
-        self.request = None
+        self.log = _logger
+        self.request: Response
         self.tql = Tql()
         self._model = None
         self.type_ = None  # defined in child class
-        self.utils = Utils()
+        self.util = Util()
 
     def __len__(self) -> int:
         """Return the length of the collection."""
         parameters = self._params.copy()
         parameters['resultLimit'] = 1
         parameters['count'] = True
         tql_string = self.tql.raw_tql
         if not self.tql.raw_tql:
             tql_string = self.tql.as_str
         if tql_string:
             parameters['tql'] = tql_string
 
         # convert all keys to camel case
         for k, v in list(parameters.items()):
-            k = self.utils.snake_to_camel(k)
+            k = self.util.snake_to_camel(k)
             # if result_limit and resultLimit both show up use the proper cased version
             if k not in parameters:
                 parameters[k] = v
 
         self._request(
             'GET',
             self._api_endpoint,
@@ -100,17 +80,17 @@
         """Return filter method."""
         raise NotImplementedError('Child class must implement this method.')
 
     def _request(
         self,
         method: str,
         url: str,
-        body: Optional[Union[bytes, str]] = None,
-        params: Optional[dict] = None,
-        headers: Optional[dict] = None,
+        body: bytes | str | None = None,
+        params: dict | None = None,
+        headers: dict | None = None,
     ):
         """Handle standard request with error checking."""
         try:
             self.request = self._session.request(
                 method, url, data=body, headers=headers, params=params
             )
             self.log.debug(f'feature=api-tc-v3, request-body={self.request.request.body}')
@@ -126,15 +106,15 @@
             )
 
         if not self.success(self.request):
             err = self.request.text or self.request.reason
             handle_error(
                 code=950,
                 message_values=[
-                    self.request.request.method.upper(),
+                    self.request.request.method,
                     self.request.status_code,
                     err,
                     self.request.url,
                 ],
             )
 
         # log content for debugging
@@ -159,30 +139,30 @@
 
     @model.setter
     def model(self, data):
         self._model = type(self.model)(**data)
 
     def iterate(
         self,
-        base_class: 'BaseModel',
-        api_endpoint: Optional[str] = None,
-        params: Optional[dict] = None,
-    ) -> 'CaseManagementType':
+        base_class: Any,
+        api_endpoint: str | None = None,
+        params: dict | None = None,
+    ) -> Generator:
         """Iterate over CM/TI objects."""
         url = api_endpoint or self._api_endpoint
         params = params or self.params
 
         # special parameter for indicators to enable the return the the indicator fields
         # (value1, value2, value3) on std-custom/custom-custom indicator types.
         if self.type_ == 'Indicators' and api_endpoint is None:
             params.setdefault('fields', []).append('genericCustomIndicatorValues')
 
         # convert all keys to camel case
         for k, v in list(params.items()):
-            k = self.utils.snake_to_camel(k)
+            k = self.util.snake_to_camel(k)
             params[k] = v
 
         tql_string = self.tql.raw_tql or self.tql.as_str
 
         if tql_string:
             params['tql'] = tql_string
 
@@ -199,28 +179,20 @@
             params = {}
 
             response = self.request.json()
             data = response.get('data', [])
             url = response.pop('next', None)
 
             for result in data:
-                yield base_class(session=self._session, **result)
+                yield base_class(session=self._session, **result)  # type: ignore
 
             # break out of pagination if no next url present in results
             if not url:
                 break
 
-    # @staticmethod
-    # def list_as_dict(added_items: 'CaseManagementType') -> dict:
-    #     """Return the dict representation of the case management collection object."""
-    #     as_dict = {'data': []}
-    #     for item in added_items:
-    #         as_dict['data'].append(item.as_dict)
-    #     return as_dict
-
     @property
     def params(self) -> dict:
         """Return the parameters of the case management object collection."""
         return self._params
 
     @params.setter
     def params(self, params: dict):
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/assignee_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/assignee_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,39 +1,37 @@
-"""ThreatConnect Assignee Module"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import Optional, Union
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 
 # third-party
 from pydantic import Field, validator
 
 # first-party
 from tcex.api.tc.v3.security.assignee_user_group_model import AssigneeUserGroupModel
 from tcex.api.tc.v3.security.assignee_user_model import AssigneeUserModel
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
 class AssigneeModel(
     V3ModelABC,
     title='User Data Model',
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """Assignee Model"""
 
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The **Type** for the Assignee.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='type',
     )
 
-    data: Optional[Union[AssigneeUserModel, AssigneeUserGroupModel]] = Field(
+    data: AssigneeUserModel | AssigneeUserGroupModel | None = Field(
         None,
         description='The **Data** for the Assignee.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='data',
     )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/assignee_user_group_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/assignee_user_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-"""ThreatConnect Assignee Module"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import Optional
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 
 # third-party
 from pydantic import Field
 
 # first-party
-from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel
-from tcex.utils import Utils
+from tcex.api.tc.v3.security.users.user_model import UserModel
+from tcex.util import Util
 
 
-class AssigneeUserGroupModel(
-    UserGroupModel,
-    title='Assignee User Group Model',
-    alias_generator=Utils().snake_to_camel,
+class AssigneeUserModel(
+    UserModel,
+    title='Assignee User Model',
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """Assignee Model"""
 
-    name: Optional[str] = Field(
+    user_name: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **name** for the User_Group.',
+        description='The **user name** for the User.',
         methods=['POST', 'PUT'],
         read_only=False,
-        title='name',
+        title='userName',
     )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/assignee_user_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/assignee_user_group_model.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-"""ThreatConnect Assignee Module"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import Optional
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 
 # third-party
 from pydantic import Field
 
 # first-party
-from tcex.api.tc.v3.security.users.user_model import UserModel
-from tcex.utils import Utils
+from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel
+from tcex.util import Util
 
 
-class AssigneeUserModel(
-    UserModel,
-    title='Assignee User Model',
-    alias_generator=Utils().snake_to_camel,
+class AssigneeUserGroupModel(
+    UserGroupModel,
+    title='Assignee User Group Model',
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """Assignee Model"""
 
-    user_name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **user name** for the User.',
+        description='The **name** for the User_Group.',
         methods=['POST', 'PUT'],
         read_only=False,
-        title='userName',
+        title='name',
     )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/owner_role.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,55 @@
-"""OwnerRole / OwnerRoles Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.owner_roles.owner_role_filter import OwnerRoleFilter
 from tcex.api.tc.v3.security.owner_roles.owner_role_model import OwnerRoleModel, OwnerRolesModel
 
 
+class OwnerRole(ObjectABC):
+    """OwnerRoles Object."""
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(kwargs.pop('session', None))
+
+        # properties
+        self._model: OwnerRoleModel = OwnerRoleModel(**kwargs)
+        self._nested_field_name = 'ownerRoles'
+        self._nested_filter = 'has_owner_role'
+        self.type_ = 'Owner Role'
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.OWNER_ROLES.value
+
+    @property
+    def model(self) -> OwnerRoleModel:
+        """Return the model data."""
+        return self._model
+
+    @model.setter
+    def model(self, data: dict | OwnerRoleModel):
+        """Create model using the provided data."""
+        if isinstance(data, type(self.model)):
+            # provided data is already a model, nothing required to change
+            self._model = data
+        elif isinstance(data, dict):
+            # provided data is raw response, load the model
+            self._model = type(self.model)(**data)
+        else:
+            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
 class OwnerRoles(ObjectCollectionABC):
     """OwnerRoles Collection.
 
     # Example of params input
     {
         'result_limit': 100,  # Limit the retrieved results.
         'result_start': 10,  # Starting count used for pagination.
@@ -23,63 +59,27 @@
     Args:
         session (Session): Session object configured with TC API Auth.
         tql_filters (list): List of TQL filters.
         params (dict): Additional query params (see example above).
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(
             kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
         )
         self._model = OwnerRolesModel(**kwargs)
         self.type_ = 'owner_roles'
 
-    def __iter__(self) -> 'OwnerRole':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=OwnerRole)
+    def __iter__(self) -> Iterator[OwnerRole]:
+        """Return CM objects."""
+        return self.iterate(base_class=OwnerRole)  # type: ignore
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.OWNER_ROLES.value
 
     @property
-    def filter(self) -> 'OwnerRoleFilter':
+    def filter(self) -> OwnerRoleFilter:
         """Return the type specific filter object."""
         return OwnerRoleFilter(self.tql)
-
-
-class OwnerRole(ObjectABC):
-    """OwnerRoles Object."""
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(kwargs.pop('session', None))
-
-        # properties
-        self._model = OwnerRoleModel(**kwargs)
-        self._nested_field_name = 'ownerRoles'
-        self._nested_filter = 'has_owner_role'
-        self.type_ = 'Owner Role'
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.OWNER_ROLES.value
-
-    @property
-    def model(self) -> 'OwnerRoleModel':
-        """Return the model data."""
-        return self._model
-
-    @model.setter
-    def model(self, data: Union['OwnerRoleModel', dict]):
-        """Create model using the provided data."""
-        if isinstance(data, type(self.model)):
-            # provided data is already a model, nothing required to change
-            self._model = data
-        elif isinstance(data, dict):
-            # provided data is raw response, load the model
-            self._model = type(self.model)(**data)
-        else:
-            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/owner_roles/owner_role_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role_model.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,63 +1,20 @@
-"""Owner_Role / Owner_Roles Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class OwnerRolesModel(
-    BaseModel,
-    title='OwnerRoles Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Owner_Roles Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['OwnerRoleModel']] = Field(
-        [],
-        description='The data for the OwnerRoles.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class OwnerRoleDataModel(
-    BaseModel,
-    title='OwnerRole Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Owner_Roles Data Model"""
-
-    data: Optional[List['OwnerRoleModel']] = Field(
-        [],
-        description='The data for the OwnerRoles.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class OwnerRoleModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='OwnerRole Model',
     validate_assignment=True,
 ):
     """Owner_Role Model"""
 
     _associated_type = PrivateAttr(False)
@@ -75,61 +32,101 @@
     comm_role: bool = Field(
         None,
         allow_mutation=False,
         description='The **comm role** for the Owner_Role.',
         read_only=True,
         title='commRole',
     )
-    description_admin: Optional[str] = Field(
+    description_admin: str | None = Field(
         None,
         allow_mutation=False,
         description='The **description admin** for the Owner_Role.',
         read_only=True,
         title='descriptionAdmin',
     )
-    description_comm: Optional[str] = Field(
+    description_comm: str | None = Field(
         None,
         allow_mutation=False,
         description='The **description comm** for the Owner_Role.',
         read_only=True,
         title='descriptionComm',
     )
-    description_org: Optional[str] = Field(
+    description_org: str | None = Field(
         None,
         allow_mutation=False,
         description='The **description org** for the Owner_Role.',
         read_only=True,
         title='descriptionOrg',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
         description='The **name** for the Owner_Role.',
         read_only=True,
         title='name',
     )
     org_role: bool = Field(
         None,
         allow_mutation=False,
         description='The **org role** for the Owner_Role.',
         read_only=True,
         title='orgRole',
     )
-    version: Optional[int] = Field(
+    version: int | None = Field(
         None,
         allow_mutation=False,
         description='The **version** for the Owner_Role.',
         read_only=True,
         title='version',
     )
 
 
+class OwnerRoleDataModel(
+    BaseModel,
+    title='OwnerRole Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Owner_Roles Data Model"""
+
+    data: list[OwnerRoleModel] | None = Field(
+        [],
+        description='The data for the OwnerRoles.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class OwnerRolesModel(
+    BaseModel,
+    title='OwnerRoles Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Owner_Roles Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[OwnerRoleModel] | None = Field(
+        [],
+        description='The data for the OwnerRoles.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 OwnerRoleDataModel.update_forward_refs()
 OwnerRoleModel.update_forward_refs()
 OwnerRolesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/owners/owner.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owners/owner.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,55 @@
-"""Owner / Owners Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.owners.owner_filter import OwnerFilter
 from tcex.api.tc.v3.security.owners.owner_model import OwnerModel, OwnersModel
 
 
+class Owner(ObjectABC):
+    """Owners Object."""
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(kwargs.pop('session', None))
+
+        # properties
+        self._model: OwnerModel = OwnerModel(**kwargs)
+        self._nested_field_name = 'owners'
+        self._nested_filter = 'has_owner'
+        self.type_ = 'Owner'
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.OWNERS.value
+
+    @property
+    def model(self) -> OwnerModel:
+        """Return the model data."""
+        return self._model
+
+    @model.setter
+    def model(self, data: dict | OwnerModel):
+        """Create model using the provided data."""
+        if isinstance(data, type(self.model)):
+            # provided data is already a model, nothing required to change
+            self._model = data
+        elif isinstance(data, dict):
+            # provided data is raw response, load the model
+            self._model = type(self.model)(**data)
+        else:
+            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
 class Owners(ObjectCollectionABC):
     """Owners Collection.
 
     # Example of params input
     {
         'result_limit': 100,  # Limit the retrieved results.
         'result_start': 10,  # Starting count used for pagination.
@@ -23,63 +59,27 @@
     Args:
         session (Session): Session object configured with TC API Auth.
         tql_filters (list): List of TQL filters.
         params (dict): Additional query params (see example above).
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(
             kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
         )
         self._model = OwnersModel(**kwargs)
         self.type_ = 'owners'
 
-    def __iter__(self) -> 'Owner':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Owner)
+    def __iter__(self) -> Iterator[Owner]:
+        """Return CM objects."""
+        return self.iterate(base_class=Owner)  # type: ignore
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.OWNERS.value
 
     @property
-    def filter(self) -> 'OwnerFilter':
+    def filter(self) -> OwnerFilter:
         """Return the type specific filter object."""
         return OwnerFilter(self.tql)
-
-
-class Owner(ObjectABC):
-    """Owners Object."""
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(kwargs.pop('session', None))
-
-        # properties
-        self._model = OwnerModel(**kwargs)
-        self._nested_field_name = 'owners'
-        self._nested_filter = 'has_owner'
-        self.type_ = 'Owner'
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.OWNERS.value
-
-    @property
-    def model(self) -> 'OwnerModel':
-        """Return the model data."""
-        return self._model
-
-    @model.setter
-    def model(self, data: Union['OwnerModel', dict]):
-        """Create model using the provided data."""
-        if isinstance(data, type(self.model)):
-            # provided data is already a model, nothing required to change
-            self._model = data
-        elif isinstance(data, dict):
-            # provided data is raw response, load the model
-            self._model = type(self.model)(**data)
-        else:
-            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/owners/owner_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owners/owner_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,268 +1,265 @@
-"""Owner / Owners Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class OwnersModel(
-    BaseModel,
-    title='Owners Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Owners Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['OwnerModel']] = Field(
-        [],
-        description='The data for the Owners.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class OwnerDataModel(
-    BaseModel,
-    title='Owner Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Owners Data Model"""
-
-    data: Optional[List['OwnerModel']] = Field(
-        [],
-        description='The data for the Owners.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class OwnerModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Owner Model',
     validate_assignment=True,
 ):
     """Owner Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
         description='The name of the owner.',
         read_only=True,
         title='name',
     )
-    owner_role: Optional[str] = Field(
+    owner_role: str | None = Field(
         None,
         allow_mutation=False,
         description='The user\'s role within the owner.',
         read_only=True,
         title='ownerRole',
     )
-    perm_apps: Optional[str] = Field(
+    perm_apps: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to run/edit Apps.',
         read_only=True,
         title='permApps',
     )
-    perm_artifact: Optional[str] = Field(
+    perm_artifact: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access an Artifact.',
         read_only=True,
         title='permArtifact',
     )
-    perm_attribute: Optional[str] = Field(
+    perm_attribute: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Attributes.',
         read_only=True,
         title='permAttribute',
     )
-    perm_attribute_type: Optional[str] = Field(
+    perm_attribute_type: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Attribute Types.',
         read_only=True,
         title='permAttributeType',
     )
-    perm_case_tag: Optional[str] = Field(
+    perm_case_tag: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access a Tag.',
         read_only=True,
         title='permCaseTag',
     )
-    perm_comment: Optional[str] = Field(
+    perm_comment: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access a Comment.',
         read_only=True,
         title='permComment',
     )
-    perm_copy_data: Optional[str] = Field(
+    perm_copy_data: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Copy Data.',
         read_only=True,
         title='permCopyData',
     )
-    perm_group: Optional[str] = Field(
+    perm_group: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Groups.',
         read_only=True,
         title='permGroup',
     )
-    perm_indicator: Optional[str] = Field(
+    perm_indicator: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Indicators.',
         read_only=True,
         title='permIndicator',
     )
-    perm_invite: Optional[str] = Field(
+    perm_invite: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to modify friends.',
         read_only=True,
         title='permInvite',
     )
-    perm_members: Optional[str] = Field(
+    perm_members: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Members.',
         read_only=True,
         title='permMembers',
     )
-    perm_playbooks: Optional[str] = Field(
+    perm_playbooks: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used with Playbooks.',
         read_only=True,
         title='permPlaybooks',
     )
-    perm_playbooks_execute: Optional[str] = Field(
+    perm_playbooks_execute: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to execute Playbooks.',
         read_only=True,
         title='permPlaybooksExecute',
     )
-    perm_post: Optional[str] = Field(
+    perm_post: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Posts.',
         read_only=True,
         title='permPost',
     )
-    perm_publish: Optional[str] = Field(
+    perm_publish: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access Publications.',
         read_only=True,
         title='permPublish',
     )
-    perm_security_label: Optional[str] = Field(
+    perm_security_label: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Security Labels.',
         read_only=True,
         title='permSecurityLabel',
     )
-    perm_settings: Optional[str] = Field(
+    perm_settings: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Organization Settings.',
         read_only=True,
         title='permSettings',
     )
-    perm_tag: Optional[str] = Field(
+    perm_tag: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Tags.',
         read_only=True,
         title='permTag',
     )
-    perm_task: Optional[str] = Field(
+    perm_task: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access a Task.',
         read_only=True,
         title='permTask',
     )
-    perm_timeline: Optional[str] = Field(
+    perm_timeline: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access a Timeline.',
         read_only=True,
         title='permTimeline',
     )
-    perm_track: Optional[str] = Field(
+    perm_track: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Tracks.',
         read_only=True,
         title='permTrack',
     )
-    perm_users: Optional[str] = Field(
+    perm_users: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to User Settings.',
         read_only=True,
         title='permUsers',
     )
-    perm_victim: Optional[str] = Field(
+    perm_victim: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission is used for access to Victims.',
         read_only=True,
         title='permVictim',
     )
-    perm_workflow_template: Optional[str] = Field(
+    perm_workflow_template: str | None = Field(
         None,
         allow_mutation=False,
         description='Permission used to access a Workflow Templates.',
         read_only=True,
         title='permWorkflowTemplate',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         allow_mutation=False,
         description='The owner type. Possible values: Organization, Community, Source.',
         read_only=True,
         title='type',
     )
 
 
+class OwnerDataModel(
+    BaseModel,
+    title='Owner Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Owners Data Model"""
+
+    data: list[OwnerModel] | None = Field(
+        [],
+        description='The data for the Owners.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class OwnersModel(
+    BaseModel,
+    title='Owners Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Owners Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[OwnerModel] | None = Field(
+        [],
+        description='The data for the Owners.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 OwnerDataModel.update_forward_refs()
 OwnerModel.update_forward_refs()
 OwnersModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/security.py` & `tcex-4.0.0/tcex/api/tc/v3/security/security.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Security"""
+"""TcEx Framework Module"""
 # third-party
 from requests import Session
 
 # first-party
 from tcex.api.tc.v3.security.owner_roles.owner_role import OwnerRole, OwnerRoles
 from tcex.api.tc.v3.security.owners.owner import Owner, Owners
 from tcex.api.tc.v3.security.system_roles.system_role import SystemRole, SystemRoles
@@ -14,49 +14,49 @@
     """Security
 
     Args:
         session: An configured instance of request.Session with TC API Auth.
     """
 
     def __init__(self, session: Session):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self.session = session
 
-    def owner_role(self, **kwargs) -> 'OwnerRole':
+    def owner_role(self, **kwargs) -> OwnerRole:
         """Return a instance of Owner Role object."""
         return OwnerRole(session=self.session, **kwargs)
 
-    def owner_roles(self, **kwargs) -> 'OwnerRoles':
+    def owner_roles(self, **kwargs) -> OwnerRoles:
         """Return a instance of Owner Roles object."""
         return OwnerRoles(session=self.session, **kwargs)
 
-    def owner(self, **kwargs) -> 'Owner':
+    def owner(self, **kwargs) -> Owner:
         """Return a instance of Owner object."""
         return Owner(session=self.session, **kwargs)
 
-    def owners(self, **kwargs) -> 'Owners':
+    def owners(self, **kwargs) -> Owners:
         """Return a instance of Owners object."""
         return Owners(session=self.session, **kwargs)
 
-    def system_role(self, **kwargs) -> 'SystemRole':
+    def system_role(self, **kwargs) -> SystemRole:
         """Return a instance of System Role object."""
         return SystemRole(session=self.session, **kwargs)
 
-    def system_roles(self, **kwargs) -> 'SystemRoles':
+    def system_roles(self, **kwargs) -> SystemRoles:
         """Return a instance of System Roles object."""
         return SystemRoles(session=self.session, **kwargs)
 
-    def user_group(self, **kwargs) -> 'UserGroup':
+    def user_group(self, **kwargs) -> UserGroup:
         """Return a instance of User Group object."""
         return UserGroup(session=self.session, **kwargs)
 
-    def user_groups(self, **kwargs) -> 'UserGroups':
+    def user_groups(self, **kwargs) -> UserGroups:
         """Return a instance of User Group object."""
         return UserGroups(session=self.session, **kwargs)
 
-    def user(self, **kwargs) -> 'User':
+    def user(self, **kwargs) -> User:
         """Return a instance of User object."""
         return User(session=self.session, **kwargs)
 
-    def users(self, **kwargs) -> 'Users':
+    def users(self, **kwargs) -> Users:
         """Return a instance of Users object."""
         return Users(session=self.session, **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/system_roles/system_role.py` & `tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,19 +1,55 @@
-"""SystemRole / SystemRoles Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.system_roles.system_role_filter import SystemRoleFilter
 from tcex.api.tc.v3.security.system_roles.system_role_model import SystemRoleModel, SystemRolesModel
 
 
+class SystemRole(ObjectABC):
+    """SystemRoles Object."""
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(kwargs.pop('session', None))
+
+        # properties
+        self._model: SystemRoleModel = SystemRoleModel(**kwargs)
+        self._nested_field_name = 'systemRoles'
+        self._nested_filter = 'has_system_role'
+        self.type_ = 'System Role'
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.SYSTEM_ROLES.value
+
+    @property
+    def model(self) -> SystemRoleModel:
+        """Return the model data."""
+        return self._model
+
+    @model.setter
+    def model(self, data: dict | SystemRoleModel):
+        """Create model using the provided data."""
+        if isinstance(data, type(self.model)):
+            # provided data is already a model, nothing required to change
+            self._model = data
+        elif isinstance(data, dict):
+            # provided data is raw response, load the model
+            self._model = type(self.model)(**data)
+        else:
+            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
 class SystemRoles(ObjectCollectionABC):
     """SystemRoles Collection.
 
     # Example of params input
     {
         'result_limit': 100,  # Limit the retrieved results.
         'result_start': 10,  # Starting count used for pagination.
@@ -23,63 +59,27 @@
     Args:
         session (Session): Session object configured with TC API Auth.
         tql_filters (list): List of TQL filters.
         params (dict): Additional query params (see example above).
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(
             kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
         )
         self._model = SystemRolesModel(**kwargs)
         self.type_ = 'system_roles'
 
-    def __iter__(self) -> 'SystemRole':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=SystemRole)
+    def __iter__(self) -> Iterator[SystemRole]:
+        """Return CM objects."""
+        return self.iterate(base_class=SystemRole)  # type: ignore
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.SYSTEM_ROLES.value
 
     @property
-    def filter(self) -> 'SystemRoleFilter':
+    def filter(self) -> SystemRoleFilter:
         """Return the type specific filter object."""
         return SystemRoleFilter(self.tql)
-
-
-class SystemRole(ObjectABC):
-    """SystemRoles Object."""
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(kwargs.pop('session', None))
-
-        # properties
-        self._model = SystemRoleModel(**kwargs)
-        self._nested_field_name = 'systemRoles'
-        self._nested_filter = 'has_system_role'
-        self.type_ = 'System Role'
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.SYSTEM_ROLES.value
-
-    @property
-    def model(self) -> 'SystemRoleModel':
-        """Return the model data."""
-        return self._model
-
-    @model.setter
-    def model(self, data: Union['SystemRoleModel', dict]):
-        """Create model using the provided data."""
-        if isinstance(data, type(self.model)):
-            # provided data is already a model, nothing required to change
-            self._model = data
-        elif isinstance(data, dict):
-            # provided data is raw response, load the model
-            self._model = type(self.model)(**data)
-        else:
-            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/system_roles/system_role_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/system_roles/system_role_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,63 +1,20 @@
-"""System_Role / System_Roles Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class SystemRolesModel(
-    BaseModel,
-    title='SystemRoles Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """System_Roles Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['SystemRoleModel']] = Field(
-        [],
-        description='The data for the SystemRoles.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class SystemRoleDataModel(
-    BaseModel,
-    title='SystemRole Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """System_Roles Data Model"""
-
-    data: Optional[List['SystemRoleModel']] = Field(
-        [],
-        description='The data for the SystemRoles.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class SystemRoleModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='SystemRole Model',
     validate_assignment=True,
 ):
     """System_Role Model"""
 
     _associated_type = PrivateAttr(False)
@@ -82,26 +39,66 @@
     displayed: bool = Field(
         None,
         allow_mutation=False,
         description='The **displayed** for the System_Role.',
         read_only=True,
         title='displayed',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
         description='The **name** for the System_Role.',
         read_only=True,
         title='name',
     )
 
 
+class SystemRoleDataModel(
+    BaseModel,
+    title='SystemRole Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """System_Roles Data Model"""
+
+    data: list[SystemRoleModel] | None = Field(
+        [],
+        description='The data for the SystemRoles.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class SystemRolesModel(
+    BaseModel,
+    title='SystemRoles Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """System_Roles Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[SystemRoleModel] | None = Field(
+        [],
+        description='The data for the SystemRoles.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 SystemRoleDataModel.update_forward_refs()
 SystemRoleModel.update_forward_refs()
 SystemRolesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/task_assignee_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/task_assignee_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,59 +1,33 @@
-"""ThreatConnect Assignee Module"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
 from enum import Enum
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
 class AssigneeTypes(str, Enum):
     """Enum for install_json.params[].exposePlaybookAs"""
 
     Escalate = 'Escalate'
     Assigned = 'Assigned'
 
 
-class TaskAssigneesModel(
-    BaseModel,
-    title='User Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Task Assignees Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['TaskAssigneeModel']] = Field(
-        [],
-        description='The data for the Groups.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
 class TaskAssigneeModel(
     V3ModelABC,
     title='User Data Model',
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """Task Assignee Model
 
     "data": [
         {
             "id": 219,
@@ -67,39 +41,64 @@
                 "pseudonym": "username",
                 "role": "Administrator"
             }
         }
     ]
     """
 
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Entity was first created.',
         read_only=True,
         title='dateAdded',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    type: Optional[AssigneeTypes] = Field(
+    type: AssigneeTypes | None = Field(
         None,
         description='The **Type** for the Assignee.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='type',
     )
-    user: Optional[UserModel] = Field(
+    user: UserModel | None = Field(
         None,
         description='The **User Data** for the Assignee.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='user',
     )
 
 
+class TaskAssigneesModel(
+    BaseModel,
+    title='User Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Task Assignees Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[TaskAssigneeModel] | None = Field(
+        [],
+        description='The data for the Groups.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 TaskAssigneeModel.update_forward_refs()
 TaskAssigneesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/user_groups/user_group.py` & `tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,55 @@
-"""UserGroup / UserGroups Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.user_groups.user_group_filter import UserGroupFilter
 from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel, UserGroupsModel
 
 
+class UserGroup(ObjectABC):
+    """UserGroups Object."""
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(kwargs.pop('session', None))
+
+        # properties
+        self._model: UserGroupModel = UserGroupModel(**kwargs)
+        self._nested_field_name = 'userGroups'
+        self._nested_filter = 'has_user_group'
+        self.type_ = 'User Group'
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.USER_GROUPS.value
+
+    @property
+    def model(self) -> UserGroupModel:
+        """Return the model data."""
+        return self._model
+
+    @model.setter
+    def model(self, data: dict | UserGroupModel):
+        """Create model using the provided data."""
+        if isinstance(data, type(self.model)):
+            # provided data is already a model, nothing required to change
+            self._model = data
+        elif isinstance(data, dict):
+            # provided data is raw response, load the model
+            self._model = type(self.model)(**data)
+        else:
+            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
 class UserGroups(ObjectCollectionABC):
     """UserGroups Collection.
 
     # Example of params input
     {
         'result_limit': 100,  # Limit the retrieved results.
         'result_start': 10,  # Starting count used for pagination.
@@ -23,63 +59,27 @@
     Args:
         session (Session): Session object configured with TC API Auth.
         tql_filters (list): List of TQL filters.
         params (dict): Additional query params (see example above).
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(
             kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
         )
         self._model = UserGroupsModel(**kwargs)
         self.type_ = 'user_groups'
 
-    def __iter__(self) -> 'UserGroup':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=UserGroup)
+    def __iter__(self) -> Iterator[UserGroup]:
+        """Return CM objects."""
+        return self.iterate(base_class=UserGroup)  # type: ignore
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.USER_GROUPS.value
 
     @property
-    def filter(self) -> 'UserGroupFilter':
+    def filter(self) -> UserGroupFilter:
         """Return the type specific filter object."""
         return UserGroupFilter(self.tql)
-
-
-class UserGroup(ObjectABC):
-    """UserGroups Object."""
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(kwargs.pop('session', None))
-
-        # properties
-        self._model = UserGroupModel(**kwargs)
-        self._nested_field_name = 'userGroups'
-        self._nested_filter = 'has_user_group'
-        self.type_ = 'User Group'
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.USER_GROUPS.value
-
-    @property
-    def model(self) -> 'UserGroupModel':
-        """Return the model data."""
-        return self._model
-
-    @model.setter
-    def model(self, data: Union['UserGroupModel', dict]):
-        """Create model using the provided data."""
-        if isinstance(data, type(self.model)):
-            # provided data is already a model, nothing required to change
-            self._model = data
-        elif isinstance(data, dict):
-            # provided data is raw response, load the model
-            self._model = type(self.model)(**data)
-        else:
-            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/user_groups/user_group_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/user_groups/user_group_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,109 +1,106 @@
-"""User_Group / User_Groups Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class UserGroupsModel(
-    BaseModel,
-    title='UserGroups Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """User_Groups Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['UserGroupModel']] = Field(
-        [],
-        description='The data for the UserGroups.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class UserGroupDataModel(
-    BaseModel,
-    title='UserGroup Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """User_Groups Data Model"""
-
-    data: Optional[List['UserGroupModel']] = Field(
-        [],
-        description='The data for the UserGroups.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class UserGroupModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='UserGroup Model',
     validate_assignment=True,
 ):
     """User_Group Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         allow_mutation=False,
         description='The **description** for the User_Group.',
         read_only=True,
         title='description',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         allow_mutation=False,
         description='The **name** for the User_Group.',
         read_only=True,
         title='name',
     )
-    users: Optional['UsersModel'] = Field(
+    users: 'UsersModel' = Field(
         None,
         allow_mutation=False,
         description='The **users** for the User_Group.',
         read_only=True,
         title='users',
     )
 
-    @validator('users', always=True)
+    @validator('users', always=True, pre=True)
     def _validate_users(cls, v):
         if not v:
-            return UsersModel()
+            return UsersModel()  # type: ignore
         return v
 
 
+class UserGroupDataModel(
+    BaseModel,
+    title='UserGroup Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """User_Groups Data Model"""
+
+    data: list[UserGroupModel] | None = Field(
+        [],
+        description='The data for the UserGroups.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class UserGroupsModel(
+    BaseModel,
+    title='UserGroups Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """User_Groups Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[UserGroupModel] | None = Field(
+        [],
+        description='The data for the UserGroups.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.security.users.user_model import UsersModel
 
 # add forward references
 UserGroupDataModel.update_forward_refs()
 UserGroupModel.update_forward_refs()
 UserGroupsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/users/user.py` & `tcex-4.0.0/tcex/api/tc/v3/security/users/user.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,55 @@
-"""User / Users Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.users.user_filter import UserFilter
 from tcex.api.tc.v3.security.users.user_model import UserModel, UsersModel
 
 
+class User(ObjectABC):
+    """Users Object."""
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(kwargs.pop('session', None))
+
+        # properties
+        self._model: UserModel = UserModel(**kwargs)
+        self._nested_field_name = 'users'
+        self._nested_filter = 'has_user'
+        self.type_ = 'User'
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.USERS.value
+
+    @property
+    def model(self) -> UserModel:
+        """Return the model data."""
+        return self._model
+
+    @model.setter
+    def model(self, data: dict | UserModel):
+        """Create model using the provided data."""
+        if isinstance(data, type(self.model)):
+            # provided data is already a model, nothing required to change
+            self._model = data
+        elif isinstance(data, dict):
+            # provided data is raw response, load the model
+            self._model = type(self.model)(**data)
+        else:
+            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
+
+
 class Users(ObjectCollectionABC):
     """Users Collection.
 
     # Example of params input
     {
         'result_limit': 100,  # Limit the retrieved results.
         'result_start': 10,  # Starting count used for pagination.
@@ -23,63 +59,27 @@
     Args:
         session (Session): Session object configured with TC API Auth.
         tql_filters (list): List of TQL filters.
         params (dict): Additional query params (see example above).
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(
             kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
         )
         self._model = UsersModel(**kwargs)
         self.type_ = 'users'
 
-    def __iter__(self) -> 'User':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=User)
+    def __iter__(self) -> Iterator[User]:
+        """Return CM objects."""
+        return self.iterate(base_class=User)  # type: ignore
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.USERS.value
 
     @property
-    def filter(self) -> 'UserFilter':
+    def filter(self) -> UserFilter:
         """Return the type specific filter object."""
         return UserFilter(self.tql)
-
-
-class User(ObjectABC):
-    """Users Object."""
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(kwargs.pop('session', None))
-
-        # properties
-        self._model = UserModel(**kwargs)
-        self._nested_field_name = 'users'
-        self._nested_filter = 'has_user'
-        self.type_ = 'User'
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.USERS.value
-
-    @property
-    def model(self) -> 'UserModel':
-        """Return the model data."""
-        return self._model
-
-    @model.setter
-    def model(self, data: Union['UserModel', dict]):
-        """Create model using the provided data."""
-        if isinstance(data, type(self.model)):
-            # provided data is already a model, nothing required to change
-            self._model = data
-        elif isinstance(data, dict):
-            # provided data is raw response, load the model
-            self._model = type(self.model)(**data)
-        else:
-            raise RuntimeError(f'Invalid data type: {type(data)} provided.')
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/users/user_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset_filter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,180 +1,206 @@
-"""User TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
+from tcex.api.tc.v3.tql.tql import Tql
+from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class UserFilter(FilterABC):
-    """Filter Object for Users"""
+class VictimAssetFilter(FilterABC):
+    """Filter Object for VictimAssets"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.USERS.value
+        return ApiEndpoints.VICTIM_ASSETS.value
 
-    def disabled(self, operator: Enum, disabled: bool):
-        """Filter Disabled based on **disabled** keyword.
+    def asset(self, operator: Enum, asset: list | str):
+        """Filter Asset based on **asset** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            disabled: A flag indicating whether or not the user's account has been disabled.
+            asset: The sub-type of the victim asset.
         """
-        self._tql.add_filter('disabled', operator, disabled, TqlType.BOOLEAN)
+        if isinstance(asset, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def first_name(self, operator: Enum, first_name: str):
-        """Filter First Name based on **firstName** keyword.
+        self._tql.add_filter('asset', operator, asset, TqlType.STRING)
+
+    def associated_group(self, operator: Enum, associated_group: int | list):
+        """Filter associatedGroup based on **associatedGroup** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            first_name: The first name of the user.
+            associated_group: No description provided.
         """
-        self._tql.add_filter('firstName', operator, first_name, TqlType.STRING)
+        if isinstance(associated_group, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def group_id(self, operator: Enum, group_id: int):
-        """Filter groupID based on **groupId** keyword.
+        self._tql.add_filter('associatedGroup', operator, associated_group, TqlType.INTEGER)
 
-        Args:
-            operator: The operator enum for the filter.
-            group_id: The ID of the group the user belongs to.
-        """
-        self._tql.add_filter('groupId', operator, group_id, TqlType.INTEGER)
+    @property
+    def has_group(self):
+        """Return **GroupFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.groups.group_filter import GroupFilter
+
+        groups = GroupFilter(Tql())
+        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
+        return groups
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    @property
+    def has_indicator(self):
+        """Return **IndicatorFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
+
+        indicators = IndicatorFilter(Tql())
+        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
+        return indicators
+
+    @property
+    def has_victim(self):
+        """Return **VictimFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
+
+        victims = VictimFilter(Tql())
+        self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
+        return victims
+
+    @property
+    def has_victim_asset(self):
+        """Return **VictimAssetFilter** for further filtering."""
+        victim_assets = VictimAssetFilter(Tql())
+        self._tql.add_filter('hasVictimAsset', TqlOperator.EQ, victim_assets, TqlType.SUB_QUERY)
+        return victim_assets
+
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the user.
+            id: The ID of the victim asset.
         """
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def job_function(self, operator: Enum, job_function: str):
-        """Filter Job Function based on **jobFunction** keyword.
+    def owner(self, operator: Enum, owner: int | list):
+        """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            job_function: The user's job function.
+            owner: The owner ID of the victim.
         """
-        self._tql.add_filter('jobFunction', operator, job_function, TqlType.STRING)
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def job_role(self, operator: Enum, job_role: str):
-        """Filter Job Role based on **jobRole** keyword.
+        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-        Args:
-            operator: The operator enum for the filter.
-            job_role: The user's job role.
-        """
-        self._tql.add_filter('jobRole', operator, job_role, TqlType.STRING)
-
-    def last_login(self, operator: Enum, last_login: str):
-        """Filter Last Login based on **lastLogin** keyword.
+    def owner_name(self, operator: Enum, owner_name: list | str):
+        """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_login: The last time the user logged in.
+            owner_name: The owner name of the victim.
         """
-        last_login = self.utils.any_to_datetime(last_login).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('lastLogin', operator, last_login, TqlType.STRING)
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def last_name(self, operator: Enum, last_name: str):
-        """Filter Last Name based on **lastName** keyword.
+        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            last_name: The last name of the user.
-        """
-        self._tql.add_filter('lastName', operator, last_name, TqlType.STRING)
-
-    def last_password_change(self, operator: Enum, last_password_change: str):
-        """Filter Last Password Change based on **lastPasswordChange** keyword.
+    def summary(self, operator: Enum, summary: list | str):
+        """Filter Summary based on **summary** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            last_password_change: The last time the user changed their password.
+            summary: The name of the victim asset.
         """
-        last_password_change = self.utils.any_to_datetime(last_password_change).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('lastPasswordChange', operator, last_password_change, TqlType.STRING)
-
-    def locked(self, operator: Enum, locked: bool):
-        """Filter Locked based on **locked** keyword.
+        if isinstance(summary, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            locked: A flag indicating whether or not the user's account has been locked.
-        """
-        self._tql.add_filter('locked', operator, locked, TqlType.BOOLEAN)
+        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
 
-    def password_reset_required(self, operator: Enum, password_reset_required: bool):
-        """Filter Password Reset Required based on **passwordResetRequired** keyword.
+    def type(self, operator: Enum, type: int | list):  # pylint: disable=redefined-builtin
+        """Filter Type ID based on **type** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            password_reset_required: A flag indicating whether or not the user's password needs to
-                be reset upoin next login.
+            type: The ID of the victim asset type.
         """
-        self._tql.add_filter(
-            'passwordResetRequired', operator, password_reset_required, TqlType.BOOLEAN
-        )
+        if isinstance(type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def pseudonym(self, operator: Enum, pseudonym: str):
-        """Filter Pseudonym based on **pseudonym** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            pseudonym: The user's pseudonym.
-        """
-        self._tql.add_filter('pseudonym', operator, pseudonym, TqlType.STRING)
+        self._tql.add_filter('type', operator, type, TqlType.INTEGER)
 
-    def system_role(self, operator: Enum, system_role: str):
-        """Filter Role Name based on **systemRole** keyword.
+    def type_name(self, operator: Enum, type_name: list | str):
+        """Filter Type Name based on **typeName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            system_role: The system role name defined for the user.
+            type_name: The name of the victim asset type.
         """
-        self._tql.add_filter('systemRole', operator, system_role, TqlType.STRING)
+        if isinstance(type_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def terms_accepted(self, operator: Enum, terms_accepted: bool):
-        """Filter Terms Accepted based on **termsAccepted** keyword.
+        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            terms_accepted: Flag indicating whether user has accepted the current Terms of Service.
-        """
-        self._tql.add_filter('termsAccepted', operator, terms_accepted, TqlType.BOOLEAN)
-
-    def terms_accepted_date(self, operator: Enum, terms_accepted_date: str):
-        """Filter Terms Accepted Date based on **termsAcceptedDate** keyword.
+    def victim_id(self, operator: Enum, victim_id: int | list):
+        """Filter Victim ID based on **victimId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            terms_accepted_date: Date and time the user accepted the current Terms of Service.
+            victim_id: The ID of the victim the victim asset is applied to.
         """
-        terms_accepted_date = self.utils.any_to_datetime(terms_accepted_date).strftime(
-            '%Y-%m-%d %H:%M:%S'
-        )
-        self._tql.add_filter('termsAcceptedDate', operator, terms_accepted_date, TqlType.STRING)
+        if isinstance(victim_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def tql_timeout(self, operator: Enum, tql_timeout: int):
-        """Filter TQL Timeout based on **tqlTimeout** keyword.
+        self._tql.add_filter('victimId', operator, victim_id, TqlType.INTEGER)
 
-        Args:
-            operator: The operator enum for the filter.
-            tql_timeout: The custom TQL timeout value (if defined).
-        """
-        self._tql.add_filter('tqlTimeout', operator, tql_timeout, TqlType.INTEGER)
-
-    def user_name(self, operator: Enum, user_name: str):
-        """Filter User Name based on **userName** keyword.
+    def victim_name(self, operator: Enum, victim_name: list | str):
+        """Filter Victim Name based on **victimName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            user_name: The user name of the user.
+            victim_name: The name of the victim.
         """
-        self._tql.add_filter('userName', operator, user_name, TqlType.STRING)
+        if isinstance(victim_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('victimName', operator, victim_name, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security/users/user_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security/users/user_model.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,86 +1,83 @@
-"""User / Users Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
-class UsersModel(
-    BaseModel,
-    title='Users Model',
-    alias_generator=Utils().snake_to_camel,
+class UserModel(
+    V3ModelABC,
+    alias_generator=Util().snake_to_camel,
+    extra=Extra.allow,
+    title='User Model',
     validate_assignment=True,
 ):
-    """Users Model"""
+    """User Model"""
 
-    _mode_support = PrivateAttr(False)
+    _associated_type = PrivateAttr(False)
+    _cm_type = PrivateAttr(False)
+    _shared_type = PrivateAttr(False)
+    _staged = PrivateAttr(False)
 
-    data: Optional[List['UserModel']] = Field(
-        [],
-        description='The data for the Users.',
-        methods=['POST', 'PUT'],
-        title='data',
+    id: int | None = Field(
+        None,
+        description='The ID of the item.',
+        read_only=True,
+        title='id',
     )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
+    user_name: str | None = Field(
+        None,
+        allow_mutation=False,
+        description='The **user name** for the User.',
+        read_only=True,
+        title='userName',
     )
 
 
 class UserDataModel(
     BaseModel,
     title='User Data Model',
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
     """Users Data Model"""
 
-    data: Optional[List['UserModel']] = Field(
+    data: list[UserModel] | None = Field(
         [],
         description='The data for the Users.',
         methods=['POST', 'PUT'],
         title='data',
     )
 
 
-class UserModel(
-    V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
-    extra=Extra.allow,
-    title='User Model',
+class UsersModel(
+    BaseModel,
+    title='Users Model',
+    alias_generator=Util().snake_to_camel,
     validate_assignment=True,
 ):
-    """User Model"""
+    """Users Model"""
 
-    _associated_type = PrivateAttr(False)
-    _cm_type = PrivateAttr(False)
-    _shared_type = PrivateAttr(False)
-    _staged = PrivateAttr(False)
+    _mode_support = PrivateAttr(False)
 
-    id: Optional[int] = Field(
-        None,
-        description='The ID of the item.',
-        read_only=True,
-        title='id',
+    data: list[UserModel] | None = Field(
+        [],
+        description='The data for the Users.',
+        methods=['POST', 'PUT'],
+        title='data',
     )
-    user_name: Optional[str] = Field(
-        None,
-        allow_mutation=False,
-        description='The **user name** for the User.',
-        read_only=True,
-        title='userName',
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
     )
 
 
 # add forward references
 UserDataModel.update_forward_refs()
 UserModel.update_forward_refs()
 UsersModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security_labels/security_label.py` & `tcex-4.0.0/tcex/api/tc/v3/security_labels/security_label.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,105 +1,66 @@
-"""SecurityLabel / SecurityLabels Object"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import Optional, Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_filter import SecurityLabelFilter
 from tcex.api.tc.v3.security_labels.security_label_model import (
     SecurityLabelModel,
     SecurityLabelsModel,
 )
 
 
-class SecurityLabels(ObjectCollectionABC):
-    """SecurityLabels Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = SecurityLabelsModel(**kwargs)
-        self.type_ = 'security_labels'
-
-    def __iter__(self) -> 'SecurityLabel':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=SecurityLabel)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.SECURITY_LABELS.value
-
-    @property
-    def filter(self) -> 'SecurityLabelFilter':
-        """Return the type specific filter object."""
-        return SecurityLabelFilter(self.tql)
-
-
 class SecurityLabel(ObjectABC):
     """SecurityLabels Object.
 
     Args:
         color (str, kwargs): Color of the security label.
         description (str, kwargs): Description of the security label.
         name (str, kwargs): Name of the security label.
         owner (str, kwargs): The name of the Owner of the Label.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = SecurityLabelModel(**kwargs)
+        self._model: SecurityLabelModel = SecurityLabelModel(**kwargs)
         self._nested_field_name = 'securityLabels'
         self._nested_filter = 'has_security_label'
         self.type_ = 'Security Label'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.SECURITY_LABELS.value
 
     @property
-    def model(self) -> 'SecurityLabelModel':
+    def model(self) -> SecurityLabelModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['SecurityLabelModel', dict]):
+    def model(self, data: dict | SecurityLabelModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
-    def remove(self, params: Optional[dict] = None):
+    def remove(self, params: dict | None = None):
         """Remove a nested object."""
         method = 'PUT'
         unique_id = self._calculate_unique_id()
 
         # validate an id is available
         self._validate_id(unique_id.get('value'), '')
 
@@ -125,7 +86,46 @@
             url=url,
             body=body,
             headers={'content-type': 'application/json'},
             params=params,
         )
 
         return self.request
+
+
+class SecurityLabels(ObjectCollectionABC):
+    """SecurityLabels Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = SecurityLabelsModel(**kwargs)
+        self.type_ = 'security_labels'
+
+    def __iter__(self) -> Iterator[SecurityLabel]:
+        """Return CM objects."""
+        return self.iterate(base_class=SecurityLabel)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.SECURITY_LABELS.value
+
+    @property
+    def filter(self) -> SecurityLabelFilter:
+        """Return the type specific filter object."""
+        return SecurityLabelFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/security_labels/security_label_model.py` & `tcex-4.0.0/tcex/api/tc/v3/security_labels/security_label_model.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,121 +1,120 @@
-"""Security_Label / Security_Labels Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class SecurityLabelsModel(
-    BaseModel,
-    title='SecurityLabels Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Security_Labels Model"""
-
-    _mode_support = PrivateAttr(True)
-
-    data: Optional[List['SecurityLabelModel']] = Field(
-        [],
-        description='The data for the SecurityLabels.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class SecurityLabelDataModel(
-    BaseModel,
-    title='SecurityLabel Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Security_Labels Data Model"""
-
-    data: Optional[List['SecurityLabelModel']] = Field(
-        [],
-        description='The data for the SecurityLabels.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class SecurityLabelModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='SecurityLabel Model',
     validate_assignment=True,
 ):
     """Security_Label Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(True)
     _staged = PrivateAttr(False)
 
-    color: Optional[str] = Field(
+    color: str | None = Field(
         None,
         description='Color of the security label.',
         methods=['POST', 'PUT'],
         max_length=10,
         min_length=1,
         read_only=False,
         title='color',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the label was added.',
         read_only=True,
         title='dateAdded',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         description='Description of the security label.',
         methods=['POST', 'PUT'],
         max_length=400,
         min_length=1,
         read_only=False,
         title='description',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='Name of the security label.',
         methods=['POST', 'PUT'],
         max_length=50,
         min_length=1,
         read_only=False,
         title='name',
     )
-    owner: Optional[str] = Field(
+    owner: str | None = Field(
         None,
         description='The name of the Owner of the Label.',
         methods=['POST'],
         read_only=False,
         title='owner',
     )
 
 
+class SecurityLabelDataModel(
+    BaseModel,
+    title='SecurityLabel Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Security_Labels Data Model"""
+
+    data: list[SecurityLabelModel] | None = Field(
+        [],
+        description='The data for the SecurityLabels.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class SecurityLabelsModel(
+    BaseModel,
+    title='SecurityLabels Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Security_Labels Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[SecurityLabelModel] | None = Field(
+        [],
+        description='The data for the SecurityLabels.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # add forward references
 SecurityLabelDataModel.update_forward_refs()
 SecurityLabelModel.update_forward_refs()
 SecurityLabelsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tags/tag.py` & `tcex-4.0.0/tcex/api/tc/v3/tags/tag.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,101 +1,62 @@
-"""Tag / Tags Object"""
+"""TcEx Framework Module"""
 # standard library
 import json
-from typing import Optional, Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.tags.tag_filter import TagFilter
 from tcex.api.tc.v3.tags.tag_model import TagModel, TagsModel
 
 
-class Tags(ObjectCollectionABC):
-    """Tags Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = TagsModel(**kwargs)
-        self.type_ = 'tags'
-
-    def __iter__(self) -> 'Tag':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Tag)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.TAGS.value
-
-    @property
-    def filter(self) -> 'TagFilter':
-        """Return the type specific filter object."""
-        return TagFilter(self.tql)
-
-
 class Tag(ObjectABC):
     """Tags Object.
 
     Args:
         description (str, kwargs): A brief description of the Tag.
         name (str, kwargs): The **name** for the Tag.
         owner (str, kwargs): The name of the Owner of the Tag.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = TagModel(**kwargs)
+        self._model: TagModel = TagModel(**kwargs)
         self._nested_field_name = 'tags'
         self._nested_filter = 'has_tag'
         self.type_ = 'Tag'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.TAGS.value
 
     @property
-    def model(self) -> 'TagModel':
+    def model(self) -> TagModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['TagModel', dict]):
+    def model(self, data: dict | TagModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
-    def remove(self, params: Optional[dict] = None):
+    def remove(self, params: dict | None = None):
         """Remove a nested object."""
         method = 'PUT'
         unique_id = self._calculate_unique_id()
 
         # validate an id is available
         self._validate_id(unique_id.get('value'), '')
 
@@ -121,7 +82,46 @@
             url=url,
             body=body,
             headers={'content-type': 'application/json'},
             params=params,
         )
 
         return self.request
+
+
+class Tags(ObjectCollectionABC):
+    """Tags Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = TagsModel(**kwargs)
+        self.type_ = 'tags'
+
+    def __iter__(self) -> Iterator[Tag]:
+        """Return CM objects."""
+        return self.iterate(base_class=Tag)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.TAGS.value
+
+    @property
+    def filter(self) -> TagFilter:
+        """Return the type specific filter object."""
+        return TagFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tags/tag_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/security/owner_roles/owner_role_filter.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,168 +1,134 @@
-"""Tag TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
-from tcex.api.tc.v3.tql.tql import Tql
-from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class TagFilter(FilterABC):
-    """Filter Object for Tags"""
+class OwnerRoleFilter(FilterABC):
+    """Filter Object for OwnerRoles"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.TAGS.value
+        return ApiEndpoints.OWNER_ROLES.value
 
-    def associated_case(self, operator: Enum, associated_case: int):
-        """Filter associatedCase based on **associatedCase** keyword.
+    def available(self, operator: Enum, available: bool):
+        """Filter Available based on **available** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            associated_case: No description provided.
+            available: The availability status of the role.
         """
-        self._tql.add_filter('associatedCase', operator, associated_case, TqlType.INTEGER)
+        self._tql.add_filter('available', operator, available, TqlType.BOOLEAN)
 
-    def associated_group(self, operator: Enum, associated_group: int):
-        """Filter associatedGroup based on **associatedGroup** keyword.
+    def comm_role(self, operator: Enum, comm_role: bool):
+        """Filter Community Role based on **commRole** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            associated_group: No description provided.
+            comm_role: The scope of the role.
         """
-        self._tql.add_filter('associatedGroup', operator, associated_group, TqlType.INTEGER)
+        self._tql.add_filter('commRole', operator, comm_role, TqlType.BOOLEAN)
 
-    def associated_indicator(self, operator: Enum, associated_indicator: int):
-        """Filter associatedIndicator based on **associatedIndicator** keyword.
+    def description_admin(self, operator: Enum, description_admin: list | str):
+        """Filter Admin Description based on **descriptionAdmin** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            associated_indicator: No description provided.
+            description_admin: The description of this role's admin access.
         """
-        self._tql.add_filter('associatedIndicator', operator, associated_indicator, TqlType.INTEGER)
+        if isinstance(description_admin, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def associated_victim(self, operator: Enum, associated_victim: int):
-        """Filter associatedVictim based on **associatedVictim** keyword.
+        self._tql.add_filter('descriptionAdmin', operator, description_admin, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            associated_victim: No description provided.
-        """
-        self._tql.add_filter('associatedVictim', operator, associated_victim, TqlType.INTEGER)
-
-    def case_id(self, operator: Enum, case_id: int):
-        """Filter Case ID based on **caseId** keyword.
+    def description_comm(self, operator: Enum, description_comm: list | str):
+        """Filter Community Description based on **descriptionComm** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_id: The ID of the case the tag is applied to.
+            description_comm: The description of this role's access within a community.
         """
-        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
+        if isinstance(description_comm, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('descriptionComm', operator, description_comm, TqlType.STRING)
 
-    def description(self, operator: Enum, description: str):
-        """Filter Description based on **description** keyword.
+    def description_org(self, operator: Enum, description_org: list | str):
+        """Filter Organization Description based on **descriptionOrg** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the tag.
+            description_org: The description of this role's access within an organization.
         """
-        self._tql.add_filter('description', operator, description, TqlType.STRING)
-
-    @property
-    def has_case(self):
-        """Return **CaseFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.cases.case_filter import CaseFilter
-
-        cases = CaseFilter(Tql())
-        self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
-        return cases
-
-    @property
-    def has_group(self):
-        """Return **GroupFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.groups.group_filter import GroupFilter
-
-        groups = GroupFilter(Tql())
-        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
-        return groups
+        if isinstance(description_org, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    @property
-    def has_indicator(self):
-        """Return **IndicatorFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-
-        indicators = IndicatorFilter(Tql())
-        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
-        return indicators
-
-    @property
-    def has_victim(self):
-        """Return **VictimFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
-
-        victims = VictimFilter(Tql())
-        self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
-        return victims
+        self._tql.add_filter('descriptionOrg', operator, description_org, TqlType.STRING)
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the tag.
+            id: The ID of the user.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
-
-    def last_used(self, operator: Enum, last_used: str):
-        """Filter LastUsed based on **lastUsed** keyword.
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            last_used: The date this tag was last used.
-        """
-        last_used = self.utils.any_to_datetime(last_used).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('lastUsed', operator, last_used, TqlType.STRING)
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def name(self, operator: Enum, name: str):
+    def name(self, operator: Enum, name: list | str):
         """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the tag (case sensitive).
+            name: The name of the role.
         """
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('name', operator, name, TqlType.STRING)
 
-    def owner(self, operator: Enum, owner: int):
-        """Filter Owner ID based on **owner** keyword.
+    def org_role(self, operator: Enum, org_role: bool):
+        """Filter Organization Role based on **orgRole** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner: The owner ID of the tag.
+            org_role: The scope of this role.
         """
-        self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
+        self._tql.add_filter('orgRole', operator, org_role, TqlType.BOOLEAN)
 
-    def owner_name(self, operator: Enum, owner_name: str):
-        """Filter Owner Name based on **ownerName** keyword.
+    def version(self, operator: Enum, version: int | list):
+        """Filter Version based on **version** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name of the tag.
+            version: The version number of the role.
         """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
-
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
+        if isinstance(version, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            summary: The name of the tag (case insensitive).
-        """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+        self._tql.add_filter('version', operator, version, TqlType.INTEGER)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tasks/task.py` & `tcex-4.0.0/tcex/api/tc/v3/tasks/task.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,65 +1,27 @@
-"""Task / Tasks Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactModel
 from tcex.api.tc.v3.notes.note_model import NoteModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security.user_groups.user_group_model import UserGroupModel
 from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.tasks.task_filter import TaskFilter
 from tcex.api.tc.v3.tasks.task_model import TaskModel, TasksModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.artifacts.artifact import Artifact
-    from tcex.api.tc.v3.notes.note import Note
-
-
-class Tasks(ObjectCollectionABC):
-    """Tasks Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = TasksModel(**kwargs)
-        self.type_ = 'tasks'
-
-    def __iter__(self) -> 'Task':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Task)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.TASKS.value
-
-    @property
-    def filter(self) -> 'TaskFilter':
-        """Return the type specific filter object."""
-        return TaskFilter(self.tql)
+    from tcex.api.tc.v3.artifacts.artifact import Artifact  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.notes.note import Note  # CIRCULAR-IMPORT
 
 
 class Task(ObjectABC):
     """Tasks Object.
 
     Args:
         artifacts (Artifacts, kwargs): A list of Artifacts corresponding to the Task.
@@ -77,35 +39,35 @@
         status (str, kwargs): The **status** for the Task.
         workflow_phase (int, kwargs): The phase of the workflow.
         workflow_step (int, kwargs): The step of the workflow.
         xid (str, kwargs): The **xid** for the Task.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = TaskModel(**kwargs)
+        self._model: TaskModel = TaskModel(**kwargs)
         self._nested_field_name = 'tasks'
         self._nested_filter = 'has_task'
         self.type_ = 'Task'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.TASKS.value
 
     @property
-    def model(self) -> 'TaskModel':
+    def model(self) -> TaskModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['TaskModel', dict]):
+    def model(self, data: dict | TaskModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -116,62 +78,101 @@
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.name}
 
     @property
-    def artifacts(self) -> Iterator['Artifact']:
+    def artifacts(self) -> Generator['Artifact', None, None]:
         """Yield Artifact from Artifacts."""
         # first-party
         from tcex.api.tc.v3.artifacts.artifact import Artifacts
 
-        yield from self._iterate_over_sublist(Artifacts)
+        yield from self._iterate_over_sublist(Artifacts)  # type: ignore
 
     @property
-    def notes(self) -> Iterator['Note']:
+    def notes(self) -> Generator['Note', None, None]:
         """Yield Note from Notes."""
         # first-party
         from tcex.api.tc.v3.notes.note import Notes
 
-        yield from self._iterate_over_sublist(Notes)
+        yield from self._iterate_over_sublist(Notes)  # type: ignore
 
-    def stage_artifact(self, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
+    def stage_artifact(self, data: dict | ObjectABC | ArtifactModel):
         """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = ArtifactModel(**data)
 
         if not isinstance(data, ArtifactModel):
             raise RuntimeError('Invalid type passed in to stage_artifact')
         data._staged = True
-        self.model.artifacts.data.append(data)
+        self.model.artifacts.data.append(data)  # type: ignore
 
     # pylint: disable=redefined-builtin
-    def stage_assignee(self, type: str, data: Union[dict, 'ObjectABC', 'ArtifactModel']):
+    def stage_assignee(self, type: str, data: dict | ObjectABC | UserModel | UserGroupModel):
         """Stage artifact on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif type.lower() == 'user' and isinstance(data, dict):
             data = UserModel(**data)
         elif type.lower() == 'group' and isinstance(data, dict):
             data = UserGroupModel(**data)
 
-        if not isinstance(data, (UserModel, UserGroupModel)):
+        if not isinstance(data, UserModel | UserGroupModel):
             raise RuntimeError('Invalid type passed in to stage_assignee')
         data._staged = True
         self.model.assignee._staged = True
         self.model.assignee.type = type
-        self.model.assignee.data = data
+        self.model.assignee.data = data  # type: ignore
 
-    def stage_note(self, data: Union[dict, 'ObjectABC', 'NoteModel']):
+    def stage_note(self, data: dict | ObjectABC | NoteModel):
         """Stage note on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = NoteModel(**data)
 
         if not isinstance(data, NoteModel):
             raise RuntimeError('Invalid type passed in to stage_note')
         data._staged = True
-        self.model.notes.data.append(data)
+        self.model.notes.data.append(data)  # type: ignore
+
+
+class Tasks(ObjectCollectionABC):
+    """Tasks Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = TasksModel(**kwargs)
+        self.type_ = 'tasks'
+
+    def __iter__(self) -> Iterator[Task]:
+        """Return CM objects."""
+        return self.iterate(base_class=Task)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.TASKS.value
+
+    @property
+    def filter(self) -> TaskFilter:
+        """Return the type specific filter object."""
+        return TaskFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tasks/task_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/tags/tag_filter.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,253 +1,253 @@
-"""Task TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql import Tql
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class TaskFilter(FilterABC):
-    """Filter Object for Tasks"""
+class TagFilter(FilterABC):
+    """Filter Object for Tags"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.TASKS.value
+        return ApiEndpoints.TAGS.value
 
-    def assigned_to_user_or_group(self, operator: Enum, assigned_to_user_or_group: str):
-        """Filter Assigned To User or Group based on **assignedToUserOrGroup** keyword.
+    def associated_case(self, operator: Enum, associated_case: int | list):
+        """Filter associatedCase based on **associatedCase** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            assigned_to_user_or_group: A value of User, Group, or None depending on the assignee.
+            associated_case: No description provided.
         """
-        self._tql.add_filter(
-            'assignedToUserOrGroup', operator, assigned_to_user_or_group, TqlType.STRING
-        )
-
-    def assignee_name(self, operator: Enum, assignee_name: str):
-        """Filter Assignee Name based on **assigneeName** keyword.
+        if isinstance(associated_case, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            assignee_name: The user or group name assigned to the Task.
-        """
-        self._tql.add_filter('assigneeName', operator, assignee_name, TqlType.STRING)
+        self._tql.add_filter('associatedCase', operator, associated_case, TqlType.INTEGER)
 
-    def automated(self, operator: Enum, automated: bool):
-        """Filter Automated based on **automated** keyword.
+    def associated_group(self, operator: Enum, associated_group: int | list):
+        """Filter associatedGroup based on **associatedGroup** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            automated: A flag indicating whether or not the task is automated.
+            associated_group: No description provided.
         """
-        self._tql.add_filter('automated', operator, automated, TqlType.BOOLEAN)
-
-    def case_id(self, operator: Enum, case_id: int):
-        """Filter Case ID based on **caseId** keyword.
+        if isinstance(associated_group, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            case_id: The ID of the case this Task is associated with.
-        """
-        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
+        self._tql.add_filter('associatedGroup', operator, associated_group, TqlType.INTEGER)
 
-    def case_id_as_string(self, operator: Enum, case_id_as_string: str):
-        """Filter CaseID As String based on **caseIdAsString** keyword.
+    def associated_indicator(self, operator: Enum, associated_indicator: int | list):
+        """Filter associatedIndicator based on **associatedIndicator** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            case_id_as_string: The ID of the case as a String.
+            associated_indicator: No description provided.
         """
-        self._tql.add_filter('caseIdAsString', operator, case_id_as_string, TqlType.STRING)
-
-    def case_severity(self, operator: Enum, case_severity: str):
-        """Filter Case Severity based on **caseSeverity** keyword.
+        if isinstance(associated_indicator, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            case_severity: The severity of the case associated with the task.
-        """
-        self._tql.add_filter('caseSeverity', operator, case_severity, TqlType.STRING)
+        self._tql.add_filter('associatedIndicator', operator, associated_indicator, TqlType.INTEGER)
 
-    def completed_by(self, operator: Enum, completed_by: str):
-        """Filter Completed By based on **completedBy** keyword.
+    def associated_victim(self, operator: Enum, associated_victim: int | list):
+        """Filter associatedVictim based on **associatedVictim** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            completed_by: The account login of the user who completed the task.
+            associated_victim: No description provided.
         """
-        self._tql.add_filter('completedBy', operator, completed_by, TqlType.STRING)
-
-    def completed_date(self, operator: Enum, completed_date: str):
-        """Filter Completed Date based on **completedDate** keyword.
+        if isinstance(associated_victim, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            completed_date: The completion date for the task.
-        """
-        completed_date = self.utils.any_to_datetime(completed_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('completedDate', operator, completed_date, TqlType.STRING)
+        self._tql.add_filter('associatedVictim', operator, associated_victim, TqlType.INTEGER)
 
-    def description(self, operator: Enum, description: str):
-        """Filter Description based on **description** keyword.
+    def case_id(self, operator: Enum, case_id: int | list):
+        """Filter Case ID based on **caseId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the task.
+            case_id: The ID of the case the tag is applied to.
         """
-        self._tql.add_filter('description', operator, description, TqlType.STRING)
+        if isinstance(case_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('caseId', operator, case_id, TqlType.INTEGER)
 
-    def due_date(self, operator: Enum, due_date: str):
-        """Filter Due Date based on **dueDate** keyword.
+    def description(self, operator: Enum, description: list | str):
+        """Filter Description based on **description** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            due_date: The due date for the task.
+            description: The description of the tag.
         """
-        due_date = self.utils.any_to_datetime(due_date).strftime('%Y-%m-%d %H:%M:%S')
-        self._tql.add_filter('dueDate', operator, due_date, TqlType.STRING)
-
-    @property
-    def has_artifact(self):
-        """Return **ArtifactFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.artifacts.artifact_filter import ArtifactFilter
+        if isinstance(description, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        artifacts = ArtifactFilter(Tql())
-        self._tql.add_filter('hasArtifact', TqlOperator.EQ, artifacts, TqlType.SUB_QUERY)
-        return artifacts
+        self._tql.add_filter('description', operator, description, TqlType.STRING)
 
     @property
     def has_case(self):
         """Return **CaseFilter** for further filtering."""
         # first-party
         from tcex.api.tc.v3.cases.case_filter import CaseFilter
 
         cases = CaseFilter(Tql())
         self._tql.add_filter('hasCase', TqlOperator.EQ, cases, TqlType.SUB_QUERY)
         return cases
 
     @property
-    def has_note(self):
-        """Return **NoteFilter** for further filtering."""
+    def has_group(self):
+        """Return **GroupFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.groups.group_filter import GroupFilter
+
+        groups = GroupFilter(Tql())
+        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
+        return groups
+
+    @property
+    def has_indicator(self):
+        """Return **IndicatorFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
+
+        indicators = IndicatorFilter(Tql())
+        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
+        return indicators
+
+    @property
+    def has_victim(self):
+        """Return **VictimFilter** for further filtering."""
         # first-party
-        from tcex.api.tc.v3.notes.note_filter import NoteFilter
+        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
 
-        notes = NoteFilter(Tql())
-        self._tql.add_filter('hasNote', TqlOperator.EQ, notes, TqlType.SUB_QUERY)
-        return notes
+        victims = VictimFilter(Tql())
+        self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
+        return victims
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the task.
+            id: The ID of the tag.
         """
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def missing_artifact_count(self, operator: Enum, missing_artifact_count: int):
-        """Filter Missing Artifact Count based on **missingArtifactCount** keyword.
+    def last_used(self, operator: Enum, last_used: Arrow | datetime | int | str):
+        """Filter LastUsed based on **lastUsed** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            missing_artifact_count: The number of required artifacts that are missing.
+            last_used: The date this tag was last used.
         """
-        self._tql.add_filter(
-            'missingArtifactCount', operator, missing_artifact_count, TqlType.INTEGER
-        )
+        last_used = self.util.any_to_datetime(last_used).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('lastUsed', operator, last_used, TqlType.STRING)
 
-    def name(self, operator: Enum, name: str):
+    def name(self, operator: Enum, name: list | str):
         """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the task.
+            name: The name of the tag (case sensitive).
         """
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('name', operator, name, TqlType.STRING)
 
-    def owner(self, operator: Enum, owner: int):
+    def owner(self, operator: Enum, owner: int | list):
         """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner: The Owner ID for the case.
+            owner: The owner ID of the tag.
         """
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-    def owner_name(self, operator: Enum, owner_name: str):
+    def owner_name(self, operator: Enum, owner_name: list | str):
         """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name for the case.
-        """
-        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
-
-    def required(self, operator: Enum, required: bool):
-        """Filter Required based on **required** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            required: Flag indicating whether or not the task is required.
-        """
-        self._tql.add_filter('required', operator, required, TqlType.BOOLEAN)
-
-    def status(self, operator: Enum, status: str):
-        """Filter Status based on **status** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            status: The status of the task.
+            owner_name: The owner name of the tag.
         """
-        self._tql.add_filter('status', operator, status, TqlType.STRING)
-
-    def target_id(self, operator: Enum, target_id: int):
-        """Filter Assignee based on **targetId** keyword.
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            target_id: The assigned user or group ID for the task.
-        """
-        self._tql.add_filter('targetId', operator, target_id, TqlType.INTEGER)
+        self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def target_type(self, operator: Enum, target_type: str):
-        """Filter Target Type based on **targetType** keyword.
+    def summary(self, operator: Enum, summary: list | str):
+        """Filter Summary based on **summary** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            target_type: The target type for this task (either User or Group).
+            summary: The name of the tag (case insensitive).
         """
-        self._tql.add_filter('targetType', operator, target_type, TqlType.STRING)
+        if isinstance(summary, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def workflow_phase(self, operator: Enum, workflow_phase: int):
-        """Filter Workflow Phase based on **workflowPhase** keyword.
+        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            workflow_phase: The workflow phase of the task.
-        """
-        self._tql.add_filter('workflowPhase', operator, workflow_phase, TqlType.INTEGER)
-
-    def workflow_step(self, operator: Enum, workflow_step: int):
-        """Filter Workflow Step based on **workflowStep** keyword.
+    def technique_id(self, operator: Enum, technique_id: list | str):
+        """Filter Technique ID based on **techniqueId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            workflow_step: The workflow step of the task.
+            technique_id: The standard ID for specific MITRE ATT&CK techniques and sub-techniques.
         """
-        self._tql.add_filter('workflowStep', operator, workflow_step, TqlType.INTEGER)
+        if isinstance(technique_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def xid(self, operator: Enum, xid: str):
-        """Filter XID based on **xid** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            xid: The XID of the task.
-        """
-        self._tql.add_filter('xid', operator, xid, TqlType.STRING)
+        self._tql.add_filter('techniqueId', operator, technique_id, TqlType.STRING)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tasks/task_model.py` & `tcex-4.0.0/tcex/api/tc/v3/tasks/task_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,273 +1,272 @@
-"""Task / Tasks Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional, Union
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class TasksModel(
-    BaseModel,
-    title='Tasks Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Tasks Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['TaskModel']] = Field(
-        [],
-        description='The data for the Tasks.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class TaskDataModel(
-    BaseModel,
-    title='Task Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Tasks Data Model"""
-
-    data: Optional[List['TaskModel']] = Field(
-        [],
-        description='The data for the Tasks.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class TaskModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Task Model',
     validate_assignment=True,
 ):
     """Task Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    artifacts: Optional['ArtifactsModel'] = Field(
+    artifacts: 'ArtifactsModel' = Field(
         None,
         description='A list of Artifacts corresponding to the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='artifacts',
     )
-    assignee: Optional['AssigneeModel'] = Field(
+    assignee: 'AssigneeModel' = Field(
         None,
         description='The user or group Assignee object for the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='assignee',
     )
-    case_id: Optional[int] = Field(
+    case_id: int | None = Field(
         None,
         description='The **case id** for the Task.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseXid',
         title='caseId',
     )
-    case_xid: Optional[str] = Field(
+    case_xid: str | None = Field(
         None,
         description='The **case xid** for the Task.',
         methods=['POST'],
         read_only=False,
         required_alt_field='caseId',
         title='caseXid',
     )
-    completed_by: Optional[str] = Field(
+    completed_by: str | None = Field(
         None,
         allow_mutation=False,
         description='The **completed by** for the Task.',
         read_only=True,
         title='completedBy',
     )
-    completed_date: Optional[datetime] = Field(
+    completed_date: datetime | None = Field(
         None,
         description='The completion date of the Task.',
         methods=['POST'],
         read_only=False,
         title='completedDate',
     )
-    config_playbook: Optional[str] = Field(
+    config_playbook: str | None = Field(
         None,
         allow_mutation=False,
         description='The **config playbook** for the Task.',
         read_only=True,
         title='configPlaybook',
     )
-    config_task: Union[Optional[dict], Optional[List[dict]]] = Field(
+    config_task: dict | list[dict] | None = Field(
         None,
         allow_mutation=False,
         description='The **config task** for the Task.',
         read_only=True,
         title='configTask',
     )
-    dependent_on_id: Optional[int] = Field(
+    dependent_on_id: int | None = Field(
         None,
         description='The ID of another Task that this Task is dependent upon.',
         methods=['POST'],
         read_only=False,
         title='dependentOnId',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         description='The **description** for the Task.',
         methods=['POST', 'PUT'],
         max_length=1500,
         min_length=0,
         read_only=False,
         title='description',
     )
-    due_date: Optional[datetime] = Field(
+    due_date: datetime | None = Field(
         None,
         description='The due date of the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='dueDate',
     )
-    duration: Optional[int] = Field(
+    duration: int | None = Field(
         None,
         allow_mutation=False,
         description='The **duration** for the Task.',
         read_only=True,
         title='duration',
     )
-    duration_type: Optional[str] = Field(
+    duration_type: str | None = Field(
         None,
         description='The **duration type** for the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='durationType',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='The **name** for the Task.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='name',
     )
-    notes: Optional['NotesModel'] = Field(
+    notes: 'NotesModel' = Field(
         None,
         description='A list of Notes corresponding to the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='notes',
     )
-    owner: Optional[str] = Field(
+    owner: str | None = Field(
         None,
         allow_mutation=False,
         description='The name of the Owner of the Case.',
         read_only=True,
         title='owner',
     )
-    parent_case: Optional['CaseModel'] = Field(
+    parent_case: 'CaseModel' = Field(
         None,
         allow_mutation=False,
         description='The **parent case** for the Task.',
         read_only=True,
         title='parentCase',
     )
     required: bool = Field(
         None,
         description='Flag indicating whether or not the task is required.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='required',
     )
-    status: Optional[str] = Field(
+    status: str | None = Field(
         None,
         description='The **status** for the Task.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='status',
     )
-    workflow_phase: Optional[int] = Field(
+    workflow_phase: int | None = Field(
         None,
         description='The phase of the workflow.',
         methods=['POST'],
         maximum=127,
         minimum=0,
         read_only=False,
         title='workflowPhase',
     )
-    workflow_step: Optional[int] = Field(
+    workflow_step: int | None = Field(
         None,
         description='The step of the workflow.',
         methods=['POST'],
         maximum=127,
         minimum=1,
         read_only=False,
         title='workflowStep',
     )
-    xid: Optional[str] = Field(
+    xid: str | None = Field(
         None,
         description='The **xid** for the Task.',
         methods=['POST'],
         max_length=100,
         min_length=10,
         read_only=False,
         title='xid',
     )
 
-    @validator('artifacts', always=True)
+    @validator('artifacts', always=True, pre=True)
     def _validate_artifacts(cls, v):
         if not v:
-            return ArtifactsModel()
+            return ArtifactsModel()  # type: ignore
         return v
 
-    @validator('assignee', always=True)
+    @validator('assignee', always=True, pre=True)
     def _validate_assignee(cls, v):
         if not v:
-            return AssigneeModel()
+            return AssigneeModel()  # type: ignore
         return v
 
-    @validator('parent_case', always=True)
+    @validator('parent_case', always=True, pre=True)
     def _validate_case(cls, v):
         if not v:
-            return CaseModel()
+            return CaseModel()  # type: ignore
         return v
 
-    @validator('notes', always=True)
+    @validator('notes', always=True, pre=True)
     def _validate_notes(cls, v):
         if not v:
-            return NotesModel()
+            return NotesModel()  # type: ignore
         return v
 
 
+class TaskDataModel(
+    BaseModel,
+    title='Task Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Tasks Data Model"""
+
+    data: list[TaskModel] | None = Field(
+        [],
+        description='The data for the Tasks.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class TasksModel(
+    BaseModel,
+    title='Tasks Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Tasks Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[TaskModel] | None = Field(
+        [],
+        description='The data for the Tasks.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.artifacts.artifact_model import ArtifactsModel
 from tcex.api.tc.v3.cases.case_model import CaseModel
 from tcex.api.tc.v3.notes.note_model import NotesModel
 from tcex.api.tc.v3.security.assignee_model import AssigneeModel
 
 # add forward references
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/threat_intelligence/threat_intelligence.py` & `tcex-4.0.0/tcex/api/tc/v3/threat_intelligence/threat_intelligence.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""Threat Intelligence"""
+"""TcEx Framework Module"""
 # third-party
 from requests import Session
 
 # first-party
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
 from tcex.api.tc.v3.group_attributes.group_attribute import GroupAttribute, GroupAttributes
 from tcex.api.tc.v3.groups.group import Group, Groups
 from tcex.api.tc.v3.indicator_attributes.indicator_attribute import (
     IndicatorAttribute,
     IndicatorAttributes,
 )
 from tcex.api.tc.v3.indicators.indicator import Indicator, Indicators
@@ -21,28 +21,28 @@
     """Threat Intelligence
 
     Args:
         session: An configured instance of request.Session with TC API Auth.
     """
 
     def __init__(self, session: Session):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self.session = session
         self._ti_utils = None
 
     @property
     def ti_utils(self):
         """Return instance of Threat Intel Utils."""
         if not self._ti_utils:
-            self._ti_utils = ThreatIntelUtils(session_tc=self.session)
+            self._ti_utils = ThreatIntelUtil(session_tc=self.session)
         return self._ti_utils
 
-    def create_entity(self, entity: dict, owner: str) -> dict:
+    def create_entity(self, entity: dict, owner: str) -> dict | None:
         """Create a CM object provided a dict and owner."""
-        entity_type = entity.get('type').lower()
+        entity_type = entity['type'].lower()
         entity_type = entity_type.replace(' ', '_')
         try:
             if entity_type in (type_.lower() for type_ in self.ti_utils.group_types):
                 main_type = 'Group'
                 obj = self.group(**entity)
             elif entity_type in (type_.lower() for type_ in self.ti_utils.indicator_types):
                 main_type = 'Indicator'
@@ -52,27 +52,30 @@
                 obj = self.victim(**entity)
             else:
                 raise RuntimeError(f'Invalid entity type provided for: {entity}')
         except AttributeError:
             return None
 
         r = obj.create()
-        data = {'status_code': r.status_code}
+        data: dict[str, int | str] = {'status_code': r.status_code}
         if r.ok:
             data.update(r.json().get('data', {}))
             data['main_type'] = main_type
             data['sub_type'] = entity_type
             data['owner'] = owner
 
         return data
 
-    def group(self, **kwargs) -> 'Group':
+    def group(self, **kwargs) -> Group:
         """Return a instance of Group object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             assignments (None, kwargs): A list of assignees and escalatees associated with this
                 group (Task specific).
             associated_groups (Groups, kwargs): A list of groups associated with this group.
             associated_indicators (Indicators, kwargs): A list of indicators associated with this
                 group.
             associated_victim_assets (VictimAssets, kwargs): A list of victim assets associated with
                 this group.
@@ -110,73 +113,85 @@
             to (str, kwargs): The email To field .
             type (str, kwargs): The **type** for the Group.
             urls (AdversaryAssets, kwargs): A list of url adversary assets associated with this
                 group.
         """
         return Group(session=self.session, **kwargs)
 
-    def group_attribute(self, **kwargs) -> 'GroupAttribute':
+    def group_attribute(self, **kwargs) -> GroupAttribute:
         """Return a instance of Group Attributes object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             default (bool, kwargs): A flag indicating that this is the default attribute of its type
                 within the object. Only applies to certain attribute and data types.
             indicator_id (int, kwargs): Indicator associated with attribute.
             source (str, kwargs): The attribute source.
             type (str, kwargs): The attribute type.
             value (str, kwargs): Attribute value.
         """
         return GroupAttribute(session=self.session, **kwargs)
 
-    def group_attributes(self, **kwargs) -> 'GroupAttributes':
+    def group_attributes(self, **kwargs) -> GroupAttributes:
         """Return a instance of Group Attributes object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Group.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return GroupAttributes(session=self.session, **kwargs)
 
-    def groups(self, **kwargs) -> 'Groups':
+    def groups(self, **kwargs) -> Groups:
         """Return a instance of Groups object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Group.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return Groups(session=self.session, **kwargs)
 
-    def indicator(self, **kwargs) -> 'Indicator':
+    def indicator(self, **kwargs) -> Indicator:
         """Return a instance of Group object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             active (bool, kwargs): Is the indicator active?
             active_locked (bool, kwargs): Lock the indicator active value?
             address (str, kwargs): The email address associated with this indicator (EmailAddress
                 specific summary field).
             associated_groups (Groups, kwargs): A list of groups that this indicator is associated
                 with.
             associated_indicators (Indicators, kwargs): A list of indicators associated with this
@@ -207,84 +222,99 @@
             value1 (str, kwargs): Custom Indicator summary field value1.
             value2 (str, kwargs): Custom Indicator summary field value2.
             value3 (str, kwargs): Custom Indicator summary field value3.
             whois_active (bool, kwargs): Is whois active for the indicator?
         """
         return Indicator(session=self.session, **kwargs)
 
-    def indicator_attribute(self, **kwargs) -> 'IndicatorAttribute':
+    def indicator_attribute(self, **kwargs) -> IndicatorAttribute:
         """Return a instance of Case Attributes object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             default (bool, kwargs): A flag indicating that this is the default attribute of its type
                 within the object. Only applies to certain attribute and data types.
             indicator_id (int, kwargs): Indicator associated with attribute.
             source (str, kwargs): The attribute source.
             type (str, kwargs): The attribute type.
             value (str, kwargs): Attribute value.
         """
         return IndicatorAttribute(session=self.session, **kwargs)
 
-    def indicator_attributes(self, **kwargs) -> 'IndicatorAttributes':
+    def indicator_attributes(self, **kwargs) -> IndicatorAttributes:
         """Return a instance of Indicator Attributes object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Group.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return IndicatorAttributes(session=self.session, **kwargs)
 
-    def indicators(self, **kwargs) -> 'Indicators':
+    def indicators(self, **kwargs) -> Indicators:
         """Return a instance of Indicators object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Indicator.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return Indicators(session=self.session, **kwargs)
 
-    def security_label(self, **kwargs) -> 'SecurityLabel':
+    def security_label(self, **kwargs) -> SecurityLabel:
         """Return a instance of Case Attributes object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             color (str, kwargs): Color of the security label.
             description (str, kwargs): Description of the security label.
             name (str, kwargs): Name of the security label.
             owner (str, kwargs): The name of the Owner of the Label.
         """
         return SecurityLabel(session=self.session, **kwargs)
 
-    def victim(self, **kwargs) -> 'Victim':
+    def victim(self, **kwargs) -> Victim:
         """Return a instance of Victim object.
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             assets (VictimAssets, kwargs): A list of victim assets corresponding to the Victim.
             associated_groups (Groups, kwargs): A list of groups that this indicator is associated
                 with.
             attributes (VictimAttributes, kwargs): A list of Attributes corresponding to the
                 Victim.
             description (str, kwargs): The indicator description text.
             name (str, kwargs): Name of the Victim.
@@ -301,79 +331,88 @@
                 parameter will replace any existing tag(s) with the one(s) specified)
             type (str, kwargs): The type for the Victim.
             work_location (str, kwargs): Work Location of the Victim.
         """
 
         return Victim(session=self.session, **kwargs)
 
-    def victims(self, **kwargs) -> 'Victims':
+    def victims(self, **kwargs) -> Victims:
         """Return a instance of Victims object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Indicator.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return Victims(session=self.session, **kwargs)
 
-    def victim_asset(self, **kwargs) -> 'VictimAsset':
+    def victim_asset(self, **kwargs) -> VictimAsset:
         """Return a instance of VictimAsset object."""
 
         return VictimAsset(session=self.session, **kwargs)
 
-    def victim_assets(self, **kwargs) -> 'VictimAssets':
+    def victim_assets(self, **kwargs) -> VictimAssets:
         """Return a instance of Victims object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Indicator.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return VictimAssets(session=self.session, **kwargs)
 
-    def victim_attribute(self, **kwargs) -> 'VictimAttribute':
+    def victim_attribute(self, **kwargs) -> VictimAttribute:
         """Return a instance of VictimAttribute object."""
 
         return VictimAttribute(session=self.session, **kwargs)
 
-    def victim_attributes(self, **kwargs) -> 'VictimAttributes':
+    def victim_attributes(self, **kwargs) -> VictimAttributes:
         """Return a instance of Victims object.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
 
             # Example of params input
             {
                 'result_limit': 100,  # How many results are retrieved.
                 'result_start': 10,  # Starting point on retrieved results.
                 'fields': ['caseId', 'summary']  # Additional fields returned on the results
             }
 
         Args:
+            **kwargs: Additional keyword arguments.
+
+        Keyword Args:
             initial_response (dict, optional): Initial data in Case Object for Indicator.
             tql_filters (list, optional): A list of TQL filters.
             params (dict, optional): A dict of query params for the request.
         """
         return VictimAttributes(session=self.session, **kwargs)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/tql/tql.py` & `tcex-4.0.0/tcex/api/tc/v3/tql/tql.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,59 +1,64 @@
-"""ThreatConnect TQL"""
+"""TcEx Framework Module"""
 # standard library
-from typing import List, Optional
+from enum import Enum
 
 # first-party
+from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
 class Tql:
     """ThreatConnect TQL"""
 
     def __init__(self):
-        """Initialize Class Properties"""
+        """Initialize instance properties"""
         self._filters = []
         self.raw_tql = None
 
     @property
     def as_str(self):
         """Convert the TQL obj to a string"""
         filters = []
         for tql_filter in self.filters:
             # keywords are all one work (e.g. task_id should be taskid)
-            keyword = tql_filter.get('keyword').replace('_', '')
-            value = tql_filter.get('value')
+            keyword = tql_filter['keyword'].replace('_', '')
+            value = tql_filter['value']
             try:
                 filters.append(f'''{keyword}({value._tql.as_str})''')
             except Exception:
-                if isinstance(value, List):
+                if isinstance(value, list):
                     if tql_filter.get('type') == TqlType.INTEGER:
                         value = [str(int_) for int_ in value]
                     elif tql_filter.get('type') == TqlType.STRING:
                         value = [f'"{str(str_)}"' for str_ in value]
                     value = ','.join(value)
                     value = f'({value})'
                 elif tql_filter.get('type') == TqlType.STRING:
                     value = f'"{value}"'
-                filters.append(f'''{keyword} {tql_filter.get('operator').value} {value}''')
+                filters.append(f'''{keyword} {tql_filter['operator'].value} {value}''')
 
         return ' and '.join(filters)
 
     @property
-    def filters(self) -> List[dict]:
+    def filters(self) -> list[dict]:
         """Return the filters"""
         return self._filters
 
     @filters.setter
-    def filters(self, filters: List[dict]):
+    def filters(self, filters: list[dict]):
         """Set the filters"""
         self._filters = filters
 
     def add_filter(
-        self, keyword: str, operator: str, value: str, type_: Optional[TqlType] = TqlType.STRING
+        self,
+        keyword: str,
+        operator: Enum | str,
+        value: int | list | str | FilterABC,
+        type_: TqlType | None = TqlType.STRING,
     ):
         """Add a filter to the current obj
 
         Args:
             keyword: the field to search on
             operator: the operator to use
             value: the value to compare
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/v3.py` & `tcex-4.0.0/tcex/api/tc/v3/v3.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""V3 API"""
+"""TcEx Framework Module"""
 
 # first-party
 from tcex.api.tc.v3.attribute_types.attribute_type import AttributeType, AttributeTypes
 from tcex.api.tc.v3.case_management.case_management import CaseManagement
 from tcex.api.tc.v3.security.security import Security
 from tcex.api.tc.v3.threat_intelligence.threat_intelligence import ThreatIntelligence
 
@@ -10,29 +10,29 @@
 class V3(CaseManagement, Security, ThreatIntelligence):
     """V3 API Collection
 
     Args:
         session: An configured instance of request.Session with TC API Auth.
     """
 
-    def attribute_type(self, **kwargs) -> 'AttributeType':
+    def attribute_type(self, **kwargs) -> AttributeType:
         """Return a instance of Attribute Types object."""
         return AttributeType(session=self.session, **kwargs)
 
-    def attribute_types(self, **kwargs) -> 'AttributeTypes':
+    def attribute_types(self, **kwargs) -> AttributeTypes:
         """Return a instance of Attribute Types object."""
         return AttributeTypes(session=self.session, **kwargs)
 
     @property
-    def cm(self) -> 'CaseManagement':
+    def cm(self) -> CaseManagement:
         """Return Case Management API collection."""
         return CaseManagement(self.session)
 
     @property
-    def security(self) -> 'Security':
+    def security(self) -> Security:
         """Return Security API collection."""
         return Security(self.session)
 
     @property
-    def ti(self) -> 'ThreatIntelligence':
+    def ti(self) -> ThreatIntelligence:
         """Return Threat Intelligence API collection."""
         return ThreatIntelligence(self.session)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/v3_model_abc.py` & `tcex-4.0.0/tcex/api/tc/v3/v3_model_abc.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,67 +1,70 @@
-"""ThreatConnect API V3 Base Model."""
+"""TcEx Framework Module"""
 # standard library
 import datetime
 import hashlib
 import json
 import logging
 from abc import ABC
 from json import JSONEncoder
-from typing import Any, Optional
+from typing import Any, Self
 
 # third-party
 from pydantic import BaseModel, PrivateAttr
 
+# first-party
+from tcex.logger.trace_logger import TraceLogger
+
 # get tcex logger
 
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class CustomJSONEncoder(JSONEncoder):
     """Format object in JSON data."""
 
     def default(self, o: Any) -> str:
         """Format object"""
         if isinstance(o, BaseModel):
             raise ValueError(
                 f'Object of type {type(o)} is not JSON serializable. '
                 'Please verify that the object has been converted to a dictionary.'
             )
-        if isinstance(o, (datetime.date, datetime.datetime)):
+        if isinstance(o, datetime.date | datetime.datetime):
             return o.isoformat()
         return o
 
 
 class V3ModelABC(BaseModel, ABC):
     """V3 Base Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _dict_hash: str = PrivateAttr()
-    _log = logger
+    _log = _logger
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
-    id: int = None
+    id: int | None = None
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(**kwargs)
 
         # when "id" field is present it indicates that the data was returned from the
         # API, otherwise the assumption is that the developer staged the data during
         # instantiation of the object.
         if kwargs and hasattr(self, 'id') and self.id is None:  # pylint: disable=no-member
             self._staged = True
 
         # store initial dict hash of model
         self._dict_hash = self.gen_model_hash(self.json(sort_keys=True))
 
     def _calculate_field_inclusion(
-        self, field: str, method: str, mode: str, nested: bool, property_: dict, value: Any
-    ) -> str:
+        self, field: str, method: str, mode: str | None, nested: bool, property_: dict, value: Any
+    ) -> bool:
         """Return True if the field is calculated to be included."""
 
         # INDICATOR ID RULE: If an indicator has a ID set, then the indicator fields
         #     cannot be provided (updateable is false) or the API request will fail.
         #     Since Note model CAN update the `text` field we need to specifically state
         #     that this test is for the `Indicator Model` only.
         if (
@@ -106,22 +109,22 @@
         #    PUT methods instead of the POST fields.  This handles not sending owner field
         #    for tag.
         if method == 'POST' and nested is True and self._shared_type is True:
             method = 'PUT'
 
         # METHOD RULE: If the current method is in the property "methods" list the
         #     field should be included when available.
-        if method in property_.get('methods', []) and (value or value in [0, False]):
+        if method in property_.get('methods', []) and value:
             return True
 
         # DEFAULT RULE -> Fields should not be included unless the match a previous rule.
         return False
 
     # pylint: disable=too-many-return-statements
-    def _calculate_nested_inclusion(self, method: str, mode: str, model: 'BaseModel') -> str:
+    def _calculate_nested_inclusion(self, method: str, mode: str | None, model: Self) -> bool:
         """Return True if the field is calculated to be included.
 
         Case Management Nested Logic:
         * CM Types (e.g., artifacts, notes, task, etc) -> behavior is APPEND and duplicates will
             be created if resent. Object with an ID should never be sent in parent update. Updating
             the nested object should be done directly on the object.
         * User/User Group Types -> ???
@@ -153,15 +156,15 @@
         if method == 'POST':
             return True
 
         # Current Object Restrictions:
         # * The method is PUT
         # * The nested object was NOT added via the stage_xxx method
         # * The nested object contains a ID or Name Field
-        # * The nested object could either have been set during initing the object or fetched.
+        # * The nested object could either have been set during initializing the object or fetched.
 
         # CM and TI endpoint behaves differently. Start with rules based on the parent type,
         # then add more specific rules.
 
         if self._cm_type is True:
             #
             # CM PARENT TYPES
@@ -194,15 +197,15 @@
                 return True
 
             # RULE: Nested Attributes w/ APPEND mode
             # Nested attributes on a parent CM type use the mode feature. When the mode
             #     is APPEND and has been UPDATED, then the attributes should be INCLUDED.
             #     For new nested objects added with the stage_xxx() method, the STAGED
             #     RULE would trigger first.
-            # A secondary PATTERN concideration is that attributes can be immediately
+            # A secondary PATTERN consideration is that attributes can be immediately
             #     updated using the attribute.updated() method. While this isn't as
             #     efficient as updating them all in one request, it's is a simpler
             #     development design pattern.
 
             if mode == 'replace':
                 # RULE: Nested Attributes w/ REPLACE mode
                 # Nested attributes on a parent CM type use the mode feature. When the mode
@@ -210,15 +213,15 @@
                 return True
 
             # RULE: Nested Attributes w/ DELETE mode
             # Nested attributes on a parent CM type use the mode feature. When the mode
             #     is DELETE the attribute should NOT be INCLUDED. Any attribute that was
             #     added by the developer using the stage_xxx() method would have hit the
             #     STAGED RULE above and would be INCLUDED.
-            # A secondary PATTERN concideration is that attributes can be immediately
+            # A secondary PATTERN consideration is that attributes can be immediately
             #     deleted using the attribute.delete() method. While this isn't as
             #     efficient as deleting them all in one request, it's is a simpler
             #     development design pattern.
 
             # All non-matching nested object that did not match a rule above will NOT be INCLUDED.
             return False
 
@@ -250,142 +253,144 @@
             return True
 
         # * security_label -> delete (support id or name only)
         # * tag -> delete (support id or name only)
         if (
             mode == 'delete'
             and (model._shared_type is True or self._associated_type is True)
-            and (model.id is not None or model.name is not None)
+            and (model.id is not None or model.name is not None)  # type: ignore
         ):
             # RULE: Nested Shared Object w/ DELETE mode (TAGS, SECURITY LABELS)
             # Nested shared object on a parent TI type use the mode feature. When the mode
             #     is DELETE the shard object should not be INCLUDED. Any object that was
             #     added by the developer would have hit the STAGED RULE above and would
             #     be INCLUDED.
             return True
 
-        # * asssoc -> delete (support id only)
+        # * associated -> delete (support id only)
         # * attribute -> delete (support id only)
         # RULE: Nested Object w/ DELETE mode
         # Nested object on a parent TI type use the mode feature. When the mode
         #     is DELETE the object should not be INCLUDED. Any object that was
         #     added by the developer would have hit the STAGED RULE above and would
         #     be INCLUDED.
 
         # All non-matching nested object that did not match a rule above will NOT be INCLUDED.
         return False
 
-    def _process_nested_data_array(self, method: str, mode: str, nested_object: 'BaseModel'):
+    def _process_nested_data_array(self, method: str, mode: str | None, nested_object: Self):
         """Process the nested data object (e.g., GroupsModel.data).
 
         Nested Object Inclusion Rules:
         * If the method is not PUT.
         * The model doesn't have an "id" field.
           * Object was created using the "add_xxx" method on the parent object.
         * The model's "updated" field is True.
           * Object was modified after it was created. Since object pulled from the API
               are create using **kwargs they are not updated.
         """
         _data = []
-        for model in nested_object.data:
+        for model in nested_object.data:  # type: ignore
             if self._calculate_nested_inclusion(method, mode, model):
                 data = model.gen_body(method, mode, nested=True)
                 if data:
                     _data.append(data)
 
         return _data
 
-    def _process_nested_data_object(self, method: str, mode: str, nested_object: 'BaseModel'):
+    def _process_nested_data_object(self, method: str, mode: str | None, nested_object: Self):
         """Process the nested data object (e.g., GroupsModel.data).
 
         Nested Object Inclusion Rules:
         * If the method is not PUT.
         * The model doesn't have an "id" field.
           * Object was created using the "add_xxx" method on the parent object.
         * The model's "updated" field is True.
           * Object was modified after it was created. Since object pulled from the API
               are create using **kwargs they are not updated.
         """
-        if self._calculate_nested_inclusion(method, mode, nested_object.data):
-            data = nested_object.data.gen_body(method, mode, nested=True)
+        if self._calculate_nested_inclusion(method, mode, nested_object.data):  # type: ignore
+            data = nested_object.data.gen_body(method, mode, nested=True)  # type: ignore
             if data:
                 return data
         return None
 
-    def _properties(self):
+    def _properties(self) -> dict[str, dict[str, str]]:
         """Return properties of the current model."""
         schema = self.schema(by_alias=False)
         if schema.get('properties') is not None:
-            return schema.get('properties')
-        return schema.get('definitions').get(self.__class__.__name__).get('properties')
+            return schema.get('properties', {})
+        return schema.get('definitions', {}).get(self.__class__.__name__, {}).get('properties', {})
 
     @staticmethod
     def gen_model_hash(json_: str) -> str:
         """Return the current dict hash."""
         # get hash of dict
         hash_ = hashlib.md5()  # nosec
         encoded = json_.encode()
         hash_.update(encoded)
         return hash_.hexdigest()
 
     def gen_body(
         self,
         method: str,
-        mode: Optional[str] = None,
-        exclude_none: Optional[bool] = True,
-        nested: Optional[bool] = False,
+        mode: str | None = None,
+        exclude_none: bool = True,
+        nested: bool = False,
     ) -> dict:
         """Return the generated body.
 
         The field included in the body depend on the HTTP Method and whether or not the object
         is nested. For example the ID should not be send on the parent object on a POST or PUT,
         but should be added for a PUT on a nested object.
         """
         _body = {}
         schema_properties = self._properties()
         for name, value in self:
             if exclude_none is True and value is None:
                 continue
 
             # get the current field from the schema to us in validating method membership.
-            property_ = schema_properties.get(name)
-            if property_ is None:
+            if schema_properties.get(name) is None:
                 # a field not being available does not indicate a failure, it could simple
                 # be the incorrect field was passed to the object, which will be dropped.
                 self._log.warning(
                     f'action=schema-check, type={self.__class__.__name__}, '
                     f'property={name}, result=not-found'
                 )
                 continue
 
-            key = property_.get('title')
+            property_ = schema_properties.get(name, {})
+            key = property_['title']
             if isinstance(value, BaseModel) and property_.get('read_only') is False:
-                # Handle nested models that should be included in the body (non-read-only).
+                value: Self = value
+                # Handle nested model that should be included in the body (non-read-only).
 
-                if hasattr(value, 'data') and isinstance(value.data, list):
-                    # Handle nested object types where the "data" field contains an array of models.
+                if hasattr(value, 'data') and isinstance(value.data, list):  # type: ignore
+                    # Handle nested object types where the "data" field contains an array of model.
                     _data = self._process_nested_data_array(method, mode, value)
                     if _data:
                         _body.setdefault(key, {})['data'] = _data
 
-                        if value._mode_support:
+                        # value as a model can be ArtifactTypeModel, ArtifactModel, etc.
+                        if value._mode_support:  # type: ignore
                             # Use the default mode defined in the model ("append") or the
                             # mode passed into this method as an override.
-                            _body.setdefault(key, {})['mode'] = mode or value.mode
+                            _body.setdefault(key, {})['mode'] = mode or value.mode  # type: ignore
 
                 elif hasattr(value, 'data'):
                     # Handle "non-standard" condition for Assignee where the nested "data"
                     # field contains an object instead of an Array.
                     _data = self._process_nested_data_object(method, mode, value)
                     if _data:
                         _body.setdefault(key, {})['data'] = _data
 
                         # Handle the extra "type" field that is only on Assignee objects.
                         if hasattr(value, 'type'):
-                            _body.setdefault(key, {})['type'] = value.type
+                            _body.setdefault(key, {})['type'] = value.type  # type: ignore
 
                 else:
                     # Handle nested object types where field contains an object.
                     # (e.g., CaseModel -> workflowTemplate field)
                     # if method == 'POST' or value.id is None or value.updated is True:
                     if self._calculate_nested_inclusion(method, mode, value):
                         _data = value.gen_body(method, mode, nested=True)
@@ -397,17 +402,17 @@
                 _body[key] = value
 
         return _body
 
     def gen_body_json(
         self,
         method: str,
-        mode: Optional[str] = None,
-        indent: Optional[int] = None,
-        sort_keys: Optional[bool] = False,
+        mode: str | None = None,
+        indent: int | None = None,
+        sort_keys: bool = False,
     ) -> str:
         """Wrap gen_body method returning JSON instead of dict."""
         # ensure mode is set to lower case if provided on gen_body entry point
         if mode is not None:
             mode = mode.lower()
 
         body = self.gen_body(method, mode)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/v3_types.py` & `tcex-4.0.0/tcex/api/tc/v3/v3_types.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-"""ThreatConnect API V3 Types."""
-# flake8: noqa
+"""TcEx Framework Module"""
+
 # standard library
-from typing import TYPE_CHECKING, Union
+from typing import TYPE_CHECKING
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.adversary_assets.adversary_asset import AdversaryAsset
+    # from tcex.api.tc.v3.adversary_assets.adversary_asset import AdversaryAsset
     from tcex.api.tc.v3.artifact_types.artifact_type import ArtifactType
     from tcex.api.tc.v3.artifacts.artifact import Artifact
     from tcex.api.tc.v3.cases.case import Case
     from tcex.api.tc.v3.groups.group import Group
     from tcex.api.tc.v3.indicators.indicator import Indicator
     from tcex.api.tc.v3.notes.note import Note
     from tcex.api.tc.v3.security.owner_roles.owner_role import OwnerRole
@@ -20,27 +20,27 @@
     from tcex.api.tc.v3.tags.tag import Tag
     from tcex.api.tc.v3.tasks.task import Task
     from tcex.api.tc.v3.victim_assets.victim_asset import VictimAsset
     from tcex.api.tc.v3.victims.victim import Victim
     from tcex.api.tc.v3.workflow_events.workflow_event import WorkflowEvent
     from tcex.api.tc.v3.workflow_templates.workflow_template import WorkflowTemplate
 
-    V3Type = Union[
-        AdversaryAsset,
-        ArtifactType,
-        Artifact,
-        Case,
-        Group,
-        Indicator,
-        Note,
-        OwnerRole,
-        Owner,
-        SystemRole,
-        UserGroup,
-        User,
-        Tag,
-        Task,
-        VictimAsset,
-        Victim,
-        WorkflowEvent,
-        WorkflowTemplate,
-    ]
+    V3Type = (
+        # AdversaryAsset
+        ArtifactType
+        | Artifact
+        | Case
+        | Group
+        | Indicator
+        | Note
+        | OwnerRole
+        | Owner
+        | SystemRole
+        | UserGroup
+        | User
+        | Tag
+        | Task
+        | VictimAsset
+        | Victim
+        | WorkflowEvent
+        | WorkflowTemplate
+    )
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,61 +1,23 @@
-"""VictimAsset / VictimAssets Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.groups.group_model import GroupModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.victim_assets.victim_asset_filter import VictimAssetFilter
 from tcex.api.tc.v3.victim_assets.victim_asset_model import VictimAssetModel, VictimAssetsModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.groups.group import Group
-
-
-class VictimAssets(ObjectCollectionABC):
-    """VictimAssets Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = VictimAssetsModel(**kwargs)
-        self.type_ = 'victim_assets'
-
-    def __iter__(self) -> 'VictimAsset':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=VictimAsset)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.VICTIM_ASSETS.value
-
-    @property
-    def filter(self) -> 'VictimAssetFilter':
-        """Return the type specific filter object."""
-        return VictimAssetFilter(self.tql)
+    from tcex.api.tc.v3.groups.group import Group  # CIRCULAR-IMPORT
 
 
 class VictimAsset(ObjectABC):
     """VictimAssets Object.
 
     Args:
         account_name (str, kwargs): The network name.
@@ -68,35 +30,35 @@
         social_network (str, kwargs): The type of social network.
         type (str, kwargs): Type of victim asset.
         victim_id (int, kwargs): Victim id of victim asset.
         website (str, kwargs): The website of the asset.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = VictimAssetModel(**kwargs)
+        self._model: VictimAssetModel = VictimAssetModel(**kwargs)
         self._nested_field_name = 'victimAssets'
         self._nested_filter = 'has_victim_asset'
         self.type_ = 'Victim Asset'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.VICTIM_ASSETS.value
 
     @property
-    def model(self) -> 'VictimAssetModel':
+    def model(self) -> VictimAssetModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['VictimAssetModel', dict]):
+    def model(self, data: dict | VictimAssetModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -104,53 +66,93 @@
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         value = []
 
-        if self.model.type.lower() == 'phone':
-            if self.model.phone:
-                value.append(self.model.phone)
-        elif self.model.type.lower() == 'socialnetwork':
-            if self.model.social_network:
-                value.append(self.model.social_network)
-            if self.model.account_name:
-                value.append(self.model.account_name)
-        elif self.model.type.lower() == 'networkaccount':
-            if self.model.network_type:
-                value.append(self.model.network_type)
-            if self.model.account_name:
-                value.append(self.model.account_name)
-        elif self.model.type.lower() == 'emailaddress':
-            if self.model.address_type:
-                value.append(self.model.address_type)
-            if self.model.address:
-                value.append(self.model.address)
-        elif self.model.type.lower() == 'website':
-            if self.model.website:
-                value.append(self.model.website)
+        if self.model.type is not None:
+            if self.model.type.lower() == 'phone':
+                if self.model.phone:
+                    value.append(self.model.phone)
+            elif self.model.type.lower() == 'socialnetwork':
+                if self.model.social_network:
+                    value.append(self.model.social_network)
+                if self.model.account_name:
+                    value.append(self.model.account_name)
+            elif self.model.type.lower() == 'networkaccount':
+                if self.model.network_type:
+                    value.append(self.model.network_type)
+                if self.model.account_name:
+                    value.append(self.model.account_name)
+            elif self.model.type.lower() == 'emailaddress':
+                if self.model.address_type:
+                    value.append(self.model.address_type)
+                if self.model.address:
+                    value.append(self.model.address)
+            elif self.model.type.lower() == 'website':
+                if self.model.website:
+                    value.append(self.model.website)
 
         value = ' : '.join(value) if value else ''
         type_ = f'Victim Asset : {self.model.type}'
 
         return {'type': type_, 'id': self.model.id, 'value': value}
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator['Group', None, None]:
         """Yield Group from Groups."""
         # first-party
         from tcex.api.tc.v3.groups.group import Groups
 
-        yield from self._iterate_over_sublist(Groups)
+        yield from self._iterate_over_sublist(Groups)  # type: ignore
 
-    def stage_associated_group(self, data: Union[dict, 'ObjectABC', 'GroupModel']):
+    def stage_associated_group(self, data: dict | ObjectABC | GroupModel):
         """Stage group on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = GroupModel(**data)
 
         if not isinstance(data, GroupModel):
             raise RuntimeError('Invalid type passed in to stage_associated_group')
         data._staged = True
-        self.model.associated_groups.data.append(data)
+        self.model.associated_groups.data.append(data)  # type: ignore
+
+
+class VictimAssets(ObjectCollectionABC):
+    """VictimAssets Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = VictimAssetsModel(**kwargs)
+        self.type_ = 'victim_assets'
+
+    def __iter__(self) -> Iterator[VictimAsset]:
+        """Return CM objects."""
+        return self.iterate(base_class=VictimAsset)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.VICTIM_ASSETS.value
+
+    @property
+    def filter(self) -> VictimAssetFilter:
+        """Return the type specific filter object."""
+        return VictimAssetFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template_filter.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,146 +1,146 @@
-"""Victim_Asset TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
 from enum import Enum
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
-from tcex.api.tc.v3.tql.tql import Tql
-from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class VictimAssetFilter(FilterABC):
-    """Filter Object for VictimAssets"""
+class WorkflowTemplateFilter(FilterABC):
+    """Filter Object for WorkflowTemplates"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.VICTIM_ASSETS.value
+        return ApiEndpoints.WORKFLOW_TEMPLATES.value
 
-    def asset(self, operator: Enum, asset: str):
-        """Filter Asset based on **asset** keyword.
+    def active(self, operator: Enum, active: bool):
+        """Filter Active based on **active** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            asset: The sub-type of the victim asset.
+            active: The active status of this template.
         """
-        self._tql.add_filter('asset', operator, asset, TqlType.STRING)
+        self._tql.add_filter('active', operator, active, TqlType.BOOLEAN)
 
-    def associated_group(self, operator: Enum, associated_group: int):
-        """Filter associatedGroup based on **associatedGroup** keyword.
+    def description(self, operator: Enum, description: list | str):
+        """Filter Description based on **description** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            associated_group: No description provided.
+            description: The description of this template.
         """
-        self._tql.add_filter('associatedGroup', operator, associated_group, TqlType.INTEGER)
+        if isinstance(description, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    @property
-    def has_group(self):
-        """Return **GroupFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.groups.group_filter import GroupFilter
-
-        groups = GroupFilter(Tql())
-        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
-        return groups
+        self._tql.add_filter('description', operator, description, TqlType.STRING)
 
-    @property
-    def has_indicator(self):
-        """Return **IndicatorFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-
-        indicators = IndicatorFilter(Tql())
-        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
-        return indicators
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
+        """Filter ID based on **id** keyword.
 
-    @property
-    def has_victim(self):
-        """Return **VictimFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
-
-        victims = VictimFilter(Tql())
-        self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
-        return victims
+        Args:
+            operator: The operator enum for the filter.
+            id: The ID of the template.
+        """
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    @property
-    def has_victim_asset(self):
-        """Return **VictimAssetFilter** for further filtering."""
-        victim_assets = VictimAssetFilter(Tql())
-        self._tql.add_filter('hasVictimAsset', TqlOperator.EQ, victim_assets, TqlType.SUB_QUERY)
-        return victim_assets
+        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
-        """Filter ID based on **id** keyword.
+    def name(self, operator: Enum, name: list | str):
+        """Filter Name based on **name** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the victim asset.
+            name: The name of this template.
         """
-        self._tql.add_filter('id', operator, id, TqlType.INTEGER)
+        if isinstance(name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('name', operator, name, TqlType.STRING)
 
-    def owner(self, operator: Enum, owner: int):
+    def owner(self, operator: Enum, owner: int | list):
         """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner: The owner ID of the victim.
+            owner: The Owner ID for the template.
         """
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-    def owner_name(self, operator: Enum, owner_name: str):
+    def owner_name(self, operator: Enum, owner_name: list | str):
         """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name of the victim.
+            owner_name: The owner name for the template.
         """
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
+    def target_id(self, operator: Enum, target_id: int | list):
+        """Filter Target ID based on **targetId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            summary: The name of the victim asset.
+            target_id: The assigned user or group ID for the template.
         """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
-
-    def type(self, operator: Enum, type: int):  # pylint: disable=redefined-builtin
-        """Filter Type ID based on **type** keyword.
+        if isinstance(target_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-        Args:
-            operator: The operator enum for the filter.
-            type: The ID of the victim asset type.
-        """
-        self._tql.add_filter('type', operator, type, TqlType.INTEGER)
+        self._tql.add_filter('targetId', operator, target_id, TqlType.INTEGER)
 
-    def type_name(self, operator: Enum, type_name: str):
-        """Filter Type Name based on **typeName** keyword.
+    def target_type(self, operator: Enum, target_type: list | str):
+        """Filter Target Type based on **targetType** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            type_name: The name of the victim asset type.
+            target_type: The target type for this template (either User or Group).
         """
-        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
+        if isinstance(target_type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def victim_id(self, operator: Enum, victim_id: int):
-        """Filter Victim ID based on **victimId** keyword.
+        self._tql.add_filter('targetType', operator, target_type, TqlType.STRING)
 
-        Args:
-            operator: The operator enum for the filter.
-            victim_id: The ID of the victim the victim asset is applied to.
-        """
-        self._tql.add_filter('victimId', operator, victim_id, TqlType.INTEGER)
-
-    def victim_name(self, operator: Enum, victim_name: str):
-        """Filter Victim Name based on **victimName** keyword.
+    def version(self, operator: Enum, version: int | list):
+        """Filter Version based on **version** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            victim_name: The name of the victim.
+            version: The version of this template.
         """
-        self._tql.add_filter('victimName', operator, victim_name, TqlType.STRING)
+        if isinstance(version, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('version', operator, version, TqlType.INTEGER)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victim_assets/victim_asset_model.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_assets/victim_asset_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,187 +1,184 @@
-"""Victim_Asset / Victim_Assets Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class VictimAssetsModel(
-    BaseModel,
-    title='VictimAssets Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victim_Assets Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['VictimAssetModel']] = Field(
-        [],
-        description='The data for the VictimAssets.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class VictimAssetDataModel(
-    BaseModel,
-    title='VictimAsset Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victim_Assets Data Model"""
-
-    data: Optional[List['VictimAssetModel']] = Field(
-        [],
-        description='The data for the VictimAssets.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class VictimAssetModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='VictimAsset Model',
     validate_assignment=True,
 ):
     """Victim_Asset Model"""
 
     _associated_type = PrivateAttr(True)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    account_name: Optional[str] = Field(
+    account_name: str | None = Field(
         None,
         applies_to=['SocialNetwork', 'NetworkAccount'],
         conditional_required=['SocialNetwork', 'NetworkAccount'],
         description='The network name.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='accountName',
     )
-    address: Optional[str] = Field(
+    address: str | None = Field(
         None,
         applies_to=['EmailAddress'],
         conditional_required=['EmailAddress'],
         description='The email address associated with the E-Mail Address asset.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='address',
     )
-    address_type: Optional[str] = Field(
+    address_type: str | None = Field(
         None,
         applies_to=['EmailAddress'],
         description='The type of the E-Mail Address asset.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='addressType',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of groups that this victim asset is associated with.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    network_type: Optional[str] = Field(
+    network_type: str | None = Field(
         None,
         applies_to=['NetworkAccount'],
         conditional_required=['NetworkAccount'],
         description='The type of network.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='networkType',
     )
-    phone: Optional[str] = Field(
+    phone: str | None = Field(
         None,
         applies_to=['Phone'],
         conditional_required=['Phone'],
         description='The phone number of the asset.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='phone',
     )
-    social_network: Optional[str] = Field(
+    social_network: str | None = Field(
         None,
         applies_to=['SocialNetwork'],
         conditional_required=['SocialNetwork'],
         description='The type of social network.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='socialNetwork',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='Type of victim asset.',
         methods=['POST'],
         min_length=1,
         read_only=False,
         title='type',
     )
-    victim_id: Optional[int] = Field(
+    victim_id: int | None = Field(
         None,
         description='Victim id of victim asset.',
         methods=['POST'],
         read_only=False,
         title='victimId',
     )
-    web_link: Optional[str] = Field(
+    web_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the ThreatConnect details page for this entity.',
         read_only=True,
         title='webLink',
     )
-    website: Optional[str] = Field(
+    website: str | None = Field(
         None,
         applies_to=['WebSite'],
         conditional_required=['WebSite'],
         description='The website of the asset.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
         title='website',
     )
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
 
+class VictimAssetDataModel(
+    BaseModel,
+    title='VictimAsset Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victim_Assets Data Model"""
+
+    data: list[VictimAssetModel] | None = Field(
+        [],
+        description='The data for the VictimAssets.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class VictimAssetsModel(
+    BaseModel,
+    title='VictimAssets Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victim_Assets Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[VictimAssetModel] | None = Field(
+        [],
+        description='The data for the VictimAssets.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.groups.group_model import GroupsModel
 
 # add forward references
 VictimAssetDataModel.update_forward_refs()
 VictimAssetModel.update_forward_refs()
 VictimAssetsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victim_attributes/victim_attribute.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,64 +1,26 @@
-"""VictimAttribute / VictimAttributes Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 from tcex.api.tc.v3.victim_attributes.victim_attribute_filter import VictimAttributeFilter
 from tcex.api.tc.v3.victim_attributes.victim_attribute_model import (
     VictimAttributeModel,
     VictimAttributesModel,
 )
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-
-
-class VictimAttributes(ObjectCollectionABC):
-    """VictimAttributes Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = VictimAttributesModel(**kwargs)
-        self.type_ = 'victim_attributes'
-
-    def __iter__(self) -> 'VictimAttribute':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=VictimAttribute)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.VICTIM_ATTRIBUTES.value
-
-    @property
-    def filter(self) -> 'VictimAttributeFilter':
-        """Return the type specific filter object."""
-        return VictimAttributeFilter(self.tql)
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
 
 
 class VictimAttribute(ObjectABC):
     """VictimAttributes Object.
 
     Args:
         default (bool, kwargs): A flag indicating that this is the default attribute of its type
@@ -70,57 +32,96 @@
         source (str, kwargs): The attribute source.
         type (str, kwargs): The attribute type.
         value (str, kwargs): The attribute value.
         victim_id (int, kwargs): Victim associated with attribute.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = VictimAttributeModel(**kwargs)
+        self._model: VictimAttributeModel = VictimAttributeModel(**kwargs)
         self._nested_field_name = 'victimAttributes'
         self._nested_filter = 'has_victim_attribute'
         self.type_ = 'Victim Attribute'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.VICTIM_ATTRIBUTES.value
 
     @property
-    def model(self) -> 'VictimAttributeModel':
+    def model(self) -> VictimAttributeModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['VictimAttributeModel', dict]):
+    def model(self, data: dict | VictimAttributeModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
         else:
             raise RuntimeError(f'Invalid data type: {type(data)} provided.')
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
+
+
+class VictimAttributes(ObjectCollectionABC):
+    """VictimAttributes Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = VictimAttributesModel(**kwargs)
+        self.type_ = 'victim_attributes'
+
+    def __iter__(self) -> Iterator[VictimAttribute]:
+        """Return CM objects."""
+        return self.iterate(base_class=VictimAttribute)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.VICTIM_ATTRIBUTES.value
+
+    @property
+    def filter(self) -> VictimAttributeFilter:
+        """Return the type specific filter object."""
+        return VictimAttributeFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victim_attributes/victim_attribute_model.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,83 +1,42 @@
-"""Victim_Attribute / Victim_Attributes Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class VictimAttributesModel(
-    BaseModel,
-    title='VictimAttributes Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victim_Attributes Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['VictimAttributeModel']] = Field(
-        [],
-        description='The data for the VictimAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class VictimAttributeDataModel(
-    BaseModel,
-    title='VictimAttribute Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victim_Attributes Data Model"""
-
-    data: Optional[List['VictimAttributeModel']] = Field(
-        [],
-        description='The data for the VictimAttributes.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class VictimAttributeModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='VictimAttribute Model',
     validate_assignment=True,
 ):
     """Victim_Attribute Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    created_by: Optional['UserModel'] = Field(
+    created_by: 'UserModel' = Field(
         None,
         allow_mutation=False,
         description='The **created by** for the Victim_Attribute.',
         read_only=True,
         title='createdBy',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
     default: bool = Field(
@@ -86,87 +45,127 @@
             'A flag indicating that this is the default attribute of its type within the object. '
             'Only applies to certain attribute and data types.'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='default',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    last_modified: Optional[datetime] = Field(
+    last_modified: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the Attribute was last modified.',
         read_only=True,
         title='lastModified',
     )
     pinned: bool = Field(
         None,
         description='A flag indicating that the attribute has been noted for importance.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='pinned',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    source: Optional[str] = Field(
+    source: str | None = Field(
         None,
         description='The attribute source.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='source',
     )
-    type: Optional[str] = Field(
+    type: str | None = Field(
         None,
         description='The attribute type.',
         methods=['POST'],
         read_only=False,
         title='type',
     )
-    value: Optional[str] = Field(
+    value: str | None = Field(
         None,
         description='The attribute value.',
         methods=['POST', 'PUT'],
         min_length=1,
         read_only=False,
         title='value',
     )
-    victim_id: Optional[int] = Field(
+    victim_id: int | None = Field(
         None,
         description='Victim associated with attribute.',
         methods=['POST'],
         read_only=False,
         title='victimId',
     )
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('created_by', always=True)
+    @validator('created_by', always=True, pre=True)
     def _validate_user(cls, v):
         if not v:
-            return UserModel()
+            return UserModel()  # type: ignore
         return v
 
 
+class VictimAttributeDataModel(
+    BaseModel,
+    title='VictimAttribute Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victim_Attributes Data Model"""
+
+    data: list[VictimAttributeModel] | None = Field(
+        [],
+        description='The data for the VictimAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class VictimAttributesModel(
+    BaseModel,
+    title='VictimAttributes Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victim_Attributes Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[VictimAttributeModel] | None = Field(
+        [],
+        description='The data for the VictimAttributes.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.security.users.user_model import UserModel
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelsModel
 
 # add forward references
 VictimAttributeDataModel.update_forward_refs()
 VictimAttributeModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victims/victim.py` & `tcex-4.0.0/tcex/api/tc/v3/victims/victim.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,68 +1,30 @@
-"""Victim / Victims Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelModel
 from tcex.api.tc.v3.tags.tag_model import TagModel
 from tcex.api.tc.v3.victim_assets.victim_asset_model import VictimAssetModel
 from tcex.api.tc.v3.victim_attributes.victim_attribute_model import VictimAttributeModel
 from tcex.api.tc.v3.victims.victim_filter import VictimFilter
 from tcex.api.tc.v3.victims.victim_model import VictimModel, VictimsModel
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.groups.group import Group
-    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel
-    from tcex.api.tc.v3.tags.tag import Tag
-    from tcex.api.tc.v3.victim_assets.victim_asset import VictimAsset
-    from tcex.api.tc.v3.victim_attributes.victim_attribute import VictimAttribute
-
-
-class Victims(ObjectCollectionABC):
-    """Victims Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = VictimsModel(**kwargs)
-        self.type_ = 'victims'
-
-    def __iter__(self) -> 'Victim':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=Victim)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.VICTIMS.value
-
-    @property
-    def filter(self) -> 'VictimFilter':
-        """Return the type specific filter object."""
-        return VictimFilter(self.tql)
+    from tcex.api.tc.v3.groups.group import Group  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.security_labels.security_label import SecurityLabel  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.tags.tag import Tag  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.victim_assets.victim_asset import VictimAsset  # CIRCULAR-IMPORT
+    from tcex.api.tc.v3.victim_attributes.victim_attribute import VictimAttribute  # CIRCULAR-IMPORT
 
 
 class Victim(ObjectABC):
     """Victims Object.
 
     Args:
         assets (VictimAssets, kwargs): A list of victim assets corresponding to the Victim.
@@ -77,35 +39,35 @@
         suborg (str, kwargs): Suborg of the Victim.
         tags (Tags, kwargs): A list of Tags corresponding to the item (NOTE: Setting this parameter
             will replace any existing tag(s) with the one(s) specified).
         work_location (str, kwargs): Work location of the Victim.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = VictimModel(**kwargs)
+        self._model: VictimModel = VictimModel(**kwargs)
         self._nested_field_name = 'victims'
         self._nested_filter = 'has_victim'
         self.type_ = 'Victim'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.VICTIMS.value
 
     @property
-    def model(self) -> 'VictimModel':
+    def model(self) -> VictimModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['VictimModel', dict]):
+    def model(self, data: dict | VictimModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -116,93 +78,132 @@
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.name}
 
     @property
-    def victim_assets(self) -> Iterator['VictimAsset']:
+    def victim_assets(self) -> Generator['VictimAsset', None, None]:
         """Yield VictimAsset from VictimAssets."""
         # first-party
         from tcex.api.tc.v3.victim_assets.victim_asset import VictimAssets
 
-        yield from self._iterate_over_sublist(VictimAssets)
+        yield from self._iterate_over_sublist(VictimAssets)  # type: ignore
 
     @property
-    def associated_groups(self) -> Iterator['Group']:
+    def associated_groups(self) -> Generator['Group', None, None]:
         """Yield Group from Groups."""
         # first-party
         from tcex.api.tc.v3.groups.group import Groups
 
-        yield from self._iterate_over_sublist(Groups)
+        yield from self._iterate_over_sublist(Groups)  # type: ignore
 
     @property
-    def attributes(self) -> Iterator['VictimAttribute']:
+    def attributes(self) -> Generator['VictimAttribute', None, None]:
         """Yield Attribute from Attributes."""
         # first-party
         from tcex.api.tc.v3.victim_attributes.victim_attribute import VictimAttributes
 
-        yield from self._iterate_over_sublist(VictimAttributes)
+        yield from self._iterate_over_sublist(VictimAttributes)  # type: ignore
 
     @property
-    def security_labels(self) -> Iterator['SecurityLabel']:
+    def security_labels(self) -> Generator['SecurityLabel', None, None]:
         """Yield SecurityLabel from SecurityLabels."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label import SecurityLabels
 
-        yield from self._iterate_over_sublist(SecurityLabels)
+        yield from self._iterate_over_sublist(SecurityLabels)  # type: ignore
 
     @property
-    def tags(self) -> Iterator['Tag']:
+    def tags(self) -> Generator['Tag', None, None]:
         """Yield Tag from Tags."""
         # first-party
         from tcex.api.tc.v3.tags.tag import Tags
 
-        yield from self._iterate_over_sublist(Tags)
+        yield from self._iterate_over_sublist(Tags)  # type: ignore
 
-    def stage_victim_asset(self, data: Union[dict, 'ObjectABC', 'VictimAssetModel']):
+    def stage_victim_asset(self, data: dict | ObjectABC | VictimAssetModel):
         """Stage victim_asset on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = VictimAssetModel(**data)
 
         if not isinstance(data, VictimAssetModel):
             raise RuntimeError('Invalid type passed in to stage_victim_asset')
         data._staged = True
-        self.model.assets.data.append(data)
+        self.model.assets.data.append(data)  # type: ignore
 
-    def stage_attribute(self, data: Union[dict, 'ObjectABC', 'VictimAttributeModel']):
+    def stage_attribute(self, data: dict | ObjectABC | VictimAttributeModel):
         """Stage attribute on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = VictimAttributeModel(**data)
 
         if not isinstance(data, VictimAttributeModel):
             raise RuntimeError('Invalid type passed in to stage_attribute')
         data._staged = True
-        self.model.attributes.data.append(data)
+        self.model.attributes.data.append(data)  # type: ignore
 
-    def stage_security_label(self, data: Union[dict, 'ObjectABC', 'SecurityLabelModel']):
+    def stage_security_label(self, data: dict | ObjectABC | SecurityLabelModel):
         """Stage security_label on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = SecurityLabelModel(**data)
 
         if not isinstance(data, SecurityLabelModel):
             raise RuntimeError('Invalid type passed in to stage_security_label')
         data._staged = True
-        self.model.security_labels.data.append(data)
+        self.model.security_labels.data.append(data)  # type: ignore
 
-    def stage_tag(self, data: Union[dict, 'ObjectABC', 'TagModel']):
+    def stage_tag(self, data: dict | ObjectABC | TagModel):
         """Stage tag on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = TagModel(**data)
 
         if not isinstance(data, TagModel):
             raise RuntimeError('Invalid type passed in to stage_tag')
         data._staged = True
-        self.model.tags.data.append(data)
+        self.model.tags.data.append(data)  # type: ignore
+
+
+class Victims(ObjectCollectionABC):
+    """Victims Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = VictimsModel(**kwargs)
+        self.type_ = 'victims'
+
+    def __iter__(self) -> Iterator[Victim]:
+        """Return CM objects."""
+        return self.iterate(base_class=Victim)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.VICTIMS.value
+
+    @property
+    def filter(self) -> VictimFilter:
+        """Return the type specific filter object."""
+        return VictimFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victims/victim_filter.py` & `tcex-4.0.0/tcex/api/tc/v3/victim_attributes/victim_attribute_filter.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,248 +1,256 @@
-"""Victim TQL Filter"""
+"""TcEx Framework Module"""
 # standard library
+from datetime import datetime
 from enum import Enum
 
+# third-party
+from arrow import Arrow
+
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.filter_abc import FilterABC
 from tcex.api.tc.v3.tql.tql import Tql
 from tcex.api.tc.v3.tql.tql_operator import TqlOperator
 from tcex.api.tc.v3.tql.tql_type import TqlType
 
 
-class VictimFilter(FilterABC):
-    """Filter Object for Victims"""
+class VictimAttributeFilter(FilterABC):
+    """Filter Object for VictimAttributes"""
 
     @property
     def _api_endpoint(self) -> str:
         """Return the API endpoint."""
-        return ApiEndpoints.VICTIMS.value
-
-    def asset_name(self, operator: Enum, asset_name: str):
-        """Filter Asset Name based on **assetName** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            asset_name: The asset name assigned to a victim.
-        """
-        self._tql.add_filter('assetName', operator, asset_name, TqlType.STRING)
-
-    def asset_type(self, operator: Enum, asset_type: int):
-        """Filter Asset Type ID based on **assetType** keyword.
-
-        Args:
-            operator: The operator enum for the filter.
-            asset_type: The asset type ID assigned to a victim.
-        """
-        self._tql.add_filter('assetType', operator, asset_type, TqlType.INTEGER)
+        return ApiEndpoints.VICTIM_ATTRIBUTES.value
 
-    def asset_typename(self, operator: Enum, asset_typename: str):
-        """Filter Asset Type Name based on **assetTypename** keyword.
+    def date_added(self, operator: Enum, date_added: Arrow | datetime | int | str):
+        """Filter Date Added based on **dateAdded** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            asset_typename: The asset type name assigned to a victim.
+            date_added: The date the attribute was added to the system.
         """
-        self._tql.add_filter('assetTypename', operator, asset_typename, TqlType.STRING)
+        date_added = self.util.any_to_datetime(date_added).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('dateAdded', operator, date_added, TqlType.STRING)
 
-    def attribute(self, operator: Enum, attribute: str):
-        """Filter attribute based on **attribute** keyword.
+    def date_val(self, operator: Enum, date_val: Arrow | datetime | int | str):
+        """Filter Date based on **dateVal** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            attribute: No description provided.
+            date_val: The date value of the attribute (only applies to certain types).
         """
-        self._tql.add_filter('attribute', operator, attribute, TqlType.STRING)
+        date_val = self.util.any_to_datetime(date_val).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('dateVal', operator, date_val, TqlType.STRING)
 
-    def description(self, operator: Enum, description: str):
-        """Filter Description based on **description** keyword.
+    def displayed(self, operator: Enum, displayed: bool):
+        """Filter Displayed based on **displayed** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            description: The description of the victim.
+            displayed: Whether or not the attribute is displayed on the item.
         """
-        self._tql.add_filter('description', operator, description, TqlType.STRING)
-
-    @property
-    def has_attribute(self):
-        """Return **VictimAttributeFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.victim_attributes.victim_attribute_filter import VictimAttributeFilter
-
-        attributes = VictimAttributeFilter(Tql())
-        self._tql.add_filter('hasAttribute', TqlOperator.EQ, attributes, TqlType.SUB_QUERY)
-        return attributes
-
-    @property
-    def has_group(self):
-        """Return **GroupFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.groups.group_filter import GroupFilter
-
-        groups = GroupFilter(Tql())
-        self._tql.add_filter('hasGroup', TqlOperator.EQ, groups, TqlType.SUB_QUERY)
-        return groups
-
-    @property
-    def has_indicator(self):
-        """Return **IndicatorFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.indicators.indicator_filter import IndicatorFilter
-
-        indicators = IndicatorFilter(Tql())
-        self._tql.add_filter('hasIndicator', TqlOperator.EQ, indicators, TqlType.SUB_QUERY)
-        return indicators
+        self._tql.add_filter('displayed', operator, displayed, TqlType.BOOLEAN)
 
     @property
     def has_security_label(self):
         """Return **SecurityLabel** for further filtering."""
         # first-party
         from tcex.api.tc.v3.security_labels.security_label_filter import SecurityLabelFilter
 
         security_labels = SecurityLabelFilter(Tql())
         self._tql.add_filter('hasSecurityLabel', TqlOperator.EQ, security_labels, TqlType.SUB_QUERY)
         return security_labels
 
     @property
-    def has_tag(self):
-        """Return **TagFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.tags.tag_filter import TagFilter
-
-        tags = TagFilter(Tql())
-        self._tql.add_filter('hasTag', TqlOperator.EQ, tags, TqlType.SUB_QUERY)
-        return tags
-
-    @property
     def has_victim(self):
         """Return **VictimFilter** for further filtering."""
+        # first-party
+        from tcex.api.tc.v3.victims.victim_filter import VictimFilter
+
         victims = VictimFilter(Tql())
         self._tql.add_filter('hasVictim', TqlOperator.EQ, victims, TqlType.SUB_QUERY)
         return victims
 
-    @property
-    def has_victim_asset(self):
-        """Return **VictimAssetFilter** for further filtering."""
-        # first-party
-        from tcex.api.tc.v3.victim_assets.victim_asset_filter import VictimAssetFilter
-
-        victim_assets = VictimAssetFilter(Tql())
-        self._tql.add_filter('hasVictimAsset', TqlOperator.EQ, victim_assets, TqlType.SUB_QUERY)
-        return victim_assets
-
-    def id(self, operator: Enum, id: int):  # pylint: disable=redefined-builtin
+    def id(self, operator: Enum, id: int | list):  # pylint: disable=redefined-builtin
         """Filter ID based on **id** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            id: The ID of the victim.
+            id: The ID of the attribute.
         """
+        if isinstance(id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('id', operator, id, TqlType.INTEGER)
 
-    def name(self, operator: Enum, name: str):
-        """Filter Name based on **name** keyword.
+    def int_val(self, operator: Enum, int_val: int | list):
+        """Filter Integer Value based on **intVal** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            name: The name of the victim.
+            int_val: The integer value of the attribute (only applies to certain types).
         """
-        self._tql.add_filter('name', operator, name, TqlType.STRING)
+        if isinstance(int_val, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('intVal', operator, int_val, TqlType.INTEGER)
 
-    def nationality(self, operator: Enum, nationality: str):
-        """Filter Nationality based on **nationality** keyword.
+    def last_modified(self, operator: Enum, last_modified: Arrow | datetime | int | str):
+        """Filter Last Modified based on **lastModified** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            nationality: The nationality of the victim.
+            last_modified: The date the attribute was last modified in the system.
         """
-        self._tql.add_filter('nationality', operator, nationality, TqlType.STRING)
+        last_modified = self.util.any_to_datetime(last_modified).strftime('%Y-%m-%d %H:%M:%S')
+        self._tql.add_filter('lastModified', operator, last_modified, TqlType.STRING)
 
-    def organization(self, operator: Enum, organization: str):
-        """Filter Organization based on **organization** keyword.
+    def max_size(self, operator: Enum, max_size: int | list):
+        """Filter Max Size based on **maxSize** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            organization: The organization of the victim.
+            max_size: The max length of the attribute text.
         """
-        self._tql.add_filter('organization', operator, organization, TqlType.STRING)
+        if isinstance(max_size, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('maxSize', operator, max_size, TqlType.INTEGER)
 
-    def owner(self, operator: Enum, owner: int):
+    def owner(self, operator: Enum, owner: int | list):
         """Filter Owner ID based on **owner** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner: The owner ID of the victim.
+            owner: The owner ID of the attribute.
         """
+        if isinstance(owner, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('owner', operator, owner, TqlType.INTEGER)
 
-    def owner_name(self, operator: Enum, owner_name: str):
+    def owner_name(self, operator: Enum, owner_name: list | str):
         """Filter Owner Name based on **ownerName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            owner_name: The owner name of the victim.
+            owner_name: The owner name of the attribute.
         """
+        if isinstance(owner_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
         self._tql.add_filter('ownerName', operator, owner_name, TqlType.STRING)
 
-    def security_label(self, operator: Enum, security_label: str):
-        """Filter Security Label based on **securityLabel** keyword.
+    def pinned(self, operator: Enum, pinned: bool):
+        """Filter Pinned based on **pinned** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            security_label: The name of a security label applied to the victim.
+            pinned: Whether or not the attribute is pinned with importance.
         """
-        self._tql.add_filter('securityLabel', operator, security_label, TqlType.STRING)
+        self._tql.add_filter('pinned', operator, pinned, TqlType.BOOLEAN)
 
-    def sub_org(self, operator: Enum, sub_org: str):
-        """Filter Sub-organization based on **subOrg** keyword.
+    def source(self, operator: Enum, source: list | str):
+        """Filter Source based on **source** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            sub_org: The sub-organization of the victim.
+            source: The source text of the attribute.
         """
-        self._tql.add_filter('subOrg', operator, sub_org, TqlType.STRING)
+        if isinstance(source, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('source', operator, source, TqlType.STRING)
 
-    def summary(self, operator: Enum, summary: str):
-        """Filter Summary based on **summary** keyword.
+    def text(self, operator: Enum, text: list | str):
+        """Filter Text based on **text** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            summary: The name of the victim.
+            text: The text of the attribute (only applies to certain types).
         """
-        self._tql.add_filter('summary', operator, summary, TqlType.STRING)
+        if isinstance(text, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def tag(self, operator: Enum, tag: str):
-        """Filter Tag based on **tag** keyword.
+        self._tql.add_filter('text', operator, text, TqlType.STRING)
+
+    def type(self, operator: Enum, type: int | list):  # pylint: disable=redefined-builtin
+        """Filter Type ID based on **type** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag: The name of a tag applied to the victim.
+            type: The ID of the attribute type.
         """
-        self._tql.add_filter('tag', operator, tag, TqlType.STRING)
+        if isinstance(type, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('type', operator, type, TqlType.INTEGER)
 
-    def tag_owner(self, operator: Enum, tag_owner: int):
-        """Filter Tag Owner ID based on **tagOwner** keyword.
+    def type_name(self, operator: Enum, type_name: list | str):
+        """Filter Type Name based on **typeName** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag_owner: The owner ID of a tag applied to the victim.
+            type_name: The name of the attribute type.
         """
-        self._tql.add_filter('tagOwner', operator, tag_owner, TqlType.INTEGER)
+        if isinstance(type_name, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('typeName', operator, type_name, TqlType.STRING)
 
-    def tag_owner_name(self, operator: Enum, tag_owner_name: str):
-        """Filter Tag Owner Name based on **tagOwnerName** keyword.
+    def user(self, operator: Enum, user: list | str):
+        """Filter User based on **user** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            tag_owner_name: The owner name of a tag applied to the victim.
+            user: The user who created the attribute.
         """
-        self._tql.add_filter('tagOwnerName', operator, tag_owner_name, TqlType.STRING)
+        if isinstance(user, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
 
-    def work_location(self, operator: Enum, work_location: str):
-        """Filter Work Location based on **workLocation** keyword.
+        self._tql.add_filter('user', operator, user, TqlType.STRING)
+
+    def victim_id(self, operator: Enum, victim_id: int | list):
+        """Filter Victim ID based on **victimId** keyword.
 
         Args:
             operator: The operator enum for the filter.
-            work_location: The work location of the victim.
+            victim_id: The ID of the victim the victim attribute is applied to.
         """
-        self._tql.add_filter('workLocation', operator, work_location, TqlType.STRING)
+        if isinstance(victim_id, list) and operator not in self.list_types:
+            raise RuntimeError(
+                'Operator must be CONTAINS, NOT_CONTAINS, IN'
+                'or NOT_IN when filtering on a list of values.'
+            )
+
+        self._tql.add_filter('victimId', operator, victim_id, TqlType.INTEGER)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/victims/victim_model.py` & `tcex-4.0.0/tcex/api/tc/v3/victims/victim_model.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,229 +1,228 @@
-"""Victim / Victims Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
 from datetime import datetime
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
-
-class VictimsModel(
-    BaseModel,
-    title='Victims Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victims Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['VictimModel']] = Field(
-        [],
-        description='The data for the Victims.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class VictimDataModel(
-    BaseModel,
-    title='Victim Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Victims Data Model"""
-
-    data: Optional[List['VictimModel']] = Field(
-        [],
-        description='The data for the Victims.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
+from tcex.util import Util
 
 
 class VictimModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
     title='Victim Model',
     validate_assignment=True,
 ):
     """Victim Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(False)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    assets: Optional['VictimAssetsModel'] = Field(
+    assets: 'VictimAssetsModel' = Field(
         None,
         description='A list of victim assets corresponding to the Victim.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='assets',
     )
-    associated_groups: Optional['GroupsModel'] = Field(
+    associated_groups: 'GroupsModel' = Field(
         None,
         description='A list of groups that this victim is associated with.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='associatedGroups',
     )
-    attributes: Optional['VictimAttributesModel'] = Field(
+    attributes: 'VictimAttributesModel' = Field(
         None,
         description='A list of Attributes corresponding to the Victim.',
         methods=['POST', 'PUT'],
         read_only=False,
         title='attributes',
     )
-    date_added: Optional[datetime] = Field(
+    date_added: datetime | None = Field(
         None,
         allow_mutation=False,
         description='The date and time that the item was first created.',
         read_only=True,
         title='dateAdded',
     )
-    description: Optional[str] = Field(
+    description: str | None = Field(
         None,
         allow_mutation=False,
         description='Description of the Victim.',
         max_length=255,
         min_length=0,
         read_only=True,
         title='description',
     )
-    id: Optional[int] = Field(
+    id: int | None = Field(
         None,
         description='The ID of the item.',
         read_only=True,
         title='id',
     )
-    name: Optional[str] = Field(
+    name: str | None = Field(
         None,
         description='Name of the Victim.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=1,
         read_only=False,
         title='name',
     )
-    nationality: Optional[str] = Field(
+    nationality: str | None = Field(
         None,
         description='Nationality of the Victim.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='nationality',
     )
-    org: Optional[str] = Field(
+    org: str | None = Field(
         None,
         description='Org of the Victim.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='org',
     )
-    owner_name: Optional[str] = Field(
+    owner_name: str | None = Field(
         None,
         allow_mutation=False,
         description='The name of the Organization, Community, or Source that the item belongs to.',
         read_only=True,
         title='ownerName',
     )
-    security_labels: Optional['SecurityLabelsModel'] = Field(
+    security_labels: 'SecurityLabelsModel' = Field(
         None,
         description=(
             'A list of Security Labels corresponding to the Intel item (NOTE: Setting this '
             'parameter will replace any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='securityLabels',
     )
-    suborg: Optional[str] = Field(
+    suborg: str | None = Field(
         None,
         description='Suborg of the Victim.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='suborg',
     )
-    tags: Optional['TagsModel'] = Field(
+    tags: 'TagsModel' = Field(
         None,
         description=(
             'A list of Tags corresponding to the item (NOTE: Setting this parameter will replace '
             'any existing tag(s) with the one(s) specified).'
         ),
         methods=['POST', 'PUT'],
         read_only=False,
         title='tags',
     )
-    web_link: Optional[str] = Field(
+    web_link: str | None = Field(
         None,
         allow_mutation=False,
         description='A link to the ThreatConnect details page for this entity.',
         read_only=True,
         title='webLink',
     )
-    work_location: Optional[str] = Field(
+    work_location: str | None = Field(
         None,
         description='Work location of the Victim.',
         methods=['POST', 'PUT'],
         max_length=100,
         min_length=0,
         read_only=False,
         title='workLocation',
     )
 
-    @validator('associated_groups', always=True)
+    @validator('associated_groups', always=True, pre=True)
     def _validate_groups(cls, v):
         if not v:
-            return GroupsModel()
+            return GroupsModel()  # type: ignore
         return v
 
-    @validator('security_labels', always=True)
+    @validator('security_labels', always=True, pre=True)
     def _validate_security_labels(cls, v):
         if not v:
-            return SecurityLabelsModel()
+            return SecurityLabelsModel()  # type: ignore
         return v
 
-    @validator('tags', always=True)
+    @validator('tags', always=True, pre=True)
     def _validate_tags(cls, v):
         if not v:
-            return TagsModel()
+            return TagsModel()  # type: ignore
         return v
 
-    @validator('assets', always=True)
+    @validator('assets', always=True, pre=True)
     def _validate_victim_assets(cls, v):
         if not v:
-            return VictimAssetsModel()
+            return VictimAssetsModel()  # type: ignore
         return v
 
-    @validator('attributes', always=True)
+    @validator('attributes', always=True, pre=True)
     def _validate_victim_attributes(cls, v):
         if not v:
-            return VictimAttributesModel()
+            return VictimAttributesModel()  # type: ignore
         return v
 
 
+class VictimDataModel(
+    BaseModel,
+    title='Victim Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victims Data Model"""
+
+    data: list[VictimModel] | None = Field(
+        [],
+        description='The data for the Victims.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class VictimsModel(
+    BaseModel,
+    title='Victims Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Victims Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[VictimModel] | None = Field(
+        [],
+        description='The data for the Victims.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
+
 # first-party
 from tcex.api.tc.v3.groups.group_model import GroupsModel
 from tcex.api.tc.v3.security_labels.security_label_model import SecurityLabelsModel
 from tcex.api.tc.v3.tags.tag_model import TagsModel
 from tcex.api.tc.v3.victim_assets.victim_asset_model import VictimAssetsModel
 from tcex.api.tc.v3.victim_attributes.victim_attribute_model import VictimAttributesModel
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/workflow_events/workflow_event.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_events/workflow_event.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,64 +1,26 @@
-"""WorkflowEvent / WorkflowEvents Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Iterator, Union
+from collections.abc import Generator, Iterator
+from typing import TYPE_CHECKING
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.notes.note_model import NoteModel
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.workflow_events.workflow_event_filter import WorkflowEventFilter
 from tcex.api.tc.v3.workflow_events.workflow_event_model import (
     WorkflowEventModel,
     WorkflowEventsModel,
 )
 
 if TYPE_CHECKING:  # pragma: no cover
     # first-party
-    from tcex.api.tc.v3.notes.note import Note
-
-
-class WorkflowEvents(ObjectCollectionABC):
-    """WorkflowEvents Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = WorkflowEventsModel(**kwargs)
-        self.type_ = 'workflow_events'
-
-    def __iter__(self) -> 'WorkflowEvent':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=WorkflowEvent)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.WORKFLOW_EVENTS.value
-
-    @property
-    def filter(self) -> 'WorkflowEventFilter':
-        """Return the type specific filter object."""
-        return WorkflowEventFilter(self.tql)
+    from tcex.api.tc.v3.notes.note import Note  # CIRCULAR-IMPORT
 
 
 class WorkflowEvent(ObjectABC):
     """WorkflowEvents Object.
 
     Args:
         case_id (int, kwargs): The **case id** for the Workflow_Event.
@@ -67,35 +29,35 @@
             operation only).
         event_date (str, kwargs): The time that the Event is logged.
         notes (Notes, kwargs): A list of Notes corresponding to the Event.
         summary (str, kwargs): The **summary** for the Workflow_Event.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = WorkflowEventModel(**kwargs)
+        self._model: WorkflowEventModel = WorkflowEventModel(**kwargs)
         self._nested_field_name = 'workflowEvents'
         self._nested_filter = 'has_workflow_event'
         self.type_ = 'Workflow Event'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.WORKFLOW_EVENTS.value
 
     @property
-    def model(self) -> 'WorkflowEventModel':
+    def model(self) -> WorkflowEventModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['WorkflowEventModel', dict]):
+    def model(self, data: dict | WorkflowEventModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -106,25 +68,64 @@
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.summary}
 
     @property
-    def notes(self) -> Iterator['Note']:
+    def notes(self) -> Generator['Note', None, None]:
         """Yield Note from Notes."""
         # first-party
         from tcex.api.tc.v3.notes.note import Notes
 
-        yield from self._iterate_over_sublist(Notes)
+        yield from self._iterate_over_sublist(Notes)  # type: ignore
 
-    def stage_note(self, data: Union[dict, 'ObjectABC', 'NoteModel']):
+    def stage_note(self, data: dict | ObjectABC | NoteModel):
         """Stage note on the object."""
         if isinstance(data, ObjectABC):
-            data = data.model
+            data = data.model  # type: ignore
         elif isinstance(data, dict):
             data = NoteModel(**data)
 
         if not isinstance(data, NoteModel):
             raise RuntimeError('Invalid type passed in to stage_note')
         data._staged = True
-        self.model.notes.data.append(data)
+        self.model.notes.data.append(data)  # type: ignore
+
+
+class WorkflowEvents(ObjectCollectionABC):
+    """WorkflowEvents Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = WorkflowEventsModel(**kwargs)
+        self.type_ = 'workflow_events'
+
+    def __iter__(self) -> Iterator[WorkflowEvent]:
+        """Return CM objects."""
+        return self.iterate(base_class=WorkflowEvent)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.WORKFLOW_EVENTS.value
+
+    @property
+    def filter(self) -> WorkflowEventFilter:
+        """Return the type specific filter object."""
+        return WorkflowEventFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/workflow_events/workflow_event_model.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,200 +1,181 @@
-"""Workflow_Event / Workflow_Events Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
-# standard library
-from datetime import datetime
-from typing import List, Optional
-
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
-
+from tcex.util import Util
 
-class WorkflowEventsModel(
-    BaseModel,
-    title='WorkflowEvents Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Workflow_Events Model"""
 
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['WorkflowEventModel']] = Field(
-        [],
-        description='The data for the WorkflowEvents.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class WorkflowEventDataModel(
-    BaseModel,
-    title='WorkflowEvent Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Workflow_Events Data Model"""
-
-    data: Optional[List['WorkflowEventModel']] = Field(
-        [],
-        description='The data for the WorkflowEvents.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-
-class WorkflowEventModel(
+class WorkflowTemplateModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
-    title='WorkflowEvent Model',
+    title='WorkflowTemplate Model',
     validate_assignment=True,
 ):
-    """Workflow_Event Model"""
+    """Workflow_Template Model"""
 
     _associated_type = PrivateAttr(False)
     _cm_type = PrivateAttr(True)
     _shared_type = PrivateAttr(False)
     _staged = PrivateAttr(False)
 
-    case_id: Optional[int] = Field(
-        None,
-        description='The **case id** for the Workflow_Event.',
-        methods=['POST'],
-        read_only=False,
-        required_alt_field='caseXid',
-        title='caseId',
-    )
-    case_xid: Optional[str] = Field(
+    active: bool = Field(
         None,
-        description='The **case xid** for the Workflow_Event.',
-        methods=['POST'],
-        read_only=False,
-        required_alt_field='caseId',
-        title='caseXid',
+        allow_mutation=False,
+        description='The **active** for the Workflow_Template.',
+        read_only=True,
+        title='active',
     )
-    date_added: Optional[datetime] = Field(
+    assignee: 'AssigneeModel' = Field(
         None,
         allow_mutation=False,
-        description='The **date added** for the Workflow_Event.',
+        description='The **assignee** for the Workflow_Template.',
         read_only=True,
-        title='dateAdded',
+        title='assignee',
     )
-    deleted: bool = Field(
+    cases: 'CasesModel' = Field(
         None,
         allow_mutation=False,
-        description='The **deleted** for the Workflow_Event.',
+        description='The **cases** for the Workflow_Template.',
         read_only=True,
-        title='deleted',
+        title='cases',
     )
-    deleted_reason: Optional[str] = Field(
+    config_artifact: str | None = Field(
         None,
-        description='The reason for deleting the event (required input for DELETE operation only).',
-        methods=['DELETE'],
-        max_length=255,
-        min_length=1,
-        read_only=False,
-        title='deletedReason',
+        allow_mutation=False,
+        description='The **config artifact** for the Workflow_Template.',
+        read_only=True,
+        title='configArtifact',
     )
-    event_date: Optional[datetime] = Field(
+    config_attribute: dict | list[dict] | None = Field(
         None,
-        description='The time that the Event is logged.',
+        description='The **config attribute** for the Workflow_Template.',
         methods=['POST', 'PUT'],
         read_only=False,
-        title='eventDate',
+        title='configAttribute',
     )
-    id: Optional[int] = Field(
-        None,
-        description='The ID of the item.',
-        read_only=True,
-        title='id',
-    )
-    link: Optional[str] = Field(
+    config_playbook: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **link** for the Workflow_Event.',
+        description='The **config playbook** for the Workflow_Template.',
         read_only=True,
-        title='link',
+        title='configPlaybook',
     )
-    link_text: Optional[str] = Field(
+    config_task: dict | list[dict] | None = Field(
         None,
         allow_mutation=False,
-        description='The **link text** for the Workflow_Event.',
+        description='The **config task** for the Workflow_Template.',
         read_only=True,
-        title='linkText',
+        title='configTask',
     )
-    notes: Optional['NotesModel'] = Field(
+    description: str | None = Field(
         None,
-        description='A list of Notes corresponding to the Event.',
+        description='The **description** for the Workflow_Template.',
         methods=['POST', 'PUT'],
+        max_length=1500,
+        min_length=0,
         read_only=False,
-        title='notes',
+        title='description',
     )
-    parent_case: Optional['CaseModel'] = Field(
+    id: int | None = Field(
         None,
-        allow_mutation=False,
-        description='The **parent case** for the Workflow_Event.',
+        description='The ID of the item.',
         read_only=True,
-        title='parentCase',
+        title='id',
     )
-    summary: Optional[str] = Field(
+    name: str | None = Field(
         None,
-        description='The **summary** for the Workflow_Event.',
+        description='The **name** for the Workflow_Template.',
         methods=['POST', 'PUT'],
         max_length=255,
         min_length=1,
         read_only=False,
-        title='summary',
+        title='name',
     )
-    system_generated: bool = Field(
+    owner: str | None = Field(
         None,
         allow_mutation=False,
-        description='The **system generated** for the Workflow_Event.',
+        description='The name of the Owner of the Case.',
         read_only=True,
-        title='systemGenerated',
+        title='owner',
     )
-    user: Optional['UserModel'] = Field(
+    owner_id: int | None = Field(
         None,
         allow_mutation=False,
-        description='The **user** for the Workflow_Event.',
+        description='The name of the Owner of the Case.',
         read_only=True,
-        title='user',
+        title='ownerId',
+    )
+    version: int | None = Field(
+        None,
+        description='The **version** for the Workflow_Template.',
+        methods=['POST', 'PUT'],
+        minimum=1,
+        read_only=False,
+        title='version',
     )
 
-    @validator('parent_case', always=True)
-    def _validate_case(cls, v):
+    @validator('assignee', always=True, pre=True)
+    def _validate_assignee(cls, v):
         if not v:
-            return CaseModel()
+            return AssigneeModel()  # type: ignore
         return v
 
-    @validator('notes', always=True)
-    def _validate_notes(cls, v):
+    @validator('cases', always=True, pre=True)
+    def _validate_cases(cls, v):
         if not v:
-            return NotesModel()
+            return CasesModel()  # type: ignore
         return v
 
-    @validator('user', always=True)
-    def _validate_user(cls, v):
-        if not v:
-            return UserModel()
-        return v
+
+class WorkflowTemplateDataModel(
+    BaseModel,
+    title='WorkflowTemplate Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Workflow_Templates Data Model"""
+
+    data: list[WorkflowTemplateModel] | None = Field(
+        [],
+        description='The data for the WorkflowTemplates.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class WorkflowTemplatesModel(
+    BaseModel,
+    title='WorkflowTemplates Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Workflow_Templates Model"""
+
+    _mode_support = PrivateAttr(False)
+
+    data: list[WorkflowTemplateModel] | None = Field(
+        [],
+        description='The data for the WorkflowTemplates.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
 
 
 # first-party
-from tcex.api.tc.v3.cases.case_model import CaseModel
-from tcex.api.tc.v3.notes.note_model import NotesModel
-from tcex.api.tc.v3.security.users.user_model import UserModel
+from tcex.api.tc.v3.cases.case_model import CasesModel
+from tcex.api.tc.v3.security.assignee_model import AssigneeModel
 
 # add forward references
-WorkflowEventDataModel.update_forward_refs()
-WorkflowEventModel.update_forward_refs()
-WorkflowEventsModel.update_forward_refs()
+WorkflowTemplateDataModel.update_forward_refs()
+WorkflowTemplateModel.update_forward_refs()
+WorkflowTemplatesModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/workflow_templates/workflow_template.py` & `tcex-4.0.0/tcex/api/tc/v3/workflow_templates/workflow_template.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,93 +1,54 @@
-"""WorkflowTemplate / WorkflowTemplates Object"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Union
+from collections.abc import Iterator
 
 # first-party
 from tcex.api.tc.v3.api_endpoints import ApiEndpoints
 from tcex.api.tc.v3.object_abc import ObjectABC
 from tcex.api.tc.v3.object_collection_abc import ObjectCollectionABC
 from tcex.api.tc.v3.workflow_templates.workflow_template_filter import WorkflowTemplateFilter
 from tcex.api.tc.v3.workflow_templates.workflow_template_model import (
     WorkflowTemplateModel,
     WorkflowTemplatesModel,
 )
 
 
-class WorkflowTemplates(ObjectCollectionABC):
-    """WorkflowTemplates Collection.
-
-    # Example of params input
-    {
-        'result_limit': 100,  # Limit the retrieved results.
-        'result_start': 10,  # Starting count used for pagination.
-        'fields': ['caseId', 'summary']  # Select additional return fields.
-    }
-
-    Args:
-        session (Session): Session object configured with TC API Auth.
-        tql_filters (list): List of TQL filters.
-        params (dict): Additional query params (see example above).
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize class properties."""
-        super().__init__(
-            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
-        )
-        self._model = WorkflowTemplatesModel(**kwargs)
-        self.type_ = 'workflow_templates'
-
-    def __iter__(self) -> 'WorkflowTemplate':
-        """Iterate over CM objects."""
-        return self.iterate(base_class=WorkflowTemplate)
-
-    @property
-    def _api_endpoint(self) -> str:
-        """Return the type specific API endpoint."""
-        return ApiEndpoints.WORKFLOW_TEMPLATES.value
-
-    @property
-    def filter(self) -> 'WorkflowTemplateFilter':
-        """Return the type specific filter object."""
-        return WorkflowTemplateFilter(self.tql)
-
-
 class WorkflowTemplate(ObjectABC):
     """WorkflowTemplates Object.
 
     Args:
         config_attribute (None, kwargs): The **config attribute** for the Workflow_Template.
         description (str, kwargs): The **description** for the Workflow_Template.
         name (str, kwargs): The **name** for the Workflow_Template.
         version (int, kwargs): The **version** for the Workflow_Template.
     """
 
     def __init__(self, **kwargs):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         super().__init__(kwargs.pop('session', None))
 
         # properties
-        self._model = WorkflowTemplateModel(**kwargs)
+        self._model: WorkflowTemplateModel = WorkflowTemplateModel(**kwargs)
         self._nested_field_name = 'workflowTemplates'
         self._nested_filter = 'has_workflow_template'
         self.type_ = 'Workflow Template'
 
     @property
     def _api_endpoint(self) -> str:
         """Return the type specific API endpoint."""
         return ApiEndpoints.WORKFLOW_TEMPLATES.value
 
     @property
-    def model(self) -> 'WorkflowTemplateModel':
+    def model(self) -> WorkflowTemplateModel:
         """Return the model data."""
         return self._model
 
     @model.setter
-    def model(self, data: Union['WorkflowTemplateModel', dict]):
+    def model(self, data: dict | WorkflowTemplateModel):
         """Create model using the provided data."""
         if isinstance(data, type(self.model)):
             # provided data is already a model, nothing required to change
             self._model = data
         elif isinstance(data, dict):
             # provided data is raw response, load the model
             self._model = type(self.model)(**data)
@@ -96,7 +57,46 @@
 
     @property
     def as_entity(self) -> dict:
         """Return the entity representation of the object."""
         type_ = self.type_
 
         return {'type': type_, 'id': self.model.id, 'value': self.model.name}
+
+
+class WorkflowTemplates(ObjectCollectionABC):
+    """WorkflowTemplates Collection.
+
+    # Example of params input
+    {
+        'result_limit': 100,  # Limit the retrieved results.
+        'result_start': 10,  # Starting count used for pagination.
+        'fields': ['caseId', 'summary']  # Select additional return fields.
+    }
+
+    Args:
+        session (Session): Session object configured with TC API Auth.
+        tql_filters (list): List of TQL filters.
+        params (dict): Additional query params (see example above).
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize instance properties."""
+        super().__init__(
+            kwargs.pop('session', None), kwargs.pop('tql_filter', None), kwargs.pop('params', None)
+        )
+        self._model = WorkflowTemplatesModel(**kwargs)
+        self.type_ = 'workflow_templates'
+
+    def __iter__(self) -> Iterator[WorkflowTemplate]:
+        """Return CM objects."""
+        return self.iterate(base_class=WorkflowTemplate)  # type: ignore
+
+    @property
+    def _api_endpoint(self) -> str:
+        """Return the type specific API endpoint."""
+        return ApiEndpoints.WORKFLOW_TEMPLATES.value
+
+    @property
+    def filter(self) -> WorkflowTemplateFilter:
+        """Return the type specific filter object."""
+        return WorkflowTemplateFilter(self.tql)
```

### Comparing `tcex-3.0.9/tcex/api/tc/v3/workflow_templates/workflow_template_model.py` & `tcex-4.0.0/tcex/api/tc/v3/tags/tag_model.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,184 +1,202 @@
-"""Workflow_Template / Workflow_Templates Model"""
-# pylint: disable=no-member,no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-member,no-self-argument,wrong-import-position
 # standard library
-from typing import List, Optional, Union
+from datetime import datetime
 
 # third-party
 from pydantic import BaseModel, Extra, Field, PrivateAttr, validator
 
 # first-party
 from tcex.api.tc.v3.v3_model_abc import V3ModelABC
-from tcex.utils import Utils
+from tcex.util import Util
 
 
-class WorkflowTemplatesModel(
-    BaseModel,
-    title='WorkflowTemplates Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Workflow_Templates Model"""
-
-    _mode_support = PrivateAttr(False)
-
-    data: Optional[List['WorkflowTemplateModel']] = Field(
-        [],
-        description='The data for the WorkflowTemplates.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-    mode: str = Field(
-        'append',
-        description='The PUT mode for nested objects (append, delete, replace). Default: append',
-        methods=['POST', 'PUT'],
-        title='append',
-    )
-
-
-class WorkflowTemplateDataModel(
-    BaseModel,
-    title='WorkflowTemplate Data Model',
-    alias_generator=Utils().snake_to_camel,
-    validate_assignment=True,
-):
-    """Workflow_Templates Data Model"""
-
-    data: Optional[List['WorkflowTemplateModel']] = Field(
-        [],
-        description='The data for the WorkflowTemplates.',
-        methods=['POST', 'PUT'],
-        title='data',
-    )
-
-
-class WorkflowTemplateModel(
+class TagModel(
     V3ModelABC,
-    alias_generator=Utils().snake_to_camel,
+    alias_generator=Util().snake_to_camel,
     extra=Extra.allow,
-    title='WorkflowTemplate Model',
+    title='Tag Model',
     validate_assignment=True,
 ):
-    """Workflow_Template Model"""
+    """Tag Model"""
 
     _associated_type = PrivateAttr(False)
-    _cm_type = PrivateAttr(True)
-    _shared_type = PrivateAttr(False)
+    _cm_type = PrivateAttr(False)
+    _shared_type = PrivateAttr(True)
     _staged = PrivateAttr(False)
 
-    active: bool = Field(
+    cases: 'CasesModel' = Field(
         None,
         allow_mutation=False,
-        description='The **active** for the Workflow_Template.',
+        description='The **cases** for the Tag.',
         read_only=True,
-        title='active',
+        title='cases',
     )
-    assignee: Optional['AssigneeModel'] = Field(
+    description: str | None = Field(
         None,
-        allow_mutation=False,
-        description='The **assignee** for the Workflow_Template.',
-        read_only=True,
-        title='assignee',
+        description='A brief description of the Tag.',
+        methods=['POST', 'PUT'],
+        max_length=4000,
+        min_length=0,
+        read_only=False,
+        title='description',
     )
-    cases: Optional['CasesModel'] = Field(
+    groups: 'GroupsModel' = Field(
         None,
         allow_mutation=False,
-        description='The **cases** for the Workflow_Template.',
+        description='The **groups** for the Tag.',
         read_only=True,
-        title='cases',
+        title='groups',
     )
-    config_artifact: Optional[str] = Field(
+    id: int | None = Field(
         None,
-        allow_mutation=False,
-        description='The **config artifact** for the Workflow_Template.',
+        description='The ID of the item.',
         read_only=True,
-        title='configArtifact',
-    )
-    config_attribute: Union[Optional[dict], Optional[List[dict]]] = Field(
-        None,
-        description='The **config attribute** for the Workflow_Template.',
-        methods=['POST', 'PUT'],
-        read_only=False,
-        title='configAttribute',
+        title='id',
     )
-    config_playbook: Optional[str] = Field(
+    indicators: 'IndicatorsModel' = Field(
         None,
         allow_mutation=False,
-        description='The **config playbook** for the Workflow_Template.',
+        description='The **indicators** for the Tag.',
         read_only=True,
-        title='configPlaybook',
+        title='indicators',
     )
-    config_task: Union[Optional[dict], Optional[List[dict]]] = Field(
+    last_used: datetime | None = Field(
         None,
         allow_mutation=False,
-        description='The **config task** for the Workflow_Template.',
+        description='The date and time that the Tag was last used.',
         read_only=True,
-        title='configTask',
+        title='lastUsed',
     )
-    description: Optional[str] = Field(
+    name: str | None = Field(
         None,
-        description='The **description** for the Workflow_Template.',
+        description='The **name** for the Tag.',
         methods=['POST', 'PUT'],
-        max_length=1500,
-        min_length=0,
+        max_length=128,
+        min_length=1,
         read_only=False,
-        title='description',
+        title='name',
     )
-    id: Optional[int] = Field(
+    normalized: bool = Field(
         None,
-        description='The ID of the item.',
+        allow_mutation=False,
+        description=(
+            'Indicates whether this tag is specified as a Main Tag within Tag Normalization.'
+        ),
         read_only=True,
-        title='id',
+        title='normalized',
     )
-    name: Optional[str] = Field(
+    owner: str | None = Field(
         None,
-        description='The **name** for the Workflow_Template.',
-        methods=['POST', 'PUT'],
-        max_length=255,
-        min_length=1,
+        description='The name of the Owner of the Tag.',
+        methods=['POST'],
         read_only=False,
-        title='name',
+        title='owner',
     )
-    owner: Optional[str] = Field(
+    platforms: dict | None = Field(
         None,
         allow_mutation=False,
-        description='The name of the Owner of the Case.',
+        description='For ATT&CK-based tags, these are the platforms applicable to the technique.',
         read_only=True,
-        title='owner',
+        title='platforms',
     )
-    owner_id: Optional[int] = Field(
+    synonymous_tag_names: dict | None = Field(
         None,
         allow_mutation=False,
-        description='The name of the Owner of the Case.',
+        description=(
+            'For Normalized tags, this is a list of defined synonymous tag names that would '
+            'normalize to this main tag.'
+        ),
         read_only=True,
-        title='ownerId',
+        title='synonymousTagNames',
     )
-    version: Optional[int] = Field(
+    technique_id: str | None = Field(
         None,
-        description='The **version** for the Workflow_Template.',
-        methods=['POST', 'PUT'],
-        minimum=1,
-        read_only=False,
-        title='version',
+        allow_mutation=False,
+        description='For ATT&CK-based tags, this is the technique ID assigned to the tag.',
+        read_only=True,
+        title='techniqueId',
+    )
+    victims: 'VictimsModel' = Field(
+        None,
+        allow_mutation=False,
+        description='The **victims** for the Tag.',
+        read_only=True,
+        title='victims',
     )
 
-    @validator('assignee', always=True)
-    def _validate_assignee(cls, v):
+    @validator('cases', always=True, pre=True)
+    def _validate_cases(cls, v):
         if not v:
-            return AssigneeModel()
+            return CasesModel()  # type: ignore
         return v
 
-    @validator('cases', always=True)
-    def _validate_cases(cls, v):
+    @validator('groups', always=True, pre=True)
+    def _validate_groups(cls, v):
+        if not v:
+            return GroupsModel()  # type: ignore
+        return v
+
+    @validator('indicators', always=True, pre=True)
+    def _validate_indicators(cls, v):
         if not v:
-            return CasesModel()
+            return IndicatorsModel()  # type: ignore
         return v
 
+    @validator('victims', always=True, pre=True)
+    def _validate_victims(cls, v):
+        if not v:
+            return VictimsModel()  # type: ignore
+        return v
+
+
+class TagDataModel(
+    BaseModel,
+    title='Tag Data Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Tags Data Model"""
+
+    data: list[TagModel] | None = Field(
+        [],
+        description='The data for the Tags.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+
+
+class TagsModel(
+    BaseModel,
+    title='Tags Model',
+    alias_generator=Util().snake_to_camel,
+    validate_assignment=True,
+):
+    """Tags Model"""
+
+    _mode_support = PrivateAttr(True)
+
+    data: list[TagModel] | None = Field(
+        [],
+        description='The data for the Tags.',
+        methods=['POST', 'PUT'],
+        title='data',
+    )
+    mode: str = Field(
+        'append',
+        description='The PUT mode for nested objects (append, delete, replace). Default: append',
+        methods=['POST', 'PUT'],
+        title='append',
+    )
+
 
 # first-party
 from tcex.api.tc.v3.cases.case_model import CasesModel
-from tcex.api.tc.v3.security.assignee_model import AssigneeModel
+from tcex.api.tc.v3.groups.group_model import GroupsModel
+from tcex.api.tc.v3.indicators.indicator_model import IndicatorsModel
+from tcex.api.tc.v3.victims.victim_model import VictimsModel
 
 # add forward references
-WorkflowTemplateDataModel.update_forward_refs()
-WorkflowTemplateModel.update_forward_refs()
-WorkflowTemplatesModel.update_forward_refs()
+TagDataModel.update_forward_refs()
+TagModel.update_forward_refs()
+TagsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/app_config/install_json.py` & `tcex-4.0.0/tcex/app/config/install_json.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,58 +1,52 @@
-"""Install JSON App Config"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
-import os
 from collections import OrderedDict
+from functools import cached_property
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Dict, List, Optional
+from typing import Any
 
-# first-party
-from tcex.app_config.install_json_update import InstallJsonUpdate
-from tcex.app_config.install_json_validate import InstallJsonValidate
-from tcex.app_config.models import InstallJsonModel
-from tcex.backports import cached_property
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.app_config.models.install_json_model import ParamsModel
+from .install_json_update import InstallJsonUpdate
+from .install_json_validate import InstallJsonValidate
+from .model.install_json_model import InstallJsonModel, ParamsModel
 
-# get tcex logger
-tcex_logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class InstallJson:
-    """Provide a model for the install.json config file.
+    """Config object for install.json configuration file
 
     This class can't be a Singleton because it's used by the package
     command to create a install.json file in the build directory.
     """
 
     def __init__(
         self,
-        filename: Optional[str] = None,
-        path: Optional[str] = None,
-        logger: Optional[logging.Logger] = None,
+        filename: str | None = None,
+        path: Path | str | None = None,
+        logger: logging.Logger | None = None,
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         filename = filename or 'install.json'
-        path = path or os.getcwd()
-        self.log = logger or tcex_logger
+        path = Path(path or Path.cwd())
+        self.log = logger or _logger
 
         # properties
-        self.fqfn = Path(os.path.join(path, filename))
+        self.fqfn = path / filename
 
     @property
     def app_prefix(self) -> str:
         """Return the appropriate output var type for the current App."""
         return self.app_prefixes.get(self.model.runtime_level.lower(), '')
 
     @property
-    def app_prefixes(self) -> str:
+    def app_prefixes(self) -> dict[str, str]:
         """Return all the current App prefixes."""
         return {
             'organization': 'TC_-_',
             'playbook': 'TCPB_-_',
             'apiservice': 'TCVA_-_',
             'feedapiservice': 'TCVF_-_',
             'triggerservice': 'TCVC_-_',
@@ -61,62 +55,62 @@
 
     @cached_property
     def contents(self) -> dict:
         """Return install.json file contents."""
         if self.fqfn.is_file():
             try:
                 with self.fqfn.open() as fh:
-                    contents = json.load(fh, object_pairs_hook=OrderedDict)
+                    return json.load(fh, object_pairs_hook=OrderedDict)
             except (OSError, ValueError):  # pragma: no cover
                 self.log.error(
                     f'feature=install-json, exception=failed-reading-file, filename={self.fqfn}'
                 )
-        else:  # pragma: no cover
-            contents = {
-                'displayName': 'External App',
-                'features': [],
-                'languageVersion': '3.9',
-                'listDelimiter': '|',
-                'programLanguage': 'python',
-                'programMain': 'run.py',
-                'programVersion': '0.0.0',
-                'runtimeLevel': 'external',
-            }
-        return contents
 
-    def create_output_variables(self, output_variables: dict, job_id: Optional[int] = 9876) -> list:
+        return {
+            'displayName': 'External App',
+            'features': [],
+            'languageVersion': '3.11',
+            'listDelimiter': '|',
+            'programLanguage': 'python',
+            'programMain': 'run.py',
+            'programVersion': '0.0.0',
+            'runtimeLevel': 'external',
+            'sdkVersion': '4.0.0',
+        }
+
+    def create_output_variables(self, output_variables: list, job_id: int = 9876) -> list:
         """Create output variables.
 
         # "#App:9876:app.data.count!String"
         # "#Trigger:9876:app.data.count!String"
 
         Args:
             output_variables: A dict of the output variables
             job_id: A job id to use in output variable string.
         """
         variables = []
         for p in output_variables:
             variables.append(self.create_variable(p.name, p.type, job_id))
         return variables
 
-    def create_variable(self, var_name: str, var_type: str, job_id: Optional[int] = 1234) -> str:
+    def create_variable(self, var_name: str, var_type: str, job_id: int = 1234) -> str:
         """Create output variables.
 
         # "#App:9876:app.data.count!String"
         # "#Trigger:9876:app.data.count!String"
 
         Args:
             var_name: The variable name.
             var_type: The variable type.
             job_id: A job id to use in output variable string.
         """
         return f'#{self.model.app_output_var_type}:{job_id}:{var_name}!{var_type}'
 
     @staticmethod
-    def expand_valid_values(valid_values: list) -> List[str]:
+    def expand_valid_values(valid_values: list) -> list[str]:
         """Expand supported playbook variables to their full list.
 
         Args:
             valid_values: The list of valid values for Choice or MultiChoice inputs.
 
         Returns:
             list: An expanded list of valid values for Choice or MultiChoice inputs.
@@ -162,46 +156,47 @@
         return feature.lower() in [f.lower() for f in self.model.features]
 
     @cached_property
     def is_external_app(self) -> bool:
         """Return True if App does not have a install.json file."""
         return not self.fqfn.is_file()
 
-    # @cached_property
-    @property
-    def model(self) -> 'InstallJsonModel':
+    # this needs to be a cached property, for tcex package to update install.json properly
+    @cached_property
+    def model(self) -> InstallJsonModel:
         """Return the Install JSON model."""
         return InstallJsonModel(**self.contents)
 
     @property
-    def params_dict(self) -> List['ParamsModel']:
+    def params_dict(self) -> dict[str, ParamsModel]:
         """Return params as name/model.
 
         Used in tcex_testing for dynamic generation of output variables.
         """
         params = {}
         for p in self.model.params:
             params.setdefault(p.name, p)
         return params
 
     def params_to_args(
         self,
-        name: Optional[str] = None,
-        hidden: Optional[bool] = None,
-        required: Optional[bool] = None,
-        service_config: Optional[bool] = None,
-        _type: Optional[str] = None,
-        input_permutations: Optional[list] = None,
-    ) -> Dict[str, Any]:
+        name: str | None = None,
+        hidden: bool | None = None,
+        required: bool | None = None,
+        service_config: bool | None = None,
+        _type: str | None = None,
+        input_permutations: dict | None = None,
+    ) -> dict[str, Any]:
         """Return params as cli args.
 
         Used by tcex_testing project.
 
         Args:
             name: The name of the input to return.
+            hidden: If set the inputs will be filtered based on hidden field.
             required: If set the inputs will be filtered based on required field.
             service_config: If set the inputs will be filtered based on serviceConfig field.
             _type: The type of input to return.
             input_permutations: A list of valid input names for provided permutation.
 
         Returns:
             dict: All args for current filter
@@ -239,28 +234,30 @@
                 else:  # pragma: no cover
                     args[n] = p.default or ''
         return args
 
     @property
     def tc_playbook_out_variables(self) -> list:
         """Return playbook output variable name array"""
+        if self.model.playbook is None:
+            return []
         return self.create_output_variables(self.model.playbook.output_variables)
 
     @property
     def tc_playbook_out_variables_csv(self) -> str:
         """Return playbook output variables as CSV string"""
         return ','.join(self.tc_playbook_out_variables)
 
     @property
-    def update(self) -> 'InstallJsonUpdate':
+    def update(self) -> InstallJsonUpdate:
         """Return InstallJsonUpdate instance."""
         return InstallJsonUpdate(ij=self)
 
     @property
-    def validate(self) -> 'InstallJsonValidate':
+    def validate(self) -> InstallJsonValidate:
         """Validate install.json."""
         return InstallJsonValidate(ij=self)
 
     def write(self):
         """Write current data file."""
         data = self.model.json(
             by_alias=True, exclude_defaults=True, exclude_none=True, indent=2, sort_keys=True
```

### Comparing `tcex-3.0.9/tcex/app_config/install_json_update.py` & `tcex-4.0.0/tcex/app/config/install_json_update.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,45 +1,56 @@
-"""Install JSON Update"""
-# pylint: disable=R0401
+"""TcEx Framework Module"""
 # standard library
 import os
-from typing import TYPE_CHECKING, Optional
+from importlib.metadata import version
+from typing import TYPE_CHECKING
 
-if TYPE_CHECKING:  # pragma: no cover
-    from .install_json import InstallJson
+# third-party
+from semantic_version import Version
+
+if TYPE_CHECKING:
+    from .install_json import InstallJson  # CIRCULAR-IMPORT
 
 
 class InstallJsonUpdate:
-    """Update install.json file with current standards and schema."""
+    """Config object for install.json file (update)"""
 
     def __init__(self, ij: 'InstallJson'):  # pylint: disable=E0601
-        """Initialize class properties."""
+        """Initialize instance properties"""
         self.ij = ij
 
     def multiple(
         self,
-        features: Optional[bool] = True,
-        migrate: Optional[bool] = False,
-        sequence: Optional[bool] = True,
-        valid_values: Optional[bool] = True,
-        playbook_data_types: Optional[bool] = True,
+        features: bool = True,
+        # language_version: bool = True,
+        migrate: bool = False,
+        sequence: bool = True,
+        valid_values: bool = True,
+        playbook_data_types: bool = True,
+        sdk_version: bool = True,
     ):
         """Update the profile with all required changes.
 
         Args:
             features: If True, features will be updated.
+            language_version: If True, the language version will be updated.
             migrate: If True, programMain will be set to "run".
             sequence: If True, sequence numbers will be updated.
             valid_values: If True, validValues will be updated.
             playbook_data_types:  If True, pbDataTypes will be updated.
+            sdk_version: If True, the sdk version will be updated.
         """
         # update features array
         if features is True:
             self.update_features()
 
+        # if language_version is True:
+        #     # update language version to the current version of Python
+        #     self.update_language_version()
+
         if migrate is True:
             # update programMain to run
             self.update_program_main()
 
         # update sequence numbers
         if sequence is True:
             self.update_sequence_numbers()
@@ -48,43 +59,41 @@
         if valid_values is True:
             self.update_valid_values()
 
         # update playbook data types
         if playbook_data_types is True:
             self.update_playbook_data_types()
 
+        if sdk_version is True:
+            # update language version to the current version of Python
+            self.update_sdk_version()
+
         # write updated profile
         self.ij.write()
 
-    # def update_display_name(self, json_data: dict):
-    #     """Update the displayName parameter."""
-    #     if not self.ij.model.display_name:
-    #         display_name = os.path.basename(os.getcwd()).replace(self.app_prefix, '')
-    #         display_name = display_name.replace('_', ' ').replace('-', ' ')
-    #         display_name = ' '.join([a.title() for a in display_name.split(' ')])
-    #     self.ij.model.display_name = self.ij.model.display_name or display_name
-
     def update_features(self):
         """Update feature set based on App type."""
         features = ['runtimeVariables']
 
         if self.ij.model.is_organization_app:
             features.extend(['fileParams', 'secureParams'])
         elif self.ij.model.is_playbook_app:
             features.extend(
                 [
                     'aotExecutionEnabled',
                     'appBuilderCompliant',
                     'fileParams',
+                    'redisPasswordSupport',
                     'runtimeVariables',
-                    'secureParams',
                 ]
             )
-        elif self.ij.model.is_service_app:
-            features.extend(['appBuilderCompliant', 'fileParams'])
+        elif self.ij.model.is_trigger_app:
+            features.extend(['appBuilderCompliant', 'fileParams', 'redisPasswordSupport'])
+        elif self.ij.model.is_api_service_app:
+            features.extend(['fileParams', 'linkApiPath', 'redisPasswordSupport'])
 
         # add layoutEnabledApp if layout.json file exists in project
         if os.path.isfile(os.path.join(self.ij.fqfn.parent, 'layout.json')):  # pragma: no cover
             features.append('layoutEnabledApp')
 
         # re-add supported optional features
         for feature in self.ij.model.features:
@@ -103,15 +112,19 @@
                 'DeletesGroup',
                 'DeletesIndicator',
                 'DeletesSecurityLabel',
                 'DeletesTag',
             ]:
                 features.append(feature)
 
-        self.ij.model.features = sorted(list(set(features)))
+        self.ij.model.features = sorted(set(features))
+
+    # def update_language_version(self):
+    #     """Update language version."""
+    #     self.ij.model.language_version = Version(platform.python_version())
 
     def update_program_main(self):
         """Update program main."""
         self.ij.model.program_main = 'run'
 
     def update_sequence_numbers(self):
         """Update program sequence numbers."""
@@ -157,7 +170,15 @@
             return
 
         for param in self.ij.model.params:
             if param.type != 'String':
                 continue
             if not param.playbook_data_type:
                 param.playbook_data_type.append('String')
+
+    def update_sdk_version(self):
+        """Update sdk version."""
+        try:
+            # best effort to get the version of the tcex package
+            self.ij.model.sdk_version = Version(version('tcex'))
+        except (ImportError, ValueError):
+            pass
```

### Comparing `tcex-3.0.9/tcex/app_config/install_json_validate.py` & `tcex-4.0.0/tcex/app/config/install_json_validate.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,20 @@
-"""Install JSON Validate"""
-# pylint: disable=R0401
+"""TcEx Framework Module"""
 # standard library
 from typing import TYPE_CHECKING
 
 if TYPE_CHECKING:  # pragma: no cover
     from .install_json import InstallJson
 
 
 class InstallJsonValidate:
-    """Validate install.json file."""
+    """Config object for install.json file (validator)"""
 
     def __init__(self, ij: 'InstallJson'):  # pylint: disable=E0601
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.ij = ij
 
     def validate_duplicate_input(self) -> list:
         """Check for duplicate input names."""
         duplicates = []
         tracker = []
         for param in self.ij.model.params:
@@ -24,14 +23,17 @@
             tracker.append(param.name)
         return duplicates
 
     def validate_duplicate_output(self) -> list:
         """Check for duplicate input names."""
         duplicates = []
         tracker = []
+        if self.ij.model.playbook is None:
+            return duplicates
+
         for output in self.ij.model.playbook.output_variables or []:
             name_type = f'{output.name}-{output.type}'
             if name_type in tracker:
                 duplicates.append(output.name)
             tracker.append(name_type)
         return duplicates
```

### Comparing `tcex-3.0.9/tcex/app_config/job_json.py` & `tcex-4.0.0/tcex/app/config/tcex_json.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,41 +1,40 @@
-"""TcEx JSON App Config"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
-import os
 from collections import OrderedDict
+from functools import cached_property
 from pathlib import Path
-from typing import Optional
 
-# first-party
-from tcex.app_config.models import JobJsonModel
-from tcex.backports import cached_property
-from tcex.pleb.singleton import Singleton
+from .install_json import InstallJson
+from .model.tcex_json_model import TcexJsonModel
+from .tcex_json_update import TcexJsonUpdate
 
-# get tcex logger
-tcex_logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
-class JobJson(metaclass=Singleton):
-    """Provide a model for the tcex.json config file."""
+class TcexJson:
+    """Config object for tcex.json configuration file"""
 
     def __init__(
         self,
-        filename: Optional[str] = None,
-        path: Optional[str] = None,
-        logger: Optional[logging.Logger] = None,
+        filename: str | None = None,
+        path: Path | str | None = None,
+        logger: logging.Logger | None = None,
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         filename = filename or 'tcex.json'
-        path = path or os.getcwd()
-        self.log = logger or tcex_logger
+        path = Path(path or Path.cwd())
+        self.log = logger or _logger
 
         # properties
-        self.fqfn = Path(os.path.join(path, filename))
+        self.fqfn = path / filename
+        self.ij = InstallJson(logger=self.log)
 
     @cached_property
     def contents(self) -> dict:
         """Return tcex.json file contents."""
         _contents = {}
 
         if self.fqfn.is_file():
@@ -48,19 +47,21 @@
                 )
         else:  # pragma: no cover
             self.log.error(f'feature=tcex-json, exception=file-not-found, filename={self.fqfn}')
 
         return _contents
 
     @cached_property
-    def model(self) -> 'JobJsonModel':
+    def model(self) -> TcexJsonModel:
         """Return the Install JSON model."""
-        return JobJsonModel(**self.contents)
+        return TcexJsonModel(**self.contents)
 
-    # TODO: [low] possibly add auto fix of version and program name and then uncomment this code.
-    # def write(self):
-    #     """Write current data file."""
-    #     data = self.model.json(
-    #         by_alias=True, exclude_defaults=True, exclude_none=True, indent=2, sort_keys=True
-    #     )
-    #     with self.fqfn.open(mode='w') as fh:
-    #         fh.write(f'{data}\n')
+    @property
+    def update(self) -> TcexJsonUpdate:
+        """Return InstallJsonUpdate instance."""
+        return TcexJsonUpdate(tj=self)
+
+    def write(self):
+        """Write current data file."""
+        data = self.model.json(exclude_defaults=True, exclude_none=True, indent=2, sort_keys=True)
+        with self.fqfn.open(mode='w') as fh:
+            fh.write(f'{data}\n')
```

### Comparing `tcex-3.0.9/tcex/app_config/layout_json.py` & `tcex-4.0.0/tcex/app/config/layout_json.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,45 +1,39 @@
-"""Layout JSON App Config"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
-import os
 from collections import OrderedDict
+from functools import cached_property
 from pathlib import Path
-from typing import TYPE_CHECKING, Optional
 
-# first-party
-from tcex.app_config.models import LayoutJsonModel
-from tcex.backports import cached_property
-from tcex.pleb.singleton import Singleton
-
-if TYPE_CHECKING:  # pragma: no cover
-    # first-party
-    from tcex.app_config.models.install_json_model import OutputVariablesModel, ParamsModel
+from ...pleb.singleton import Singleton
+from .model.install_json_model import OutputVariablesModel, ParamsModel
+from .model.layout_json_model import LayoutJsonModel
 
-# get tcex logger
-tcex_logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class LayoutJson(metaclass=Singleton):
-    """Provide a model for the layout.json config file."""
+    """Config object for layout.json configuration file"""
 
     def __init__(
         self,
-        filename: Optional[str] = None,
-        path: Optional[str] = None,
-        logger: Optional[logging.Logger] = None,
+        filename: str | None = None,
+        path: Path | str | None = None,
+        logger: logging.Logger | None = None,
     ):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         filename = filename or 'layout.json'
-        path = path or os.getcwd()
-        self.log = logger or tcex_logger
+        path = Path(path or Path.cwd())
+        self.log = logger or _logger
 
         # properties
-        self.fqfn = Path(os.path.join(path, filename))
+        self.fqfn = path / filename
 
     @cached_property
     def contents(self) -> dict:
         """Return layout.json file contents."""
         contents = {}
         if self.fqfn.is_file():
             try:
@@ -49,15 +43,15 @@
                 self.log.error(
                     f'feature=layout-json, exception=failed-reading-file, filename={self.fqfn}'
                 )
         else:  # pragma: no cover
             self.log.error(f'feature=layout-json, exception=file-not-found, filename={self.fqfn}')
         return contents
 
-    def create(self, inputs: 'ParamsModel', outputs: 'OutputVariablesModel'):
+    def create(self, inputs: list[ParamsModel], outputs: list[OutputVariablesModel]):
         """Create new layout.json file based on inputs and outputs."""
 
         def input_data(sequence: int, title: str) -> dict:
             return {
                 'parameters': [],
                 'sequence': sequence,
                 'title': title,
@@ -73,35 +67,39 @@
                 ],
                 'outputs': [{'display': '', 'name': o.name} for o in outputs],
             }
         )
 
         for input_ in inputs:
             if input_.name == 'tc_action':
-                lj.inputs[0].parameters.append({'name': 'tc_action'})
+                lj.inputs[0].parameters.append({'name': 'tc_action'})  # type: ignore
             elif input_.hidden is True:
                 lj.inputs[2].parameters.append(
-                    {'display': "'hidden' != 'hidden'", 'hidden': 'true', 'name': input_.name}
+                    {
+                        'display': "'hidden' != 'hidden'",
+                        'hidden': 'true',
+                        'name': input_.name,
+                    }  # type: ignore
                 )
             else:
-                lj.inputs[2].parameters.append({'display': '', 'name': input_.name})
+                lj.inputs[2].parameters.append({'display': '', 'name': input_.name})  # type: ignore
 
         # write layout file to disk
         data = lj.json(
             by_alias=True, exclude_defaults=True, exclude_none=True, indent=2, sort_keys=True
         )
         self.write(data)
 
     @property
     def has_layout(self):
         """Return True if App has layout.json file."""
         return self.fqfn.is_file()
 
     @cached_property
-    def model(self) -> 'LayoutJsonModel':
+    def model(self) -> LayoutJsonModel:
         """Return the Install JSON model."""
         return LayoutJsonModel(**self.contents)
 
     @property
     def update(self):
         """Return InstallJsonUpdate instance."""
         return LayoutJsonUpdate(lj=self)
@@ -116,15 +114,15 @@
             fh.write(f'{data}\n')
 
 
 class LayoutJsonUpdate:
     """Update layout.json file with current standards and schema."""
 
     def __init__(self, lj: LayoutJson):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self.lj = lj
 
     def multiple(self):
         """Update the layouts.json file."""
         # APP-86 - sort output data by name
         self.update_sort_outputs()
 
@@ -133,9 +131,9 @@
         )
         self.lj.write(data)
 
     def update_sort_outputs(self):
         """Sort output field by name."""
         # APP-86 - sort output data by name
         self.lj.model.outputs = sorted(
-            self.lj.model.dict().get('outputs', []), key=lambda i: i['name']
+            self.lj.model.dict().get('outputs', []), key=lambda i: i['name']  # type: ignore
         )
```

### Comparing `tcex-3.0.9/tcex/app_config/models/app_spec_yml_model.py` & `tcex-4.0.0/tcex/app/config/model/app_spec_yml_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,70 +1,65 @@
-"""App Spec Model"""
-# pylint: disable=no-self-argument,no-self-use
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 # standard library
 import re
 from copy import deepcopy
-from typing import List, Optional
 
 # third-party
 from pydantic import BaseModel, Field, root_validator, validator
 from semantic_version import Version
 
-# first-party
-from tcex.app_config.models.install_json_model import (
+from .install_json_model import (
     FeedsModel,
     InstallJsonCommonModel,
     InstallJsonOrganizationModel,
     OutputVariablesModel,
     ParamsModel,
     RetryModel,
     TypeEnum,
     snake_to_camel,
 )
-from tcex.app_config.models.job_json_model import JobJsonCommonModel
-from tcex.pleb.none_model import NoneModel
-
-__all__ = ['AppSpecYmlModel']
+from .job_json_model import JobJsonCommonModel
 
 
 class FeedsSpecModel(FeedsModel):
-    """Model for app_spec.organization.feeds."""
+    """Model definition for app_spec.organization.feeds."""
 
-    job: Optional[JobJsonCommonModel] = Field(None, description='')
+    job: JobJsonCommonModel = Field(..., description='')
 
 
 class NotesPerActionModel(BaseModel):
-    """Model for app_spec.notes_per_action."""
+    """Model definition for app_spec.notes_per_action."""
 
     action: str = Field(..., description='The action name.')
     note: str = Field(..., description='The note describing the action.')
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class OrganizationModel(InstallJsonOrganizationModel):
-    """Model for app_spec.organization."""
+    """Model definition for app_spec.organization."""
 
-    feeds: Optional[List[FeedsSpecModel]] = Field(None, description='')
+    feeds: list[FeedsSpecModel] = Field([], description='')
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class OutputVariablesSpecModel(OutputVariablesModel):
-    """Model for app_spec.outputs.output_variables."""
+    """Model definition for app_spec.outputs.output_variables."""
 
-    disabled: Optional[bool] = Field(
+    disabled: bool = Field(
         False,
         description='If True, the output will not be included in ij/lj files.',
     )
     type: str = Field(
         'String',
         description='The output variable type (e.g., String, TCEntity, etc).',
     )
@@ -73,21 +68,21 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class OutputDataModel(BaseModel):
-    """Model for app_spec.output_data."""
+    """Model definition for app_spec.output_data."""
 
-    display: Optional[str] = Field(
+    display: str | None = Field(
         None,
         description='The display clause that controls visibility of the output.',
     )
-    output_variables: List[OutputVariablesSpecModel] = Field(
+    output_variables: list[OutputVariablesSpecModel] = Field(
         ...,
         description='An array of output variables.',
     )
 
     class Config:
         """DataModel Config"""
 
@@ -99,21 +94,21 @@
         """Normalize "always True" expression for display clause."""
         if v is not None and v.lower() == '''tc_action not in ('')''':
             v = '1'
         return v  # pragma: no cover
 
 
 class ParamsSpecModel(ParamsModel):
-    """Model for app_spec.params."""
+    """Model definition for app_spec.params."""
 
-    display: Optional[str] = Field(
+    display: str | None = Field(
         None,
         description='The display clause from the layout.json file.',
     )
-    disabled: Optional[bool] = Field(
+    disabled: bool | None = Field(
         False,
         description='If True, the parameter will not be included in ij/lj files.',
     )
     type: TypeEnum = Field(
         TypeEnum.String,
         description='',
     )
@@ -125,32 +120,32 @@
         fields = {'sequence': {'exclude': True}}
         smart_union = True
         use_enum_values = True
         validate_assignment = True
 
 
 class PlaybookSpecModel(BaseModel):
-    """Model for app_spec.playbook."""
+    """Model definition for app_spec.playbook."""
 
-    retry: Optional[RetryModel] = Field(
+    retry: RetryModel | None = Field(
         None,
         description='',
     )
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class ReleaseNoteModel(BaseModel):
-    """Model for app_spec.releaseNotes."""
+    """Model definition for app_spec.releaseNotes."""
 
-    notes: List[str] = Field(
+    notes: list[str] = Field(
         ...,
         description='One or more notes for the release.',
     )
     version: str = Field(
         ...,
         description='The version of the release.',
     )
@@ -159,79 +154,79 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class SectionsModel(BaseModel):
-    """Model for app_spec.sections."""
+    """Model definition for app_spec.sections."""
 
     section_name: str = Field(
         ...,
         description='The name of the section.',
     )
-    params: List[ParamsSpecModel] = Field(
+    params: list[ParamsSpecModel] = Field(
         ...,
         description='A list of input parameter data.',
     )
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class AppSpecYmlModel(InstallJsonCommonModel):
-    """Model for the app_spec.yml file."""
+    """Model definition for the app_spec.yml file."""
 
-    note_per_action: Optional[List[NotesPerActionModel]] = Field(
+    note_per_action: list[NotesPerActionModel] | None = Field(
         None,
         description='',
     )
-    organization: Optional[OrganizationModel] = Field(
+    organization: OrganizationModel | None = Field(
         None,
         description='A section for settings related to the organization (job) Apps.',
     )
-    output_data: Optional[List[OutputDataModel]] = Field(
+    output_data: list[OutputDataModel] | None = Field(
         None,
         description='The outputs data for Playbook and Service Apps.',
     )
-    output_prefix: Optional[str] = Field(
+    output_prefix: str | None = Field(
         None,
         description=(
             'The prefix for output variables, used for advanced request outputs. This value '
             'should match what is passed to the advanced request method in the playbook App.'
         ),
     )
     package_name: str = Field(
         None,
         description='The package name (app_name in tcex.json) for the App.',
     )
-    playbook: Optional[PlaybookSpecModel] = Field(
+    playbook: PlaybookSpecModel | None = Field(
         None,
         description='The playbook section of the install.json.',
     )
-    internal_notes: Optional[List[str]] = Field(
+    internal_notes: list[str] | None = Field(
         None,
         description='Internal notes for the App.',
     )
-    release_notes: List[ReleaseNoteModel] = Field(
+    release_notes: list[ReleaseNoteModel] = Field(
         ...,
         description='The release notes for the App.',
     )
     schema_version: str = Field(
         '1.0.0',
         description='The version of the App Spec schema.',
     )
-    sections: List[SectionsModel] = Field(
+    sections: list[SectionsModel] = Field(
         ...,
         description='Layout sections for an App including params.',
     )
-    service_details: Optional[str] = Field(
+    service_details: str | None = Field(
         None, description='Optional service details for Service Apps.'
     )
 
     @root_validator
     def _validate_no_input_duplication(cls, values):
         """Validate that no two parameters have the same name."""
         duplicates = {}
@@ -251,15 +246,15 @@
     def _version(cls, v: str):
         """Return a version object for "version" fields."""
         if v is not None:
             return Version(v)
         return v  # pragma: no cover
 
     @validator('output_prefix', always=True, pre=True)
-    def _output_prefix(cls, v: str, values: dict):
+    def _output_prefix(cls, v: str | None, values: dict):
         """Validate output_prefix is set when required."""
         if 'advancedRequest' in values.get('features', []):
             if v is None:
                 raise ValueError(
                     'The outputPrefix field is required when feature advancedRequest is enabled.'
                 )
         else:
@@ -298,59 +293,59 @@
                         'parameters': parameters,
                         'sequence': sequence,
                         'title': section.section_name,
                     }
                 )
         return _inputs
 
-    def get_note_per_action(self, action: str) -> 'NotesPerActionModel':
+    def get_note_per_action(self, action: str) -> NotesPerActionModel | None:
         """Return the note_per_action for the provided action."""
         for npa in self.note_per_action or []:
             if npa.action == action:
                 return npa
-        return NoneModel()
+        return None
 
     @property
-    def note_per_action_formatted(self) -> List[str]:
+    def note_per_action_formatted(self) -> list[str]:
         """Return formatted note_per_action."""
         _note_per_action = ['\n\nThe following actions are included:']
         _note_per_action.extend(
-            [f'-   **{npa.action}** - {npa.note}' for npa in self.note_per_action]
+            [f'-   **{npa.action}** - {npa.note}' for npa in self.note_per_action or []]
         )
         return _note_per_action
 
     @property
-    def outputs(self) -> List[OutputVariablesModel]:
+    def outputs(self) -> list[OutputVariablesModel]:
         """Return lj.outputs."""
         _outputs = []
-        for output_data in self.output_data:
+        for output_data in self.output_data or []:
             for output_variable in output_data.output_variables:
                 if output_variable.disabled is True:
                     continue
 
                 _outputs.append(
                     {
                         'display': output_data.display,
                         'name': output_variable.name,
                     }
                 )
         return _outputs
 
     @property
-    def output_variables(self) -> List[OutputVariablesModel]:
+    def output_variables(self) -> list[OutputVariablesModel]:
         """Return ij.playbook.outputVariables."""
         return [
             ov
             for output in self.output_data or []
             for ov in output.output_variables or []
             if ov.disabled is False
         ]
 
     @property
-    def params(self) -> List[ParamsModel]:
+    def params(self) -> list[ParamsSpecModel]:
         """Return ij.params."""
         _params = []
         sequence = 1
         for section in deepcopy(self.sections):
             for param in section.params:
                 if param.disabled is True:
                     continue
@@ -373,24 +368,24 @@
                 _params.append(param)
 
                 # increment sequence
                 sequence += 1
         return _params
 
     @property
-    def release_notes_formatted(self) -> List[str]:
+    def release_notes_formatted(self) -> list[str]:
         """Return readme_md.releaseNotes."""
         _release_notes = ['## Release Notes']
         _release_notes.append('')
 
         # try to sort release notes by version.  If we encounter any issues, just use release_notes
         try:
             sorted_releases = sorted(
                 (r for r in self.release_notes),
-                key=lambda r: Version(re.match(r'^\d+.\d+.\d+', r.version)[0]),
+                key=lambda r: Version(re.match(r'^\d+.\d+.\d+', r.version)[0]),  # type: ignore
                 reverse=True,
             )
         except Exception:
             sorted_releases = self.release_notes
 
         for release_note in sorted_releases:
             _release_notes.append(f'### {release_note.version}')
@@ -412,30 +407,30 @@
 
         for output_data in self.output_data or []:
             if output_data.display not in [None, '1', '']:
                 return True
 
         return False
 
-    def _set_default_playbook_data_type(self, param: 'ParamsSpecModel'):
+    def _set_default_playbook_data_type(self, param: ParamsSpecModel):
         """Set default playbookDataType for String type params.
 
         Playbook Data Types rule:
           * Input type is "String"
           * No "playbookDataType" values are provided
         """
         if self.runtime_level.lower() == 'playbook':
             # by rule any input of type String must have String and playbookDataType
             if (
                 param.type in ['EditChoice', 'KeyValueList', 'String']
                 and not param.playbook_data_type
             ):
                 param.playbook_data_type = ['String']
 
-    def _set_default_valid_values(self, param: 'ParamsSpecModel'):
+    def _set_default_valid_values(self, param: ParamsSpecModel):
         """Set default playbookDataType for String type params.
 
         Valid Values rule:
           * Input type is "String"
           * No "validValues" values are provided
           * The playbookDataType supports String
         """
```

### Comparing `tcex-3.0.9/tcex/app_config/models/install_json_model.py` & `tcex-4.0.0/tcex/app/config/model/install_json_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,49 +1,47 @@
-"""Install JSON Model"""
-# pylint: disable=no-self-argument,no-self-use; noqa: N805
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 # standard library
 import os
+import platform
 import re
 import uuid
 from enum import Enum
-from typing import Dict, List, Optional, Union
+from importlib.metadata import version
 
 # third-party
 from pydantic import BaseModel, Field, validator
 from pydantic.types import UUID4, UUID5, constr
 from semantic_version import Version
 
-# first-party
-from tcex.pleb.none_model import NoneModel
-
 __all__ = ['InstallJsonModel']
 
 
 def snake_to_camel(snake_string: str) -> str:
     """Convert snake_case to camelCase"""
     components = snake_string.split('_')
     return components[0] + ''.join(x.title() for x in components[1:])
 
 
 # define JSON encoders
-json_encoders = {Version: str}  # pylint: disable=unnecessary-lambda
+json_encoders = {Version: str, UUID4: str, UUID5: str}
 
 
 class DeprecationModel(BaseModel):
-    """Model for install_json.deprecation"""
+    """Model definition for install_json.deprecation"""
 
-    indicator_type: Optional[str] = Field(
+    indicator_type: str | None = Field(
         None,
         description='The indicator type for the deprecation rule.',
     )
-    interval_days: Optional[int] = Field(
+    interval_days: int | None = Field(
         None,
         description='The frequency the deprecation rule should run.',
     )
-    confidence_amount: Optional[int] = Field(
+    confidence_amount: int | None = Field(
         None,
         description='The amount the confidence should be reduced by.',
     )
     delete_at_minimum: bool = Field(
         False,
         description='If true, the indicator will be deleted at the minimum confidence.',
     )
@@ -56,56 +54,56 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class FirstRunParamsModel(BaseModel):
-    """Model for install_json.deprecation"""
+    """Model definition for install_json.deprecation"""
 
-    param: Optional[str] = Field(
+    param: str | None = Field(
         None,
         description='The parameter to set to the first run value.',
     )
-    value: Optional[Union[int, str]] = Field(
+    value: int | str | None = Field(
         None,
         description='The value to set the parameter to.',
     )
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class FeedsModel(BaseModel):
-    """Model for install_json.feeds"""
+    """Model definition for install_json.feeds"""
 
-    attributes_file: Optional[str] = Field(
+    attributes_file: str | None = Field(
         None,
         description=(
             'Optional property that provides the name of the CSV file with any custom '
             'Attributes required for the feed (e.g., attribute.json).'
         ),
     )
-    deprecation: Optional[List[DeprecationModel]] = Field(
-        None,
+    deprecation: list[DeprecationModel] = Field(
+        [],
         description='The deprecation rules for the feed.',
     )
     document_storage_limit_mb: int = Field(
         ...,
         description='Optional property that sets the Document storage limit.',
     )
     enable_bulk_json: bool = Field(
         False,
         description='Optional property that enables or disables the bulk JSON capability.',
     )
-    first_run_params: Optional[List[FirstRunParamsModel]] = Field(
-        None,
+    first_run_params: list[FirstRunParamsModel] = Field(
+        [],
         description='Param overrides for the first run of the feed.',
     )
     indicator_limit: int = Field(
         ...,
         description='Optional property that sets the Indicator limit.',
     )
     job_file: str = Field(
@@ -163,44 +161,44 @@
     KeyValueList = 'KeyValueList'
     MultiChoice = 'MultiChoice'
     String = 'String'
     StringMixed = 'StringMixed'
 
 
 class ParamsModel(BaseModel):
-    """Model for install_json.params"""
+    """Model definition for install_json.params"""
 
     allow_multiple: bool = Field(
         False,
         description=(
             'The value of this optional property is automatically set to true if the '
             'MultiChoice type is used. If a String type is used, this flag allows the '
             'user to define multiple values in a single input field delimited by a pipe '
             '("|") character.'
         ),
     )
     allow_nested: bool = Field(
         False,
         description='',
     )
-    default: Optional[Union[bool, str]] = Field(
+    default: bool | str | None = Field(
         None,
         description='Optional property that is the default value for an App input parameter.',
     )
     encrypt: bool = Field(
         False,
         description=(
             'Optional property that designates a parameter as an encrypted value. '
             'Parameters defined as encrypted will be managed by the Keychain feature '
             'that encrypts password while at rest. This flag should be used with the '
             'String type and will render a password input text box in the App '
             'configuration.'
         ),
     )
-    expose_playbook_key_as: Optional[ExposePlaybookKeyAsEnum] = Field(
+    expose_playbook_key_as: ExposePlaybookKeyAsEnum | None = Field(
         None,
         description='',
     )
     feed_deployer: bool = Field(
         False,
         description='',
     )
@@ -211,16 +209,16 @@
             'from the Job Wizard. Hidden parameters allow the developer to persist '
             'parameters between Job executions without the need to render the values in '
             'the Job Wizard. This option is valid only for Python and Java Apps. Further '
             'details on persisting parameters directly from the app are beyond the scope '
             'of this documentation.'
         ),
     )
-    intel_type: Optional[List[str]] = Field(
-        None,
+    intel_type: list[str] = Field(
+        [],
         description='',
     )
     label: str = Field(
         ...,
         description=(
             'Required property providing a description of the parameter displayed in the '
             'Job Wizard or Spaces Configuration dialog box within the ThreatConnect '
@@ -231,23 +229,23 @@
         ...,
         description=(
             'Required property that is the internal parameter name taken from the Job '
             'Wizard and passed to the App at runtime. It is the effective command-line '
             'argument name passed to the App.'
         ),
     )
-    note: Optional[str] = Field(
+    note: str | None = Field(
         None,
         description=(
             'Optional parameter-description field available in Playbook Apps under the ? '
             'tooltip when the App parameters are being edited. Use this field to '
             'describe the purpose of the parameter in two to three sentences.'
         ),
     )
-    playbook_data_type: Optional[List[str]] = Field(
+    playbook_data_type: list[str] = Field(
         [],
         description=(
             'Optional property restricting the data type of incoming Playbook variables. '
             'This is different than the type property that controls the UI input type. '
             'The playbookDataType can be any standard or custom type and is expected to '
             'be an array of strings.'
         ),
@@ -255,15 +253,15 @@
     required: bool = Field(
         False,
         description=(
             'Optional property designating this parameter as a required field that must '
             'be populated to save the Job or Playbook App.'
         ),
     )
-    sequence: Optional[int] = Field(
+    sequence: int | None = Field(
         None,
         description=(
             'Optional number used to control the ordering of the parameters in the Job '
             'Wizard or Spaces Configuration dialog box. If it is not defined, the order '
             'of the parameters in the install.json file will be used.'
         ),
     )
@@ -280,22 +278,22 @@
         description=(
             'Required property to enable the UI to display relevant components and allow '
             'the Job Executor to adapt how parameters are passed to an App at runtime. '
             'The table below lists the available types and how they affect elements '
             'within the platform.'
         ),
     )
-    valid_values: Optional[List[str]] = Field(
+    valid_values: list[str] = Field(
         [],
         description=(
             'Optional property to be used with the Choice, MultiChoice, and String input '
             'types to provide pre-defined inputs for the user selection.'
         ),
     )
-    view_rows: Optional[int] = Field(
+    view_rows: int | None = Field(
         None,
         description=(
             'Optional property for Playbook Apps to control the height of the display in '
             'the input parameter, and it expects an integer value. A value of 1 is '
             'default (and will show a text input element) and anything greater than 1 '
             'displays a textarea input when editing the Playbook App in ThreatConnect.'
         ),
@@ -324,52 +322,53 @@
 
     def __hash__(self):
         """Make model hashable."""
         return hash(self.name)
 
 
 class OutputVariablesModel(BaseModel):
-    """Model for install_json.playbook.outputVariables"""
+    """Model definition for install_json.playbook.outputVariables"""
 
     # sensitive value
     encrypt: bool = Field(
         False,
         description='',
     )
-    intel_type: Optional[List] = Field(
+    intel_type: list | None = Field(
         None,
         description='',
     )
     name: str = Field(
         ...,
         description='',
     )
-    note: Optional[str] = Field(
+    note: str | None = Field(
         None,
         description='',
     )
     type: str = Field(
         ..., description='Required property that specifies the type of the output variable.'
     )
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
     def __hash__(self):
+        """Make model hashable."""
         return hash(f'{self.name}{self.type}')
 
 
 class RetryModel(BaseModel):
-    """Model for install_json.playbook.retry"""
+    """Model definition for install_json.playbook.retry"""
 
-    actions: Optional[List[str]] = Field(
-        None,
+    actions: list[str] = Field(
+        [],
         description='A list of tc_actions that support retry.',
     )
     allowed: bool = Field(
         False,
         description=(
             'Optional property that specifies whether the Playbook App can retry its ' 'execution.'
         ),
@@ -395,25 +394,25 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class PlaybookModel(BaseModel):
-    """Model for install_json.playbook"""
+    """Model definition for install_json.playbook"""
 
-    output_prefix: Optional[str] = Field(None, description='')
-    output_variables: Optional[List[OutputVariablesModel]] = Field(
+    output_prefix: str | None = Field(None, description='')
+    output_variables: list[OutputVariablesModel] = Field(
         [],
         description=(
             'Optional outputVariables property that specifies the variables that a '
             'Playbook App will provide for downstream Playbooks.'
         ),
     )
-    retry: Optional[RetryModel] = Field(
+    retry: RetryModel | None = Field(
         None,
         description=(
             'Optional retry property that can be used to allow a Playbook to retry its '
             'execution in case of failure.'
         ),
     )
     type: str = Field(
@@ -425,92 +424,92 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class ServiceModel(BaseModel):
-    """Model for install_json.service"""
+    """Model definition for install_json.service"""
 
-    discovery_types: Optional[List[str]] = Field(
-        None,
+    discovery_types: list[str] = Field(
+        [],
         description='Service App discovery types (e.g., TaxiiApi).',
     )
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
-def get_commit_hash() -> Optional[str]:
+def get_commit_hash() -> str | None:
     """Return the current commit hash if available.
 
     This is not a required task so best effort is fine. In other words this is not guaranteed
     to work 100% of the time.
     """
     commit_hash = None
     branch = None
     branch_file = '.git/HEAD'  # ref: refs/heads/develop
 
     # get current branch
     if os.path.isfile(branch_file):
-        with open(branch_file) as f:
+        with open(branch_file, encoding='utf-8') as f:
             try:
                 branch = '/'.join(f.read().strip().split('/')[2:])
             except IndexError:  # pragma: no cover
                 pass
 
         # get commit hash
         if branch:
             hash_file = f'.git/refs/heads/{branch}'
             if os.path.isfile(hash_file):
-                with open(hash_file) as f:
+                with open(hash_file, encoding='utf-8') as f:
                     commit_hash = f.read().strip()
 
     if commit_hash is None:
         # gitlab / github CI environment variable
         commit_hash = os.getenv('CI_COMMIT_SHA') or os.getenv('GITHUB_SHA')
 
     return commit_hash
 
 
-def gen_app_id() -> str:
+def gen_app_id() -> UUID5:
     """Return a generate id for the current App."""
     return uuid.uuid5(uuid.NAMESPACE_X500, os.path.basename(os.getcwd()).lower())
 
 
 class InstallJsonCommonModel(BaseModel):
-    """Install JSON Common Model
+    """Model definition for install.json common configuration
 
     This model contains the common fields for the install.json file and
     the app_spec.yaml file.
     """
 
     allow_on_demand: bool = Field(
         False,
         description=(
             'Required property that allows or disallows an App to be run on demand using '
             'the Run Now button when the App is configured as a Job in the ThreatConnect '
             'platform. This property only applies to Python and Java Apps.'
         ),
     )
-    allow_run_as_user: Optional[bool] = Field(
+    allow_run_as_user: bool = Field(
         False,
         description='Controls whether a Playbook App supports run-as-users.',
     )
-    api_user_token_param: Optional[bool] = Field(
+    api_user_token_param: bool = Field(
         True,
         description=(
             '[Deprecated] Optional property that specifies whether or not the App should '
             'use an API user token (which allows access to the DataStore).'
         ),
     )
-    app_id: Union[UUID4, UUID5] = Field(
+    app_id: UUID4 | UUID5 = Field(
         default_factory=gen_app_id,
         description=(
             '[TcEx 1.1.4+] A unique identifier for the App. This field is not currently '
             'used in the core product, but will be used in other tooling to identify the '
             'App. The appId field with the major version from programVersion make up a '
             'unique Application release. If this field does not exist while packaging '
             'the App via the `tcex package` command, a value will be added using the '
@@ -518,66 +517,65 @@
             'field should not be changed.'
         ),
     )
     category: str = Field(
         '',
         description='The category of the App. Also playbook.type for playbook Apps.',
     )
-    deprecates_apps: Optional[List[str]] = Field(
-        None,
+    deprecates_apps: list[str] = Field(
+        [],
         description=(
             'Optional property that provides a list of Apps that should be '
             'deprecated by this App.'
         ),
     )
-    display_name: constr(min_length=3, max_length=100) = Field(
+    display_name: constr(min_length=3, max_length=100) = Field(  # type: ignore
         ...,
         description=(
             'Required property providing the name of the App as it will be displayed in '
             'the ThreatConnect platform.'
         ),
     )
-    display_path: Optional[constr(min_length=3, max_length=100)] = Field(
+    display_path: constr(min_length=3, max_length=100) | None = Field(  # type: ignore
         None,
         description='The display path for API service Apps.',
     )
-    features: List[str] = Field(
+    features: list[str] = Field(
         ...,
         description=(
             'An array of supported features for the App. These feature enable '
             'additional functionality in the Core Platform and/or for the App.'
         ),
     )
-    labels: Optional[List[str]] = Field(
-        None,
+    labels: list[str] = Field(
+        [],
         description='A list of labels for the App.',
     )
-    language_version: Optional[str] = Field(
+    language_version: str = Field(
         ...,
         description=(
-            'Optional property used solely for tracking purposes. It does not affect '
-            'the version of Python or Java used by the Job Execution Engine to run the App.'
+            'The major.minor version of the language (e.g., Python "3.11"). This value is used by '
+            'the Core platform to control which version of Python is used to launch the App.'
         ),
     )
     list_delimiter: str = Field(
         ...,
         description=(
             'Optional property that sets the character used to delimit the values of '
             'an input that support the allowMultiple param option.'
         ),
     )
-    min_server_version: str = Field(
-        '6.2.0',
+    min_server_version: Version = Field(
+        '7.2.0',
         description=(
             'Optional string property restricting the ThreatConnect instance from '
-            'installing the App if it does not meet this version requirement '
-            '(e.g., 6.5.0).'
+            'installing the App if it does not meet this version requirement (e.g., 7.2.0).'
         ),
     )
-    note: Optional[str] = Field(
+    note: str | None = Field(
         None,
         description=(
             'Optional property available in Playbook Apps while configuring App inputs '
             'in the UI. This is the top level not of the App and should describe the '
             'functionality and use cases of the App.'
         ),
     )
@@ -595,38 +593,96 @@
         description=(
             'Required property providing the entry point into the App. For Python Apps, '
             'it is the name of the .py file (or exclude the extension if running it as a '
             'module). For Java Apps, it is the main class the Job Execution Engine '
             'should use when calling the App using the Java Runtime Environment.'
         ),
     )
-    program_version: str = Field(
+    program_version: Version = Field(
         ...,
         description=(
             'Required property providing the version number for the App that will be '
             'displayed in the Installed Apps section available to a System '
             'Administrator. ThreatConnect recommends the use of semantic versioning '
             '(e.g., 1.0.1).'
         ),
     )
-    runtime_level: Union[List, str] = Field(
+    runtime_level: str = Field(
         ...,
         description='The type for the App (e.g., Playbook, Organization, etc).',
     )
-    service: Optional[ServiceModel] = Field(
+    service: ServiceModel | None = Field(
         None,
         description='',
     )
+    sdk_version: Version | None = Field(
+        None,
+        description=(
+            'The version of the SDK (TcEx). This value is used by the Core '
+            'platform to control behavior in App Builder.'
+        ),
+    )
+
+    @validator('language_version', always=True, pre=True)
+    def _language_version(cls, v) -> str:
+        """Return a version object for "version" field."""
+
+        def _major_minor(v):
+            """Return the major.minor version."""
+            try:
+                version_ = Version.coerce(v)
+                v = f'{version_.major}.{version_.minor}'
+            except Exception:  # nosec
+                # best effort
+                pass
 
-    @validator('min_server_version', 'program_version')
-    def version(cls, v):
+            return v
+
+        if v is None:
+            v = _major_minor(platform.python_version())
+        else:
+            # for TC version >= 7.0.1 and < 7.2.0
+            v = _major_minor(v)
+
+        return v
+
+    @validator('min_server_version', pre=True)
+    def _min_server_version(cls, v) -> Version:
+        """Return a version object for "version" fields."""
+        # all tcex 4 Apps must have min server version of at least 7.2.0
+        if v is None or Version.coerce(v) < Version('7.2.0'):
+            v = '7.2.0'
+        return Version.coerce(v)
+
+    @validator('program_version', pre=True)
+    def _program_version(cls, v) -> Version:
         """Return a version object for "version" fields."""
         if v is not None:
             return Version(v)
-        return v  # pragma: no cover
+        return v
+
+    @validator('sdk_version', always=True, pre=True)
+    def _sdk_version(cls, v) -> Version:
+        """Return a version object for "version" field."""
+        if v is None:
+            # assume legacy App
+            return Version('2.0.0')
+
+        # ensure v is a Version object
+        v = v if isinstance(v, Version) else Version.coerce(v)
+
+        # update version
+        if v >= Version('4.0.0'):
+            try:
+                # best effort to update the tcex version
+                return Version.coerce(version('tcex'))
+            except Exception:
+                return v
+
+        return v
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         arbitrary_types_allowed = True
         json_encoders = json_encoders
@@ -687,31 +743,31 @@
 class InstallJsonOrganizationModel(BaseModel):
     """Install JSON Common Model
 
     This model contains the common fields for the install.json file and
     the app_spec.yaml file.
     """
 
-    feeds: Optional[List[FeedsModel]] = Field(
-        None,
+    feeds: list[FeedsModel] = Field(
+        [],
         description='A list of features enabled for the App.',
     )
-    publish_out_files: Optional[List[str]] = Field(
-        None,
+    publish_out_files: list[str] = Field(
+        [],
         description=(
             'Optional field available for job-style Apps that can be scheduled to serve '
             'files. If this array is populated, the App is responsible for writing the '
             'files to the relative tc_output_path parameter that is passed in. This will '
             'enable HTTP-based file serving of these files as a unique URL available to '
             'the user in ThreatConnect. This parameter accepts an array of strings and '
             'can include file globs.'
         ),
     )
-    repeating_minutes: Optional[List[int]] = Field(
-        None,
+    repeating_minutes: list[int] = Field(
+        [],
         description=(
             'Optional property that provides a list of minute increments to display in '
             'the Repeat Every section in the Schedule panel of the Job Wizard. This '
             'property is relevant only for Python and Java Apps for which the developer '
             'wants to control how frequently an App can be executed. If this property is '
             'not defined, the default listing is as follows: [60, 120, 240, 360, 720].'
         ),
@@ -721,45 +777,45 @@
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class InstallJsonModel(InstallJsonCommonModel, InstallJsonOrganizationModel):
-    """Install JSON Model"""
+    """Model definition for install.json configuration file"""
 
-    commit_hash: Optional[str] = Field(
+    commit_hash: str | None = Field(
         default_factory=get_commit_hash,
         description='The git commit hash from when the App was built.',
     )
-    docker_image: Optional[str] = Field(
+    docker_image: str | None = Field(
         None,
         description='[unsupported] The docker image to run the App.',
     )
-    params: Optional[List[ParamsModel]] = Field(
-        None,
+    params: list[ParamsModel] = Field(
+        [],
         description='',
     )
-    playbook: Optional[PlaybookModel] = Field(
+    playbook: PlaybookModel | None = Field(
         None,
         description='',
     )
-    program_icon: Optional[str] = Field(
+    program_icon: str | None = Field(
         None,
         description=(
             'Optional property providing the icon that will be used to represent Central '
             'Spaces Apps.'
         ),
     )
-    program_name: Optional[str] = Field(
+    program_name: str | None = Field(
         None,
         description='',
     )
-    runtime_context: Optional[List] = Field(
-        None,
+    runtime_context: list = Field(
+        [],
         description=(
             'Optional property enabling Spaces Apps to be context aware (i.e., Spaces '
             'Apps that can be added to the Details screen of an object in the '
             'ThreatConnect platform). Because this property is an array of strings, the '
             'App can be displayed in Spaces under multiple contexts within the '
             'ThreatConnect platform, including the Menu and Search screens. This property '
             'is only applicable to Spaces Apps.'
@@ -779,21 +835,21 @@
         """Return the appropriate output var type for the current App."""
         if self.is_trigger_app:
             return 'Trigger'
         return 'App'
 
     def filter_params(
         self,
-        name: Optional[str] = None,
-        hidden: Optional[bool] = None,
-        required: Optional[bool] = None,
-        service_config: Optional[bool] = None,
-        _type: Optional[str] = None,
-        input_permutations: Optional[List] = None,
-    ) -> Dict[str, 'ParamsModel']:
+        name: str | None = None,
+        hidden: bool | None = None,
+        required: bool | None = None,
+        service_config: bool | None = None,
+        _type: str | None = None,
+        input_permutations: dict | None = None,
+    ) -> dict[str, ParamsModel]:
         """Return params as name/data dict.
 
         Args:
             name: The name of the input to return.
             hidden: If set the inputs will be filtered based on hidden field.
             required: If set the inputs will be filtered based on required field.
             service_config: If set the inputs will be filtered based on serviceConfig field.
@@ -801,15 +857,14 @@
             input_permutations: A list of valid input names for provided permutation.
 
         Returns:
             dict: All valid inputs for current filter.
         """
         params = {}
         for p in self.params:
-
             if name is not None:
                 if p.name != name:
                     continue
 
             if hidden is not None:
                 if p.hidden is not hidden:
                     continue
@@ -829,54 +884,54 @@
             if input_permutations is not None:
                 if p.name not in input_permutations:
                     continue
 
             params.setdefault(p.name, p)
         return params
 
-    def get_output(self, name: str) -> Union['NoneModel', 'OutputVariablesModel']:
+    def get_output(self, name: str) -> OutputVariablesModel | None:
         """Return output for the matching name."""
-        return self.playbook_outputs.get(name) or NoneModel()
+        return self.playbook_outputs.get(name)
 
-    def get_param(self, name: str) -> Union['NoneModel', 'ParamsModel']:
+    def get_param(self, name: str) -> ParamsModel | None:
         """Return param for the matching name."""
-        return self.params_dict.get(name) or NoneModel()
+        return self.params_dict.get(name)
 
     @property
-    def optional_params(self) -> Dict[str, 'ParamsModel']:
+    def optional_params(self) -> dict[str, ParamsModel]:
         """Return params as name/data model."""
         return {p.name: p for p in self.params if p.required is False}
 
     @property
     def package_version(self):
         """Return the major version of the App."""
         return f'v{self.program_version.major}'
 
     @property
-    def param_names(self) -> List[str]:
+    def param_names(self) -> list[str]:
         """Return the "name" field from all params."""
         return [p.name for p in self.params]
 
     @property
-    def params_dict(self) -> Dict[str, 'ParamsModel']:
+    def params_dict(self) -> dict[str, ParamsModel]:
         """Return params as name/data dict."""
         return {p.name: p for p in self.params}
 
     @property
-    def playbook_outputs(self) -> Dict[str, 'OutputVariablesModel']:
+    def playbook_outputs(self) -> dict[str, OutputVariablesModel]:
         """Return outputs as name/data model."""
-        return {o.name: o for o in self.playbook.output_variables}
+        return {} if self.playbook is None else {o.name: o for o in self.playbook.output_variables}
 
     @property
-    def required_params(self) -> Dict[str, 'ParamsModel']:
+    def required_params(self) -> dict[str, ParamsModel]:
         """Return params as name/data dict."""
         return {p.name: p for p in self.params if p.required is True}
 
     @property
-    def service_config_params(self) -> Dict[str, 'ParamsModel']:
+    def service_config_params(self) -> dict[str, ParamsModel]:
         """Return params as name/data dict."""
         return {p.name: p for p in self.params if p.service_config is True}
 
     @property
-    def service_playbook_params(self) -> Dict[str, 'ParamsModel']:
+    def service_playbook_params(self) -> dict[str, ParamsModel]:
         """Return params as name/data dict."""
         return {p.name: p for p in self.params if p.service_config is False}
```

### Comparing `tcex-3.0.9/tcex/app_config/models/job_json_model.py` & `tcex-4.0.0/tcex/app/config/model/job_json_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,9 @@
-"""TcEx JSON Model"""
-# pylint: disable=no-self-argument,no-self-use; noqa: N805
-# standard library
-from typing import List, Optional, Union
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 
 # third-party
 from pydantic import BaseModel, Field, validator
 from semantic_version import Version
 
 __all__ = ['JobJsonModel']
 
@@ -13,44 +11,44 @@
 def snake_to_camel(snake_string: str) -> str:
     """Convert snake_case to camelCase"""
     components = snake_string.split('_')
     return components[0] + ''.join(x.title() for x in components[1:])
 
 
 class ParamsModel(BaseModel):
-    """Model for jj.params"""
+    """Model definition for job.json.params"""
 
-    default: Optional[Union[bool, str]]
-    encrypt: Optional[bool] = False
+    default: bool | str | None
+    encrypt: bool = False
     name: str
     prevent_updates: bool = False
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         # without smart_union the default value as a string of "0" would be converted to a bool
         smart_union = True
         validate_assignment = True
 
 
 class JobJsonCommonModel(BaseModel):
-    """Model for common field in job.json."""
+    """Model definition for common field in job.json."""
 
     allow_on_demand: bool = Field(
         ...,
         description='If true, the job can be run on demand.',
     )
     enable_notifications: bool = Field(
-        ..., description='Enables pass/fail notifications for this job.'
+        ..., description='Enables pass/fail notification for this job.'
     )
     job_name: str
     notify_email: str = Field(
         ...,
-        description='Email address to send notifications to.',
+        description='Email address to send notification to.',
     )
     notify_include_log_files: bool = Field(
         ...,
         description='If true, the job log files will be included in the notification email.',
     )
     notify_on_complete: bool = Field(
         ...,
@@ -62,15 +60,15 @@
     )
     notify_on_partial_failure: bool = Field(
         ...,
         description=(
             'If true, a notification will be sent when the job completes with partial success.'
         ),
     )
-    params: List[ParamsModel]
+    params: list[ParamsModel]
     publish_auth: bool = Field(
         ...,
         description='If true, the job will publish the authentication token.',
     )
     schedule_cron_format: str
     schedule_start_date: int
     schedule_type: str
@@ -80,15 +78,15 @@
 
         alias_generator = snake_to_camel
         arbitrary_types_allowed = True
         validate_assignment = True
 
 
 class JobJsonModel(JobJsonCommonModel):
-    """Model for field in job.json."""
+    """Model definition for job.json configuration file"""
 
     program_name: str
     program_version: str
 
     @validator('program_version')
     def version(cls, v):
         """Return a version object for "version" fields."""
```

### Comparing `tcex-3.0.9/tcex/app_config/models/layout_json_model.py` & `tcex-4.0.0/tcex/app/config/model/layout_json_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,103 +1,104 @@
-"""Layout JSON Model"""
-# pylint: disable=no-self-argument,no-self-use; noqa: N805
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 # standard library
 from collections import OrderedDict
-from typing import Dict, List, Optional, Union
 
 # third-party
-from pydantic import BaseModel
+from pydantic import BaseModel, Field
 from pydantic.types import constr
 
-# first-party
-from tcex.pleb.none_model import NoneModel
+from ....pleb.none_model import NoneModel
 
 __all__ = ['LayoutJsonModel']
 
 
 def snake_to_camel(snake_string: str) -> str:
     """Convert snake_case to camelCase"""
     components = snake_string.split('_')
     return components[0] + ''.join(x.title() for x in components[1:])
 
 
 class ParametersModel(BaseModel):
-    """Model for layout_json.inputs.{}"""
+    """Model definition for layout_json.inputs.{}"""
 
-    display: Optional[str]
+    display: str | None
     name: str
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class InputsModel(BaseModel):
-    """Model for layout_json.inputs"""
+    """Model definition for layout_json.inputs"""
 
-    parameters: List[ParametersModel]
+    parameters: list[ParametersModel]
     sequence: int
-    title: constr(min_length=3, max_length=100)
+    title: constr(min_length=3, max_length=100)  # type: ignore
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class OutputsModel(BaseModel):
-    """Model for layout_json.outputs"""
+    """Model definition for layout_json.outputs"""
 
-    display: Optional[str]
+    display: str | None
     name: str
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
 
 class LayoutJsonModel(BaseModel):
-    """Layout JSON Model"""
+    """Model definition for layout.json configuration file"""
 
-    inputs: List[InputsModel]
-    outputs: Optional[List[OutputsModel]]
+    inputs: list[InputsModel]
+    outputs: list[OutputsModel] = Field([], description='Layout output variable definitions.')
 
     class Config:
         """DataModel Config"""
 
         alias_generator = snake_to_camel
         validate_assignment = True
 
-    def get_param(self, name: str) -> Union['NoneModel', 'ParametersModel']:
+    def get_param(self, name: str) -> NoneModel | ParametersModel:
         """Return the param or a None Model."""
         return self.params.get(name) or NoneModel()
 
-    def get_output(self, name: str) -> Union['NoneModel', 'OutputsModel']:
+    def get_output(self, name: str) -> NoneModel | OutputsModel:
         """Return layout.json outputs in a flattened dict with name param as key."""
         return self.outputs_.get(name) or NoneModel()
 
     @property
-    def outputs_(self) -> Dict[str, 'OutputsModel']:
+    def outputs_(self) -> dict[str, OutputsModel]:
         """Return layout.json outputs in a flattened dict with name param as key."""
         return {o.name: o for o in self.outputs}
 
     @property
     def param_names(self) -> list:
         """Return all param names in a single list."""
         return list(self.params.keys())
 
     @property
-    def params(self) -> Dict[str, 'ParametersModel']:
+    def params(self) -> dict[str, ParametersModel]:
         """Return layout.json params in a flattened dict with name param as key."""
         # return {p.name: p for i in self.inputs for p in i.parameters}
 
         # order is required for display clauses to be evaluated correctly
         parameters = OrderedDict()  # remove after python 3.7
         for i in self.inputs:
             for p in i.parameters:
                 parameters.setdefault(p.name, p)
         return parameters
+
+
+OutputsModel.update_forward_refs()
```

### Comparing `tcex-3.0.9/tcex/app_config/permutation.py` & `tcex-4.0.0/tcex/app/config/permutation.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,87 +1,90 @@
-#!/usr/bin/env python
-"""Permutation"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
 import os
 import random
 import re
 import sys
+from collections.abc import Iterator
 from pathlib import Path
-from typing import Any, List, Optional, Tuple, Union
+from typing import Any, cast
 
 try:
     # standard library
     import sqlite3
 except ImportError:  # pragma: no cover
     pass  # sqlite3 is only required for local development
 
-# first-party
-from tcex.app_config.install_json import InstallJson
-from tcex.app_config.layout_json import LayoutJson
-from tcex.app_config.models.install_json_model import ParamsModel
-from tcex.app_config.models.layout_json_model import OutputsModel, ParametersModel
-from tcex.backports import cached_property
-from tcex.pleb.none_model import NoneModel
+from ...pleb.cached_property import cached_property
+from ...pleb.none_model import NoneModel
+from ...util.render.render import Render
+from .install_json import InstallJson
+from .layout_json import LayoutJson
+from .model.install_json_model import OutputVariablesModel, ParamsModel
+from .model.layout_json_model import OutputsModel
 
-# get tcex logger
-tcex_logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class InputModel(ParamsModel):
     """Input Model"""
 
     value: Any
 
     def __hash__(self):
         """Make model hashable."""
         return hash(self.name)
 
 
 class Permutation:
-    """Permutations Module"""
+    """Permutations Module
 
-    def __init__(self, logger: Optional[logging.Logger] = None):
-        """Initialize Class properties"""
-        self.log = logger or tcex_logger
+    Calculate permutations for inputs and outputs based on layout.json and install.json files.
+    """
+
+    def __init__(self):
+        """Initialize instance properties"""
 
         # properties
         self._input_names = None
-        self._input_table = 'inputs'
-        self._input_permutations = None
-        self._output_permutations = None
+        self._input_permutations: list[list[InputModel]] = []
+        self._output_permutations: list[list[OutputVariablesModel]] = []
         self.fqfn = Path(os.getcwd(), 'permutations.json')
-        self.ij = InstallJson(logger=self.log)
-        self.lj = LayoutJson(logger=self.log)
+        self.ij = InstallJson()
+        self.input_table = 'inputs'
+        self.lj = LayoutJson()
+        self.log = _logger
 
     @staticmethod
-    def _create_input_model(ij_param: ParamsModel, value: any) -> InputModel:
+    def _create_input_model(ij_param: ParamsModel, value: Any) -> InputModel:
         """Create an input model from the install.json param model."""
         _input_model = InputModel(**ij_param.dict())
         # manually adding List values due to bug where data is not getting loaded into model in init
         _input_model.intel_type = ij_param.intel_type
         _input_model.playbook_data_type = ij_param.playbook_data_type
         _input_model.valid_values = ij_param.valid_values
         _input_model.value = value
         return _input_model
 
     @cached_property
-    def _display_keywords(self) -> List[str]:
+    def _display_keywords(self) -> set[str]:
         """Return the display keywords."""
         _keywords = set()
         for param in self.lj.model.params.values():
             for keyword in (param.display or '').split(' '):
                 keyword = re.sub(r'[^a-zA-Z0-9_]', '', keyword)
                 if keyword in self.ij.model.param_names:
                     _keywords.add(keyword)
         self.log.debug(f'keywords={_keywords}')
         return _keywords
 
-    def _gen_permutations(self, index: Optional[int] = 0, params: Optional[list] = None):
+    def _gen_permutations(self, index: int = 0, params: list | None = None):
         """Iterate recursively over layout.json parameter names to build permutations.
 
         .. NOTE:: Permutations are for layout.json based Apps.
 
         Args:
             index: The current index position in the layout names list.
             params: The current list of args.
@@ -89,46 +92,46 @@
         params = params or []
         try:
             # grab the name using the index value of all params in the layout.json file.
             # after the last name is hit the IndexError will trigger collecting outputs.
             name = list(self.lj.model.param_names)[index]
 
             # get layout.json param name and data
-            lj_param: Union[NoneModel, ParametersModel] = self.lj.model.get_param(name)
+            lj_param = self.lj.model.get_param(name)
 
             # get install.json param to match layout.json param
-            ij_param: Union[NoneModel, ParamsModel] = self.ij.model.get_param(name)
-            if not isinstance(ij_param, ParamsModel):  # pragma: no cover
-                self.handle_error(f'No param found in install.json for "{name}".')
+            ij_param = self.ij.model.get_param(name)
+            if ij_param is None:  # pragma: no cover
+                Render.panel.failure(f'No param found in install.json for "{name}".')
 
-            if self.validate_layout_display(self._input_table, lj_param.display) or ij_param.hidden:
+            if self.validate_layout_display(self.input_table, lj_param.display) or ij_param.hidden:
                 # only process params that match display query or are hidden
                 if name != 'tc_action' and name not in self._display_keywords:
                     params.append(self._create_input_model(ij_param, None))
 
                     # recursively call method to get all permutations
                     self._gen_permutations(index + 1, list(params))
                 elif ij_param.type.lower() == 'boolean':
                     for val in [True, False]:
                         params.append(self._create_input_model(ij_param, val))
 
                         # update the data in the sqlite db so for next iteration
-                        self.db_update_record(self._input_table, name, val)
+                        self.db_update_record(self.input_table, name, val)
 
                         # recursively call method to get all permutations
                         self._gen_permutations(index + 1, list(params))
 
                         # remove the previous arg before next iteration
                         params.pop()
                 elif ij_param.type.lower() in ['choice', 'editchoice']:
                     for val in self.ij.expand_valid_values(ij_param.valid_values):
                         params.append(self._create_input_model(ij_param, val))
 
                         # update the data in the sqlite db so for next iteration
-                        self.db_update_record(self._input_table, name, val)
+                        self.db_update_record(self.input_table, name, val)
 
                         # recursively call method to get all permutations
                         self._gen_permutations(index + 1, list(params))
 
                         # remove the previous arg before next iteration
                         params.pop()
                 else:
@@ -138,53 +141,55 @@
                     self._gen_permutations(index + 1, list(params))
             else:
                 # do not add param since it's not required for this permutation
                 self._gen_permutations(index + 1, list(params))
         except IndexError:
             # when IndexError is reached all params has been processed
             self._input_permutations.append(params)
-            outputs = []
+            outputs: list[OutputVariablesModel] = []
 
             # iterate of InstallJsonModel -> PlaybookModel -> OutputVariablesModel
-            for o in self.ij.model.playbook.output_variables:
-
-                # get layout.json param to match install.json output variable
-                lj_output: Union[NoneModel, OutputsModel] = self.lj.model.get_output(o.name)
-                if isinstance(lj_output, OutputsModel):
-                    valid = self.validate_layout_display(self._input_table, lj_output.display)
-                    if lj_output.display is None or not valid:
-                        continue
-                # output meet permutation check
-                outputs.append(o)
-            self._output_permutations.append(outputs)
+            if self.ij.model.playbook is not None:
+                for o in self.ij.model.playbook.output_variables:
+                    # get layout.json param to match install.json output variable
+                    lj_output: NoneModel | OutputsModel = self.lj.model.get_output(o.name)
+                    if isinstance(lj_output, OutputsModel):
+                        valid = self.validate_layout_display(self.input_table, lj_output.display)
+                        if lj_output.display is None or not valid:
+                            continue
+                    # output meet permutation check
+                    outputs.append(o)
+                self._output_permutations.append(outputs)
 
     @property
-    def _params_data(self) -> Tuple[str, 'ParamsModel']:
+    def _params_data(self) -> Iterator[ParamsModel]:
         """Return all defined params from layout.json/install.json, including hidden params."""
         # using inputs from layout.json since they are required to be in order
         # (display field can only use inputs previously defined)
         for input_name in self.lj.model.params:
             # get data from install.json based on name
-            ij_data = self.ij.model.get_param(input_name)
-            yield ij_data
+            param = self.ij.model.get_param(input_name)
+            if param is not None:
+                yield param
 
         # hidden fields will not be in layout.json so they need to be include manually
         for input_name, ij_data in self.ij.model.filter_params(hidden=True).items():
             yield ij_data
 
     @cached_property
     def action_configurations(self) -> dict:
         """Return action configuration."""
         self.init_permutations()
 
         _action_configurations = {}
         for index, inputs in enumerate(self._input_permutations):
             for input_ in inputs:
                 if input_.name == 'tc_action':
-                    action = input_.value
+                    # the value should always be a string
+                    action = cast(str, input_.value)
                     _action_configurations.setdefault(action, {'inputs': [], 'outputs': []})
                     _action_configurations[action]['inputs'].extend(inputs)
                     _action_configurations[action]['outputs'].extend(
                         self._output_permutations[index]
                     )
                     break
 
@@ -193,75 +198,73 @@
                 'inputs': sorted(list(set(data['inputs'])), key=lambda x: x.name),
                 'outputs': sorted(list(set(data['outputs'])), key=lambda x: x.name),
             }
 
         return _action_configurations
 
     @cached_property
-    def db_conn(self) -> 'sqlite3.Connection':
+    def db_conn(self) -> sqlite3.Connection:  # type: ignore
         """Create a temporary in memory DB and return the connection."""
         try:
             return sqlite3.connect(':memory:')
-        except sqlite3.Error as e:  # pragma: no cover
-            self.handle_error(e)
+        except sqlite3.Error as ex:  # pragma: no cover
+            Render.panel.failure(f'Failed initializing database ({ex}).')
 
-        return None
-
-    def db_create_table(self, table_name: str, columns: List[str]):
+    def db_create_table(self, table_name: str, columns: list[str]):
         """Create a temporary DB table.
 
         Args:
             table_name: The DB table name.
             columns: The DB column names.
         """
-        columns = ', '.join([f'''"{c.strip('"').strip("'")}" text''' for c in set(columns)])
-        self.log.debug(f'action=db-create-table, table-name={table_name}, columns={columns}')
-        sql = f'CREATE TABLE IF NOT EXISTS {table_name} ({columns});'
+        columns_ = ', '.join([f'''"{c.strip('"').strip("'")}" text''' for c in set(columns)])
+        self.log.debug(f'action=db-create-table, table-name={table_name}, columns={columns_}')
+        sql = f'CREATE TABLE IF NOT EXISTS {table_name} ({columns_});'
         try:
             cr = self.db_conn.cursor()
             cr.execute(sql)
         except sqlite3.Error as e:  # pragma: no cover
-            self.handle_error(f'SQL create db failed - SQL: "{sql}", Error: "{e}"')
+            Render.panel.failure(f'SQL create db failed - SQL: "{sql}", Error: "{e}"')
 
     def db_drop_table(self, table_name: str):
         """Drop a DB table.
 
         Args:
             table_name: The DB table name.
         """
         sql = f'DROP TABLE IF EXISTS {table_name};'
         try:
             cr = self.db_conn.cursor()
             cr.execute(sql)
         except sqlite3.Error as e:  # pragma: no cover
-            self.handle_error(f'SQL drop db failed - SQL: "{sql}", Error: "{e}"')
+            Render.panel.failure(f'SQL drop db failed - SQL: "{sql}", Error: "{e}"')
 
-    def db_insert_record(self, table_name: str, columns: List[str]):
+    def db_insert_record(self, table_name: str, columns: list[str]):
         """Insert records into DB.
 
         A single row will all values as None so that values can be updated one at a
         time during parsing. The row and values will be used to determine permutations.
 
         Args:
             table_name: The DB table name.
             columns: The DB column names.
         """
         # sort and unique columns
-        columns = sorted(list(set(columns)))
+        columns = sorted(set(columns))
         bindings = ', '.join(['?'] * len(columns))
         columns_string = ', '.join([f'''"{c.strip('"').strip("'")}"''' for c in columns])
         values = [None] * len(columns)
+        sql = f'INSERT INTO {table_name} ({columns_string}) VALUES ({bindings})'
         try:
-            sql = f'''INSERT INTO {table_name} ({columns_string}) VALUES ({bindings})'''
             cur = self.db_conn.cursor()
             cur.execute(sql, values)
-        except sqlite3.OperationalError as ex:  # pragma: no cover
-            self.handle_error(f'SQL insert failed - SQL: "{sql}", Error: "{ex}"')
+        except sqlite3.OperationalError as ex:  # type: ignore
+            Render.panel.failure(f'SQL insert failed - SQL: "{sql}", Error: "{ex}"')
 
-    def db_update_record(self, table_name: str, column: str, value: str):
+    def db_update_record(self, table_name: str, column: str, value: bool | str | None):
         """Update a single column in the row-column create in db_insert_record.
 
         Args:
             table_name: The DB table name.
             column: The DB column names.
             value: The DB values to store (row data).
         """
@@ -273,76 +276,121 @@
             value = str(value).lower()
         else:  # pragma: no cover
             # no other types can be used in a layout.json display clause
             return
 
         # only column defined in install.json can be updated
         if column in self.ij.model.param_names:
+            # value should be wrapped in single quotes to be properly parsed
+            sql = f'UPDATE {table_name} SET {column} = \'{value}\''
             try:
-                # value should be wrapped in single quotes to be properly parsed
-                sql = f'''UPDATE {table_name} SET {column} = '{value}\''''
                 cur = self.db_conn.cursor()
                 cur.execute(sql)
-            except sqlite3.OperationalError as e:  # pragma: no cover
-                self.handle_error(f'SQL update failed - SQL: "{sql}", Error: "{e}"')
-
-    def handle_error(self, err: str, halt: Optional[bool] = True):  # pragma: no cover
-        """Print errors message and optionally exit.
-
-        Args:
-            err: The error message to print.
-            halt: If True, the script will exit.
-        """
-        self.log.error(err)
-        print(err)
-        if halt:
-            sys.exit(1)
+            except sqlite3.OperationalError as ex:  # pragma: no cover
+                Render.panel.failure(f'SQL update failed - SQL: "{sql}", Error: "{ex}"')
 
-    def get_action_input_names(self, action: str) -> List[str]:
+    def get_action_input_names(self, action: str) -> list[str]:
         """Return the input names for the provided action."""
         return [i.name for i in self.get_action_inputs(action)]
 
-    def get_action_inputs(self, action: str) -> List[InputModel]:
+    def get_action_inputs(self, action: str) -> list[InputModel]:
         """Return the inputs for the provided action."""
         return self.action_configurations.get(action, {}).get('inputs', [])
 
-    def get_action_output_names(self, action: str) -> List[str]:
+    def get_action_output_names(self, action: str) -> list[str]:
         """Return the output names for the provided action."""
         return [i.name for i in self.get_action_outputs(action)]
 
-    def get_action_outputs(self, action: str) -> List[OutputsModel]:
+    def get_action_outputs(self, action: str) -> list[OutputVariablesModel]:
         """Return the outputs for the provided action."""
         return self.action_configurations.get(action, {}).get('outputs', [])
 
     def get_input_applies_to_all(self, input_name: str) -> bool:
         """Return the outputs for the provided action."""
         for data in self.action_configurations.values():
             for d in data.get('inputs', []):
                 if d.name == input_name:
                     break
             else:
                 return False  # not found
         return True
 
+    def extract_tc_action_clause(self, display_clause: str | None) -> str | None:
+        """Extract the tc_action part of the display clause."""
+        if display_clause is not None:
+            # action_clause_extract_pattern = r'(tc_action\sin\s\([^\)]*\))'
+            action_clause_extract_pattern = r'''(tc_action\sin\s\(.+?(?<='\)))'''
+            _tc_action_clause = re.search(
+                action_clause_extract_pattern, display_clause, re.IGNORECASE
+            )
+            if _tc_action_clause is not None:
+                self.log.debug(f'action=extract-action-clause, display-clause={display_clause}')
+                return _tc_action_clause.group(1)
+        return None
+
+    @property
+    def inputs_ordered(self) -> Iterator[ParamsModel]:
+        """Return inputs ordered properly.
+
+        Layout based playbook Apps have the inputs ordered in
+        the layout.json so that the display clause is guaranteed
+        to have conditional defined before the clause is executed.
+        """
+        if self.lj.has_layout:
+            for name in self.lj.model.param_names:
+                param = self.ij.model.get_param(name)
+                if param is not None:
+                    yield param
+        else:
+            for param in self.ij.model.params:
+                yield param
+
     # TODO: [low] improve this logic
     def init_permutations(self):
         """Process layout.json names/display to get all permutations of args."""
-        if self._input_permutations is None and self._output_permutations is None:
+        if not all([self._input_permutations, self._output_permutations]):
             self._input_permutations = []
             self._output_permutations = []
 
             # create db for permutations testing
-            self.db_create_table(self._input_table, self.ij.model.param_names)
-            self.db_insert_record(self._input_table, self.ij.model.param_names)
+            self.db_create_table(self.input_table, self.ij.model.param_names)
+            self.db_insert_record(self.input_table, self.ij.model.param_names)
 
             # only gen permutations if none have been generated previously
             self._gen_permutations()
 
             # drop database
-            self.db_drop_table(self._input_table)
+            self.db_drop_table(self.input_table)
+
+    def inputs_by_action(
+        self, action: str, include_hidden: bool = True
+    ) -> Iterator[dict[str, bool | ParamsModel]]:
+        """Return all inputs for the provided action."""
+        for ij_data in self._params_data:
+            # get a display clause with just the tc_action condition
+            display = self.extract_tc_action_clause(self.lj.model.get_param(ij_data.name).display)
+            self.log.debug(f'action=input-by-action, input-name={ij_data.name}, display={display}')
+
+            if ij_data.service_config:
+                # inputs that are serviceConfig are not applicable for profiles
+                continue
+
+            if display is None:
+                # when there is no display clause or the input is hidden,
+                # then the input gets added to the AppBaseModel
+                applies_to_all = True
+            elif ij_data.hidden is True and include_hidden is True:
+                applies_to_all = True
+            elif self.validate_input_variable(ij_data.name, {'tc_action': action}, display):
+                # each input will be checked for permutations if the App has layout and not hidden
+                applies_to_all = False
+            else:
+                continue
+
+            yield {'applies_to_all': applies_to_all, 'input': ij_data}
 
     def input_dict(self, permutation_id: int) -> dict:
         """Return all input permutation names for provided permutation id.
 
         {'tc_action': 'Append', 'input_strings': None, 'append_chars': None}
 
         Args:
@@ -353,77 +401,111 @@
         """
         input_dict = {}
         if self.lj.has_layout:
             for permutation in self.input_permutations[permutation_id]:
                 input_dict.setdefault(permutation.name, permutation.value)
         return input_dict
 
-    @property
-    def input_names(self) -> List[list]:
+    @cached_property
+    def input_names(self) -> list[list[str]]:
         """Return all input permutation names for current App.
 
         Returns:
             list: List of Lists of input names.
         """
-        if self._input_names is None and self.lj.has_layout:
-            self._input_names = []
+        input_names = []
+        if self.lj.has_layout:
             for permutation in self.input_permutations:
-                self._input_names.append([p.name for p in permutation])
-        return self._input_names
+                input_names.append([p.name for p in permutation])
+        return input_names
 
     @property
-    def input_permutations(self) -> List[List[dict]]:
+    def input_permutations(self) -> list[list[InputModel]]:
         """Return all input permutations for current App.
 
         self._input_permutations is an array of permutations arrays.
         [[<perm obj #1], [<perm obj #2]]
 
         Returns:
             list: List of Lists of valid input permutations.
         """
-        if self._input_permutations is None and self.lj.has_layout:
+        if not self._input_permutations and self.lj.has_layout:
             self.init_permutations()
         return self._input_permutations
 
     @property
-    def output_permutations(self) -> List[List[dict]]:
+    def output_permutations(self) -> list[list[OutputVariablesModel]]:
         """Return all output permutations for current App.
 
         Returns:
             list: List of Lists of valid outputs permutations.
         """
         if self._output_permutations is None:
             self.init_permutations()
         return self._output_permutations
 
+    def outputs_by_action(self, action: str) -> Iterator[OutputVariablesModel]:
+        """Return all inputs for the provided action."""
+        yield from self.outputs_by_inputs({'tc_action': action})
+
+    def outputs_by_inputs(self, inputs: dict[str, str]) -> Iterator[OutputVariablesModel]:
+        """Return all output based on provided inputs
+
+        Args:
+            inputs: The args/inputs dict.
+
+        Returns:
+            list: List of Lists of valid outputs objects.
+        """
+        table = f'temp_{random.randint(100,999)}'  # nosec
+        self.db_create_table(table, self.ij.model.param_names)
+        self.db_insert_record(table, self.ij.model.param_names)
+
+        for name, val in inputs.items():
+            self.db_update_record(table, name, val)
+
+        # iterate of InstallJsonModel -> PlaybookModel -> OutputVariablesModel
+        if self.ij.model.playbook:
+            for o in self.ij.model.playbook.output_variables:
+                lj_output = self.lj.model.get_output(o.name)
+                if isinstance(lj_output, NoneModel):  # pragma: no cover
+                    # an output not listed in layout.json should always be shown
+                    yield o
+                elif self.validate_layout_display(table, lj_output.display):
+                    # all other outputs must be validated
+                    yield o
+
+        # drop database
+        self.db_drop_table(table)
+
     def permutations(self):
         """Process layout.json names/display to get all permutations of args."""
         if not self.lj.has_layout:  # pragma: no cover
-            print('Only Apps with a layout.json are supported.')
-            sys.exit(1)
+            Render.panel.failure('Only Apps with a layout.json are supported.')
 
         if 'sqlite3' not in sys.modules:  # pragma: no cover
-            print('The sqlite3 module needs to be built-in to Python for this feature.')
-            sys.exit(1)
+            Render.panel.failure(
+                'The sqlite3 module needs to be built-in to Python for this feature.'
+            )
 
         # create db for permutations testing
-        self.db_create_table(self._input_table, self.ij.model.param_names)
-        self.db_insert_record(self._input_table, self.ij.model.param_names)
+        self.db_create_table(self.input_table, self.ij.model.param_names)
+        self.db_insert_record(self.input_table, self.ij.model.param_names)
 
         # only gen permutations if none have been generated previously
-        if not self._input_permutations and not self._output_permutations:
+        if not all([self._input_permutations, self._output_permutations]):
             self._input_permutations = self._input_permutations or []
             self._output_permutations = self._output_permutations or []
             self._gen_permutations()
 
         # output permutations
         self.write_permutations_file()
 
     def validate_input_variable(
-        self, input_name: str, inputs: dict, display: Optional[str] = None
+        self, input_name: str, inputs: dict, display: str | None = None
     ) -> bool:
         """Return True if the provided variables display where clause returns results.
 
         Args:
             input_name: The input variable name (e.g. tc_action).
             inputs: The current name/value dict.
             display: An optional display clause to validate. If not provided the
@@ -459,15 +541,15 @@
         valid = self.validate_layout_display(table, display)
 
         # cleanup temp table
         self.db_drop_table(table)
 
         return valid
 
-    def validate_layout_display(self, table: str, display_condition: str) -> bool:
+    def validate_layout_display(self, table: str, display_condition: str | None) -> bool:
         """Check to see if the display condition passes.
 
         Args:
             table: The name of the DB table which hold the App data.
             display_condition: The "where" clause of the DB SQL statement.
 
         Returns:
@@ -481,22 +563,21 @@
             try:
                 cur = self.db_conn.cursor()
                 cur.execute(display_query.replace('"', ''))
                 rows = cur.fetchall()
                 if rows[0][0] > 0:
                     display = True
             except sqlite3.Error as e:  # pragma: no cover
-                print(f'"{display_query}" query returned an error: ({e}).')
-                sys.exit(1)
+                Render.panel.failure(f'"{display_query}" query returned an error: ({e}).')
         return display
 
     def write_permutations_file(self):
-        """Print all valid permutations."""
+        """Write permutations file."""
         _permutations = []
         for index, permutations in enumerate(self.input_permutations):
             _permutations.append(
                 {'index': index, 'args': [{'name': p.name, 'value': p.value} for p in permutations]}
             )
 
-        with self.fqfn.open(mode='w') as fh:
+        with self.fqfn.open(mode='w', encoding='utf-8') as fh:
             json.dump(_permutations, fh, indent=2, sort_keys=True)
-        print('All permutations written to the "permutations.json" file.')
+        Render.panel.success('All permutations written to the "permutations.json" file.')
```

### Comparing `tcex-3.0.9/tcex/app_config/tcex_json_update.py` & `tcex-4.0.0/tcex/app/config/tcex_json_update.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,45 +1,47 @@
-"""TcEx JSON Update"""
+"""TcEx Framework Module"""
 # standard library
 import os
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING
 
-if TYPE_CHECKING:  # pragma: no cover
-    from .tcex_json import TcexJson
+if TYPE_CHECKING:
+    from .tcex_json import TcexJson  # CIRCULAR-IMPORT
 
 
 class TcexJsonUpdate:
-    """Update install.json file with current standards and schema."""
+    """Config object for tcex.json configuration file (updater)"""
 
-    def __init__(self, tj: 'TcexJson'):  # pylint: disable=E0601
-        """Initialize class properties."""
+    def __init__(self, tj: 'TcexJson'):
+        """Initialize instance properties."""
         self.tj = tj
 
-    def multiple(self, template: Optional[str] = None):
+    def multiple(self, template: str | None = None):
         """Update the contents of the tcex.json file."""
 
         # update app_name
         self.update_package_app_name()
 
         # update deprecated fields
-        # self.update_deprecated_fields()
+        self.update_deprecated_fields()
 
         # update package excludes
         self.update_package_excludes()
 
-        # update package excludes
-        self.update_lib_versions()
-
         # update template
         if template is not None:
-            self.tj.template = template
+            self.tj.model.template_name = template
 
         # write updated profile
         self.tj.write()
 
+    def update_deprecated_fields(self):
+        """Update the lib_versions array in the tcex.json file."""
+        if hasattr(self.tj.model, 'lib_versions'):
+            self.tj.model.lib_versions = None
+
     def update_package_app_name(self):
         """Update the package app_name in the tcex.json file."""
         if (
             self.tj.model.package.app_name is None
             or self.tj.model.package.app_name in self.tj.ij.app_prefixes.values()
         ):
             # lower case name and replace prefix if already exists
@@ -55,39 +57,19 @@
 
             # prepend appropriate App prefix (e.g., TCPB_-_)
             _app_name = f'{self.tj.ij.app_prefix}{_app_name}'
 
             # update App name
             self.tj.model.package.app_name = _app_name
 
-    # def update_deprecated_fields(self):
-    #     """Update deprecated fields in the tcex.json file."""
-    #     deprecated_fields = ['profile_include_dirs']
-    #     for d in deprecated_fields:
-    #         setattr(self.tj.model, d, None)
-
     def update_package_excludes(self):
         """Update the excludes values in the tcex.json file."""
         for i in [
             '.gitignore',
             '.pre-commit-config.yaml',
+            'app_spec.yaml',
             'local-*',
             'pyproject.toml',
-            'setup.cfg',
-            'tcex.json',
         ]:
             if i not in self.tj.model.package.excludes:
                 # TODO: [low] pydantic doesn't seem to allow removing items from list???
                 self.tj.model.package.excludes.append(i)
-
-    def update_lib_versions(self):
-        """Update the lib_versions array in the tcex.json file."""
-        if os.getenv('TCEX_LIB_VERSIONS') and not self.tj.model.lib_versions:
-            _lib_versions = []
-            for version in os.getenv('TCEX_LIB_VERSIONS').split(','):
-                _lib_versions.append(
-                    {
-                        'lib_dir': f'lib_${{env:{version}}}',
-                        'python_executable': f'~/.pyenv/versions/${{env:{version}}}/bin/python',
-                    }
-                )
-            self.tj.model.lib_versions = _lib_versions
```

### Comparing `tcex-3.0.9/tcex/app_feature/advanced_request.py` & `tcex-4.0.0/tcex/app/playbook/advanced_request.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,23 +1,24 @@
-"""ThreatConnect Exchange App Feature Advanced Request Module"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
 from mimetypes import MimeTypes
-from typing import Optional, Union
+from typing import cast
 
 # third-party
-import requests
+from requests import Response, Session
+from requests.exceptions import RequestException
 
-# first-party
-from tcex.input.input import Input
-from tcex.playbook import Playbook
+from ...app.playbook import Playbook
+from ...input.model.advanced_request_model import AdvancedRequestModel
+from ...logger.trace_logger import TraceLogger
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class AdvancedRequest:
     """App Feature Advanced Request Module
 
     Args:
         inputs: The instance of App inputs.
@@ -25,127 +26,134 @@
         session: An instance of Requests Session object.
         output_prefix: The output prefix.
         timeout: The timeout value for the request.
     """
 
     def __init__(
         self,
-        inputs: Input,
+        model: AdvancedRequestModel,
         playbook: Playbook,
-        session: requests.Session,
+        session: Session,
         output_prefix: str,
-        timeout: Optional[int] = 600,
+        timeout: int = 600,
     ):
-        """Initialize class properties."""
-        self.inputs = inputs
-        self.output_prefix: str = output_prefix
+        """Initialize instance properties."""
+        self.model = model
         self.playbook = playbook
+        self.output_prefix = output_prefix
         self.session = session
-        self.timeout: int = timeout or 600
+        self.timeout = timeout or 600
 
         # properties
         self.allow_redirects: bool = True
-        self.data: Optional[Union[dict, str]] = None
+        self.data: bytes | dict | str | None = None
         self.headers: dict = {}
-        self.log = logger
+        self.log = _logger
         self.max_mb: int = 500
-        self.mt: callable = MimeTypes()
+        self.mt = MimeTypes()
         self.params: dict = {}
 
     def configure_body(self):
         """Configure Body"""
-        self.data: Union[bytes, str] = self.inputs.model.tc_adv_req_body
+        self.data = self.model.tc_adv_req_body
         if self.data is not None:
             # INT-1386
             try:
-                self.data: str = self.data.encode('utf-8')
+                self.data = self.data.encode('utf-8')  # type: ignore
             except AttributeError:
                 pass  # Binary Data
 
-        if self.inputs.model.tc_adv_req_urlencode_body:
+        if self.model.tc_adv_req_urlencode_body:
+            # the user has selected to urlencode the body, which indicates that
+            # the body is a JSON string and should be converted to a dict
+            self.data = cast(str, self.data)
             try:
-                self.data: dict = json.loads(self.data)
+                self.data = json.loads(self.data)
             except ValueError:  # pragma: no cover
                 self.log.error('Failed loading body as JSON data.')
 
     def configure_headers(self):
         """Configure Headers
 
         [{
             "key": "User-Agent",
             "value": "TcEx MyApp: 1.0.0",
         }]
         """
-        for header_data in self.inputs.model.tc_adv_req_headers:
-            value: str = self.playbook.read.variable(header_data.get('value'))
+        for header_data in self.model.tc_adv_req_headers or []:
+            value = self.playbook.read.variable(header_data['value'])
             self.headers[str(header_data.get('key'))] = str(value)
 
     def configure_params(self):
         """Configure Params
 
         [{
             "count": "500",
             "page": "1",
         }]
         """
-        for param_data in self.inputs.model.tc_adv_req_params:
-            param: str = str(param_data.get('key'))
-            values: str = self.playbook.read.variable(param_data.get('value'))
+        for param_data in self.model.tc_adv_req_params or []:
+            param = param_data.get('key')
+            values = self.playbook.read.variable(param_data['value'])
             if not isinstance(values, list):
-                values: list = [values]
+                values = [values]
             for value in values:
-                if not value and self.inputs.model.tc_adv_req_exclude_null_params:
+                if not value and self.model.tc_adv_req_exclude_null_params:
                     self.log.warning(
                         f'Query parameter {param} has a null/empty value '
                         'and will not be added to the request.'
                     )
                 else:
                     self.params.setdefault(param, []).append(str(value))
 
-    def request(self):
+    def request(self) -> Response | None:
         """Make the HTTP request."""
+        if self.model.tc_adv_req_path is None:
+            return None
+
         # configure body
         self.configure_body()
 
         # configure headers
         self.configure_headers()
 
         # configure params
         self.configure_params()
 
         # make http request
         try:
-            response: object = self.session.request(
+            response = self.session.request(
                 allow_redirects=self.allow_redirects,
                 data=self.data,
                 headers=self.headers,
-                method=self.inputs.model.tc_adv_req_http_method,
+                method=self.model.tc_adv_req_http_method,
                 params=self.params,
                 timeout=self.timeout,
-                url=self.inputs.model.tc_adv_req_path,
+                url=self.model.tc_adv_req_path,
             )
-        except requests.exceptions.RequestException as e:  # pragma: no cover
-            response = None
-            raise RuntimeError(f'Exception during request ({e}).')
+        except RequestException as ex:  # pragma: no cover
+            raise RuntimeError(f'Exception during request ({ex}).') from ex
 
         # write outputs as soon as they are available
         self.playbook.create.variable(
             f'{self.output_prefix}.request.headers', json.dumps(dict(response.headers)), 'String'
         )
         self.playbook.create.variable(
             f'{self.output_prefix}.request.ok', str(response.ok).lower(), 'String'
         )
         self.playbook.create.variable(
             f'{self.output_prefix}.request.reason', response.reason, 'String'
         )
         self.playbook.create.variable(
-            f'{self.output_prefix}.request.status_code', response.status_code, 'String'
+            f'{self.output_prefix}.request.status_code', str(response.status_code), 'String'
         )
         self.playbook.create.variable(
-            f'{self.output_prefix}.request.url', response.request.url, 'String'
+            f'{self.output_prefix}.request.url',
+            response.request.url or self.model.tc_adv_req_path,
+            'String',
         )
 
         # get response size
         response_bytes: int = len(response.content)
         response_mb: float = response_bytes / 1000000
         self.log.info(f'Response MB: {response_mb}')
         if response_mb > self.max_mb:  # pragma: no cover
@@ -156,11 +164,11 @@
             f'{self.output_prefix}.request.content', response.text, 'String'
         )
         self.playbook.create.variable(
             f'{self.output_prefix}.request.content.binary', response.content, 'Binary'
         )
 
         # fail if fail_on_error is selected and not ok
-        if self.inputs.model.tc_adv_req_fail_on_error and not response.ok:
+        if self.model.tc_adv_req_fail_on_error and not response.ok:
             raise RuntimeError(f'Failed for status ({response.status_code})')
 
         return response
```

### Comparing `tcex-3.0.9/tcex/backports/__init__.py` & `tcex-4.0.0/tcex/pleb/cached_property.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,37 +1,30 @@
-"""Python Backports"""
-# flake8: noqa
+"""TcEx Framework Module"""
 # standard library
-from typing import Callable, Generic, TypeVar
-
-try:
-    # standard library
-    from functools import cached_property as functool_cached_property
-except ImportError:
-    # third-party
-    from backports.cached_property import cached_property as functool_cached_property
-
+from collections.abc import Callable
+from functools import cached_property as functool_cached_property
+from typing import Generic, TypeVar
 
 R = TypeVar('R')
 
 
 class cached_property(functool_cached_property, Generic[R]):
     """Customized cached_property."""
 
     # pylint: disable=useless-super-delegation
-    def __init__(self, func: Callable[..., R]) -> None:
-        """Initialize Class properties."""
+    def __init__(self, func: Callable[..., R]):
+        """Initialize instance properties."""
         super().__init__(func)
 
     instances = []
 
     def __get__(self, instance, owner=None) -> R:
         """Override method."""
         self.instances.append(instance)
-        return super().__get__(instance, owner)
+        return super().__get__(instance, owner)  # type: ignore
 
     @staticmethod
     def _reset():
         """Reset cache"""
         for i in cached_property.instances:
             for key, value in i.__dict__.items():
                 if isinstance(value, cached_property):
```

### Comparing `tcex-3.0.9/tcex/decorators/benchmark.py` & `tcex-4.0.0/tcex/app/decorator/benchmark.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,22 @@
-"""App Decorators Module."""
+"""TcEx Framework Module"""
 # standard library
 import datetime
 import logging
-from typing import Optional
+from collections.abc import Callable
+from typing import Any
 
 # third-party
 import wrapt
 
+# first-party
+from tcex.logger.trace_logger import TraceLogger
+
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class Benchmark:
     """Log benchmarking times.
 
     This decorator will log the time of execution (benchmark_time) to the app.log file. It can be
     helpful in troubleshooting performance issues with Apps.
@@ -26,25 +30,25 @@
         @Benchmark()
         def my_method():
             time.sleep(1)
     """
 
     def __init__(
         self,
-        microseconds: Optional[int] = 0,
-        milliseconds: Optional[int] = 0,
-        seconds: Optional[int] = 0,
+        microseconds: int = 0,
+        milliseconds: int = 0,
+        seconds: int = 0,
     ):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         self.microseconds = microseconds
         self.milliseconds = milliseconds
         self.seconds = seconds
 
     @wrapt.decorator
-    def __call__(self, wrapped, instance, args, kwargs):
+    def __call__(self, *wrapped_args) -> Any:
         """Implement __call__ function for decorator.
 
         Args:
             wrapped (callable): The wrapped function which in turns
                 needs to be called by your wrapper function.
             instance (App): The object to which the wrapped
                 function was bound when it was called.
@@ -52,26 +56,32 @@
                 when the decorated function was called.
             kwargs (dict): The dictionary of keyword arguments
                 supplied when the decorated function was called.
 
         Returns:
             function: The custom decorator function.
         """
+        # using wrapped args to support typing hints in PyRight
+        wrapped: Callable = wrapped_args[0]
+        args: list = wrapped_args[2] if len(wrapped_args) > 1 else []
+        kwargs: dict = wrapped_args[3] if len(wrapped_args) > 2 else {}
 
-        def benchmark(_, *args, **kwargs):
+        def benchmark() -> Any:
             """Iterate over data, calling the decorated function for each value.
 
             Args:
                 app (class): The instance of the App class "self".
+                *args: Additional positional arguments.
+                **kwargs: Additional keyword arguments.
             """
 
             before = datetime.datetime.now()
             data = wrapped(*args, **kwargs)
             after = datetime.datetime.now()
             delta = after - before
             if delta > datetime.timedelta(
                 microseconds=self.microseconds, milliseconds=self.milliseconds, seconds=self.seconds
             ):
-                logger.debug(f'function: "{wrapped.__name__}", benchmark_time: "{delta}"')
+                _logger.debug(f'function: "{wrapped.__name__}", benchmark_time: "{delta}"')
             return data
 
-        return benchmark(instance, *args, **kwargs)
+        return benchmark()
```

### Comparing `tcex-3.0.9/tcex/decorators/fail_on_output.py` & `tcex-4.0.0/tcex/app/decorator/fail_on_output.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,13 +1,18 @@
-"""App Decorators Module."""
+"""TcEx Framework Module"""
+# standard library
+from collections.abc import Callable
+from typing import Any, cast
+
 # third-party
 import wrapt
 
 # first-party
 from tcex.exit import ExitCode
+from tcex.tcex import TcEx
 
 
 class FailOnOutput:
     """Fail App if return value (output) value conditions are met.
 
     This decorator allows for the App to exit on conditions defined in the function
     parameters.
@@ -19,71 +24,80 @@
         @FailOnOutput(
             fail_on=['false'], fail_msg='Operation returned a value of "false".'
         )
         def my_method(data):
             return data.lowercase()
 
     Args:
-        fail_enabled (boolean|str, kwargs): Accepts a boolean or string value.  If a boolean value
+        fail_enabled: Accepts a boolean or string value.  If a boolean value
             is provided that value will control enabling/disabling this feature. A string
             value should reference an item in the args namespace which resolves to a boolean.
             The value of this boolean will control enabling/disabling this feature.
-        fail_msg (str, kwargs): The message to log when raising RuntimeError.
-        fail_msg_property (str, kwargs): The App property containing the dynamic exit message.
-        fail_on (list, kwargs):
-            Fail if return value from App method is in the list.
-        write_output (bool, kwargs): Defaults to True.
-            If true, will call App.write_outputs() before failing on matched fail_on value.
+        fail_msg: The message to log when raising RuntimeError.
+        fail_msg_property: The App property containing the dynamic exit message.
+        fail_on: Fail if return value from App method is in the list.
+        write_output: Defaults to True. If true, will call App.write_outputs() before failing
+            on matched fail_on value.
     """
 
-    def __init__(self, **kwargs):
-        """Initialize Class properties."""
-        self.fail_enabled = kwargs.get('fail_enabled', True)
-        self.fail_msg = kwargs.get('fail_msg', 'Method returned invalid output.')
-        self.fail_on = kwargs.get('fail_on', [])
-        self.fail_msg_property = kwargs.get('fail_msg_property')
-        self.write_output = kwargs.get('write_output', True)
+    def __init__(
+        self,
+        fail_enabled: bool | str = True,
+        fail_msg: str = 'Method returned invalid output.',
+        fail_on: list | None = None,
+        fail_msg_property: str | None = None,
+        write_output: bool = True,
+    ):
+        """Initialize instance properties."""
+        self.fail_enabled = fail_enabled
+        self.fail_msg = fail_msg
+        self.fail_on = fail_on or []
+        self.fail_msg_property = fail_msg_property
+        self.write_output = write_output
 
     @wrapt.decorator
-    def __call__(self, wrapped, instance, args, kwargs):
+    def __call__(self, *wrapped_args) -> Any:
         """Implement __call__ function for decorator.
 
         Args:
-            wrapped (callable): The wrapped function which in turns
+            wrapped: The wrapped function which in turns
                 needs to be called by your wrapper function.
-            instance (App): The object to which the wrapped
+            instance: The object to which the wrapped
                 function was bound when it was called.
-            args (list): The list of positional arguments supplied
+            args: The list of positional arguments supplied
                 when the decorated function was called.
-            kwargs (dict): The dictionary of keyword arguments
+            kwargs: The dictionary of keyword arguments
                 supplied when the decorated function was called.
 
         Returns:
             function: The custom decorator function.
         """
+        # using wrapped args to support typing hints in PyRight
+        wrapped: Callable = wrapped_args[0]
+        app: Any = wrapped_args[1]
+        args: list = wrapped_args[2] if len(wrapped_args) > 1 else []
+        kwargs: dict = wrapped_args[3] if len(wrapped_args) > 2 else {}
+
+        def fail() -> Any:
+            """Call the function and store or append return value."""
+            tcex = cast(TcEx, app.tcex)
 
-        def fail(app, *args, **kwargs):
-            """Call the function and store or append return value.
-
-            Args:
-                app (class): The instance of the App class "self".
-            """
             # call method to get output
             data = wrapped(*args, **kwargs)
 
             # self.enable (e.g., True or 'fail_on_false') enables/disables this feature
             enabled = self.fail_enabled
-            if not isinstance(enabled, bool):
+            if isinstance(enabled, str):
                 # get enabled value from App inputs
-                enabled = getattr(app.tcex.inputs.model, enabled)
+                enabled = getattr(tcex.inputs.model, enabled)
                 if not isinstance(enabled, bool):  # pragma: no cover
                     raise RuntimeError(
                         'The fail_enabled value must be a boolean or resolved to bool.'
                     )
-                app.tcex.log.debug(f'Fail enabled is {enabled} ({self.fail_enabled}).')
+                tcex.log.debug(f'Fail enabled is {enabled} ({self.fail_enabled}).')
 
             failed = False
             if enabled:
                 if isinstance(data, list):
                     # validate each value in the list of results.
                     for d in data:
                         if d in self.fail_on:
@@ -91,22 +105,23 @@
                             break
                 else:
                     if data in self.fail_on:
                         failed = True
 
                 if failed:
                     if self.write_output:
-                        app.tcex.playbook.output.process()
+                        tcex.app.playbook.output.process()
                         if hasattr(app, 'write_output'):
                             app.write_output()
                     app.exit_message = self.get_fail_msg(app)  # for test cases
-                    app.tcex.exit(ExitCode.FAILURE, self.get_fail_msg(app))
+                    tcex.exit.exit(ExitCode.FAILURE, self.get_fail_msg(app))
             return data
 
-        return fail(instance, *args, **kwargs)
+        return fail()
 
-    def get_fail_msg(self, app):
+    def get_fail_msg(self, app) -> str:
         """Return the appropriate fail message."""
         fail_msg = self.fail_msg
-        if self.fail_msg_property and hasattr(app, self.fail_msg_property):
-            fail_msg = getattr(app, self.fail_msg_property)
+        if isinstance(self.fail_msg_property, str):
+            if self.fail_msg_property and hasattr(app, self.fail_msg_property):
+                fail_msg = getattr(app, self.fail_msg_property)
         return fail_msg
```

### Comparing `tcex-3.0.9/tcex/decorators/on_exception.py` & `tcex-4.0.0/tcex/app/decorator/on_exception.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-"""App Decorators Module."""
+"""TcEx Framework Module"""
 # standard library
 import traceback
-from typing import Optional
+from collections.abc import Callable
+from typing import Any, cast
 
 # third-party
 import wrapt
 
 # first-party
 from tcex.exit import ExitCode
+from tcex.tcex import TcEx
 
 
 class OnException:
     """Set exit message on failed execution.
 
     This decorator will catch the generic "Exception" error, log the supplied error message, set
     the "exit_message", and exit the App with an exit code of 1.
@@ -32,63 +34,67 @@
             The value of this boolean will control enabling/disabling this feature.
         write_output (boolean): default True.
             If enabled, will call app.write_output() when an exception is raised.
     """
 
     def __init__(
         self,
-        exit_msg: Optional[str] = None,
-        exit_enabled: Optional[bool] = True,
-        write_output: Optional[bool] = True,
+        exit_msg: str | None = None,
+        exit_enabled: bool | str = True,
+        write_output: bool = True,
     ):
-        """Initialize Class properties"""
+        """Initialize instance properties"""
         self.exit_enabled = exit_enabled
         self.exit_msg = exit_msg or 'An exception has been caught. See the logs for more details.'
         self.write_output = write_output
 
     @wrapt.decorator
-    def __call__(self, wrapped, instance, args, kwargs):
+    def __call__(self, *wrapped_args) -> Any:
         """Implement __call__ function for decorator.
 
         Args:
-            wrapped (callable): The wrapped function which in turns
+            wrapped: The wrapped function which in turns
                 needs to be called by your wrapper function.
-            instance (App): The object to which the wrapped
+            instance: The object to which the wrapped
                 function was bound when it was called.
-            args (list): The list of positional arguments supplied
+            args: The list of positional arguments supplied
                 when the decorated function was called.
-            kwargs (dict): The dictionary of keyword arguments
+            kwargs: The dictionary of keyword arguments
                 supplied when the decorated function was called.
 
         Returns:
             function: The custom decorator function.
         """
+        # using wrapped args to support typing hints in PyRight
+        wrapped: Callable = wrapped_args[0]
+        app: Any = wrapped_args[1]
+        args: list = wrapped_args[2] if len(wrapped_args) > 1 else []
+        kwargs: dict = wrapped_args[3] if len(wrapped_args) > 2 else {}
+
+        def exception() -> Any:  # pylint: disable=inconsistent-return-statements
+            """Call the function and handle any exception."""
+            tcex = cast(TcEx, app.tcex)
 
-        def exception(app, *args, **kwargs):  # pylint: disable=inconsistent-return-statements
-            """Call the function and handle any exception.
-
-            Args:
-                app (class): The instance of the App class "self".
-            """
             # self.enable (e.g., True or 'fail_on_false') enables/disables this feature
             enabled = self.exit_enabled
             if not isinstance(self.exit_enabled, bool):
-                enabled = getattr(app.tcex.inputs.model, self.exit_enabled)
+                enabled = getattr(tcex.inputs.model, self.exit_enabled)
                 if not isinstance(enabled, bool):  # pragma: no cover
                     raise RuntimeError(
                         'The exit_enabled value must be a boolean or resolved to bool.'
                     )
-                app.log.debug(f'Fail enabled is {enabled} ({self.exit_enabled}).')
+                tcex.log.debug(f'Fail enabled is {enabled} ({self.exit_enabled}).')
 
             try:
                 return wrapped(*args, **kwargs)
             except Exception:
-                app.log.error(traceback.format_exc())
+                tcex.log.error(traceback.format_exc())
                 app.exit_message = self.exit_msg  # for test cases
                 if enabled:
                     if self.write_output:
-                        app.tcex.playbook.output.process()
+                        tcex.app.playbook.output.process()
                         if hasattr(app, 'write_output'):
                             app.write_output()
-                    app.tcex.exit(ExitCode.FAILURE, self.exit_msg)
+                    tcex.exit.exit(ExitCode.FAILURE, self.exit_msg)
+            return None
 
-        return exception(instance, *args, **kwargs)
+        return exception()
```

### Comparing `tcex-3.0.9/tcex/decorators/on_success.py` & `tcex-4.0.0/tcex/app/decorator/debug.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,55 +1,66 @@
-"""App Decorators Module."""
+"""TcEx Framework Module"""
+# standard library
+from collections.abc import Callable
+from typing import Any, cast
+
 # third-party
 import wrapt
 
+# first-party
+from tcex.tcex import TcEx
+
 
-class OnSuccess:
-    """Set exit message on successful execution.
+class Debug:
+    """Debug function inputs.
 
-    This decorator will set the supplied msg as the App "exit_message". Typically and App would
-    only have 1 exit message so this decorator would typically be used in App that used "actions".
+    This decorator will log the inputs to the function to assist in debugging an App.
 
     .. code-block:: python
         :linenos:
         :lineno-start: 1
 
-        @OnSuccess(exit_msg='Successfully processed JSON data.')
-        def my_method(json_data):
-            json.dumps(json_data)
-
-    Args:
-        exit_msg (str): The message to send to exit method.
+        @Debug()
+        def my_method(arg1, args2):
+            print(arg1, arg2)
     """
 
-    def __init__(self, exit_msg=None):
-        """Initialize Class properties"""
-        self.exit_msg = exit_msg or 'App finished successfully.'
-
     @wrapt.decorator
-    def __call__(self, wrapped, instance, args, kwargs):
+    def __call__(self, *wrapped_args) -> Any:
         """Implement __call__ function for decorator.
 
         Args:
-            wrapped (callable): The wrapped function which in turns
+            wrapped: The wrapped function which in turns
                 needs to be called by your wrapper function.
-            instance (App): The object to which the wrapped
+            instance: The object to which the wrapped
                 function was bound when it was called.
-            args (list): The list of positional arguments supplied
+            args: The list of positional arguments supplied
                 when the decorated function was called.
-            kwargs (dict): The dictionary of keyword arguments
+            kwargs: The dictionary of keyword arguments
                 supplied when the decorated function was called.
 
         Returns:
             function: The custom decorator function.
         """
+        # using wrapped args to support typing hints in PyRight
+        wrapped: Callable = wrapped_args[0]
+        app: Any = wrapped_args[1]
+        args: list = wrapped_args[2] if len(wrapped_args) > 1 else []
+        kwargs: dict = wrapped_args[3] if len(wrapped_args) > 2 else {}
 
-        def completion(app, *args, **kwargs):
-            """Call the function and handle any exception.
+        def debug() -> Any:
+            """Iterate over data, calling the decorated function for each value.
 
             Args:
                 app (class): The instance of the App class "self".
+                *args: Additional positional arguments.
+                **kwargs: Additional keyword arguments.
             """
-            app.exit_message = self.exit_msg
-            return wrapped(*args, **kwargs)
+            tcex = cast(TcEx, app.tcex)
+
+            data = wrapped(*args, **kwargs)
+            tcex.log.debug(
+                f'function: "{self.__class__.__name__}", args: "{args}", kwargs: "{kwargs}"'
+            )
+            return data
 
-        return completion(instance, *args, **kwargs)
+        return debug()
```

### Comparing `tcex-3.0.9/tcex/decorators/output.py` & `tcex-4.0.0/tcex/app/decorator/output.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,12 @@
-"""App Decorators Module."""
+"""TcEx Framework Module"""
+# standard library
+from collections.abc import Callable
+from typing import Any
+
 # third-party
 import wrapt
 
 
 class Output:
     """Store the method return value in self.<attribute>.
 
@@ -19,47 +23,51 @@
             self.output_strings = []  # Output decorator writes here.
 
         @Output(attribute='output_strings')
         def my_method(data):
             return data.lowercase()
 
     Args:
-        attribute (str): The name of the App attribute to write data.
-        overwrite (bool): When True and the method is called more than once the previous value
+        attribute: The name of the App attribute to write data.
+        overwrite: When True and the method is called more than once the previous value
             will be overwritten.
     """
 
-    def __init__(self, attribute, overwrite=False):
-        """Initialize Class properties"""
+    def __init__(self, attribute: str, overwrite: bool = False):
+        """Initialize instance properties"""
         self.attribute = attribute
         self.overwrite = overwrite
 
     @wrapt.decorator
-    def __call__(self, wrapped, instance, args, kwargs):
+    def __call__(self, *wrapped_args) -> Any:
         """Implement __call__ function for decorator.
 
         Args:
-            wrapped (callable): The wrapped function which in turns
+            wrapped: The wrapped function which in turns
                 needs to be called by your wrapper function.
-            instance (App): The object to which the wrapped
+            instance: The object to which the wrapped
                 function was bound when it was called.
-            args (list): The list of positional arguments supplied
+            args: The list of positional arguments supplied
                 when the decorated function was called.
-            kwargs (dict): The dictionary of keyword arguments
+            kwargs: The dictionary of keyword arguments
                 supplied when the decorated function was called.
-
-        Returns:
-            function: The custom decorator function.
         """
+        # using wrapped args to support typing hints in PyRight
+        wrapped: Callable = wrapped_args[0]
+        app: Any = wrapped_args[1]
+        args: list = wrapped_args[2] if len(wrapped_args) > 1 else []
+        kwargs: dict = wrapped_args[3] if len(wrapped_args) > 2 else {}
 
-        def output(app, *args, **kwargs):
+        def output() -> Any:
             """Call the function and store or append return value.
 
             Args:
                 app (class): The instance of the App class "self".
+                *args: Additional positional arguments.
+                **kwargs: Additional keyword arguments.
             """
             data = wrapped(*args, **kwargs)
             attr = getattr(app, self.attribute)
 
             # tracker to indicate see if attribute has already been updated
             attr_tracker_name = f'__{self.attribute}_tracker__'
             attr_tracker = False
@@ -87,8 +95,8 @@
                 setattr(app, self.attribute, data)
 
             # update tracker to indicate the attribute has already been set at least once
             setattr(app, attr_tracker_name, True)
 
             return data
 
-        return output(instance, *args, **kwargs)
+        return output()
```

### Comparing `tcex-3.0.9/tcex/exit/error_codes.py` & `tcex-4.0.0/tcex/exit/error_code.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-"""TcExErrorCodes class and handle_error function."""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import Optional
 
 # first-party
+from tcex.logger.trace_logger import TraceLogger
 from tcex.pleb.singleton import Singleton
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
-class TcExErrorCodes(metaclass=Singleton):
+class TcExErrorCode(metaclass=Singleton):
     """TcEx Framework Error Codes."""
 
     @property
     def errors(self):
         """Return TcEx defined error codes and messages.
 
         .. note:: RuntimeErrors with a code of >= 10000 are considered critical.  Those < 10000
@@ -44,20 +44,20 @@
             590: 'No hash values provided.',
             # threat intelligence
             600: 'Failed adding group type "{}" with name "{}" ({}).',
             605: 'Failed adding attribute type "{}" with value "{}" to group id "{}" ({}).',
             610: 'Failed adding label "{}" to group id "{}" ({}).',
             615: 'Failed adding tag "{}" to group id "{}" ({}).',
             650: 'Failed adding label "{}" to attribute id "{}" ({}).',
-            # metrics
+            # metric
             700: 'Failed to create metric. API status code: {}, API message: {}.',
             705: 'Error while finding metric by name. API status code: {}, API message: {}.',
             710: 'Failed to add metric data. API status code: {}, API message: {}.',
             715: 'No metric ID found for "{}".',
-            # notifications
+            # notification
             750: 'Failed to send notification. API status code: {}, API message: {}.',
             # datastore
             800: 'Failed to create index. API status code: {}, API message: {}.',
             805: 'Failed to {} record data. API status code: {}, API message: {}.',
             # threat intelligence module
             905: 'Error during update. {} does not have a unique_id set and cannot be updated.',
             910: 'Error during get. {} does not have a unique_id set and cannot be fetched.',
@@ -75,39 +75,39 @@
             10500: 'Critical batch error ({}).',
             10505: 'Failed submitting batch job requests ({}).',
             10510: 'Failed submitting batch job requests. API status code: {}, API message: {}.',
             10520: 'Failed submitting batch data ({}).',
             10525: 'Failed submitting batch data. API status code: {}, API message: {}.',
         }
 
-    def message(self, code):
+    def message(self, code: int) -> str:
         """Return the error message.
 
         Args:
             code (integer): The error code integer.
 
         Returns:
             (string): The error message.
         """
-        return self.errors.get(code)
+        try:
+            return self.errors[code]
+        except KeyError:
+            raise RuntimeError(100, 'Generic Failure, invalid error code provided.')
 
 
 def handle_error(
     code: int,
-    message_values: Optional[list] = None,
-    raise_error: Optional[bool] = True,
-    cause: Optional[Exception] = None,
+    message_values: list | None = None,
+    raise_error: bool = True,
+    cause: Exception | None = None,
 ):
     """Log a defined error and optionally raises a RuntimeError."""
-    try:
-        if message_values is None:
-            message_values = []
-        message = TcExErrorCodes().message(code).format(*message_values)
-        logger.error(f'Error code: {code}, {message}')
-        if raise_error:
-            raise RuntimeError(code, message) from cause
-    except AttributeError:
-        logger.error(f'Incorrect error code provided ({code}).')
-        raise RuntimeError(100, 'Generic Failure, see logs for more details.') from cause
-    except IndexError:
-        logger.error(f'Incorrect message values provided for error code {code} ({message_values}).')
+    message_values = message_values or []
+    message = TcExErrorCode().message(code)
+    if message is None:
+        _logger.error(f'Incorrect error code provided ({code}).')
         raise RuntimeError(100, 'Generic Failure, see logs for more details.') from cause
+
+    message = message.format(*message_values)
+    _logger.error(f'Error code: {code}, {message}')
+    if raise_error:
+        raise RuntimeError(code, message) from cause
```

### Comparing `tcex-3.0.9/tcex/exit/exit.py` & `tcex-4.0.0/tcex/exit/exit.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,86 +1,144 @@
-"""TcEx Exit Module"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import os
 import sys
 from enum import Enum
-from typing import Optional, Union
+from pathlib import Path
+from typing import TYPE_CHECKING, Literal, NoReturn
 
 # first-party
-from tcex.app_config import InstallJson
-from tcex.pleb.registry import registry
+from tcex.app.config import InstallJson
+from tcex.logger.trace_logger import TraceLogger
+from tcex.registry import registry
+
+if TYPE_CHECKING:
+    # first-party
+    from tcex.input.input import Input  # CIRCULAR-IMPORT
+
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
+
+
+EXIT_CODES = Literal[0, 1, 3, 4]
 
 
 class ExitCode(int, Enum):
     """Valid exit codes for a ThreatConnect app.
 
-    Note not all exit codes are valid for all app types: partial failure is not valid for playbook
-    apps.
+    Note not all exit codes are valid for all app types:
+    partial failure is not valid for playbook apps.
     """
 
     SUCCESS = 0
     FAILURE = 1
     PARTIAL_FAILURE = 3
     HARD_FAILURE = 4
 
     def __str__(self):
         """@cblades"""
         clean_name = self.name.replace('_', ' ').title()
         return f'{self.value} ({clean_name})'
 
 
-class ExitService:
+class Exit:
     """Provides functionality around exiting an app."""
 
-    def __init__(self, inputs):
-        """."""
+    def __init__(self, inputs: 'Input'):
+        """Initialize instance properties."""
         self.ij = InstallJson()
         self.inputs = inputs
 
+        # properties
         self._exit_code = ExitCode.SUCCESS
+        self._message = None
+        self.log = _logger
+
+    def _aot_rpush(self, exit_code: int):
+        """Push message to AOT action channel."""
+        if self.inputs.contents.get('tc_playbook_db_type') == 'Redis':
+            try:
+                # pylint: disable=no-member
+                registry.redis_client.rpush(self.inputs.contents['tc_exit_channel'], exit_code)
+            except Exception as e:  # pragma: no cover
+                self._exit(ExitCode.FAILURE, f'Exception during AOT exit push ({e}).')
+
+    def _exit(self, code: ExitCode | int, msg: str) -> NoReturn:
+        """Exit the App"""
+        code = ExitCode(code) if code is not None else self.code
+
+        # handle exit msg logging
+        self._exit_msg_handler(code, msg)
+
+        self.log.info(f'exit-code={code}')
+        sys.exit(code.value)
+
+    def _message_tc(self, message: str, max_length: int = 255):
+        """Write data to message_tc file in TcEX specified directory.
+
+        This method is used to set and exit message in the ThreatConnect Platform.
+        ThreatConnect only supports files of max_message_length.  Any data exceeding
+        this limit will be truncated. The last <max_length> characters will be preserved.
+
+        Args:
+            message: The message to add to message_tc file
+            max_length: The maximum length of an exit message. Defaults to 255.
+        """
+        if not isinstance(message, str):
+            message = str(message)
+
+        if os.access(self.inputs.model_tc.tc_out_path, os.W_OK):
+            message_file = self.inputs.model_tc.tc_out_path / 'message.tc'
+        else:
+            message_file = Path('message.tc')
+
+        if not message.endswith('\n'):
+            message += '\n'
+        with message_file.open('w') as mh:
+            # write last <max_length> characters to file
+            mh.write(message[-max_length:])
 
     @property
-    def exit_code(self) -> 'ExitCode':
+    def code(self) -> ExitCode:
         """Get exit code."""
         return self._exit_code
 
-    @exit_code.setter
-    def exit_code(self, exit_code: Union[ExitCode, int]):
+    @code.setter
+    def code(self, exit_code: ExitCode | int):
         """Set exit code.
 
         Will automatically change partial failure to success if app is a playbook app.
 
         Args:
             exit_code: the new exit code.
         """
         exit_code = ExitCode(exit_code)
         if exit_code == ExitCode.PARTIAL_FAILURE and self.ij.model.is_playbook_app:
-            logger.info(
+            self.log.info(
                 f'Changing exit code from {ExitCode.PARTIAL_FAILURE} '
                 f'to {ExitCode.SUCCESS} for Playbook App.'
             )
             exit_code = ExitCode.SUCCESS
         self._exit_code = exit_code
 
-    def exit(self, code: Optional[Union[ExitCode, int]] = None, msg: Optional[str] = None):
+    def exit(self, code: ExitCode | int | None = None, msg: str | None = None) -> NoReturn:
         """Application exit method with proper exit code
 
         The method will run the Python standard sys.exit() with the exit code
         previously defined via :py:meth:`~tcex.tcex.TcEx.exit_code` or provided
         during the call of this method.
 
         Args:
             code: The exit code value for the app.
             msg: A message to log and add to message tc output.
         """
-        code = ExitCode(code) if code is not None else self.exit_code
+        code = ExitCode(code) if code is not None else self.code
+        msg = msg if msg is not None else ''
 
         # playbook exit handler
         if self.ij.model.is_playbook_app:
             self.exit_playbook_handler(msg)
 
         # aot notify
         if 'tc_aot_enabled' in self.inputs.contents and self.inputs.contents.get('tc_aot_enabled'):
@@ -90,97 +148,64 @@
         # exit token renewal thread
         if not self.ij.is_external_app:
             registry.token.shutdown = True
 
         # exit
         self._exit(code, msg)
 
-    def _exit(self, code: int, msg: str):
-        """Exit the App"""
-        # handle exit msg logging
-        self._exit_msg_handler(code, msg)
-
-        logger.info(f'exit-code={code}')
-        sys.exit(code.value)
-
     # TODO: [med] @cblades - is msg required?
     # pylint: disable=unused-argument
-    def exit_aot_terminate(
-        self, code: Optional[Union[ExitCode, int]] = None, msg: Optional[str] = None
-    ):
+    def exit_aot_terminate(self, code: ExitCode | int | None = None, msg: str | None = None):
         """Application exit method with proper exit code only for AOT.
 
         The method will run the Python standard sys.exit() with the exit code
         previously defined via :py:meth:`~tcex.tcex.TcEx.exit_code` or provided
         during the call of this method.
 
         Args:
             code: The exit code value for the app.
             msg: A message to log and add to message tc output.
         """
-        code = ExitCode(code) if code is not None else self.exit_code
+        code = ExitCode(code) if code is not None else self.code
+        msg = msg if msg is not None else self.message
 
         # aot notify
         if 'tc_aot_enabled' in self.inputs.contents and self.inputs.contents.get('tc_aot_enabled'):
             # push exit message
             self._aot_rpush(code.value)
 
-        logger.info(f'exit-code={code}')
+        self.log.info(f'exit-code={code}')
         sys.exit(code)
 
+    def _exit_msg_handler(self, code: ExitCode, msg: str):
+        """Handle exit message. Write to both log and message_tc."""
+        if msg is not None:
+            log_msg = msg.replace('\n', ',')
+            if code in [ExitCode.SUCCESS, ExitCode.PARTIAL_FAILURE]:
+                self.log.info(f'exit-message="{log_msg}"')
+            else:
+                self.log.error(f'exit-message="{log_msg}"')
+            self._message_tc(msg)
+
     def exit_playbook_handler(self, msg: str):
         """Perform special action for PB Apps before exit."""
         # write outputs before exiting
         registry.playbook.output.process()  # pylint: disable=no-member
 
         # required only for tcex testing framework
         if (
-            hasattr(self.inputs.model_unresolved, 'tcex_testing_context')
-            and self.inputs.model_unresolved.tcex_testing_context is not None
+            hasattr(self.inputs.model_tc, 'tcex_testing_context')
+            and self.inputs.model_tc.tcex_testing_context is not None
         ):  # pragma: no cover
             registry.redis_client.hset(  # pylint: disable=no-member
-                self.inputs.model_unresolved.tcex_testing_context, '_exit_message', msg
+                self.inputs.model_tc.tcex_testing_context, '_exit_message', msg
             )
 
-    def _exit_msg_handler(self, code: ExitCode, msg: str):
-        """Handle exit message. Write to both log and message_tc."""
-        if msg is not None:
-            log_msg = msg.replace('\n', ',')
-            if code in [ExitCode.SUCCESS, ExitCode.PARTIAL_FAILURE]:
-                logger.info(f'exit-message="{log_msg}"')
-            else:
-                logger.error(f'exit-message="{log_msg}"')
-            self._message_tc(msg)
-
-    def _aot_rpush(self, exit_code: int):
-        """Push message to AOT action channel."""
-        if self.inputs.contents.get('tc_playbook_db_type') == 'Redis':
-            try:
-                # pylint: disable=no-member
-                registry.redis_client.rpush(self.inputs.contents.get('tc_exit_channel'), exit_code)
-            except Exception as e:  # pragma: no cover
-                self._exit(ExitCode.FAILURE, f'Exception during AOT exit push ({e}).')
-
-    def _message_tc(self, message: str, max_length: Optional[int] = 255):
-        """Write data to message_tc file in TcEX specified directory.
-
-        This method is used to set and exit message in the ThreatConnect Platform.
-        ThreatConnect only supports files of max_message_length.  Any data exceeding
-        this limit will be truncated. The last <max_length> characters will be preserved.
-
-        Args:
-            message: The message to add to message_tc file
-            max_length: The maximum length of an exit message. Defaults to 255.
-        """
-        if not isinstance(message, str):
-            message = str(message)
-
-        if os.access(self.inputs.contents.get('tc_out_path'), os.W_OK):
-            message_file = os.path.join(self.inputs.contents.get('tc_out_path'), 'message.tc')
-        else:
-            message_file = 'message.tc'
+    @property
+    def message(self) -> str:
+        """Get exit code."""
+        return self._message or ''
 
-        if not message.endswith('\n'):
-            message += '\n'
-        with open(message_file, 'w') as mh:
-            # write last <max_length> characters to file
-            mh.write(message[-max_length:])
+    @message.setter
+    def message(self, message: str):
+        """Set exit message."""
+        self._message = message
```

### Comparing `tcex-3.0.9/tcex/input/field_types/binary.py` & `tcex-4.0.0/tcex/input/field_type/string.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,107 +1,104 @@
-"""Binary Field Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Callable, Union
+import re
+from collections.abc import Generator
+
+# third-party
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.input.field_types.exception import (
+from tcex.input.field_type.exception import (
     InvalidEmptyValue,
     InvalidLengthValue,
+    InvalidPatternValue,
     InvalidType,
-    InvalidVariableType,
 )
 
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
-
-    # first-party
-    from tcex.input.input import BinaryVariable
 
-
-class Binary(bytes):
-    """Binary Field Type"""
+class String(str):
+    """String Field Type"""
 
     allow_empty: bool = True
-    max_length: int = None
-    min_length: int = None
+    max_length: int | None = None
+    min_length: int | None = None
+    regex: str | None = None
     strip: bool = False
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Run validators / modifiers on input."""
-        yield cls.validate_variable_type
         yield cls.validate_type
         yield cls.validate_strip
         yield cls.validate_allow_empty
         yield cls.validate_max_length
         yield cls.validate_min_length
+        yield cls.validate_regex
 
     @classmethod
-    def validate_allow_empty(
-        cls, value: Union[bytes, 'BinaryVariable'], field: 'ModelField'
-    ) -> 'bytes':
+    def validate_allow_empty(cls, value: str, field: ModelField) -> str:
         """Raise exception if value is empty and allow_empty is False."""
-        if cls.allow_empty is False and value == b'':
-            raise InvalidEmptyValue(field_name=field.name)
+        if cls.allow_empty is False:
+            if isinstance(value, str) and value == '':
+                raise InvalidEmptyValue(field_name=field.name)
+
         return value
 
     @classmethod
-    def validate_max_length(cls, value: Union[str, 'BinaryVariable'], field: 'ModelField') -> str:
+    def validate_max_length(cls, value: str, field: ModelField) -> str:
         """Raise exception if value does not match pattern."""
         if cls.max_length is not None and len(value) > cls.max_length:
             raise InvalidLengthValue(
                 field_name=field.name, constraint=cls.max_length, operation='max'
             )
         return value
 
     @classmethod
-    def validate_min_length(cls, value: Union[str, 'BinaryVariable'], field: 'ModelField') -> str:
+    def validate_min_length(cls, value: str, field: ModelField) -> str:
         """Raise exception if value does not match pattern."""
         if cls.min_length is not None and len(value) < cls.min_length:
             raise InvalidLengthValue(
                 field_name=field.name, constraint=cls.min_length, operation='min'
             )
         return value
 
     @classmethod
-    def validate_strip(cls, value: Union[bytes, 'BinaryVariable']) -> bytes:
-        """Raise exception if value is not a Binary type."""
-        if value is not None and cls.strip is True:
-            value = value.strip()
+    def validate_regex(cls, value: str, field: ModelField) -> str:
+        """Raise exception if value does not match pattern."""
+        if isinstance(cls.regex, str):
+            if not re.compile(cls.regex).match(value):
+                raise InvalidPatternValue(field_name=field.name, pattern=cls.regex)
         return value
 
     @classmethod
-    def validate_type(cls, value: Union[bytes, 'BinaryVariable'], field: 'ModelField') -> bytes:
+    def validate_strip(cls, value: str) -> str:
         """Raise exception if value is not a Binary type."""
-        if not isinstance(value, bytes):
-            raise InvalidType(
-                field_name=field.name, expected_types='(str)', provided_type=type(value)
-            )
+        if cls.strip is True:
+            value = value.strip()
         return value
 
     @classmethod
-    def validate_variable_type(
-        cls, value: Union[bytes, 'BinaryVariable'], field: 'ModelField'
-    ) -> bytes:
-        """Raise exception if value is not a Binary type."""
-        if hasattr(value, '_variable_type') and value._variable_type != 'Binary':
-            raise InvalidVariableType(
-                field_name=field.name, expected_type='Binary', provided_type=value._variable_type
+    def validate_type(cls, value: str, field: ModelField) -> str:
+        """Raise exception if value is not a String type."""
+        if not isinstance(value, str):
+            raise InvalidType(
+                field_name=field.name, expected_types='(str)', provided_type=type(value)
             )
         return value
 
 
-def binary(
+def string(
     allow_empty: bool = True,
-    min_length: int = None,
-    max_length: int = None,
+    max_length: int | None = None,
+    min_length: int | None = None,
+    regex: str | None = None,
     strip: bool = False,
-) -> type:
-    """Return customized Binary type."""
-    namespace = dict(
-        allow_empty=allow_empty,
-        max_length=max_length,
-        min_length=min_length,
-        strip=strip,
-    )
-    return type('CustomizedBinary', (Binary,), namespace)
+) -> type[String]:
+    """Return configured instance of String."""
+    namespace = {
+        'allow_empty': allow_empty,
+        'max_length': max_length,
+        'min_length': min_length,
+        'regex': regex,
+        'strip': strip,
+    }
+    return type('ConstrainedString', (String,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/case_management_entity.py` & `tcex-4.0.0/tcex/input/field_type/case_management_entity.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,85 +1,65 @@
-"""Indicator Entity Field (Model) Type"""
+"""TcEx Framework Module"""
+
 # standard library
-from typing import TYPE_CHECKING, List
+from typing import ClassVar
 
 # third-party
-from pydantic import validator
+from pydantic import create_model, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidEntityType
-from tcex.input.field_types.tc_entity import TCEntity
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidEntityType
+from tcex.input.field_type.tc_entity import TCEntity
 
 CASE_MANAGEMENT_TYPES = [
     'artifact',
     'case',
     'task',
     'artifact type',
     'notes',
     'workflow event',
     'workflow template',
 ]
 
 
-# pylint: disable=no-self-argument, no-self-use
+# pylint: disable=no-self-argument
 class CaseManagementEntity(TCEntity):
     """Case Management Entity Field (Model) Type"""
 
-    @validator('type')
-    def is_empty(cls, value: str, field: 'ModelField') -> str:
+    case_management_types: ClassVar[list[str]] = CASE_MANAGEMENT_TYPES
+
+    @validator('type', allow_reuse=True)
+    def is_empty(cls, value: str, field: ModelField) -> str:
         """Validate that the value is a non-empty string."""
         if isinstance(value, str) and value.replace(' ', '') == '':
             raise InvalidEmptyValue(field_name=field.name)
         return value
 
-    @validator('type')
-    def is_type(cls, value: str, field: 'ModelField') -> str:
+    @validator('type', allow_reuse=True)
+    def is_type(cls, value: str, field: ModelField) -> str:
         """Validate that the entity is of Indicator type."""
-        if value.lower() not in CASE_MANAGEMENT_TYPES:
+        if value.lower() not in [i.lower() for i in cls.case_management_types]:
             raise InvalidEntityType(
-                field_name=field.name, entity_type='CaseManagement', value=value
+                field_name=field.name, entity_type=str(cls.case_management_types), value=value
             )
         return value
 
 
-def case_management_entity(case_management_types: List[str] = None) -> type:
-    """Return custom model for Case Management Entity."""
-
-    class CustomCaseManagementEntity(CaseManagementEntity):
-        """Indicator Entity Field (Model) Type"""
-
-        @validator('type', allow_reuse=True)
-        def is_empty(cls, value: str, field: 'ModelField') -> str:
-            """Validate that the value is a non-empty string."""
-            if isinstance(value, str) and value.replace(' ', '') == '':
-                raise InvalidEmptyValue(field_name=field.name)
-            return value
-
-        @validator('type', allow_reuse=True)
-        def is_type(cls, value: str, field: 'ModelField') -> str:
-            """Validate that the entity is of a specific Indicator type."""
-            if value.lower() not in [i.lower() for i in case_management_types]:
-                raise InvalidEntityType(
-                    field_name=field.name, entity_type=str(case_management_types), value=value
-                )
-            return value
-
-    return CustomCaseManagementEntity
-
-
-ArtifactEntity: CaseManagementEntity = case_management_entity(case_management_types=['Artifact'])
-CaseEntity: CaseManagementEntity = case_management_entity(case_management_types=['Case'])
-TaskEntity: CaseManagementEntity = case_management_entity(case_management_types=['Task'])
-ArtifactTypeEntity: CaseManagementEntity = case_management_entity(
-    case_management_types=['Artifact Type']
-)
-NoteEntity: CaseManagementEntity = case_management_entity(case_management_types=['Note'])
-WorkflowEventEntity: CaseManagementEntity = case_management_entity(
-    case_management_types=['Workflow Event']
-)
-WorkflowTemplateEntity: CaseManagementEntity = case_management_entity(
-    case_management_types=['Workflow Template']
-)
+def case_management_entity(
+    case_management_types: list[str], model_name: str = 'CustomCaseManagementEntity'
+) -> type[CaseManagementEntity]:
+    """Dynamically create a Case Management Entity model."""
+    return create_model(
+        model_name,
+        case_management_types=(ClassVar[list[str]], case_management_types),
+        __base__=CaseManagementEntity,
+    )
+
+
+ArtifactEntity = case_management_entity(case_management_types=['Artifact'])
+CaseEntity = case_management_entity(case_management_types=['Case'])
+TaskEntity = case_management_entity(case_management_types=['Task'])
+ArtifactTypeEntity = case_management_entity(case_management_types=['Artifact Type'])
+NoteEntity = case_management_entity(case_management_types=['Note'])
+WorkflowEventEntity = case_management_entity(case_management_types=['Workflow Event'])
+WorkflowTemplateEntity = case_management_entity(case_management_types=['Workflow Template'])
```

### Comparing `tcex-3.0.9/tcex/input/field_types/choice.py` & `tcex-4.0.0/tcex/input/field_type/choice.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,46 +1,47 @@
-"""Choice Field Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Callable, Dict, Optional
+from collections.abc import Generator
 
 # first-party
-from tcex.input.field_types.edit_choice import EditChoice
-from tcex.input.field_types.exception import InvalidInput
+from tcex.input.field_type.edit_choice import EditChoice
+from tcex.input.field_type.exception import InvalidInput
 
 
 class Choice(EditChoice):
     """Choice Field Type"""
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Run validators / modifiers on input."""
         yield from super().__get_validators__()
         yield cls.modifier_select
 
     @classmethod
-    def modifier_select(cls, value: str, field) -> str:
+    def modifier_select(cls, value: str, field) -> str | None:
         """Modify value if -- Select -- option is selected.
 
         Job Apps: If not selection None is sent.
         PB Apps: '-- Select --' has to be added to validValues by developer.
         """
-        if value == '-- Select --':
+        _value = value
+        if _value == '-- Select --':
             if field.allow_none is False:
-                raise InvalidInput(field.name, f'{value} is not a valid choice.')
-            value = None
+                raise InvalidInput(field.name, f'{_value} is not a valid choice.')
+            _value = None
 
-        return value
+        return _value
 
 
-def choice(value_transformations: Optional[Dict[str, str]] = None) -> type:
+def choice(value_transformations: dict[str, str] | None = None) -> type[Choice]:
     """Return configured instance of String.
 
     :param value_transformations: dictionary that dictates how a choice should be transformed.
     Dictionary keys should be the field's valid values as defined in the install.json. Example:
 
     value_transformations: {'my_choice': 'My Choice'}
 
     If this field were to be initialized with 'my_choice', then the final value found in the input
     model would be 'My Choice'.
     """
-    namespace = dict(_value_transformations=value_transformations)
+    namespace = {'_value_transformations': value_transformations}
     return type('CustomChoice', (Choice,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/datetime.py` & `tcex-4.0.0/tcex/input/field_type/datetime.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-"""Datetime (Arrow) Field Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Any, Callable
+from collections.abc import Generator
+from typing import Any
 
 # third-party
 import arrow
+from pydantic.fields import ModelField
 
 # first-party
-from tcex.input.field_types.exception import InvalidInput
-from tcex.utils import Utils
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.input.field_type.exception import InvalidInput
+from tcex.util import Util
 
 
 class DateTime(arrow.Arrow):
     """Datetime (Arrow) Field Type"""
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Define one or more validators for Pydantic custom type."""
         yield cls._validate
 
     @classmethod
-    def _validate(cls, value: Any, field: 'ModelField') -> 'arrow.Arrow':
+    def _validate(cls, value: Any, field: ModelField) -> arrow.Arrow:
         """Pydantic validate method."""
         try:
-            return Utils.any_to_datetime(value)
+            return Util.any_to_datetime(value)
         except RuntimeError as ex:
             raise InvalidInput(field_name=field.name, error=str(ex)) from ex
```

### Comparing `tcex-3.0.9/tcex/input/field_types/edit_choice.py` & `tcex-4.0.0/tcex/input/field_type/edit_choice.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,21 +1,19 @@
-"""Valid Values Field Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Callable, Dict, Optional
+from collections.abc import Generator
+
+# third-party
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
-from tcex.app_config.install_json import InstallJson
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidInput, InvalidType
-from tcex.pleb.none_model import NoneModel
-from tcex.pleb.registry import registry
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
+from tcex.app.config.install_json import InstallJson
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidInput, InvalidType
+from tcex.registry import registry
 
 
 class EditChoice(str):
     """EditChoice Field Type
 
     Used for Apps Param types:
     * EditChoice (pre-defined values)
@@ -25,52 +23,53 @@
     * EditChoice (dynamic values supported)
     """
 
     _allow_additional = False
     _value_transformations = None
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Run validators / modifiers on input."""
         yield cls.validate_type
         yield cls.modifier_strip
         yield cls.validate_valid_values
 
     @classmethod
     def modifier_strip(cls, value: str) -> str:
         """Modify value, stripping whitespace."""
         return value.strip()
 
     @classmethod
-    def validate_type(cls, value: str, field: 'ModelField') -> str:
+    def validate_type(cls, value: str, field: ModelField) -> str:
         """Raise exception if value is not a String type."""
         if not isinstance(value, str):
             raise InvalidType(
                 field_name=field.name, expected_types='(str)', provided_type=type(value)
             )
         return value
 
     @classmethod
-    def validate_valid_values(cls, value: str, field: 'ModelField') -> str:
+    def validate_valid_values(cls, value: str, field: ModelField) -> str:
         """Raise exception if value is not a String type."""
         if value == '':
             raise InvalidEmptyValue(field.name)
 
         ij = InstallJson()
         param = ij.model.get_param(field.name)
 
         # TODO: [high] figure out a better way ...
-        if isinstance(param, NoneModel):
+        if param is None:
             # for a multichoice input field, pydantic prefixes the name with an underscore,
             # this breaks the lookup based on the "name" field in the install.json. Strip
             # the underscore to get the correct param name.
             param = ij.model.get_param(field.name.lstrip('_'))
 
-        ti_utils = ThreatIntelUtils(registry.session_tc)
-        _valid_values = ti_utils.resolve_variables(param.valid_values or [])
+        ti_utils = ThreatIntelUtil(registry.session_tc)
+        valid_values = [] if param is None else param.valid_values
+        _valid_values = ti_utils.resolve_variables(valid_values)
         for vv in _valid_values:
             if vv.lower() == value.lower():
                 value = vv
                 break
         else:
             if cls._allow_additional is False:
                 raise InvalidInput(
@@ -81,26 +80,26 @@
         if isinstance(cls._value_transformations, dict):
             value = cls._value_transformations.get(value, value)
 
         return value
 
 
 def edit_choice(
-    allow_additional: bool = False, value_transformations: Optional[Dict[str, str]] = None
-) -> type:
+    allow_additional: bool = False, value_transformations: dict[str, str] | None = None
+) -> type[EditChoice]:
     """Return configured instance of String.
 
     :param allow_additional: Denotes whether this field will allow values that are not found in
     the field's valid values list in the install.json.
     :param value_transformations: dictionary that dictates how a choice should be transformed.
     Dictionary keys should be the field's valid values as defined in the install.json. Example:
 
     value_transformations: {'my_choice': 'My Choice'}
 
     If this field were to be initialized with 'my_choice', then the final value found in the input
     model would be 'My Choice'.
     """
-    namespace = dict(
-        _value_transformations=value_transformations,
-        _allow_additional=allow_additional,
-    )
+    namespace = {
+        '_value_transformations': value_transformations,
+        '_allow_additional': allow_additional,
+    }
     return type('CustomEditChoice', (EditChoice,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/exception.py` & `tcex-4.0.0/tcex/input/field_type/exception.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,32 +1,35 @@
-"""Field type exception classes"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 
+# first-party
+from tcex.logger.trace_logger import TraceLogger
+
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class BaseValueError(ValueError):
     """Raise customized exception."""
 
     def __init__(self, field_name: str, message: str):
         """Customize the exception message."""
-        # when using Union this logs for each type that's doesn't match
-        logger.trace(f'Checking value for field {field_name}: {message}')
+        # when a union of types are provided, this logs for each type that's doesn't match
+        _logger.trace(f'Checking value for field {field_name}: {message}')
         super().__init__(message)
 
 
 class BaseTypeError(TypeError):
     """Raise customized exception."""
 
     def __init__(self, field_name: str, message: str):
         """Customize the exception message."""
-        # when using Union this logs for each type that's doesn't match
-        logger.trace(f'Checking type for field {field_name}: {message}')
+        # when a union of types are provided, this logs for each type that's doesn't match
+        _logger.trace(f'Checking type for field {field_name}: {message}')
         super().__init__(message)
 
 
 class InvalidEmptyValue(BaseValueError):
     """Raise customized exception."""
 
     def __init__(self, field_name: str):
```

### Comparing `tcex-3.0.9/tcex/input/field_types/group_entity.py` & `tcex-4.0.0/tcex/input/field_type/group_entity.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,73 +1,66 @@
-"""Group Entity Field (Model) Type"""
+"""TcEx Framework Module"""
+
 # standard library
-from typing import TYPE_CHECKING, Dict, List
+from typing import ClassVar
 
 # third-party
-from pydantic import validator
+from pydantic import create_model, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidEntityType
-from tcex.input.field_types.tc_entity import TCEntity
-from tcex.pleb.registry import registry
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidEntityType
+from tcex.input.field_type.tc_entity import TCEntity
+from tcex.registry import registry
 
 
-# pylint: disable=no-self-argument, no-self-use
+# pylint: disable=no-self-argument
 class GroupEntity(TCEntity):
     """Group Entity Field (Model) Type"""
 
-    @validator('type')
-    def is_type(cls, value: str, field: 'ModelField') -> str:
-        """Validate that the value is a non-empty string.
+    group_types: ClassVar[list[str]] = []
 
-        Without the always and pre args, None values will validated before this validator is called.
-        """
+    @validator('type', allow_reuse=True)
+    def is_empty(cls, value: str, field: ModelField) -> str:
+        """Validate that the value is a non-empty string."""
         if isinstance(value, str) and value.replace(' ', '') == '':
             raise InvalidEmptyValue(field_name=field.name)
-
-        ti_utils = ThreatIntelUtils(session_tc=registry.session_tc)
-        if value not in ti_utils.group_types:
-            raise InvalidEntityType(field_name=field.name, entity_type='Group', value=value)
         return value
 
+    @validator('type', allow_reuse=True)
+    def is_type(cls, value: str, field: ModelField) -> str:
+        """Validate that the value is a non-empty string.
 
-def group_entity(group_types: List[str] = None) -> type:
-    """Return custom model for Group Entity."""
+        Without the always and pre args, None values will validated before this validator is called.
+        """
+        ti_utils = ThreatIntelUtil(session_tc=registry.session_tc)
+        group_types = cls.group_types or ti_utils.group_types
+        if value.lower() not in [i.lower() for i in group_types]:
+            raise InvalidEntityType(
+                field_name=field.name, entity_type=str(group_types), value=value
+            )
+        return value
 
-    class CustomGroupEntity(GroupEntity):
-        """Group Entity Field (Model) Type"""
 
-        @validator('type', allow_reuse=True)
-        def is_empty(cls, value: str, field: 'ModelField') -> Dict[str, str]:
-            """Validate that the value is a non-empty string."""
-            if isinstance(value, str) and value.replace(' ', '') == '':
-                raise InvalidEmptyValue(field_name=field.name)
-            return value
-
-        @validator('type', allow_reuse=True)
-        def is_type(cls, value: str, field: 'ModelField') -> Dict[str, str]:
-            """Validate that the entity is of a specific Group type."""
-            if value.lower() not in [i.lower() for i in group_types]:
-                raise InvalidEntityType(
-                    field_name=field.name, entity_type=str(group_types), value=value
-                )
-            return value
-
-    return CustomGroupEntity
-
-
-AdversaryEntity: GroupEntity = group_entity(group_types=['Adversary'])
-CampaignEntity: GroupEntity = group_entity(group_types=['Campaign'])
-DocumentEntity: GroupEntity = group_entity(group_types=['Document'])
-EmailEntity: GroupEntity = group_entity(group_types=['Email'])
-EventEntity: GroupEntity = group_entity(group_types=['Event'])
-IncidentEntity: GroupEntity = group_entity(group_types=['Incident'])
-IntrusionSetEntity: GroupEntity = group_entity(group_types=['Intrusion Set'])
-SignatureEntity: GroupEntity = group_entity(group_types=['Signature'])
-ReportEntity: GroupEntity = group_entity(group_types=['Report'])
-ThreatEntity: GroupEntity = group_entity(group_types=['Threat'])
-TaskEntity: GroupEntity = group_entity(group_types=['Task'])
+def group_entity(
+    group_types: list[str], model_name: str = 'CustomGroupEntity'
+) -> type[GroupEntity]:
+    """Dynamically create a Case Management Entity model."""
+    return create_model(
+        model_name,
+        group_types=(ClassVar[list[str]], group_types),
+        __base__=GroupEntity,
+    )
+
+
+AdversaryEntity = group_entity(group_types=['Adversary'])
+CampaignEntity = group_entity(group_types=['Campaign'])
+DocumentEntity = group_entity(group_types=['Document'])
+EmailEntity = group_entity(group_types=['Email'])
+EventEntity = group_entity(group_types=['Event'])
+IncidentEntity = group_entity(group_types=['Incident'])
+IntrusionSetEntity = group_entity(group_types=['Intrusion Set'])
+SignatureEntity = group_entity(group_types=['Signature'])
+ReportEntity = group_entity(group_types=['Report'])
+ThreatEntity = group_entity(group_types=['Threat'])
+TaskEntity = group_entity(group_types=['Task'])
```

### Comparing `tcex-3.0.9/tcex/input/field_types/indicator_entity.py` & `tcex-4.0.0/tcex/input/field_type/indicator_entity.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,68 +1,57 @@
-"""Indicator Entity Field (Model) Type"""
+"""TcEx Framework Module"""
+
 # standard library
-from typing import TYPE_CHECKING, List
+from typing import ClassVar
 
 # third-party
-from pydantic import validator
+from pydantic import create_model, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidEntityType
-from tcex.input.field_types.tc_entity import TCEntity
-from tcex.pleb.registry import registry
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.api.tc.util.threat_intel_util import ThreatIntelUtil
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidEntityType
+from tcex.input.field_type.tc_entity import TCEntity
+from tcex.registry import registry
 
 
-# pylint: disable=no-self-argument, no-self-use
+# pylint: disable=no-self-argument
 class IndicatorEntity(TCEntity):
     """Indicator Entity Field (Model) Type"""
 
-    @validator('type')
-    def is_empty(cls, value: str, field: 'ModelField') -> str:
+    indicator_types: ClassVar[list[str]] = []
+
+    @validator('type', allow_reuse=True)
+    def is_empty(cls, value: str, field: ModelField) -> str:
         """Validate that the value is a non-empty string."""
         if isinstance(value, str) and value.replace(' ', '') == '':
             raise InvalidEmptyValue(field_name=field.name)
         return value
 
-    @validator('type')
-    def is_type(cls, value: str, field: 'ModelField') -> str:
-        """Validate that the entity is of Indicator type."""
-        ti_utils = ThreatIntelUtils(session_tc=registry.session_tc)
-        if value not in ti_utils.indicator_types:
-            raise InvalidEntityType(field_name=field.name, entity_type='Indicator', value=value)
+    @validator('type', allow_reuse=True)
+    def is_type(cls, value: str, field: ModelField) -> str:
+        """Validate that the entity is of a specific Indicator type."""
+        ti_utils = ThreatIntelUtil(session_tc=registry.session_tc)
+        indicator_types = cls.indicator_types or ti_utils.indicator_types
+        if value.lower() not in [i.lower() for i in indicator_types]:
+            raise InvalidEntityType(
+                field_name=field.name, entity_type=str(indicator_types), value=value
+            )
         return value
 
 
-def indicator_entity(indicator_types: List[str] = None) -> type:
-    """Return custom model for Indicator Entity."""
-
-    class CustomIndicatorEntity(IndicatorEntity):
-        """Indicator Entity Field (Model) Type"""
-
-        @validator('type', allow_reuse=True)
-        def is_empty(cls, value: str, field: 'ModelField') -> str:
-            """Validate that the value is a non-empty string."""
-            if isinstance(value, str) and value.replace(' ', '') == '':
-                raise InvalidEmptyValue(field_name=field.name)
-            return value
-
-        @validator('type', allow_reuse=True)
-        def is_type(cls, value: str, field: 'ModelField') -> str:
-            """Validate that the entity is of a specific Indicator type."""
-            if value.lower() not in [i.lower() for i in indicator_types]:
-                raise InvalidEntityType(
-                    field_name=field.name, entity_type=str(indicator_types), value=value
-                )
-            return value
-
-    return CustomIndicatorEntity
-
-
-AddressEntity: IndicatorEntity = indicator_entity(indicator_types=['Address'])
-EmailAddressEntity: IndicatorEntity = indicator_entity(indicator_types=['EmailAddress'])
-HostEntity: IndicatorEntity = indicator_entity(indicator_types=['Host'])
-FileEntity: IndicatorEntity = indicator_entity(indicator_types=['File'])
-UrlEntity: IndicatorEntity = indicator_entity(indicator_types=['URL'])
+def indicator_entity(
+    indicator_types: list[str], model_name: str = 'CustomIndicatorEntity'
+) -> type[IndicatorEntity]:
+    """Dynamically create a Case Management Entity model."""
+    return create_model(
+        model_name,
+        indicator_types=(ClassVar[list[str]], indicator_types),
+        __base__=IndicatorEntity,
+    )
+
+
+AddressEntity = indicator_entity(indicator_types=['Address'])
+EmailAddressEntity = indicator_entity(indicator_types=['EmailAddress'])
+HostEntity = indicator_entity(indicator_types=['Host'])
+FileEntity = indicator_entity(indicator_types=['File'])
+UrlEntity = indicator_entity(indicator_types=['URL'])
```

### Comparing `tcex-3.0.9/tcex/input/field_types/integer.py` & `tcex-4.0.0/tcex/input/field_type/integer.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,66 +1,60 @@
-"""Integer Field Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Any, Callable, Dict, Union
+from collections.abc import Generator
+from typing import Any
 
 # third-party
+from pydantic.fields import ModelField  # TYPE-CHECKING
 from pydantic.types import OptionalInt
 
 # first-party
-from tcex.input.field_types.exception import InvalidIntegerValue, InvalidType, InvalidVariableType
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
-
-    # first-party
-    from tcex.utils.variables import StringVariable
+from tcex.input.field_type.exception import InvalidIntegerValue, InvalidType
 
 
 class Integer(int):
     """Integer Field Type"""
 
     ge: OptionalInt = None
     gt: OptionalInt = None
     le: OptionalInt = None
     lt: OptionalInt = None
 
     @classmethod
-    def __modify_schema__(cls, field_schema: Dict[str, Any]):
+    def __modify_schema__(cls, field_schema: dict[str, Any]):
         """Modify the field schema."""
 
-        def update_not_none(mapping: Dict[Any, Any], **update: Any):
+        def update_not_none(mapping: dict[Any, Any], **update: Any):
             mapping.update({k: v for k, v in update.items() if v is not None})
 
         update_not_none(
             field_schema,
             exclusiveMinimum=cls.gt,
             exclusiveMaximum=cls.lt,
             minimum=cls.ge,
             maximum=cls.le,
         )
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Run validators / modifiers on input."""
-        yield cls.validate_variable_type
         yield cls.validate_type
         yield cls.validate_value
 
     @classmethod
-    def validate_type(cls, value: Union[int, str, 'StringVariable'], field: 'ModelField') -> int:
+    def validate_type(cls, value: int | str, field: ModelField) -> int | str:
         """Raise exception if value is not a String type."""
-        if not isinstance(value, (int, str)):
+        if not isinstance(value, int | str):
             raise InvalidType(
                 field_name=field.name, expected_types='(int, str)', provided_type=type(value)
             )
         return value
 
     @classmethod
-    def validate_value(cls, value: Union[int, str, 'StringVariable'], field: 'ModelField') -> int:
+    def validate_value(cls, value: int | str, field: ModelField) -> int:
         """Raise exception if value does not meet criteria."""
         if isinstance(value, str):
             value = int(value)
 
         if cls.ge is not None and not value >= cls.ge:
             raise InvalidIntegerValue(
                 field_name=field.name, operation='greater than or equal to', constraint=cls.ge
@@ -76,33 +70,22 @@
             )
         if cls.lt is not None and not value < cls.lt:
             raise InvalidIntegerValue(
                 field_name=field.name, operation='less than', constraint=cls.lt
             )
         return value
 
-    @classmethod
-    def validate_variable_type(
-        cls, value: Union[int, str, 'StringVariable'], field: 'ModelField'
-    ) -> int:
-        """Raise exception if value is not a String type."""
-        if hasattr(value, '_variable_type') and value._variable_type != 'String':
-            raise InvalidVariableType(
-                field_name=field.name, expected_type='String', provided_type=value._variable_type
-            )
-        return value
-
 
 def integer(
     gt: OptionalInt = None,
     ge: OptionalInt = None,
     lt: OptionalInt = None,
     le: OptionalInt = None,
-) -> type:
+) -> type[Integer]:
     """Return configured instance of String."""
-    namespace = dict(
-        gt=gt,
-        ge=ge,
-        lt=lt,
-        le=le,
-    )
+    namespace = {
+        'gt': gt,
+        'ge': ge,
+        'lt': lt,
+        'le': le,
+    }
     return type('ConstrainedInteger', (Integer,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/ip_address.py` & `tcex-4.0.0/tcex/input/field_type/ip_address.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,37 +1,32 @@
-"""IP Address Field Type"""
+"""TcEx Framework Module"""
 # standard library
 import ipaddress
-from typing import TYPE_CHECKING, Callable, Union
+from collections.abc import Generator
 
-# first-party
-from tcex.input.field_types.exception import InvalidInput, InvalidVariableType
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+# third-party
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
-    # first-party
-    from tcex.utils.variables import StringVariable
+# first-party
+from tcex.input.field_type.exception import InvalidInput
 
 
 class IpAddress(str):
     """String Field Type"""
 
     strip_port: bool = False
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Run validators / modifiers on input."""
-        yield cls.validate_variable_type
         yield cls.validate_strip_port
         yield cls.validate_ipaddress
 
     @classmethod
-    def validate_strip_port(cls, value: Union[bytes, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_strip_port(cls, value: str, field: ModelField) -> str:
         """Modify value when requested."""
         if cls.strip_port is True:
             if ':' in value:
                 _value, port = value.rsplit(':', 1)
 
                 try:
                     if int(port) > 65535 or int(port) < 0:
@@ -40,37 +35,25 @@
                     raise InvalidInput(field.name, f'Invalid IP Address provided ({value}).')
 
                 value = _value
 
         return value
 
     @classmethod
-    def validate_ipaddress(cls, value: Union[str, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_ipaddress(cls, value: str, field: ModelField) -> str:
         """Raise exception if value is not a String type."""
         try:
             ipaddress.ip_address(value)
         except ValueError as ex:
             raise InvalidInput(field.name, f'Invalid IP Address provided ({value}).') from ex
 
         return value
 
-    @classmethod
-    def validate_variable_type(
-        cls, value: Union[str, 'StringVariable'], field: 'ModelField'
-    ) -> str:
-        """Raise exception if value is not a String type."""
-        if hasattr(value, '_variable_type') and value._variable_type != 'String':
-            raise InvalidVariableType(
-                field_name=field.name, expected_type='String', provided_type=value._variable_type
-            )
-
-        return value
-
 
 def ip_address(
     strip_port: bool = False,
-) -> type:
+) -> type[IpAddress]:
     """Return configured instance of String."""
-    namespace = dict(
-        strip_port=strip_port,
-    )
+    namespace = {
+        'strip_port': strip_port,
+    }
     return type('ConstrainedIpAddress', (IpAddress,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/key_value.py` & `tcex-4.0.0/tcex/input/field_type/key_value.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,44 +1,43 @@
-"""KeyValue Playbook Type"""
+"""TcEx Framework Module"""
 # standard library
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union
+from typing import ForwardRef
 
 # third-party
 from pydantic import BaseModel, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.input.field_types.binary import Binary
-from tcex.input.field_types.exception import InvalidEmptyValue
-from tcex.input.field_types.string import String
-from tcex.input.field_types.tc_entity import TCEntity
+from tcex.input.field_type.binary import Binary
+from tcex.input.field_type.exception import InvalidEmptyValue
+from tcex.input.field_type.string import String
+from tcex.input.field_type.tc_entity import TCEntity
 
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+KeyValue = ForwardRef('KeyValue')  # type: ignore
 
 
-# pylint: disable=no-self-argument, no-self-use
+# pylint: disable=no-self-argument
 class KeyValue(BaseModel):
     """Model for KeyValue Input."""
 
     key: str
-    type: Optional[str]
-    value: Union[
-        List['KeyValue'],
-        'KeyValue',
-        List[TCEntity],
-        TCEntity,
-        List[String],
-        String,
-        List[Binary],
-        Binary,
-    ]
+    type: str | None
+    value: (
+        list[KeyValue]  # SELF-REFERENCE
+        | KeyValue  # SELF-REFERENCE
+        | list[TCEntity]
+        | TCEntity
+        | list[String]
+        | String
+        | list[Binary]
+        | Binary
+    )
 
     @validator('key')
-    def non_empty_string(cls, value: str, field: 'ModelField') -> Dict[str, Any]:
+    def non_empty_string(cls, value: str, field: ModelField) -> str:
         """Validate that the value is a non-empty string."""
         if isinstance(value, str) and value.replace(' ', '') == '':
             raise InvalidEmptyValue(field_name=field.name)
         return value
 
     class Config:
         """Model Config"""
```

### Comparing `tcex-3.0.9/tcex/input/field_types/sensitive.py` & `tcex-4.0.0/tcex/input/field_type/sensitive.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,64 +1,61 @@
-"""Sensitive Field Type"""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import TYPE_CHECKING, Any, Callable, Dict, Optional, Union
+from collections.abc import Generator
+from typing import Any, Self
 
-# first-party
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidLengthValue, InvalidType
-from tcex.logger.sensitive_filter import SensitiveFilter  # pylint: disable=no-name-in-module
-from tcex.utils.variables import BinaryVariable
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
-
-    # first-party
-    from tcex.utils.variables import StringVariable
+# third-party
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
+# first-party
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidLengthValue, InvalidType
+from tcex.logger.sensitive_filter import SensitiveFilter
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util.variable import BinaryVariable
 
 # get tcex logger
 filter_sensitive = SensitiveFilter(name='sensitive_filter')
-logger = logging.getLogger('tcex')
-logger.addFilter(filter_sensitive)
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
+_logger.addFilter(filter_sensitive)
 
 
 class Sensitive:
     """Sensitive Field Type"""
 
     allow_empty: bool = True
-    min_length: Optional[int] = None
-    max_length: Optional[int] = None
+    min_length: int | None = None
+    max_length: int | None = None
 
-    def __init__(self, value: Union[str, 'Sensitive']):
+    def __init__(self, value: str | Self):
         """Initialize the Sensitive object."""
         if isinstance(value, Sensitive):
             self._sensitive_value = value.value
         else:
             self._sensitive_value = value
         filter_sensitive.add(self._sensitive_value)
 
     @classmethod
-    def __get_validators__(cls) -> Callable:
+    def __get_validators__(cls) -> Generator:
         """Define one or more validators for Pydantic custom type."""
         yield cls.validate_type
         yield cls.validate_allow_empty
         yield cls.validate_max_length
         yield cls.validate_min_length
         yield cls.wrap_type
 
     def __len__(self) -> int:
         """Return the length of the sensitive value."""
         return len(self._sensitive_value)
 
     @classmethod
-    def __modify_schema__(cls, field_schema: Dict[str, Any]):
+    def __modify_schema__(cls, field_schema: dict[str, Any]):
         """Modify the field schema."""
 
-        def _update_not_none(mapping: Dict[Any, Any], **update: Any):
+        def _update_not_none(mapping: dict[Any, Any], **update: Any):
             mapping.update({k: v for k, v in update.items() if v is not None})
 
         _update_not_none(
             field_schema,
             type='string',
             writeOnly=True,
             format='password',
@@ -73,73 +70,85 @@
     def __str__(self) -> str:
         """Return the value masked.
 
         If App is running in > DEBUG logging level and the sensitive data is greater
         than X, then show the first and last character of the value. This is very
         helpful in debugging App where the incorrect credential could have been passed.
         """
-        if self._sensitive_value and logger.getEffectiveLevel() <= 10:  # DEBUG or TRACE
+        if self._sensitive_value and _logger.getEffectiveLevel() <= 10:  # DEBUG or TRACE
             if isinstance(self.value, str) and len(self.value) >= 10:
                 return f'''{self.value[:1]}{'*' * 4}{self.value[-1:]}'''
         return '**********'
 
     @classmethod
-    def validate_allow_empty(cls, value: Union[str, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_allow_empty(
+        cls, value: bytes | str | Self, field: ModelField
+    ) -> bytes | str | Self:
         """Raise exception if value is empty and allow_empty is False."""
         if cls.allow_empty is False:
             if isinstance(value, str) and value.replace(' ', '') == '':
                 raise InvalidEmptyValue(field_name=field.name)
-
+            if isinstance(value, bytes) and value == b'':
+                raise InvalidEmptyValue(field_name=field.name)
+            if isinstance(value, Sensitive) and value.value.replace(' ', '') == '':
+                raise InvalidEmptyValue(field_name=field.name)
         return value
 
     @classmethod
-    def validate_max_length(cls, value: Union[str, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_max_length(
+        cls, value: bytes | str | Self, field: ModelField
+    ) -> bytes | str | Self:
         """Raise exception if value does not match pattern."""
         if cls.max_length is not None and len(value) > cls.max_length:
             raise InvalidLengthValue(
                 field_name=field.name, constraint=cls.max_length, operation='max'
             )
         return value
 
     @classmethod
-    def validate_min_length(cls, value: Union[str, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_min_length(
+        cls, value: bytes | str | Self, field: ModelField
+    ) -> bytes | str | Self:
         """Raise exception if value does not match pattern."""
         if cls.min_length is not None and len(value) < cls.min_length:
             raise InvalidLengthValue(
                 field_name=field.name, constraint=cls.min_length, operation='min'
             )
         return value
 
     @classmethod
-    def validate_type(cls, value: Union[str, 'StringVariable'], field: 'ModelField') -> str:
+    def validate_type(cls, value: bytes | str | Self, field: ModelField) -> bytes | str | Self:
         """Raise exception if value is not a String type."""
-        if not isinstance(value, (bytes, str, Sensitive)):
+        if not isinstance(value, bytes | str | Sensitive):
             raise InvalidType(
                 field_name=field.name, expected_types='(bytes, str)', provided_type=type(value)
             )
         return value
 
     @property
     def value(self) -> str:
         """Return the actual value."""
-        if not isinstance(self._sensitive_value, (BinaryVariable, bytes)):
+        if not isinstance(self._sensitive_value, BinaryVariable | bytes):
+            # file variables can be used for client certs, json credential,
+            # etc and the data is provided as a BinaryVariable object. This
+            # is a special case where we need to return the value as a string.
             return str(self._sensitive_value)
         return self._sensitive_value
 
     @classmethod
-    def wrap_type(cls, value: Union[str, 'StringVariable']) -> str:
+    def wrap_type(cls, value: str) -> Self:
         """Raise exception if value is not a String type."""
         return cls(value)
 
 
 def sensitive(
     allow_empty: bool = True,
-    max_length: Optional[int] = None,
-    min_length: Optional[int] = None,
-) -> type:
+    max_length: int | None = None,
+    min_length: int | None = None,
+) -> type[Sensitive]:
     """Return configured instance of String."""
-    namespace = dict(
-        allow_empty=allow_empty,
-        max_length=max_length,
-        min_length=min_length,
-    )
+    namespace = {
+        'allow_empty': allow_empty,
+        'max_length': max_length,
+        'min_length': min_length,
+    }
     return type('ConstrainedSensitive', (Sensitive,), namespace)
```

### Comparing `tcex-3.0.9/tcex/input/field_types/tc_entity.py` & `tcex-4.0.0/tcex/input/field_type/tc_entity.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,38 +1,32 @@
-"""TCEntity Playbook Type"""
-# standard library
-from typing import TYPE_CHECKING, Dict, Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Extra, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.input.field_types.exception import InvalidEmptyValue
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.input.field_type.exception import InvalidEmptyValue
 
 
-# pylint: disable=no-self-argument, no-self-use
+# pylint: disable=no-self-argument
 class TCEntity(BaseModel):
     """Model for TCEntity Input."""
 
     id: int
     type: str
     value: str
 
     # IMPORTANT: confidence and rating values are included only so that, when defined,
     #    they come back as the correct types. They are only intended for Indicator
     #    types and are not guaranteed to be populated.
-    confidence: Optional[int]
-    rating: Optional[int]
+    confidence: int | None
+    rating: int | None
 
     @validator('id', 'type', 'value')
-    def non_empty_string(cls, v: Dict[str, str], field: 'ModelField') -> Dict[str, str]:
+    def non_empty_string(cls, v: dict[str, str], field: ModelField) -> dict[str, str]:
         """Validate that the value is a non-empty string."""
         if isinstance(v, str) and v.replace(' ', '') == '':  # None value are automatically covered
             raise InvalidEmptyValue(field_name=field.name)
         return v
 
     class Config:
         """Model Config"""
```

### Comparing `tcex-3.0.9/tcex/input/field_types/validators.py` & `tcex-4.0.0/tcex/input/field_type/validator.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,42 +1,40 @@
-"""Model Validator/Modifier"""
+"""TcEx Framework Module"""
 # standard library
 import operator
-from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union
+from collections.abc import Callable
+from typing import Any
 
 # third-party
 from pydantic import BaseModel, validator
+from pydantic.fields import ModelField  # TYPE-CHECKING
 
 # first-party
-from tcex.input.field_types.exception import InvalidEmptyValue, InvalidInput, InvalidType
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from pydantic.fields import ModelField
+from tcex.input.field_type.exception import InvalidEmptyValue, InvalidInput, InvalidType
 
 
 def always_array(
-    allow_empty: Optional[bool] = True,
-    include_empty: Optional[bool] = False,
-    include_null: Optional[bool] = False,
-    split_csv: Optional[bool] = False,
-) -> List[Any]:
+    allow_empty: bool = True,
+    include_empty: bool = False,
+    include_null: bool = False,
+    split_csv: bool = False,
+) -> Callable[[Any, ModelField], list[Any]]:
     """Return customized validator that always returns a list.
 
     Args:
         allow_empty: If True, return empty list if input is empty.
         include_empty: If True, will wrap empty string in list. This does not
             affect list with existing empty strings.
         include_null: If True, will wrap null value in list. This does not
             affect list with existing null values.
         split_csv: if True and input value is a string, then string will be split on comma. No
         further processing is done on result of splitting on comma
     """
 
-    def _always_array(value: Any, field: 'ModelField') -> List[Any]:
+    def _always_array(value: Any, field: ModelField) -> list[Any]:
         """Return validator."""
 
         if split_csv and isinstance(value, str) and value:
             value = value.split(',')
 
         if include_empty is True and value == '':
             value = [value]
@@ -53,72 +51,72 @@
             raise InvalidEmptyValue(field_name=field.name)
 
         return value
 
     return _always_array
 
 
-def conditional_required(rules: List[Dict[str, str]] = True) -> Any:
+def conditional_required(rules: list[dict[str, str]]) -> Any:
     """Return customized validator that validates conditional required fields.
 
     Example Usage:
 
     If the severity field is set to 'High' the action field is required.
 
     MyModel(BaseModel):
         severity: str  # Low, Medium, High
-        action: Optional[str]
+        action: str | None
 
         _conditional_required = validator('action', allow_reuse=True, always=True, pre=True)(
             conditional_required(
                 rules=[{'field': 'severity', 'operation': 'eq', 'value': 'High'}]
             )
         )
     """
 
-    def is_in(input_: str, value: List) -> bool:
+    def is_in(input_: str, value: list) -> bool:
         """Return True if input is in value list."""
         return input_ in value
 
-    def not_in(input_: str, value: List) -> bool:
+    def not_in(input_: str, value: list) -> bool:
         """Return True if input is NOT in value list."""
         return input_ not in value
 
     def get_operator(op):
         """Get the corresponding operator"""
 
         operators = {
             'eq': operator.eq,
             'in': is_in,
             'ne': operator.ne,
             'ni': not_in,
         }
         return operators.get(op, operator.eq)
 
-    def _conditional_required(value: str, field: 'ModelField', values: Dict[str, Any]):
+    def _conditional_required(value: str, field: ModelField, values: dict[str, Any]):
         """Return validator."""
         for rule in rules or []:
             # the conditional field must be set above the conditionally required field
-            conditional_field = values.get(rule.get('field'))
+            conditional_field = values.get(rule['field'])
             conditional_operator = get_operator(rule.get('op', 'eq'))
-            conditional_value = rule.get('value')
+            conditional_value = rule['value']
 
             if conditional_operator(conditional_field, conditional_value) is True and not value:
                 raise InvalidInput(field_name=field.name, error='input is conditionally required.')
 
         return value
 
     return _conditional_required
 
 
 def entity_input(
-    allow_empty: Optional[bool] = False,
-    only_field: Optional[str] = None,
-    type_filter: Optional[List[str]] = None,
-) -> Union[str, List[Any]]:
+    allow_empty: bool = False,
+    only_field: str | None = None,
+    type_filter: list[str] | None = None,
+) -> str | list[Any]:
     """Return customized validator.
 
     allow_empty:
 
     If this is False, an emptiness check is performed on the final value that is to be returned
     just before returning it. If the return value is either an empty string or an empty list, then
     an error is raised. If allow_empty is True, then the final value is not guaranteed not to be
@@ -141,75 +139,75 @@
     method is working with TCEntities. When working with Strings, the values are not verified to be
     of any particular TCEntity type and are returned as is. Note: if target type list contains
     more than one type and only_value is True, then an array of values of mixed types could occur.
 
     Example Usage:
 
     MyModel(BaseModel):
-        ip_address: Union[
-            AddressEntity,
-            ip_address(strip_port=True)
-        ]
+        ip_address: AddressEntity | ip_address(strip_port=True)
 
         _entity_field = validator('ip_address', allow_reuse=True)(entity_field(only_value=True))
     """
 
     def _entity_input(
-        value: Union['BaseModel', List['BaseModel'], str, List[str]], field: 'ModelField'
-    ) -> Union[List[str], str]:
+        value: BaseModel | list[BaseModel] | str | list[str], field: ModelField
+    ) -> list[str] | str:
         """Return value from String or TCEntity."""
 
-        def _get_value(value: Union[str, 'BaseModel']) -> Union['BaseModel', str]:
+        def _get_value(value: str | BaseModel) -> BaseModel | str | None:
             """Return value"""
             if isinstance(value, BaseModel):
-                if isinstance(type_filter, list) and value.type not in type_filter:
+                if isinstance(type_filter, list) and value.type not in type_filter:  # type: ignore
                     return None
 
                 if only_field is None:
                     return value
                 if only_field.lower() == 'value':
-                    return value.value
+                    return value.value  # type: ignore
                 if only_field.lower() == 'id':
-                    return value.id
+                    return value.id  # type: ignore
                 raise InvalidInput(
                     field_name=field.name, error=f'Only Field {only_field} is not allowed.'
                 )
 
             return value
 
         if isinstance(value, list):
             _values = []
             for v in value:
                 _value = _get_value(v)
                 if _value is not None:
                     _values.append(_value)
             value = _values
         else:
-            value = _get_value(value)
+            # TODO: [high] fix this type ignore
+            value = _get_value(value)  # type: ignore
 
         if field.allow_none is False and value is None:
             raise InvalidInput(field_name=field.name, error='None value is not allowed.')
 
         if allow_empty is False and value in ['', []]:
             raise InvalidInput(field_name=field.name, error='Empty value is not allowed.')
 
-        return value
+        # TODO: [high] fix this type ignore
+        return value  # type: ignore
 
-    return _entity_input
+    # TODO: [high] fix this type ignore
+    return _entity_input  # type: ignore
 
 
-def modify_advanced_settings(input_name) -> Callable:
+def modify_advanced_settings(input_name) -> Any:
     """Return validator that parses an advanced settings string and returns a dictionary
 
     :param input_name: the name of the input (within the app model) that will receive the
     pipe-delimited advanced settings string. In other words, the name of the input field
     that this validator should act on to parse the pipe-delimited string into a dictionary
     """
 
-    def _modify_advanced_settings(value: Any, field: 'ModelField') -> Dict[str, str]:
+    def _modify_advanced_settings(value: Any, field: ModelField) -> dict[str, str]:
         """Return validator."""
         settings = {}
 
         if value is None:
             if field.allow_none:
                 return value
             raise InvalidInput(
```

### Comparing `tcex-3.0.9/tcex/input/input.py` & `tcex-4.0.0/tcex/input/input.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,107 +1,115 @@
-"""Input for Apps"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
 import os
 import re
 from base64 import b64decode
 from pathlib import Path
-from typing import TYPE_CHECKING, Dict, Optional, Union
 
 # third-party
+from pydantic import ValidationError  # TYPE-CHECKING
 from pydantic import BaseModel, Extra
+from redis import Redis
 
 # first-party
-from tcex.app_config.install_json import InstallJson
-from tcex.backports import cached_property
-from tcex.input.field_types import Sensitive
-from tcex.input.models import feature_map, runtime_level_map, tc_action_map
-from tcex.key_value_store import RedisClient
-from tcex.pleb.none_model import NoneModel
-from tcex.pleb.registry import registry
-from tcex.utils import Utils
-
-if TYPE_CHECKING:
-    # third-party
-    from pydantic import ValidationError
+from tcex.app.config.install_json import InstallJson
+from tcex.app.key_value_store import RedisClient
+from tcex.input.field_type import Sensitive
+from tcex.input.model.advanced_request_model import AdvancedRequestModel
+from tcex.input.model.app_external_model import AppExternalModel
+from tcex.input.model.common_advanced_model import CommonAdvancedModel
+from tcex.input.model.common_model import CommonModel
+from tcex.input.model.model_map import feature_map, runtime_level_map, tc_action_map
+from tcex.input.model.module_app_model import ModuleAppModel
+from tcex.input.model.module_requests_session_model import ModuleRequestsSessionModel
+from tcex.input.model.path_model import PathModel
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
+from tcex.registry import registry
+from tcex.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 # define JSON encoders
-json_encoders = {Sensitive: lambda v: str(v)}  # pylint: disable=W0108
+json_encoders = {Sensitive: lambda v: str(v)}  # pylint: disable=unnecessary-lambda
 
 
-def input_model(models: list) -> 'BaseModel':
+def input_model(models: list) -> CommonModel | CommonAdvancedModel:
     """Return Input Model."""
 
     class InputModel(*models):
         """Input Model"""
 
         # [legacy] if True, the App should get it's inputs from secure params (redis)
         # supported runtimeLevel: [Organization, Playbook]
         tc_secure_params: bool = False
 
         # the user id of the one executing the App
         # supported runtimeLevel: [Organization, Playbook]
-        tc_user_id: Optional[int]
+        tc_user_id: int | None
 
         class Config:
             """DataModel Config"""
 
             extra = Extra.allow
             validate_assignment = True
             json_encoders = json_encoders
 
     return InputModel
 
 
 class Input:
     """Module to handle inputs for all App types."""
 
-    def __init__(self, config: Optional[dict] = None, config_file: Optional[str] = None, **kwargs):
-        """Initialize class properties.
+    def __init__(self, config: dict | None = None, config_file: str | None = None):
+        """Initialize instance properties."""
 
-        Keyword Args:
-            tc_session: pass a tc_session object to use, else will use the one from registry.
-        """
-
-        # TODO [HIGH] kwarg - don't add built-in models, supply custom TcSession object
         self.config = config
         self.config_file = config_file
 
         # properties
         self._models = []
         self.ij = InstallJson()
-        self.log = logger
-        self.utils = Utils()
-        self.tc_session = kwargs.get('tc_session')
+        self.log = _logger
+        self.util = Util()
 
     @staticmethod
-    def _get_redis_client(host, port, db):
+    def _get_redis_client(host: str, port: int, db: int) -> Redis:
         """Return RedisClient client"""
         return RedisClient(host=host, port=port, db=db).client
 
     def _load_aot_params(
         self,
         tc_aot_enabled: bool,
         tc_kvstore_type: str,
         tc_kvstore_host: str,
         tc_kvstore_port: int,
         tc_action_channel: str,
         tc_terminate_seconds: int,
-    ) -> Dict[str, any]:
+    ) -> dict[str, dict | list | str]:
         """Subscribe to AOT action channel."""
         params = {}
         if tc_aot_enabled is not True:
             return params
 
-        if tc_kvstore_type == 'Redis':
+        if not all(
+            [
+                tc_kvstore_type,
+                tc_kvstore_host,
+                tc_kvstore_port,
+                tc_action_channel,
+                tc_terminate_seconds,
+            ]
+        ):
+            return params
 
+        if tc_kvstore_type == 'Redis':
             # get an instance of redis client
             redis_client = self._get_redis_client(
                 host=tc_kvstore_host,
                 port=tc_kvstore_port,
                 db=0,
             )
 
@@ -110,30 +118,30 @@
                 msg_data = redis_client.blpop(
                     keys=tc_action_channel,
                     timeout=int(tc_terminate_seconds),
                 )
 
                 if msg_data is None:  # pragma: no cover
                     # send exit to tcex.exit method
-                    registry.ExitService.exit_aot_terminate(
+                    registry.exit.exit_aot_terminate(
                         code=1, msg='AOT subscription timeout reached.'
                     )
-
-                msg_data = json.loads(msg_data[1])
-                msg_type = msg_data.get('type', 'terminate')
-                if msg_type == 'execute':
-                    params = msg_data.get('params', {})
-                elif msg_type == 'terminate':
-                    # send exit to tcex.exit method
-                    registry.ExitService.exit_aot_terminate(
-                        code=0, msg='Received AOT terminate message.'
-                    )
+                else:
+                    msg_data = json.loads(msg_data[1])
+                    msg_type = msg_data.get('type', 'terminate')
+                    if msg_type == 'execute':
+                        params = msg_data.get('params', {})
+                    elif msg_type == 'terminate':
+                        # send exit to tcex.exit method
+                        registry.exit.exit_aot_terminate(
+                            code=0, msg='Received AOT terminate message.'
+                        )
             except Exception as e:  # pragma: no cover
                 # send exit to tcex.exit method
-                registry.ExitService.exit_aot_terminate(
+                registry.exit.exit_aot_terminate(
                     code=1, msg=f'Exception during AOT subscription ({e}).'
                 )
 
         return params
 
     def _load_config_file(self):
         """Load config file params provided passed to inputs."""
@@ -163,60 +171,62 @@
     def _load_file_params(self):
         """Load file params provided by the core platform."""
         # default file contents
         file_content = {}
 
         tc_app_param_file = os.getenv('TC_APP_PARAM_FILE')
         tc_app_param_key = os.getenv('TC_APP_PARAM_KEY')
-        if not all([tc_app_param_file, tc_app_param_key]):
-            return file_content
-
-        # tc_app_param_file is a fully qualified file name
-        fqfn = Path(tc_app_param_file)
-        if not fqfn.is_file():  # pragma: no cover
-            self.log.error(
-                'feature=inputs, event=load-file-params, '
-                f'exception=file-not-found, filename={fqfn.name}'
-            )
-            return file_content
+        if tc_app_param_file and tc_app_param_key:
+            # tc_app_param_file is a fully qualified file name
+            fqfn = Path(tc_app_param_file)
+            if not fqfn.is_file():  # pragma: no cover
+                self.log.error(
+                    'feature=inputs, event=load-file-params, '
+                    f'exception=file-not-found, filename={fqfn.name}'
+                )
+                return file_content
 
-        # read file contents
-        try:
-            # read encrypted file from "in" directory
-            with fqfn.open(mode='rb') as fh:
-                encrypted_contents = fh.read()
-        except Exception:  # pragma: no cover
-            self.log.error(f'feature=inputs, event=config-parse-failure, filename={fqfn.name}')
-            return file_content
+            # read file contents
+            try:
+                # read encrypted file from "in" directory
+                with fqfn.open(mode='rb') as fh:
+                    encrypted_contents = fh.read()
+            except Exception:  # pragma: no cover
+                self.log.error(f'feature=inputs, event=config-parse-failure, filename={fqfn.name}')
+                return file_content
 
-        # decrypt file contents
-        try:
-            file_content = json.loads(
-                self.utils.decrypt_aes_cbc(tc_app_param_key, encrypted_contents).decode()
-            )
+            # decrypt file contents
+            try:
+                file_content = json.loads(
+                    self.util.decrypt_aes_cbc(tc_app_param_key, encrypted_contents).decode()
+                )
 
-            # delete file
-            fqfn.unlink()
-        except Exception:  # pragma: no cover
-            self.log.error(f'feature=inputs, event=config-decryption-failure, filename={fqfn.name}')
+                # delete file
+                fqfn.unlink()
+            except Exception:  # pragma: no cover
+                self.log.error(
+                    f'feature=inputs, event=config-decryption-failure, filename={fqfn.name}'
+                )
 
         return file_content
 
-    def add_model(self, model: BaseModel):
-        """Add additional input models."""
+    def add_model(self, model: type[BaseModel]):
+        """Add additional input model."""
         if model:
             self._models.insert(0, model)
 
         # clear cache for data property
         if 'model' in self.__dict__:
             del self.__dict__['model']
 
-        # add App level models based on special "tc_action" input
-        if hasattr(self.model_unresolved, 'tc_action'):
-            self._models.extend(tc_action_map.get(self.model_unresolved.tc_action, []))
+        # add App level model based on special "tc_action" input. this field
+        # doesn't exist on the common model, but can be added by the App.
+        # the tc_action can never be a variable (choice input).
+        if tc_action := self.contents.get('tc_action'):
+            self._models.extend(tc_action_map.get(tc_action, []))
 
         # force data model to load so that validation is done at this EXACT point
         _ = self.model
 
     @cached_property
     def contents(self) -> dict:
         """Return contents of inputs from all locations."""
@@ -229,24 +239,38 @@
         # config file
         _contents.update(self._load_config_file())
 
         # file params
         _contents.update(self._load_file_params())
 
         # aot params - must be loaded last so that it has the kv store channels
-        _contents.update(
-            self._load_aot_params(
-                tc_aot_enabled=self.utils.to_bool(_contents.get('tc_aot_enabled', False)),
-                tc_kvstore_type=_contents.get('tc_kvstore_type'),
-                tc_kvstore_host=_contents.get('tc_kvstore_host'),
-                tc_kvstore_port=_contents.get('tc_kvstore_port'),
-                tc_action_channel=_contents.get('tc_action_channel'),
-                tc_terminate_seconds=_contents.get('tc_terminate_seconds'),
-            )
-        )
+        tc_aot_enabled = self.util.to_bool(_contents.get('tc_aot_enabled', False))
+        if tc_aot_enabled is True:
+            tc_kvstore_type = _contents.get('tc_kvstore_type')
+            tc_kvstore_host = _contents.get('tc_kvstore_host')
+            tc_kvstore_port = _contents.get('tc_kvstore_port')
+            tc_action_channel = _contents.get('tc_action_channel')
+            tc_terminate_seconds = _contents.get('tc_terminate_seconds')
+
+            if (
+                tc_kvstore_type
+                and tc_kvstore_host
+                and tc_kvstore_port
+                and tc_action_channel
+                and tc_terminate_seconds
+            ):
+                param_data = self._load_aot_params(
+                    tc_aot_enabled=tc_aot_enabled,
+                    tc_kvstore_type=tc_kvstore_type,
+                    tc_kvstore_host=tc_kvstore_host,
+                    tc_kvstore_port=tc_kvstore_port,
+                    tc_action_channel=tc_action_channel,
+                    tc_terminate_seconds=tc_terminate_seconds,
+                )
+                _contents.update(param_data)
         return _contents
 
     @cached_property
     def contents_resolved(self) -> dict:
         """Resolve all file, keychain, playbook, and text variables.
 
         Job, Playbook, and Service Apps call can have a tc-variable, but only
@@ -256,42 +280,43 @@
 
         # support external Apps that don't have an install.json
         if not self.ij.fqfn.is_file():  # pragma: no cover
             return _inputs
 
         for name, value in _inputs.items():
             if name == 'tc_playbook_out_variables':
-                # for services, this input contains the name of the expected outputs.  If we don't
-                # skip this, we'll try to resolve the value (e.g.
-                # #Trigger:334:example.service_input!String), but that 1) won't work for services
-                # and 2) doesn't make sense.  Service configs will never have playbook variables.
+                # for services, tc_playbook_out_variables contains the name of the expected outputs.
+                # If we don't skip this, we'll try to resolve the value (e.g.
+                # #Trigger:334:example.service_input!String)
+                # 1. this won't work for services
+                # 2. service configs will never have playbook variables
                 continue
 
-            if self.utils.is_tc_variable(value):  # only matches playbook variables
+            if self.util.is_tc_variable(value):  # only matches threatconnect variables
                 value = self.resolve_variable(variable=value)
             elif self.ij.model.is_playbook_app:
                 if isinstance(value, list):
                     # list could contain playbook variables, try to resolve the value
                     updated_value_array = []
                     for v in value:
                         if isinstance(v, str):
                             v = registry.playbook.read.variable(v)
                         # TODO: [high] does resolve variable need to be added here
                         updated_value_array.append(v)
                     value = updated_value_array
-                elif self.utils.is_playbook_variable(value):  # only matches playbook variables
-                    # when using Union[Bytes, String] in App input model the value
+                elif self.util.is_playbook_variable(value):  # only matches playbook variables
+                    # when using Bytes | String in App input model the value
                     # can be coerced to the wrong type. the BinaryVariable and
                     # StringVariable custom types allows for the validator in Binary
                     # and String types to raise a value error.
                     value = registry.playbook.read.variable(value)
                 elif isinstance(value, str):
                     value = registry.playbook.read._read_embedded(value)
             else:
-                for match in re.finditer(self.utils.variable_tc_pattern, str(value)):
+                for match in re.finditer(self.util.variable_tc_pattern, str(value)):
                     variable = match.group(0)  # the full variable pattern
                     if match.group('type').lower() == 'file':
                         v = '<file>'
                     else:
                         v = self.resolve_variable(variable=variable)
                     value = value.replace(variable, v)
 
@@ -305,81 +330,136 @@
     def contents_update(self, inputs: dict):
         """Update inputs provided by AOT to be of the proper value and type."""
         for name, value in inputs.items():
             # ThreatConnect AOT params could be updated in the future to proper JSON format.
             # MultiChoice data should be represented as JSON array and Boolean values should be a
             # JSON boolean and not a string.
             param = self.ij.model.get_param(name)
-            if isinstance(param, NoneModel):
+            if param is None:
                 # skip over "default" inputs not defined in the install.json file
                 continue
 
             if param.type.lower() == 'multichoice' or param.allow_multiple:
                 # update delimited value to an array for inputs that have type of MultiChoice
                 if value is not None and not isinstance(value, list):
                     inputs[name] = value.split(self.ij.model.list_delimiter or '|')
             elif param.type == 'boolean' and isinstance(value, str):
                 # convert boolean input that are passed in as a string ("true" -> True)
                 inputs[name] = value.lower() == 'true'
 
     @cached_property
-    def model(self) -> 'BaseModel':
+    def model(self) -> CommonAdvancedModel:
         """Return the Input Model."""
-        return input_model(self.models)(**self.contents_resolved)
+        return input_model(self.models)(**self.contents_resolved)  # type: ignore
+
+    @cached_property
+    def model_advanced_request(self) -> AdvancedRequestModel:
+        """Return the Requests Session Model."""
+
+        class _AdvancedRequestModel(AdvancedRequestModel, extra=Extra.ignore):
+            """Model Definition for AdvancedRequestModel inputs ONLY."""
+
+        return _AdvancedRequestModel(**self.contents)
 
     @cached_property
-    def model_unresolved(self) -> 'BaseModel':
+    def model_organization_unresolved(self) -> CommonModel:
         """Return the Input Model using contents (no resolved values)."""
-        return input_model(self.models)(**self.contents)
+        return input_model(self.models)(**self.contents)  # type: ignore
+
+    @cached_property
+    def model_path(self) -> PathModel:
+        """Return the Requests Session Model."""
+
+        class _PathModel(PathModel, extra=Extra.ignore):
+            """Model Definition for PathModel inputs ONLY."""
+
+        return _PathModel(**self.contents)
+
+    @cached_property
+    def model_unresolved(self) -> CommonAdvancedModel:
+        """Return full data model with no resolved values.
+
+        This model has all inputs, including App inputs (e.g., tc_action), but
+        any pb/tc variables will not be resolved in the model. The model is
+        useful getting and process keyvalue variables that have mixed types.
+        """
+        return input_model(self.models)(**self.contents)  # type: ignore
+
+    @cached_property
+    def model_tc(self) -> CommonAdvancedModel:
+        """Return data model for ThreatConnect specific inputs.
+
+        This model does not have any App inputs (e.g., tc_action) and
+        should only be used for accessing ThreatConnect specific inputs.
+        """
+
+        class _CommonAdvancedModel(CommonAdvancedModel, extra=Extra.ignore):
+            """Model Definition for CommonAdvancedModel inputs ONLY."""
+
+        return _CommonAdvancedModel(**self.contents)
 
     @cached_property
     def models(self) -> list:
-        """Return all models for inputs."""
+        """Return all model for inputs."""
         # support external Apps that don't have an install.json
         if not self.ij.fqfn.is_file():
-            return runtime_level_map.get('external')
+            return [AppExternalModel]
 
-        # add all models for any supported features of the App
+        # add all model for any supported features of the App
         for feature in self.ij.model.features:
             self._models.extend(feature_map.get(feature, []))
 
-        # add all models based on the runtime level of the App
-        self._models.extend(runtime_level_map.get(self.ij.model.runtime_level.lower()))
+        # add all model based on the runtime level of the App
+        rlm = runtime_level_map.get(self.ij.model.runtime_level.lower())
+        if rlm is not None:
+            self._models.append(rlm)
 
         return self._models
 
     # TODO: [low] is this needed or can Field value be set to tc_property=True?
     @cached_property
     def model_properties(self) -> set:
         """Return only defined properties from model (exclude additional)."""
         properties = set()
         for model in self.models:
             properties.update(model.schema().get('properties').keys())
 
         return properties
 
-    def resolve_variable(self, variable: str) -> Union[bytes, str]:
+    @cached_property
+    def module_app_model(self) -> ModuleAppModel:
+        """Return the Module App Model."""
+        return ModuleAppModel(**self.contents)
+
+    @cached_property
+    def module_requests_session_model(self) -> ModuleRequestsSessionModel:
+        """Return the Module Requests Session Model."""
+        return ModuleRequestsSessionModel(**self.contents)
+
+    def resolve_variable(self, variable: str) -> bytes | str | Sensitive:
         """Resolve FILE/KEYCHAIN/TEXT variables.
 
         Feature: PLAT-2688
 
         Data Format:
         {
-            "data": "value"
+                "data": "value"
         }
         """
-        match = re.match(Utils().variable_tc_match, variable)
+        match = re.match(Util().variable_tc_match, variable)
+        if not match:
+            raise RuntimeError(f'Could not parse variable: {variable}')
+
         key = match.group('key')
         provider = match.group('provider')
         type_ = match.group('type')
 
         # retrieve value from API
         data = None
-        session = self.tc_session if self.tc_session else registry.session_tc
-        r = session.get(f'/internal/variable/runtime/{provider}/{key}')
+        r = registry.session_tc.get(f'/internal/variable/runtime/{provider}/{key}')
         if r.ok:
             try:
                 data = r.json().get('data')
 
                 if type_.lower() == 'file':
                     data = b64decode(data)  # returns bytes
                 elif type_.lower() == 'keychain':
@@ -392,19 +472,19 @@
             raise RuntimeError(
                 f'Could not retrieve variable: provider={provider}, key={key}, type={type_}.'
             )
 
         return data
 
     @staticmethod
-    def validation_exit_message(ex: 'ValidationError'):
+    def validation_exit_message(ex: ValidationError):
         """Format and return validation error message."""
         _exit_message = {}
         for err in ex.errors():
-            # deduplicate error messagese
+            # deduplicate error messages
             err_loc = ','.join([str(e) for e in err.get('loc')])
             err_msg = err.get('msg')
             _exit_message.setdefault(err_loc, [])
             if err_msg not in _exit_message[err_loc]:
                 _exit_message[err_loc].append(err_msg)
 
         # format error messages
```

### Comparing `tcex-3.0.9/tcex/input/models/advanced_request_model.py` & `tcex-4.0.0/tcex/input/model/advanced_request_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-"""Advanced Settings Model"""
-# pylint: disable=no-self-argument,no-self-use,wrong-import-position
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument,wrong-import-position
 # standard library
-from typing import Any, List, Optional
+from typing import Any
 
 # third-party
 from pydantic import BaseModel, Field, validator
 
 # first-party
-from tcex.input.field_types import EditChoice
+from tcex.input.field_type import EditChoice
 
 
-class _AdvancedRequestModel(BaseModel):
+class AdvancedRequestModel(BaseModel):
     """Advanced Settings Model
 
     * why was input included -> feature (what feature?), runtime_level
     * where is input defined -> default (core), install.json
 
     Feature: advancedRequest
 
     Supported for the following runtimeLevel:
     * Playbook
     """
 
-    tc_adv_req_body: Optional[Any] = Field(
+    tc_adv_req_body: Any | None = Field(
         None,
         description='The HTTP body for the request.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
     tc_adv_req_exclude_null_params: bool = Field(
         False,
@@ -36,44 +36,48 @@
     )
     tc_adv_req_fail_on_error: bool = Field(
         False,
         description='Flag to force fail on any error.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
-    tc_adv_req_headers: Optional[List[dict]] = Field(
+    tc_adv_req_headers: list[dict] | None = Field(
         None,
         description='The HTTP headers for the request.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
     tc_adv_req_http_method: EditChoice = Field(
         None,
         description='The HTTP method for the request.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
-    tc_adv_req_params: Optional[List[dict]] = Field(
+    tc_adv_req_params: list[dict] | None = Field(
         None,
         description='The HTTP query params for the request.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
-    tc_adv_req_path: Optional[str] = Field(
+    tc_adv_req_path: str | None = Field(
         None,
         description='The API path for the request.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
     tc_adv_req_urlencode_body: bool = Field(
         False,
         description='Flag to set URL encoding for the request body.',
         inclusion_reason='feature (advancedRequest)',
         requires_definition=True,
     )
 
     @validator('tc_adv_req_headers', 'tc_adv_req_params', always=True, pre=True)
-    def _always_array(cls, value: Optional[str]) -> list:
+    def _always_array(cls, value: list | str | None) -> list:
         """Return array value for headers and params."""
-        if not value:
-            value = []
-        return value
+        match value:
+            case list():
+                return value
+            case None:
+                return []
+            case _:
+                return [value]
```

### Comparing `tcex-3.0.9/tcex/input/models/aot_execution_enabled_model.py` & `tcex-4.0.0/tcex/input/model/aot_execution_enabled_model.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""AOT Execution Enabled Model"""
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 
 class AotExecutionEnabledModel(BaseModel):
     """AOT Execution Enabled Model
```

### Comparing `tcex-3.0.9/tcex/input/models/api_model.py` & `tcex-4.0.0/tcex/input/model/api_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,74 +1,78 @@
-"""API Model"""
-# pylint: disable=no-self-argument,no-self-use
-# standard library
-from typing import Optional
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 
 # third-party
 from pydantic import BaseModel, Field, validator
 
 # first-party
-from tcex.app_config.install_json import InstallJson
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.app.config.install_json import InstallJson
+from tcex.input.field_type.sensitive import Sensitive
 
 
 class ApiModel(BaseModel):
     """API Model
 
     Supported for the following runtimeLevel:
     * ApiService
     * Playbook
     * Organization
     * TriggerService
     * WebhookTriggerService
     """
 
-    api_default_org: Optional[str] = Field(
+    api_default_org: str | None = Field(
         None,
         description='The default ThreatConnect Org for the current API user.',
         inclusion_reason='runtimeLevel',
     )
     # alternate authentication credential when tc_token is not passed
-    tc_api_access_id: Optional[str] = Field(
+    tc_api_access_id: str | None = Field(
         None,
         description='A ThreatConnect API Access Id.',
         inclusion_reason='runtimeLevel',
         requires_definition=True,
     )
     tc_api_path: str = Field(
         'https://api.threatconnect.com',
         description='The URL for the ThreatConnect API.',
         inclusion_reason='runtimeLevel',
     )
     # alternate authentication credential when tc_token is not passed
-    tc_api_secret_key: Optional[Sensitive] = Field(
+    tc_api_secret_key: Sensitive | None = Field(
         None,
         description='A ThreatConnect API Secret Key.',
         inclusion_reason='runtimeLevel',
         requires_definition=True,
     )
-    tc_token: Optional[Sensitive] = Field(
+    tc_log_curl: bool = Field(
+        False,
+        description='Flag to enable logging curl commands.',
+        inclusion_reason='runtimeLevel',
+        requires_definition=True,
+    )
+    tc_token: Sensitive | None = Field(
         None,
         description='A ThreatConnect API token.',
         inclusion_reason='runtimeLevel',
     )
-    tc_token_expires: Optional[int] = Field(
+    tc_token_expires: int | None = Field(
         None,
         description='The expiration timestamp in epoch for tc_token.',
         inclusion_reason='runtimeLevel',
     )
-    tc_verify: Optional[bool] = Field(
+    tc_verify: bool = Field(
         True,
         description='Flag to enable SSL validation for API requests.',
         inclusion_reason='runtimeLevel',
         requires_definition=True,
     )
 
     @validator('tc_token', always=True, pre=True)
-    def one_set_of_credentials(cls, v, values):  # pylint: disable=E0213,R0201
+    def one_set_of_credentials(cls, v, values):
         """Validate that one set of credentials is provided for the TC API."""
         _ij = InstallJson()
 
         # external Apps: require credentials and would not have an install.json file
         # organization (job) Apps: require credentials
         # playbook Apps: require credentials
         # service Apps: get token on createConfig message or during request
```

### Comparing `tcex-3.0.9/tcex/input/models/batch_model.py` & `tcex-4.0.0/tcex/input/model/batch_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Batch Model"""
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 
 class BatchModel(BaseModel):
     """Batch Model
```

### Comparing `tcex-3.0.9/tcex/input/models/cal_settings_model.py` & `tcex-4.0.0/tcex/input/model/cal_setting_model.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-"""CAL Settings Model"""
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.input.field_type.sensitive import Sensitive
 
 
-class CalSettingsModel(BaseModel):
+class CalSettingModel(BaseModel):
     """CAL Settings Model
 
     Feature: CALSettings
 
     Supported for the following runtimeLevel:
     * ApiService
     * Playbook
```

### Comparing `tcex-3.0.9/tcex/input/models/create_config_model.py` & `tcex-4.0.0/tcex/input/model/create_config_model.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,50 +1,53 @@
-"""Create Config Model"""
-# pylint: disable=no-self-argument,no-self-use
+"""TcEx Framework Module"""
+# pylint: disable=no-self-argument
 # standard library
-from typing import Any, Dict, List
+from typing import Any
 
 # third-party
-from pydantic import BaseModel, root_validator, validator
+from pydantic import BaseModel, Extra, root_validator, validator
 
 # first-party
-from tcex.app_config import InstallJson
+from tcex.app.config import InstallJson
 
 # get instance of InstallJson
 ij = InstallJson()
 
 
 class CreateConfigModel(BaseModel):
     """Create Config Model"""
 
-    tc_playbook_out_variables: List[str]
+    tc_playbook_out_variables: list[str]
     trigger_id: int
 
     @validator('tc_playbook_out_variables', pre=True)
-    def _tc_playbook_out_variables(cls, v):
+    def _tc_playbook_out_variables(cls, v) -> list[str]:
         """Convert tc_playbook_out_variables into a list of strings.
 
         This value comes-in as a comma-separated list.
         """
         return v.split(',') if v else []
 
     # TODO: [low] workaround for PLAT-4393
     @root_validator(pre=True)
-    def _update_inputs(cls, values: Dict[str, Any]):
+    def _update_inputs(cls, values: dict[str, Any]):
         """Convert empty strings to None.
 
         Workarounds for core issues:
             - Core sends '' for field that are not populated instead of sending a null value.
             - Core sends a string for multi-value inputs instead of an array.
         """
         for field, value in values.items():
             param = ij.model.get_param(field)
-            if param.type is not None and (
-                param.type.lower() == 'multichoice' or param.allow_multiple
-            ):
+            if param is not None and (param.type.lower() == 'multichoice' or param.allow_multiple):
                 if value is not None and not isinstance(value, list):
                     values[field] = value.split(ij.model.list_delimiter or '|')
 
             if value == '':
                 values[field] = None
 
         return values
+
+    class Config:
+        """Model Config"""
+
+        extra = Extra.allow
```

### Comparing `tcex-3.0.9/tcex/input/models/logging_model.py` & `tcex-4.0.0/tcex/input/model/logging_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Logging Model"""
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 
 class LoggingModel(BaseModel):
     """Logging Model
 
@@ -17,20 +17,14 @@
     # target 50Mb in total log size (1x10Mb + 25x~1.6Mb = ~50Mb)
     tc_log_backup_count: int = Field(
         25,
         description='The maximum number of log files to retain for an App.',
         inclusion_reason='runtimeLevel',
         requires_definition=True,
     )
-    tc_log_curl: bool = Field(
-        False,
-        description='Flag to enable logging curl commands.',
-        inclusion_reason='runtimeLevel',
-        requires_definition=True,
-    )
     tc_log_file: str = Field(
         'app.log',
         description='The default name of the App\'s log file.',
         inclusion_reason='runtimeLevel',
         requires_definition=True,
     )
     # job Apps have to collect tc_log_level manually
```

### Comparing `tcex-3.0.9/tcex/input/models/model_map.py` & `tcex-4.0.0/tcex/input/model/model_map.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,105 +1,54 @@
-"""Model Map"""
+"""TcEx Framework Module"""
 
 # first-party
-from tcex.input.models.advanced_request_model import _AdvancedRequestModel
-from tcex.input.models.aot_execution_enabled_model import AotExecutionEnabledModel
-from tcex.input.models.api_model import ApiModel
-from tcex.input.models.batch_model import BatchModel
-from tcex.input.models.cal_settings_model import CalSettingsModel
-from tcex.input.models.logging_model import LoggingModel
-from tcex.input.models.organization_model import OrganizationModel
-from tcex.input.models.path_model import PathModel
-from tcex.input.models.playbook_common_model import PlaybookCommonModel
-from tcex.input.models.playbook_model import PlaybookModel
-from tcex.input.models.proxy_model import ProxyModel
-from tcex.input.models.service_model import ServiceModel
-from tcex.input.models.smtp_settings_model import SmtpSettingsModel
+from tcex.input.model.advanced_request_model import AdvancedRequestModel
+from tcex.input.model.aot_execution_enabled_model import AotExecutionEnabledModel
+from tcex.input.model.app_api_service_model import AppApiServiceModel
+from tcex.input.model.app_external_model import AppExternalModel
+from tcex.input.model.app_feed_api_service_model import AppFeedApiServiceModel
+from tcex.input.model.app_organization_model import AppOrganizationModel
+from tcex.input.model.app_playbook_model import AppPlaybookModel
+from tcex.input.model.app_trigger_service_model import AppTriggerServiceModel
+from tcex.input.model.app_webhook_trigger_service_model import AppWebhookTriggerServiceModel
+from tcex.input.model.cal_setting_model import CalSettingModel
+
+# from tcex.input.model.service_model import ServiceModel
+from tcex.input.model.smtp_setting_model import SmtpSettingModel
 
 # define feature to model map
 feature_map = {
     'aotExecutionEnabled': [AotExecutionEnabledModel],
     'appBuilderCompliant': [],
     # 'advancedRequest': [],
-    'CALSettings': [CalSettingsModel],
+    'CALSettings': [CalSettingModel],
     'fileParams': [],
     'layoutEnabledApp': [],
     'secureParams': [],
-    'smtpSettings': [SmtpSettingsModel],
+    'smtpSettings': [SmtpSettingModel],
     # features for TC Playbook loop prevention
     'CreatesGroup': [],
     'CreatesIndicator': [],
     'CreatesSecurityLabel': [],
     'CreatesTag': [],
     'DeletesGroup': [],
     'DeletesIndicator': [],
     'DeletesSecurityLabel': [],
     'DeletesTag': [],
 }
 
 # define runtime level to model map
 runtime_level_map = {
-    'apiservice': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        PathModel,
-        PlaybookCommonModel,
-        ProxyModel,
-        ServiceModel,
-    ],
-    'feedapiservice': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        PathModel,
-        PlaybookCommonModel,
-        ProxyModel,
-        ServiceModel,
-    ],
-    'external': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        ProxyModel,
-    ],
-    'organization': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        OrganizationModel,
-        PathModel,
-        ProxyModel,
-    ],
-    'playbook': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        PathModel,
-        PlaybookCommonModel,
-        PlaybookModel,
-        ProxyModel,
-        # ServiceModel,
-    ],
-    'triggerservice': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        PathModel,
-        PlaybookCommonModel,
-        ProxyModel,
-        ServiceModel,
-    ],
-    'webhooktriggerservice': [
-        ApiModel,
-        BatchModel,
-        LoggingModel,
-        PathModel,
-        PlaybookCommonModel,
-        ProxyModel,
-        ServiceModel,
-    ],
+    'apiservice': AppApiServiceModel,
+    'feedapiservice': AppFeedApiServiceModel,
+    'external': AppExternalModel,
+    'organization': AppOrganizationModel,
+    'playbook': AppPlaybookModel,
+    # special case for non-supported system based Apps
+    'system': AppOrganizationModel,
+    'triggerservice': AppTriggerServiceModel,
+    'webhooktriggerservice': AppWebhookTriggerServiceModel,
 }
 
 tc_action_map = {
-    'Advanced Request': [_AdvancedRequestModel],
+    'Advanced Request': [AdvancedRequestModel],
 }
```

### Comparing `tcex-3.0.9/tcex/input/models/path_model.py` & `tcex-4.0.0/tcex/input/model/path_model.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Path Model"""
+"""TcEx Framework Module"""
 # standard library
 import tempfile
 from pathlib import Path
 
 # third-party
 from pydantic import BaseModel, Field
 
@@ -19,26 +19,26 @@
     """
 
     #
     # ThreatConnect Provided Inputs
     #
 
     tc_in_path: Path = Field(
-        Path(tempfile.gettempdir() or '/tmp'),  # nosec
+        Path(tempfile.gettempdir()),
         description='The path to the Apps "in" directory.',
         inclusion_reason='runtimeLevel',
     )
     tc_log_path: Path = Field(
-        Path(tempfile.gettempdir() or '/tmp'),  # nosec
+        Path(tempfile.gettempdir()),
         description='The path to the Apps "log" directory.',
         inclusion_reason='runtimeLevel',
     )
     tc_out_path: Path = Field(
-        Path(tempfile.gettempdir() or '/tmp'),  # nosec
+        Path(tempfile.gettempdir()),
         description='The path to the Apps "out" directory.',
         inclusion_reason='runtimeLevel',
     )
     tc_temp_path: Path = Field(
-        Path(tempfile.gettempdir() or '/tmp'),  # nosec
+        Path(tempfile.gettempdir()),
         description='The path to the Apps "tmp" directory.',
         inclusion_reason='runtimeLevel',
     )
```

### Comparing `tcex-3.0.9/tcex/input/models/playbook_common_model.py` & `tcex-4.0.0/tcex/input/model/playbook_common_model.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-"""Playbook Common Model"""
-# standard library
-from typing import Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.input.field_type.sensitive import Sensitive
 
 
 class PlaybookCommonModel(BaseModel):
     """Playbook Common Model
 
     Supported for the following runtimeLevel:
     * ApiService
@@ -22,38 +19,35 @@
     tc_cache_kvstore_id: int = Field(
         10,
         description='The KV Store cache DB Id.',
         inclusion_reason='runtimeLevel',
     )
     tc_kvstore_host: str = Field(
         'localhost',
-        alias='tc_playbook_db_path',
         description='The KV Store hostname.',
         inclusion_reason='runtimeLevel',
     )
-    tc_kvstore_pass: Optional[Sensitive] = Field(
+    tc_kvstore_pass: Sensitive | None = Field(
         None,
         description='The KV Store password.',
         inclusion_reason='runtimeLevel',
     )
     tc_kvstore_port: int = Field(
         6379,
-        alias='tc_playbook_db_port',
         description='The KV Store port number.',
         inclusion_reason='runtimeLevel',
     )
-    tc_kvstore_user: Optional[str] = Field(
-        None,
-        description='The KV Store username.',
-        inclusion_reason='runtimeLevel',
-    )
     tc_kvstore_type: str = Field(
         'Redis',
-        alias='tc_playbook_db_type',
         description='The KV Store type (Redis or TCKeyValueAPI).',
         inclusion_reason='runtimeLevel',
     )
+    tc_kvstore_user: str | None = Field(
+        None,
+        description='The KV Store username.',
+        inclusion_reason='runtimeLevel',
+    )
     tc_playbook_kvstore_id: int = Field(
         0,
         description='The KV Store playbook DB Id.',
         inclusion_reason='runtimeLevel',
     )
```

### Comparing `tcex-3.0.9/tcex/input/models/playbook_model.py` & `tcex-4.0.0/tcex/input/model/playbook_model.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,33 +1,29 @@
-"""Playbook Model"""
-# standard library
-from typing import Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field, validator
 
 
 class PlaybookModel(BaseModel):
     """Playbook Model
 
     Supported for the following runtimeLevel:
     * Playbook
     """
 
     tc_playbook_kvstore_context: str = Field(
         None,
-        alias='tc_playbook_db_context',
         description='The KV Store context for the current App execution.',
         inclusion_reason='runtimeLevel',
     )
-    tc_playbook_out_variables: Optional[list] = Field(
+    tc_playbook_out_variables: list | None = Field(
         None,
         description='The list of requested output variables.',
         inclusion_reason='runtimeLevel',
     )
 
     @validator('tc_playbook_out_variables', pre=True)
-    def parse_tc_playbook_out_variables(cls, v):  # pylint: disable=no-self-argument,no-self-use
+    def parse_tc_playbook_out_variables(cls, v):  # pylint: disable=no-self-argument
         """Ensure value is an array."""
         if isinstance(v, str):
             v = v.split(',')
         return v
```

### Comparing `tcex-3.0.9/tcex/input/models/proxy_model.py` & `tcex-4.0.0/tcex/input/model/proxy_model.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,52 +1,49 @@
-"""Proxy Model"""
-# standard library
-from typing import Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.input.field_type.sensitive import Sensitive
 
 
 class ProxyModel(BaseModel):
     """Proxy Model
 
     Supported for the following runtimeLevel:
     * ApiService
     * Playbook
     * Organization
     * WebhookTriggerService
     * TriggerService
     """
 
-    tc_proxy_host: Optional[str] = Field(
+    tc_proxy_host: str | None = Field(
         None,
         description='The proxy hostname.',
         inclusion_reason='runtimeLevel',
     )
-    tc_proxy_port: Optional[int] = Field(
+    tc_proxy_port: int | None = Field(
         None,
         description='The proxy port number.',
         inclusion_reason='runtimeLevel',
     )
-    tc_proxy_username: Optional[str] = Field(
+    tc_proxy_username: str | None = Field(
         None,
         description='The proxy username.',
         inclusion_reason='runtimeLevel',
     )
-    tc_proxy_password: Optional[Sensitive] = Field(
+    tc_proxy_password: Sensitive | None = Field(
         None,
         description='The proxy password',
         inclusion_reason='runtimeLevel',
     )
-    tc_proxy_external: Optional[bool] = Field(
+    tc_proxy_external: bool = Field(
         False,
         description='Flag to enable proxy for external connections.',
         inclusion_reason='runtimeLevel',
     )
-    tc_proxy_tc: Optional[bool] = Field(
+    tc_proxy_tc: bool = Field(
         False,
         description='Flag to enable proxy for ThreatConnect connection.',
         inclusion_reason='runtimeLevel',
     )
```

### Comparing `tcex-3.0.9/tcex/input/models/service_model.py` & `tcex-4.0.0/tcex/input/model/service_model.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,13 @@
-"""Service Model"""
-# standard library
-from typing import Optional
-
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.input.field_type.sensitive import Sensitive
 
 
 class ServiceModel(BaseModel):
     """Input Service Model
 
     Supported runtimeLevel:
     * ApiService
@@ -35,20 +32,20 @@
         requires_definition=True,
     )
     tc_svc_broker_host: str = Field(
         None,
         description='The Broker service hostname.',
         inclusion_reason='runtimeLevel',
     )
-    tc_svc_broker_jks_file: Optional[str] = Field(
+    tc_svc_broker_jks_file: str | None = Field(
         'Unused',
         description='Input for Java Apps.',
         inclusion_reason='runtimeLevel',
     )
-    tc_svc_broker_jks_pwd: Optional[str] = Field(
+    tc_svc_broker_jks_pwd: str | None = Field(
         'Unused',
         description='Input for Java Apps.',
         inclusion_reason='runtimeLevel',
     )
     tc_svc_broker_port: int = Field(
         None,
         description='The Broker service port number.',
@@ -82,12 +79,12 @@
         requires_definition=True,
     )
     tc_svc_server_topic: str = Field(
         None,
         description='The Broker server topic (Core -> App).',
         inclusion_reason='runtimeLevel',
     )
-    tcex_testing_context: Optional[str] = Field(
+    tcex_testing_context: str | None = Field(
         None,
         description='[Testing] The testing framework context.',
         inclusion_reason='runtimeLevel',
     )
```

### Comparing `tcex-3.0.9/tcex/input/models/smtp_settings_model.py` & `tcex-4.0.0/tcex/input/model/smtp_setting_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-"""SMTP Settings Model"""
+"""TcEx Framework Module"""
 # third-party
 from pydantic import BaseModel, Field
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
+from tcex.input.field_type.sensitive import Sensitive
 
 
-class SmtpSettingsModel(BaseModel):
-    """SMTP Settings Model
+class SmtpSettingModel(BaseModel):
+    """SMTP Setting Model
 
     Feature: smtpSettings
 
     Supported for the following runtimeLevel:
     * ApiService
     * Organization
     * Playbook
```

### Comparing `tcex-3.0.9/tcex/key_value_store/key_value_abc.py` & `tcex-4.0.0/tcex/app/key_value_store/key_value_abc.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,30 @@
-"""KeyValueABC class."""
+"""TcEx Framework Module"""
 # standard library
-from abc import ABC
+from abc import ABC, abstractmethod
 from typing import Any
 
 
 class KeyValueABC(ABC):
     """Abstract base class for all KeyValue clients."""
 
-    def create(self, context: str, key: str, value: Any) -> str:
+    @abstractmethod
+    def create(self, context: str, key: str, value: Any) -> int:
         """Create key/value pair in remote KV store.
 
         Args:
             context: A specific context for the create.
             key: The key to create in KV store.
             value: The value to store in KV store.
 
         Returns:
             (string): The response from the KV store provider.
         """
 
+    @abstractmethod
     def read(self, context: str, key: str) -> Any:
         """Read data from KV store for the provided key.
 
         Args:
             context: A specific context for the create.
             key: The key to read in KV store.
```

### Comparing `tcex-3.0.9/tcex/key_value_store/key_value_redis.py` & `tcex-4.0.0/tcex/app/key_value_store/key_value_redis.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,96 +1,91 @@
-"""TcEx Framework Key Value Redis Module"""
-# standard library
-from typing import TYPE_CHECKING, Any, Optional
-
-# first-party
-# first party
-from tcex.key_value_store.key_value_abc import KeyValueABC
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.key_value_store.redis_client import RedisClient
+"""TcEx Framework Module"""
+
+# third-party
+from redis import Redis
+
+from .key_value_abc import KeyValueABC
 
 
 class KeyValueRedis(KeyValueABC):
     """TcEx Key Value Redis Module.
 
     Args:
         redis_client (redis.Client): An instance of redis client.
     """
 
-    def __init__(self, redis_client: 'RedisClient'):
+    def __init__(self, redis_client: Redis):
         """Initialize the Class properties."""
         self.redis_client = redis_client
 
         # properties
         self.kv_type = 'redis'
 
-    def create(self, context: str, key: str, value: Any):
+    def create(self, context: str, key: str, value: bytes | str) -> int:
         """Create key/value pair in Redis.
 
         Args:
             context: A specific context for the create.
-            key (str): The field name (key) for the kv pair in Redis.
-            value (any): The value for the kv pair in Redis.
+            key: The field name (key) for the kv pair in Redis.
+            value: The value for the kv pair in Redis.
 
         Returns:
-            str: The response from Redis.
+            str: The number of fields that were added.
         """
         return self.redis_client.hset(context, key, value)
 
-    def delete(self, context: str, key: str) -> str:
+    def delete(self, context: str, key: str) -> int:
         """Alias for hdel method.
 
         Args:
             context: A specific context for the create.
             key: The field name (key) for the kv pair in Redis.
 
         Returns:
             str: The response from Redis.
         """
         return self.redis_client.hdel(context, key)
 
-    def get_all(self, context: 'Optional[str]') -> 'Any':
+    def get_all(self, context: str) -> dict[str, bytes | str | None]:
         """Return the contents for a given context.
 
         Args:
             context: the context to return
         """
         return self.hgetall(context)
 
-    def hgetall(self, context: str):
+    def hgetall(self, context: str) -> dict[str, bytes | str | None]:
         """Read data from Redis for the current context.
 
         Args:
             context: A specific context for the create.
 
         Returns:
             list: The response data from Redis.
         """
         return self.redis_client.hgetall(context)
 
-    def read(self, context: str, key: str) -> Any:
+    def read(self, context: str, key: str) -> bytes | str | None:
         """Read data from Redis for the provided key.
 
         Args:
             context: A specific context for the create.
             key: The field name (key) for the kv pair in Redis.
 
         Returns:
             str: The response data from Redis.
         """
         return self.hget(context, key)
 
-    def hget(self, context: str, key: str) -> Optional[bytes]:
+    def hget(self, context: str, key: str) -> bytes | str | None:
         """Read data from redis for the provided key.
 
         This method will *not* convert the retrieved data (like read() does).
 
         Args:
             context: A specific context for the create.
             key: The field name (key) for the kv pair in Redis.
 
         Returns:
-            Optional[bytes]: the raw value from redis, if any
+            bytes | None: the raw value from redis, if any
         """
         return self.redis_client.hget(context, key)
```

### Comparing `tcex-3.0.9/tcex/key_value_store/redis_client.py` & `tcex-4.0.0/tcex/app/key_value_store/redis_client.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """TcEx Framework Module"""
+# standard library
+from functools import cached_property
+
 # third-party
 import redis
 
-# first-party
-from tcex.backports import cached_property
-
 
 class RedisClient:
     """A shared REDIS client connection using a Connection Pool.
 
     Initialize a single shared redis.connection.ConnectionPool.
     For a full list of kwargs see https://redis-py.readthedocs.io/en/latest/#redis.Connection.
```

### Comparing `tcex-3.0.9/tcex/logger/api_handler.py` & `tcex-4.0.0/tcex/logger/api_handler.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,22 @@
-"""API Handler Class"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import threading
 import time
 
+# third-party
+from requests import Session
+
 
 class ApiHandler(logging.Handler):
     """Logger handler for ThreatConnect Exchange API logging."""
 
-    def __init__(self, session, flush_limit=100):
-        """Initialize Class properties.
+    def __init__(self, session: Session, flush_limit=100):
+        """Initialize instance properties.
 
         Args:
             session (Request.Session): The pre-configured instance of Session for ThreatConnect API.
             flush_limit (int): The limit to flush batch logs to the API.
         """
         super().__init__()
         self.session = session
@@ -22,15 +25,15 @@
         self._entries_lock = threading.Lock()
         self.in_token_renewal = False
 
     def flush(self):
         """Close the logger and flush entries."""
         self.log_to_api(self.entries)  # pragma: no cover
 
-    def emit(self, record):
+    def emit(self, record: logging.LogRecord):
         """Emit a record.
 
         Args:
             record (obj): The record to be logged.
         """
         # TODO: [low] switch this after testing
         # if not threading.current_thread() is threading.main_thread():  # pragma: no cover
@@ -42,15 +45,15 @@
 
         # flush queue once limit is hit token module is currently renewing token
         if (
             len(self._entries) > self.flush_limit or record.levelname == 'ERROR'
         ) and not self.in_token_renewal:
             self.log_to_api(self.entries)
 
-    def handle(self, record):
+    def handle(self, record: logging.LogRecord):
         """Override base handle method to add logic that prevents threading deadlocks"""
         # append log entries from child threads to _entries to avoid deadlocks within handle method.
         # Otherwise, token monitor thread would try to acquire I/O lock within super().handle
         # when attempting to log messages (meaning token barrier is enabled in tokens.py).
         # if the main thread currently has the I/O lock from within super().handle and is trying
         # to retrieve a token from tokens.py to log to API, then a deadlock occurs because the
         # main thread is waiting for the barrier to be disabled, and the token thread is waiting
@@ -65,32 +68,32 @@
     def entries(self):
         """Return a copy and clear self._entries."""
         with self._entries_lock:
             entries = list(self._entries)
             self._entries = []
             return entries
 
-    def log_to_api(self, entries):
+    def log_to_api(self, entries: list[logging.LogRecord]):
         """Send log events to the ThreatConnect API"""
         if entries:
             try:
                 headers = {'Content-Type': 'application/json'}
                 self.session.post('/v2/logs/app', headers=headers, json=entries)
             except Exception:  # nosec; pragma: no cover
                 pass
 
 
 class ApiHandlerFormatter(logging.Formatter):
     """Logger formatter for ThreatConnect Exchange API logging."""
 
     def __init__(self):
-        """Initialize Class properties."""
+        """Initialize instance properties."""
         super().__init__()
 
-    def format(self, record):
+    def format(self, record: logging.LogRecord):
         """Format log record for ThreatConnect API.
 
         Example log event::
 
             [{
                 "timestamp": 1478907537000,
                 "message": "Test Message",
```

### Comparing `tcex-3.0.9/tcex/logger/cache_handler.py` & `tcex-4.0.0/tcex/logger/cache_handler.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-"""Cache Handler Class"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 
 
 class CacheHandler(logging.Handler):
     """Logger handler for caching event until all handlers are available."""
 
-    def __init__(self, max_cache=100):
-        """Initialize Class properties.
+    def __init__(self, max_cache: int = 100):
+        """Initialize instance properties.
 
         Args:
             max_cache (int): The maximum numbers of records to cache.
         """
         super().__init__()
         self.max_cache = max_cache
         self._events = []
 
-    def emit(self, record):
+    def emit(self, record: logging.LogRecord):
         """Emit a record.
 
         Args:
             record (obj): The record to be logged.
         """
         # cache log events
         if len(self._events) <= self.max_cache:
```

### Comparing `tcex-3.0.9/tcex/logger/pattern_file_handler.py` & `tcex-4.0.0/tcex/logger/rotating_file_handler_custom.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,92 +1,61 @@
-"""Request Key File Handler Class"""
+"""TcEx Framework Module"""
 # standard library
-import logging
+import gzip
 import os
-import re
-import threading
-from typing import Optional
+import shutil
+from logging.handlers import RotatingFileHandler
 
 
-class PatternFileHandler(logging.FileHandler):
-    """Logger handler for ThreatConnect Exchange Pattern logging.
-
-    This logging handler manages file limits based on a logging pattern. Given
-    the pattern and max log count the handler manage the number of log files
-    on disk.
-    """
+class RotatingFileHandlerCustom(RotatingFileHandler):
+    """Logger handler for ThreatConnect Exchange File logging."""
 
     def __init__(
         self,
         filename: str,
-        pattern: str,
-        mode: Optional[str] = 'a',
-        encoding: Optional[str] = None,
-        delay: Optional[bool] = False,
-        max_log_count: Optional[int] = 100,
+        mode: str = 'a',
+        maxBytes: int = 0,
+        backupCount: int = 0,
+        encoding: str | None = None,
+        delay: bool = False,
     ):
-        """Add logic to create log directory if it does not exists.
+        """Customize RotatingFileHandler to create full log path.
 
         Args:
             filename: The name of the logfile.
-            pattern: The pattern used to match the log files.
             mode: The write mode for the file.
+            maxBytes: The max file size before rotating.
+            backupCount: The maximum # of backup files.
             encoding: The log file encoding.
             delay: If True, then file opening is deferred until the first call to emit().
-            max_log_count: The maximum number of log files to preserve.
         """
         if encoding is None and os.getenv('LANG') is None:
             encoding = 'UTF-8'
-
-        if not os.path.exists(os.path.dirname(filename)):  # pragma: no cover
+        if not os.path.exists(os.path.dirname(filename)):
             os.makedirs(os.path.dirname(filename), exist_ok=True)
+        RotatingFileHandler.__init__(self, filename, mode, maxBytes, backupCount, encoding, delay)
 
-        # create pattern
-        self.pattern = re.compile(pattern, re.I)
-
-        # trim the number of logfiles to the max log count
-        self._trim_log_files(filename, max_log_count)
-
-        super().__init__(filename=filename, mode=mode, encoding=encoding, delay=delay)
-
-    def _trim_log_files(self, filename: str, max_log_count: int):
-        """Trim log files removing the oldest files.
+        # set namer
+        self.namer = self.custom_gzip_namer
+        self.rotator = self.custom_gzip_rotator
+
+    @staticmethod
+    def custom_gzip_namer(name):
+        """Namer for rotating log handler with gz extension.
 
         Args:
-            filename: The logfile name.
-            max_log_count: The max number of log files to keep.
-
+            name: The current name of the logfile.
         """
-        log_files = []
-        for entry in os.scandir(os.path.dirname(filename)):
-            if not entry.is_file():
-                continue
-
-            # find only matches
-            logfile_name = os.path.basename(entry.path)
-            if re.match(self.pattern, logfile_name):
-                log_files.append(entry)
-
-        # sort log file entries based on modified time
-        log_files.sort(key=lambda e: e.stat().st_mtime, reverse=True)
-
-        # remove oldest logfiles
-        for entry in log_files[max_log_count:]:
-            try:
-                os.remove(entry.path)
-            except Exception:  # nosec
-                # best effort
-                pass
-
-    def emit(self, record: object):
-        """Emit a record.
+        return name + '.gz'
 
-        Emit logging events only if handler_key matches thread_key.
+    @staticmethod
+    def custom_gzip_rotator(source: str, dest: str):
+        """Rotate and compress log file.
 
         Args:
-            record: The record to be logged.
+            source: The source filename.
+            dest: The destination filename.
         """
-        # handler_key and thread_key are added in logger.add_thread_file_handler() method
-        # pylint: disable=no-member
-        if hasattr(threading.current_thread(), self.thread_key):
-            if self.handler_key == getattr(threading.current_thread(), self.thread_key):
-                logging.FileHandler.emit(self, record)
+        with open(source, 'rb') as f_in:
+            with gzip.open(dest, 'wb') as f_out:
+                shutil.copyfileobj(f_in, f_out)
+        os.remove(source)
```

### Comparing `tcex-3.0.9/tcex/logger/sensitive_filter.py` & `tcex-4.0.0/tcex/logger/sensitive_filter.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,35 +1,31 @@
-"""TcEx logging filter module"""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from threading import Lock
 
 
 class SensitiveFilter(logging.Filter):
     """Sensitive Log Filter"""
 
     def __init__(self, name=''):
         """Plug in a new filter to an existing formatter"""
         super().__init__(name)
         self._sensitive_registry = set()
-        self._lock = Lock()
 
     def add(self, value: str):
         """Add sensitive value to registry."""
         if value:
-            with self._lock:
-                # don't add empty string
-                self._sensitive_registry.add(str(value))
+            # don't add empty string
+            self._sensitive_registry.add(str(value))
 
     def filter(self, record: logging.LogRecord) -> bool:
         """Filter the record"""
         # have to sniff the msg and args values of the LogRecord
         record.msg = self.replace(record.getMessage())
         record.args = {}
         return True
 
     def replace(self, obj: str):
         """Replace any sensitive data in the object if its a string"""
-        with self._lock:
-            for replacement in self._sensitive_registry:
-                obj = obj.replace(replacement, '***')
+        for replacement in self._sensitive_registry:
+            obj = obj.replace(replacement, '***')
         return obj
```

### Comparing `tcex-3.0.9/tcex/logger/trace_logger.py` & `tcex-4.0.0/tcex/logger/trace_logger.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,43 +1,32 @@
-"""Trace Logger Class"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 from inspect import getframeinfo, stack
 
 # Create trace logging level
-logging.TRACE = logging.DEBUG - 5
-logging.addLevelName(logging.TRACE, 'TRACE')
+logging.TRACE = logging.DEBUG - 5  # type: ignore
+logging.addLevelName(logging.TRACE, 'TRACE')  # type: ignore
 
 
 class TraceLogger(logging.Logger):
     """Add trace level to logging"""
 
     # supports updated call for Python 3.8
     def findCaller(
         self, stack_info=False, stacklevel=1
-    ):  # pylint: disable=arguments-differ,unused-argument
-        """Find the caller for the current log event.
-
-        Args:
-            stack_info (bool, optional): Defaults to False.
-
-        Returns:
-            tuple: The caller stack information.
-        """
+    ) -> tuple:  # pylint: disable=arguments-differ,unused-argument
+        """Find the caller for the current log event."""
         caller = None
         depth = 3
         while True:
             # search for the correct calling method
             caller = getframeinfo(stack()[depth][0])
             if caller.function != 'trace' or depth >= 6:
                 break
             depth += 1
 
         return (caller.filename, caller.lineno, caller.function, None)
 
     def trace(self, msg, *args, **kwargs):
-        """Set trace logging level
-
-        Args:
-            msg (str): The message to be logged.
-        """
-        self.log(logging.TRACE, msg, *args, **kwargs)
+        """Set trace logging level."""
+        self.log(logging.TRACE, msg, *args, **kwargs)  # type: ignore
```

### Comparing `tcex-3.0.9/tcex/playbook/playbook.py` & `tcex-4.0.0/tcex/app/playbook/playbook.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-"""TcEx Framework Playbook module"""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import Optional, Union
+from functools import cached_property
 
-# first-party
-from tcex.backports import cached_property
-from tcex.key_value_store import KeyValueApi, KeyValueRedis
-from tcex.playbook.playbook_create import PlaybookCreate
-from tcex.playbook.playbook_delete import PlaybookDelete
-from tcex.playbook.playbook_output import PlaybookOutput
-from tcex.playbook.playbook_read import PlaybookRead
-from tcex.utils.utils import Utils
+from ...app.key_value_store.key_value_store import KeyValueStore
+from ...util.model.playbook_variable_model import PlaybookVariableModel
+from ...util.util import Util
+from .playbook_create import PlaybookCreate
+from .playbook_delete import PlaybookDelete
+from .playbook_output import PlaybookOutput
+from .playbook_read import PlaybookRead
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class Playbook:
     """Playbook methods for accessing key value store.
 
     Args:
         key_value_store: A KV store instance.
@@ -25,36 +24,39 @@
             startup, but for service Apps each request gets a different context.
         output_variables: The requested output variables. For PB Apps outputs are provided on
             startup, but for service Apps each request gets different outputs.
     """
 
     def __init__(
         self,
-        key_value_store: Union[KeyValueApi, KeyValueRedis],
-        context: Optional[str] = None,
-        output_variables: Optional[list] = None,
+        key_value_store: KeyValueStore,
+        context: str | None = None,
+        output_variables: list | None = None,
     ):
         """Initialize the class properties."""
         self.context = context
         self.key_value_store = key_value_store
         self.output_variables = output_variables or []
 
         # properties
-        self.log = logger
-        self.utils = Utils()
+        self.log = _logger
+        self.util = Util()
 
     def check_key_requested(self, key: str) -> bool:
         """Return True if output key was requested by downstream app.
 
         Provide key should be in format "app.output".
         """
-        return key in [
-            self.utils.get_playbook_variable_model(variable).key
-            for variable in self.output_variables
-        ]
+        variables = []
+        for variable in self.output_variables:
+            var = self.util.get_playbook_variable_model(variable)
+            if isinstance(var, PlaybookVariableModel):
+                variables.append(var.key)
+
+        return key in variables
 
     def check_variable_requested(self, variable: str) -> bool:
         """Return True if output variable was requested by downstream app.
 
         Provide variable should be in format of "#App:1234:app.output!String".
         """
         return variable in self.create.output_variables
@@ -69,32 +71,41 @@
 
         #App:1234:output!StringArray returns **StringArray**
 
         Example String:
 
         "My Data" returns **String**
         """
-        return self.utils.get_playbook_variable_type(variable)
+        return self.util.get_playbook_variable_type(variable)
 
     @cached_property
-    def create(self) -> 'PlaybookCreate':
+    def create(self) -> PlaybookCreate:
         """Return instance of PlaybookCreate"""
+        if self.context is None:
+            raise RuntimeError('Playbook context is required for PlaybookCreate.')
+
         return PlaybookCreate(self.context, self.key_value_store, self.output_variables)
 
     @cached_property
-    def delete(self) -> 'PlaybookDelete':
+    def delete(self) -> PlaybookDelete:
         """Return instance of PlaybookDelete"""
+        if self.context is None:
+            raise RuntimeError('Playbook context is required for PlaybookDelete.')
+
         return PlaybookDelete(self.context, self.key_value_store)
 
     def is_variable(self, key: str) -> bool:
         """Return True if provided key is a properly formatted playbook variable."""
-        return self.utils.is_playbook_variable(key)
+        return self.util.is_playbook_variable(key)
 
     @cached_property
-    def output(self) -> 'PlaybookOutput':
+    def output(self) -> PlaybookOutput:
         """Return instance of PlaybookOutput"""
         return PlaybookOutput(self)
 
     @cached_property
-    def read(self) -> 'PlaybookRead':
+    def read(self) -> PlaybookRead:
         """Return instance of PlaybookRead"""
+        if self.context is None:
+            raise RuntimeError('Playbook context is required for PlaybookRead.')
+
         return PlaybookRead(self.context, self.key_value_store)
```

### Comparing `tcex-3.0.9/tcex/playbook/playbook_create.py` & `tcex-4.0.0/tcex/app/playbook/playbook_create.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,159 +1,163 @@
-"""Playbook Create"""
+"""TcEx Framework Module"""
 # standard library
 import base64
 import json
 import logging
 import os
-from typing import Any, Dict, Iterable, List, Optional, Union
+from collections.abc import Callable, Iterable
+from typing import Any
 
 # third-party
 from pydantic import BaseModel
 
-# first-party
-from tcex.key_value_store import KeyValueApi, KeyValueRedis
-from tcex.utils.utils import Utils
+from ...app.key_value_store import KeyValueRedis
+from ...app.key_value_store.key_value_store import KeyValueStore
+from ...util.util import Util
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class PlaybookCreate:
     """Playbook Write ABC"""
 
     def __init__(
         self,
         context: str,
-        key_value_store: Union[KeyValueApi, KeyValueRedis],
+        key_value_store: KeyValueStore,
         output_variables: list,
     ):
         """Initialize the class properties."""
         self.context = context
         self.key_value_store = key_value_store
         self.output_variables = output_variables
 
         # properties
-        self.log = logger
-        self.utils = Utils()
+        self.log = _logger
+        self.util = Util()
 
     @staticmethod
-    def _check_iterable(value: str, validate: bool):
+    def _check_iterable(value: dict | Iterable | str, validate: bool):
         """Raise an exception if value is not an Iterable.
 
         Validation:
           - not a dict (dicts are iterable)
           - not a string (strings are iterable)
           - is Iterable
         """
-        if validate is True and (isinstance(value, (dict, str)) or not isinstance(value, Iterable)):
+        if validate is True and (isinstance(value, dict | str) or not isinstance(value, Iterable)):
             raise RuntimeError('Invalid data provided for KeyValueArray.')
 
     def _check_null(self, key: str, value: Any) -> bool:
         """Return True if key or value is null."""
         invalid = False
         if key is None:
             self.log.warning('The provided key was None.')
             invalid = True
 
         if value is None:
             self.log.warning(f'The provided value for key {key} was None.')
             invalid = True
 
             # specifically to allow the tcex-test framework to validate outputs
-            if (
-                os.getenv('TC_PLAYBOOK_WRITE_NULL') is not None
-                and self.key_value_store.kv_type == 'redis'
+            if os.getenv('TC_PLAYBOOK_WRITE_NULL') is not None and isinstance(
+                self.key_value_store.client, KeyValueRedis
             ):
                 variable = self._get_variable(key)
-                self.log.trace(f'event=writing-null-to-kvstore, variable={variable}')
+                self.log.debug(f'event=writing-null-to-kvstore, variable={variable}')
                 self.key_value_store.redis_client.hset(
                     self.context, f'{variable}_NULL_VALIDATION', ''
                 )
 
         return invalid
 
-    def _check_requested(self, variable: str, when_requested: bool):
+    def _check_requested(self, variable: str, when_requested: bool) -> bool:
         """Return True if output variable was requested by downstream app."""
         if when_requested is True and not self.is_requested(variable):
             self.log.debug(f'Variable {variable} was NOT requested by downstream app.')
             return False
         return True
 
-    def _check_variable_type(self, variable: str, type_: str) -> bool:
+    def _check_variable_type(self, variable: str, type_: str):
         """Validate the correct type was passed to the method."""
-        if self.utils.get_playbook_variable_type(variable).lower() != type_.lower():
+        if self.util.get_playbook_variable_type(variable).lower() != type_.lower():
             raise RuntimeError(
                 f'Invalid variable provided ({variable}), variable must be of type {type_}.'
             )
 
     @staticmethod
-    def _coerce_string_value(value: Union[bool, float, int, str]) -> str:
+    def _coerce_string_value(value: bool | float | int | str) -> str:
         """Return a string value from an bool or int."""
         # coerce bool before int as python says a bool is an int
         if isinstance(value, bool):
             # coerce bool to str type
             value = str(value).lower()
 
         # coerce int to str type
-        if isinstance(value, (float, int)):
+        if isinstance(value, float | int):
             value = str(value)
 
         return value
 
-    def _create_data(self, key: str, value: Any):
+    def _create_data(self, key: str, value: bytes | str) -> int | None:
         """Write data to key value store."""
         self.log.debug(f'writing variable {key.strip()}')
         try:
-            return self.key_value_store.create(self.context, key.strip(), value)
+            return self.key_value_store.client.create(self.context, key.strip(), value)
         except RuntimeError as e:  # pragma: no cover
             self.log.error(e)
             return None
 
-    def _get_variable(self, key: str, variable_type: Optional[str] = None) -> str:
+    def _get_variable(self, key: str, variable_type: str | None = None) -> str | None:
         """Return properly formatted variable.
 
         A key can be provided as the variable key (e.g., app.output) or the
         entire (e.g., #App:1234:app.output!String). The full variable is required
         to create the record in the KV Store.
 
         If a variable_type is provided an exact match will be found, however if no
-        variable type is known the first key match will be returned. Uniqueness of
-        keys is not guaranteed, but in more recent Apps it is the standard.
+        variable type is known the first key to match will be returned. Uniqueness
+        of keys is not guaranteed, but in more recent Apps it is the standard.
 
         If no variable is found it means that the variable was not requested by the
         any downstream Apps or could possible be formatted incorrectly.
         """
-        if not self.utils.is_playbook_variable(key):
+        if not self.util.is_playbook_variable(key):
             # try to lookup the variable in the requested output variables.
             for output_variable in self.output_variables:
-                variable_model = self.utils.get_playbook_variable_model(output_variable)
-                if variable_model.key == key and (
-                    variable_type is None or variable_model.type == variable_type
+                variable_model = self.util.get_playbook_variable_model(output_variable)
+                if (
+                    variable_model
+                    and variable_model.key == key
+                    and (variable_type is None or variable_model.type == variable_type)
                 ):
                     # either an exact match, or first match
                     return output_variable
+
             # not requested by downstream App or misconfigured
             return None
+
         # key was already a properly formatted variable
         return key
 
     @staticmethod
-    def _serialize_data(value: str) -> str:
+    def _serialize_data(value: dict | list | str) -> str:
         """Get the value from Redis if applicable."""
         try:
             return json.dumps(value)
-        except ValueError as e:  # pragma: no cover
-            raise RuntimeError(f'Invalid data provided, failed to serialize value ({e}).')
+        except ValueError as ex:  # pragma: no cover
+            raise RuntimeError(f'Invalid data provided, failed to serialize value ({ex}).') from ex
 
     @staticmethod
     def _process_object_types(
-        value: Union[BaseModel, dict],
-        validate: Optional[bool] = True,
-        allow_none: Optional[bool] = False,
-    ) -> Dict[str, Any]:
+        value: BaseModel | dict,
+        validate: bool = True,
+        allow_none: bool = False,
+    ) -> dict[str, Any]:
         """Process object types (e.g., KeyValue, TCEntity)."""
         types = (BaseModel, dict)
         if allow_none is True:
             types = (BaseModel, dict, type(None))
 
         if validate and not isinstance(value, types):
             raise RuntimeError(f'Invalid type provided for object type ({type(value)}).')
@@ -175,183 +179,202 @@
         return variable in self.output_variables
 
     @staticmethod
     def is_tc_batch(data: dict) -> bool:
         """Return True if provided data has proper structure for TC Batch."""
         if not isinstance(data, dict):
             return False
-        if not isinstance(data.get('indicator', []), List):
+        if not isinstance(data.get('indicator', []), list):
             return False
-        if not isinstance(data.get('group', []), List):
+        if not isinstance(data.get('group', []), list):
             return False
         return True
 
     @staticmethod
     def is_tc_entity(data: dict) -> bool:
         """Return True if provided data has proper structure for TC Entity."""
         if not isinstance(data, dict):
             return False
         return all(x in data for x in ['id', 'value', 'type'])
 
     def any(
         self,
         key: str,
-        value: Union[
-            'BaseModel', bytes, dict, str, List['BaseModel'], List[bytes], List[dict], List[str]
-        ],
-        validate: Optional[bool] = True,
-        variable_type: Optional[str] = None,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[Union[bytes, dict, list, str]]:
+        value: BaseModel
+        | bytes
+        | dict
+        | str
+        | list[BaseModel]
+        | list[bytes]
+        | list[dict]
+        | list[str],
+        validate: bool = True,
+        variable_type: str | None = None,
+        when_requested: bool = True,
+    ) -> int | None:
         """Write the value to the keystore for all types.
 
         This is a quick helper method, for more advanced features
         the individual write methods should be used (e.g., binary).
 
         Args:
             key: The variable to write to the DB (e.g., app.colors).
             value: The data to write to the DB.
+            validate: Perform validation on the data.
             variable_type: The variable type being written. Only required if not unique.
-
-        Returns:
-            (str): Result string of DB write.
+            when_requested: Only write the data if the variable was requested by downstream App.
         """
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, variable_type)
+        if variable is None:
+            # variable is invalid or not requested by downstream App
+            return None
+
         if self._check_requested(variable, when_requested) is False:
+            # variable is not requested by downstream App
             return None
 
         # get the type from the variable
-        variable_type = self.utils.get_playbook_variable_type(variable).lower()
+        variable_type = self.util.get_playbook_variable_type(variable).lower()
 
         # map type to create method
-        variable_type_map = {
+        variable_type_map: dict[str, Callable] = {
             'binary': self.binary,
             'binaryarray': self.binary_array,
             'keyvalue': self.key_value,
             'keyvaluearray': self.key_value_array,
             'string': self.string,
             'stringarray': self.string_array,
             'tcentity': self.tc_entity,
             'tcentityarray': self.tc_entity_array,
             'tcbatch': self.tc_batch,
         }
-        return variable_type_map.get(variable_type, self.raw)(
-            variable, value, validate, when_requested
+        return variable_type_map.get(variable_type, self.raw)(  # type: ignore
+            variable, value, validate, when_requested  # type: ignore
         )
 
     def binary(
         self,
         key: str,
         value: bytes,
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[int]:
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, 'Binary')
+        if variable is None:
+            # variable is invalid or not requested by downstream App
+            return None
+
         if self._check_requested(variable, when_requested) is False:
+            # variable is not requested by downstream App
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'Binary')
 
         # basic validation of value
         if validate and not isinstance(value, bytes):
             raise RuntimeError('Invalid data provided for Binary.')
 
         # prepare value - playbook Binary fields are base64 encoded
-        value = base64.b64encode(value).decode('utf-8')
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        value_ = base64.b64encode(value).decode('utf-8')
+        value_ = self._serialize_data(value_)
+        return self._create_data(variable, value_)
 
     def binary_array(
         self,
         key: str,
-        value: List[bytes],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ):
+        value: list[bytes],
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # validate array type provided
         self._check_iterable(value, validate)
 
         # convert key to variable if required
         variable = self._get_variable(key, 'BinaryArray')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'BinaryArray')
 
         # basic validation and prep of value
         value_encoded = []
         for v in value:
             if v is not None:
                 if validate and not isinstance(v, bytes):
                     raise RuntimeError('Invalid data provided for Binary.')
                 v = base64.b64encode(v).decode('utf-8')
             value_encoded.append(v)
-        value = value_encoded
-
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value_encoded))
 
     def key_value(
         self,
         key: str,
-        value: Union[BaseModel, dict],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[int]:
+        value: BaseModel | dict,
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, 'KeyValue')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'KeyValue')
 
         # basic validation and prep of value
         value = self._process_object_types(value, validate)
         if validate and not self.is_key_value(value):
             raise RuntimeError('Invalid data provided for KeyValueArray.')
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def key_value_array(
         self,
         key: str,
-        value: List[Union[BaseModel, dict]],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
+        value: list[BaseModel | dict],
+        validate: bool = True,
+        when_requested: bool = True,
     ):
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # validate array type provided
         self._check_iterable(value, validate)
 
         # convert key to variable if required
         variable = self._get_variable(key, 'KeyValueArray')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'KeyValueArray')
 
         # basic validation and prep of value
@@ -359,171 +382,181 @@
         for v in value:
             v = self._process_object_types(v, validate, allow_none=True)
             if validate and not self.is_key_value(v):
                 raise RuntimeError('Invalid data provided for KeyValueArray.')
             _value.append(v)
         value = _value
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def string(
         self,
         key: str,
-        value: Union[bool, float, int, str],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[int]:
+        value: bool | float | int | str,
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, 'String')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'String')
 
         # coerce string values
         value = self._coerce_string_value(value)
 
         # validation only needs to check str because value was coerced
         if validate and not isinstance(value, str):
             raise RuntimeError('Invalid data provided for String.')
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def string_array(
         self,
         key: str,
-        value: List[Union[bool, float, int, str]],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
+        value: list[bool | float | int | str],
+        validate: bool = True,
+        when_requested: bool = True,
     ):
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # validate array type provided
         self._check_iterable(value, validate)
 
         # convert key to variable if required
         variable = self._get_variable(key, 'StringArray')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'StringArray')
 
         # basic validation and prep of value
         value_coerced = []
         for v in value:
             # coerce string values
             v = self._coerce_string_value(v)
 
             # validation only needs to check str because value was coerced
-            if validate and not isinstance(v, (type(None), str)):
+            if validate and not isinstance(v, type(None) | str):
                 raise RuntimeError('Invalid data provided for StringArray.')
             value_coerced.append(v)
         value = value_coerced
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     # pylint: disable=unused-argument
     def raw(
         self,
         key: str,
-        value: Union[bytes, str, int],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> str:
+        value: bytes | str,
+        _validate: bool = True,
+        _when_requested: bool = True,
+    ) -> int | None:
         """Create method of CRUD operation for raw data.
 
         Raw data can only be a byte, str or int. Other data
         structures (dict, list, etc) must be serialized.
         """
         if self._check_null(key, value):
             return None
 
         return self._create_data(key, value)
 
     def tc_batch(
         self,
         key: str,
-        value: Union[BaseModel, dict],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[int]:
+        value: BaseModel | dict,
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, 'TCBatch')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'TCBatch')
 
         # basic validation
         value = self._process_object_types(value, validate)
         if validate and not self.is_tc_batch(value):
             raise RuntimeError('Invalid data provided for TcBatch.')
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def tc_entity(
         self,
         key: str,
-        value: Union[BaseModel, dict],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
-    ) -> Optional[int]:
+        value: BaseModel | dict,
+        validate: bool = True,
+        when_requested: bool = True,
+    ) -> int | None:
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # convert key to variable if required
         variable = self._get_variable(key, 'TCEntity')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'TCEntity')
 
         # basic validation
         value = self._process_object_types(value, validate)
         if validate and not self.is_tc_entity(value):
             raise RuntimeError('Invalid data provided for TcEntityArray.')
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def tc_entity_array(
         self,
         key: str,
-        value: List[Union[BaseModel, dict]],
-        validate: Optional[bool] = True,
-        when_requested: Optional[bool] = True,
+        value: list[BaseModel | dict],
+        validate: bool = True,
+        when_requested: bool = True,
     ):
         """Create the value in Redis if applicable."""
         if self._check_null(key, value) is True:
             return None
 
         # validate array type provided
         self._check_iterable(value, validate)
 
         # convert key to variable if required
         variable = self._get_variable(key, 'TCEntityArray')
+        if variable is None:
+            return None
+
         if self._check_requested(variable, when_requested) is False:
             return None
 
         # quick check to ensure an invalid type was not provided
         self._check_variable_type(variable, 'TCEntityArray')
 
         # basic validation and prep of value
@@ -531,49 +564,56 @@
         for v in value:
             v = self._process_object_types(v, validate, allow_none=True)
             if validate and not self.is_tc_entity(v):
                 raise RuntimeError('Invalid data provided for TcEntityArray.')
             _value.append(v)
         value = _value
 
-        value = self._serialize_data(value)
-        return self._create_data(variable, value)
+        return self._create_data(variable, self._serialize_data(value))
 
     def variable(
         self,
         key: str,
-        value: Union[
-            'BaseModel', bytes, dict, str, List['BaseModel'], List[bytes], List[dict], List[str]
-        ],
-        variable_type: Optional[str] = None,
-    ) -> str:
+        value: BaseModel
+        | bytes
+        | dict
+        | int
+        | str
+        | list
+        | list[BaseModel | None]
+        | list[bytes | None]
+        | list[dict | None]
+        | list[str | None]
+        | None,
+        variable_type: str | None = None,
+    ) -> int | None:
         """Alias for any method of CRUD operation for working with KeyValue DB.
 
         This method will automatically check to see if provided variable was requested by
         a downstream app and if so create the data in the KeyValue DB.
 
         Args:
             key: The variable to write to the DB (e.g., app.colors).
             value: The data to write to the DB.
             variable_type: The variable type being written. Only required if not unique.
-
-        Returns:
-            (str): Result string of DB write.
         """
         if self._check_null(key, value) is True:
             return None
 
-        # short-circuit the process, if there are no dowstream variables requested.
+        # short-circuit the process, if there are no downstream variables requested.
         if not self.output_variables:  # pragma: no cover
             self.log.debug(f'Variable {key} was NOT requested by downstream app.')
             return None
 
         # key can be provided as the variable key (e.g., app.output) or
         # the entire (e.g., #App:1234:app.output!String). we need the
         # full variable to proceed.
         variable = self._get_variable(key, variable_type)
+        if variable is None:
+            return None
+
         if variable is None or variable not in self.output_variables:
             self.log.debug(f'Variable {key} was NOT requested by downstream app.')
             return None
 
-        # write the variable
-        return self.any(variable, value)
+        # write the variable (None value would be caught in _check_null method)
+        return self.any(variable, value)  # type: ignore
```

### Comparing `tcex-3.0.9/tcex/playbook/playbook_delete.py` & `tcex-4.0.0/tcex/app/playbook/playbook_delete.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,40 +1,34 @@
-"""Playbook delete."""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import Union
 
-# first-party
-from tcex.key_value_store import KeyValueApi, KeyValueRedis
-from tcex.utils.utils import Utils
+from ...app.key_value_store import KeyValueRedis
+from ...app.key_value_store.key_value_store import KeyValueStore
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class PlaybookDelete:
-    """Playbook Write ABC"""
+    """Playbook Delete"""
 
-    def __init__(
-        self,
-        context: str,
-        key_value_store: Union[KeyValueApi, KeyValueRedis],
-    ):
+    def __init__(self, context: str, key_value_store: KeyValueStore):
         """Initialize the class properties."""
         self.context = context
         self.key_value_store = key_value_store
 
         # properties
-        self.log = logger
-        self.utils = Utils()
+        self.log = _logger
 
-    def variable(self, key: str) -> str:
+    def variable(self, key: str | None) -> int | None:
         """Delete method of CRUD operation for all data types.
 
         Only supported when using the Redis KV store.
         """
-        data = None
-        if key is not None:
-            data = self.key_value_store.delete(self.context, key.strip())
-        else:  # pragma: no cover
-            self.log.warning('The key field was None.')
-        return data
+        if key is None:
+            return None
+
+        if not isinstance(self.key_value_store.client, KeyValueRedis):
+            return None
+
+        return self.key_value_store.client.delete(self.context, key.strip())
```

### Comparing `tcex-3.0.9/tcex/playbook/playbook_output.py` & `tcex-4.0.0/tcex/app/playbook/playbook_output.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,18 +1,13 @@
-"""Playbook ABC"""
+"""TcEx Framework Module"""
 # standard library
-import logging
 from typing import TYPE_CHECKING
 
 if TYPE_CHECKING:
-    # first-party
-    from tcex.playbook.playbook import Playbook
-
-# get tcex logger
-logger = logging.getLogger('tcex')
+    from ..app.playbook.playbook import Playbook  # type: ignore # pylint: disable=import-error
 
 
 class PlaybookOutput(dict):
     """Playbook Output
 
     Args:
         playbook: An instance of Playbook.
```

### Comparing `tcex-3.0.9/tcex/playbook/playbook_read.py` & `tcex-4.0.0/tcex/app/playbook/playbook_read.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,248 +1,171 @@
-"""Playbook ABC"""
+"""TcEx Framework Module"""
 # standard library
 import base64
 import json
 import logging
 import re
 from collections import OrderedDict
-from typing import Any, List, Optional, Union
+from typing import Any
 
-# first-party
-from tcex.key_value_store import KeyValueApi, KeyValueRedis
-from tcex.pleb.registry import registry
-from tcex.utils.utils import Utils
-from tcex.utils.variables import BinaryVariable, StringVariable
+from ...app.key_value_store.key_value_store import KeyValueStore
+from ...registry import registry
+from ...util.util import Util
+from ...util.variable import BinaryVariable, StringVariable
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class PlaybookRead:
     """Playbook Read
 
     Args:
         key_value_store: A KV store instance.
         context: The KV Store context/session_id. For PB Apps the context is provided on
             startup, but for service Apps each request gets a different context.
         output_variables: The requested output variables. For PB Apps outputs are provided on
             startup, but for service Apps each request gets different outputs.
     """
 
-    def __init__(
-        self,
-        context: str,
-        key_value_store: Union[KeyValueApi, KeyValueRedis],
-    ):
+    def __init__(self, context: str, key_value_store: KeyValueStore):
         """Initialize the class properties."""
         self.context = context
         self.key_value_store = key_value_store
 
         # properties
-        self.log = logger
-        self.utils = Utils()
+        self.log = _logger
+        self.util = Util()
 
-    def _check_variable_type(self, variable: str, type_: str) -> bool:
+    def _check_variable_type(self, variable: str, type_: str):
         """Validate the correct type was passed to the method."""
-        if self.utils.get_playbook_variable_type(variable).lower() != type_.lower():
+        if self.util.get_playbook_variable_type(variable).lower() != type_.lower():
             raise RuntimeError(
                 f'Invalid variable provided ({variable}), variable must be of type {type_}.'
             )
 
     @staticmethod
-    def _coerce_string_value(value: Union[bool, float, int, str]) -> str:
+    def _coerce_string_value(value: bool | float | int | str) -> str:
         """Return a string value from an bool or int."""
         # coerce bool before int as python says a bool is an int
         if isinstance(value, bool):
             # coerce bool to str type
             value = str(value).lower()
 
         # coerce int to str type
-        if isinstance(value, (float, int)):
+        if isinstance(value, float | int):
             value = str(value)
 
         return value
 
     @staticmethod
     def _decode_binary(data: bytes) -> str:
         """Return decoded bytes data handling data written by java apps."""
         try:
-            data = data.decode('utf-8')
+            _data = data.decode('utf-8')
         except UnicodeDecodeError:  # pragma: no cover
             # for data written an upstream java App
-            data = data.decode('latin-1')
-        return data
+            _data = data.decode('latin-1')
+        return _data
 
-    def _get_data(self, key: str) -> Any:
+    @staticmethod
+    def _deserialize_data(value: bytes | str) -> Any:
+        """Return the loaded JSON value or raise an error."""
+        try:
+            return json.loads(value, object_pairs_hook=OrderedDict)
+        except ValueError as ex:  # pragma: no cover
+            raise RuntimeError(f'Failed to JSON load data "{value}" ({ex}).') from ex
+
+    def _get_data(self, key: str) -> bytes | str | None:
         """Get the value from Redis if applicable."""
-        value = None
         try:
-            value = self.key_value_store.read(self.context, key.strip())
-        except RuntimeError as e:
-            self.log.error(e)
-        return value
+            return self.key_value_store.client.read(self.context, key.strip())
+        except RuntimeError as ex:
+            self.log.error(ex)
+        return None
 
     @staticmethod
-    def _load_data(value: str) -> dict:
+    def _load_data(value: str) -> dict | list[dict | str] | str:
         """Return the loaded JSON value or raise an error."""
         try:
             return json.loads(value, object_pairs_hook=OrderedDict)
-        except ValueError as e:  # pragma: no cover
-            raise RuntimeError(f'Failed to JSON load data "{value}" ({e}).')
+        except ValueError as ex:  # pragma: no cover
+            raise RuntimeError(f'Failed to JSON load data "{value}" ({ex}).') from ex
 
     def _null_key_check(self, key: Any) -> bool:
         """Return False if value is not null."""
         if key is None:
             self.log.warning('The provided key was None.')
             return True
 
         return False
 
-    def _process_binary(
-        self, data: str, b64decode: bool, decode: bool, serialized: bool
-    ) -> Optional[Union[str, bytes]]:
-        """Process the provided."""
-        if data is not None:
-            # Single type are serialized, array types are not
-            if serialized is True:
-                data = self._load_data(data)
-
-            if b64decode is True:
-                data = BinaryVariable(base64.b64decode(data))
-                if decode is True:
-                    # allow developer to decided if they want bytes or str
-                    data = self._decode_binary(data)
-            elif isinstance(data, bytes):
-                # data is likely returned base64 encoded bytes string, the App
-                # should get the base64 as a str if b64decode is False
-                data = data.decode()
-
-        return data
-
-    def _process_key_value(
-        self, data: str, resolve_embedded: bool, serialized: bool
-    ) -> Optional[dict]:
+    def _process_key_value(self, data: dict, resolve_embedded: bool) -> dict | None:
         """Read the value from key value store.
 
         KeyValue data should be stored as a JSON string.
         """
-        if data is not None:
-            # decode in case data comes back from kvstore as bytes
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Single type are serialized, array types are not
-            if serialized is True:
-                data = self._load_data(data)
-
-            # IMPORTANT:
-            # A Single level of nested variables is supported. There is no way
-            # in the TC platform to create double nested variables. Any App
-            # that would try and create a double nested variable is improperly
-            # written.
-
-            # KeyValue List Input
-            # -------------------------------------------------------------
-            # | key                         | value                       |
-            # =============================================================
-            # | my_binary                   | #App:7979:two!Binary        |
-            # -------------------------------------------------------------
-            # | my_binary_array             | #App:7979:two!BinaryArray   |
-            # -------------------------------------------------------------
-            # | my_key_value                | #App:7979:two!KeyValue      |
-            # -------------------------------------------------------------
-            # | my_key_value_array          | #App:7979:two!KeyValueArray |
-            # -------------------------------------------------------------
-            # | my_string                   | #App:7979:two!String        |
-            # -------------------------------------------------------------
-            # | my_string_array             | #App:7979:two!StringArray   |
-            # -------------------------------------------------------------
-            # | my_tcentity                 | #App:7979:two!TCEntity      |
-            # -------------------------------------------------------------
-            # | my_tcentity_array           | #App:7979:two!TCEntityArray |
-            # -------------------------------------------------------------
-
-            # An upstream Apps KeyValue output can be used in a KeyValueList input, but
-            # Apps SHOULD NOT be writing KeyValueArray with nested variables. This means
-            # that there will only ever be 1 levels of nesting.
-
-            # KeyValueList Input -> Nested KeyValue/KeyValueArray, the nested
-            # KeyValue/KeyValueArray CAN NOT have nested variables since they
-            # have to come from an upstream App.
-
-            # check if keyvalue value is a variable
-            if resolve_embedded:
-                value = data.get('value')
-                if self.utils.is_playbook_variable(value):
-                    # any type can be nested, but no further nesting is supported
-                    data['value'] = self.any(value)
-                else:
-                    # read embedded is less efficient and has more caveats
-                    data['value'] = self._read_embedded(value)
+        # IMPORTANT:
+        # A Single level of nested variables is supported. There is no way
+        # in the TC platform to create double nested variables. Any App
+        # that would try and create a double nested variable is improperly
+        # written.
+
+        # KeyValue List Input
+        # -------------------------------------------------------------
+        # | key                         | value                       |
+        # =============================================================
+        # | my_binary                   | #App:7979:two!Binary        |
+        # -------------------------------------------------------------
+        # | my_binary_array             | #App:7979:two!BinaryArray   |
+        # -------------------------------------------------------------
+        # | my_key_value                | #App:7979:two!KeyValue      |
+        # -------------------------------------------------------------
+        # | my_key_value_array          | #App:7979:two!KeyValueArray |
+        # -------------------------------------------------------------
+        # | my_string                   | #App:7979:two!String        |
+        # -------------------------------------------------------------
+        # | my_string_array             | #App:7979:two!StringArray   |
+        # -------------------------------------------------------------
+        # | my_tcentity                 | #App:7979:two!TCEntity      |
+        # -------------------------------------------------------------
+        # | my_tcentity_array           | #App:7979:two!TCEntityArray |
+        # -------------------------------------------------------------
+
+        # An upstream Apps KeyValue output can be used in a KeyValueList input, but
+        # Apps SHOULD NOT be writing KeyValueArray with nested variables. This means
+        # that there will only ever be 1 levels of nesting.
+
+        # KeyValueList Input -> Nested KeyValue/KeyValueArray, the nested
+        # KeyValue/KeyValueArray CAN NOT have nested variables since they
+        # have to come from an upstream App.
+
+        # check if keyvalue value is a variable
+        if resolve_embedded:
+            value = data['value']
+            if self.util.is_playbook_variable(value):
+                # any type can be nested, but no further nesting is supported
+                data['value'] = self.any(value)
+            else:
+                # read embedded is less efficient and has more caveats
+                data['value'] = self._read_embedded(value)
 
         return data
 
     @staticmethod
     def _process_space_patterns(string: str) -> str:
         r"""Return the string with \s replace with spaces."""
         # replace "\s" with a space only for user input.
         # using '\\s' will prevent replacement.
         string = re.sub(r'(?<!\\)\\s', ' ', string)
         string = re.sub(r'\\\\s', r'\\s', string)
         return string
 
-    def _process_string(self, data: str, resolve_embedded: bool, serialized: bool) -> Optional[str]:
-        """Process the provided."""
-        if data is not None:
-            # decode in case data comes back from kvstore as bytes
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Single type are serialized, array types are not
-            if serialized is True:
-                data = self._load_data(data)
-
-            # only resolve embedded variables if resolve_embedded is True and
-            # the entire string does not exactly match a variable pattern
-            if resolve_embedded and not self.utils.is_playbook_variable(data):
-                data = self._read_embedded(data)
-
-            # coerce data back to string, since technically TC doesn't support bool, int, etc
-            data = StringVariable(self._coerce_string_value(data))
-
-        return data
-
-    def _process_tc_batch(self, data: str, serialized: bool) -> Optional[dict]:
-        """Process the provided."""
-        if data is not None:
-            # decode in case data comes back from kvstore as bytes
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Single type are serialized, array types are not
-            if serialized is True:
-                data = self._load_data(data)
-
-        return data
-
-    def _process_tc_entity(self, data: str, serialized: bool) -> Optional[dict]:
-        """Process the provided."""
-        if data is not None:
-            # decode in case data comes back from kvstore as bytes
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Single type are serialized, array types are not
-            if serialized is True:
-                data = self._load_data(data)
-
-        return data
-
     def _read_embedded(self, value: str) -> str:
-        """Read method for "embedded" variables.
+        r"""Read method for "embedded" variables.
 
         .. Note:: The ``read()`` method will automatically determine if the input is a variable or
             needs to be searched for embedded variables.
 
         Embedded variable rules:
 
         * Only user input can have embedded variables.
@@ -285,65 +208,66 @@
 
         Returns:
             (str): Results retrieved from DB
         """
         if value is None:  # pragma: no cover
             return value
 
-        for match in re.finditer(self.utils.variable_expansion_pattern, str(value)):
+        for match in re.finditer(self.util.variable_expansion_pattern, str(value)):
             variable = match.group(0)  # the full variable pattern
+            v = None
             if match.group('origin') == '#':  # pb-variable
                 v = self.any(variable)
             elif match.group('origin') == '&':  # tc-variable
-                v = registry.resolve_variable(variable)
+                v = registry.inputs.resolve_variable(variable)
 
             # TODO: [high] should this behavior be changed in 3.0?
-            self.log.trace(f'embedded variable: {variable}, value: {v}')
+            self.log.debug(f'embedded variable: {variable}, value: {v}')
 
             if match.group('type') in ['Binary', 'BinaryArray']:
-                self.log.trace(
+                self.log.debug(
                     f'Binary types may not be embedded into strings. Could not embed: {variable}'
                 )
                 v = '<binary>'
 
-            if isinstance(v, (dict, list)):
+            if isinstance(v, dict | list):
                 v = json.dumps(v)
-
             elif v is None:
                 v = '<null>'
 
             # value.replace was chosen over re.sub due to an issue encountered while testing an app.
             # re.sub will handle escaped characters like \t, value.replace would not handle these
             # scenarios.
-            value = value.replace(variable, v)
+            if isinstance(v, str):
+                value = value.replace(variable, v)
 
         return StringVariable(value)
 
     @staticmethod
-    def _to_array(value: Optional[Union[List, str]]) -> List:
+    def _to_array(value: list | str | None) -> list:
         """Return the provided array as a list."""
         if value is None:
             # Adding none value to list breaks App logic. It's better to not request
             # Array and build array externally if None values are required.
             value = []
         elif not isinstance(value, list):
             value = [value]
         return value
 
-    def any(self, key: str) -> Optional[Union[bytes, dict, list, str]]:
+    def any(self, key: str) -> bytes | dict | list | str | None:
         """Return the value from the keystore for all types.
 
         This is a quick helper method, for more advanced features
         the individual read methods should be used (e.g., binary).
         """
         if self._null_key_check(key) is True:
             return None
 
         key = key.strip()  # clean up key
-        variable_type = self.utils.get_playbook_variable_type(key).lower()
+        variable_type = self.util.get_playbook_variable_type(key).lower()
         variable_type_map = {
             'binary': self.binary,
             'binaryarray': self.binary_array,
             'keyvalue': self.key_value,
             'keyvaluearray': self.key_value_array,
             'string': self.string,
             'stringarray': self.string_array,
@@ -365,259 +289,347 @@
                 value = [v if v is None else StringVariable(v) for v in value]
 
         return value
 
     def binary(
         self,
         key: str,
-        b64decode: Optional[bool] = True,
-        decode: Optional[bool] = False,
-    ) -> Optional[Union[str, bytes]]:
+        b64decode: bool = True,
+        decode: bool = False,
+    ) -> BinaryVariable | str | None:
         """Read the value from key value store.
 
-        Binary data should be stored as base64 encoded string.
+        The binary write method base64 encodes the data, then decodes the bytes to string, and
+        finally serializes the string before writing to the key value store.
+
+        This method will deserialize the string, then OPTIONALLY base64 decode the data, and
+        finally return the Binary data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'Binary')
 
-        data: Optional[str] = self._get_data(key)
-        return self._process_binary(data, b64decode=b64decode, decode=decode, serialized=True)
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # reverse the order of the binary create/write method
+        # 1. deserialize the data
+        # 2. base64 decode the data
+
+        # deserialize the data
+        data = self._deserialize_data(data)
+
+        # base64 decode the data (get_data returns multiple types, but the binary
+        # write method will always write a base64.encoded->bytes.decoded->serialized string)
+        # for the testing framework, the base64 encoded string should be returned so that
+        # the data can be compared to the expected value stored in the test profile.
+        if b64decode is True and isinstance(data, str):
+            data = BinaryVariable(base64.b64decode(data))
+            if decode is True:
+                # allow developer to decided if they want bytes or str
+                data = self._decode_binary(data)
+        elif isinstance(data, bytes):
+            # data should never be returned as bytes, but just in case an old App is using an
+            # older version of TcEx or if the TC Platform is writes binary data to the key value
+            # store, decode the bytes to a string
+            data = self._decode_binary(data)
+
+        return data
 
     def binary_array(
         self,
         key: str,
-        b64decode: Optional[bool] = True,
-        decode: Optional[bool] = False,
-    ) -> Optional[List[Union[bytes, str]]]:
+        b64decode: bool = True,
+        decode: bool = False,
+    ) -> list[BinaryVariable | str] | None:
         """Read the value from key value store.
 
-        BinaryArray data should be stored as base64 encoded serialized string.
+        The binary array write method iterates over the BinaryArray and base64 encodes the data,
+        then decodes the bytes to string, and finally serializes the array before writing to the
+        key value store.
+
+        This method will deserialize the string, then iterate over the array and OPTIONALLY base64
+        decode the data, and finally return the BinaryArray.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'BinaryArray')
 
-        data: Optional[str] = self._get_data(key)
-        if data is not None:
-            # data should be base64 encoded bytes string
-
-            # decode the entire response, but not the items in the array?
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Array type is serialized before writing to redis, deserialize the data
-            data = self._load_data(data)
-
-            values = []
-            for d in data:
-                # d should be a base64 encoded string
-                values.append(
-                    self._process_binary(d, b64decode=b64decode, decode=decode, serialized=False)
-                )
-            data = values
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
 
-        return data
+        # reverse the order of the binary create/write method
+        # 1. deserialize the data
+        # 2. iterate over the array
+        # 3. base64 decode the data
+
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode('utf-8')
+
+        # deserialize the data
+        _data: list[str] = self._deserialize_data(data)
+
+        values = []
+        for d in _data:
+            if b64decode is True and isinstance(d, str):
+                d = BinaryVariable(base64.b64decode(d))
+                if decode is True:
+                    # allow developer to decided if they want bytes or str
+                    d = self._decode_binary(d)
+            values.append(d)
+        return values
 
     def key_value(
         self,
         key: str,
-        resolve_embedded: Optional[bool] = True,
-    ) -> Optional[dict]:
+        resolve_embedded: bool = True,
+    ) -> dict | None:
         """Read the value from key value store.
 
         KeyValue data should be stored as a JSON string.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'KeyValue')
 
-        data: Optional[str] = self._get_data(key)
-        return self._process_key_value(data, resolve_embedded=resolve_embedded, serialized=True)
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # deserialize the data
+        data = self._deserialize_data(data)
+
+        return self._process_key_value(data, resolve_embedded=resolve_embedded)
 
     def key_value_array(
         self,
         key: str,
-        resolve_embedded: Optional[bool] = True,
-    ) -> Optional[List[str]]:
+        resolve_embedded: bool = True,
+    ) -> list[dict] | None:
         """Read the value from key value store.
 
         KeyValueArray data should be stored as serialized string.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'KeyValueArray')
 
-        data: Optional[str] = self._get_data(key)
-        if data is not None:
-            # data should be string
-
-            # decode the entire response, but not the items in the array?z
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Array type is serialized before writing to redis, deserialize the data
-            data = self._load_data(data)
-
-            values = []
-            for d in data:
-                # d should be a base64 encoded string
-                values.append(
-                    self._process_key_value(d, resolve_embedded=resolve_embedded, serialized=False)
-                )
-            data = values
+        data = self._get_data(key)
+        if data is None:
+            return None
 
-        return data
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
+
+        # Array type is serialized before writing to redis, deserialize the data
+        _data: list[dict] = self._deserialize_data(data)
+
+        values = []
+        for d in _data:
+            # d should be a base64 encoded string
+            values.append(self._process_key_value(d, resolve_embedded=resolve_embedded))
+        return values
 
-    def raw(self, key: str) -> Optional[any]:
+    def raw(self, key: str) -> Any | None:
         """Read method of CRUD operation for raw data.
 
         Bytes input will be returned a as string as there is no way
         to determine data from redis originated as bytes or string.
         """
         if self._null_key_check(key) is True:
             return None
 
-        return self.key_value_store.read(self.context, key.strip())
+        return self.key_value_store.client.read(self.context, key.strip())
 
     def string(
         self,
         key: str,
-        resolve_embedded: Optional[bool] = True,
-    ) -> Optional[str]:
+        resolve_embedded: bool = True,
+    ) -> StringVariable | None:
         """Read the value from key value store.
 
-        String data should be stored as serialized string.
+        The string write method serializes the string before writing to the key value store.
+
+        This method will deserialize the string and finally return the StringArray data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'String')
 
-        data: Optional[str] = self._get_data(key)
-        return self._process_string(data, resolve_embedded=resolve_embedded, serialized=True)
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
+
+        # deserialize the data
+        data = self._deserialize_data(data)
+
+        # only resolve embedded variables if resolve_embedded is True and
+        # the entire string does not exactly match a variable pattern
+        if resolve_embedded and not self.util.is_playbook_variable(data):
+            data = self._read_embedded(data)
+
+        # coerce data back to string, since technically TC doesn't support bool, int, etc
+        return StringVariable(self._coerce_string_value(data))
 
-    def string_array(self, key: str) -> Optional[List[str]]:
+    def string_array(self, key: str) -> list[StringVariable] | None:
         """Read the value from key value store.
 
-        StringArray data should be stored as serialized string.
+        The string_array write method serializes the list of strings before writing to the key value
+        store.
+
+        This method will deserialize the list of strings and finally return the StringArray data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'StringArray')
 
-        data: Optional[str] = self._get_data(key)
-        if data is not None:
-            # data should be string
-
-            # decode the entire response
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Array type is serialized before writing to redis, deserialize the data
-            data = self._load_data(data)
-
-            values = []
-            for d in data:
-                values.append(self._process_string(d, resolve_embedded=False, serialized=False))
-            data = values
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
 
-        return data
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
+
+        # deserialize the data
+        _data: list[str] = self._deserialize_data(data)
+
+        # return array of StringVariables
+        # return [StringVariable(self._coerce_string_value(d)) for d in _data]
+        return [d if d is None else StringVariable(self._coerce_string_value(d)) for d in _data]
 
-    def tc_batch(self, key: str) -> Optional[dict]:
+    def tc_batch(self, key: str) -> dict | None:
         """Read the value from key value store.
 
-        TCBatch data should be stored as serialized string.
+        The tc_batch write method serializes the string before writing to the key value store.
+
+        This method will deserialize the string and finally return the TCBatch data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'TCBatch')
 
-        data: Optional[str] = self._get_data(key)
-        return self._process_tc_batch(data, serialized=True)
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
+
+        return self._deserialize_data(data)
 
-    def tc_entity(self, key: str) -> Optional[dict]:
+    def tc_entity(self, key: str) -> dict[str, str] | None:
         """Read the value from key value store.
 
-        TCEntity data should be stored as serialized string.
+        The tc_entity write method serializes the dict before writing to the key value store.
+
+        This method will deserialize the string and finally return the TCEntity data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'TCEntity')
 
-        data: Optional[str] = self._get_data(key)
-        return self._process_tc_entity(data, serialized=True)
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
+
+        # deserialize the data
+        return self._deserialize_data(data)
 
     def tc_entity_array(
         self,
         key: str,
-    ) -> Optional[List[str]]:
+    ) -> list[dict[str, str]] | None:
         """Read the value from key value store.
 
-        TCEntityArray data should be stored as serialized string.
+        The tc_entity_array write method serializes the list of dicts before writing to the key
+        value store.
+
+        This method will deserialize the list of dicts and finally return the TCEntityArray data.
         """
         if self._null_key_check(key) is True:
             return None
 
         # quick check to ensure an invalid key was not provided
         self._check_variable_type(key, 'TCEntityArray')
 
-        data: Optional[str] = self._get_data(key)
-        if data is not None:
-            # data should be string
-
-            # decode the entire response
-            if isinstance(data, bytes):
-                data = data.decode()
-
-            # Array type is serialized before writing to redis, deserialize the data
-            data = self._load_data(data)
-
-            values = []
-            for d in data:
-                # d should be a base64 encoded string
-                values.append(self._process_tc_entity(d, serialized=False))
-            data = values
+        # get the data from the key value store
+        data = self._get_data(key)
+        if data is None:
+            return None
+
+        # data should be a serialized string, but in case there are any legacy Apps that are
+        # using an older version of TcEx, check for bytes and decode to string
+        if isinstance(data, bytes):
+            data = data.decode()
 
-        return data
+        # deserialize the data
+        return self._deserialize_data(data)
 
-    def variable(
-        self, key: str, array: Optional[bool] = False
-    ) -> Optional[Union[bytes, dict, list, str]]:
+    def variable(self, key: str | None, array: bool = False) -> bytes | dict | list | str | None:
         """Read method of CRUD operation for working with KeyValue DB.
 
         This method will automatically check to see if a single variable is passed
         or if "mixed" data is passed and return the results from the DB. It will also
         automatically determine the variable type to read.
         """
         value = key
-        if isinstance(key, str):
+        if value is not None and isinstance(key, str):
             key = key.strip()
 
-            if re.match(self.utils.variable_playbook_match, key):
+            if re.match(self.util.variable_playbook_match, key):
                 value = self.any(key=key)
             else:
                 # replace space patterns
                 value = self._process_space_patterns(value)
 
                 # key must be an embedded variable
                 value = self._read_embedded(value)
 
         if array is True:
-            value = self._to_array(value)
+            if isinstance(value, list | str):
+                value = self._to_array(value)
+            elif value is None:
+                value = []
 
         return value
```

### Comparing `tcex-3.0.9/tcex/pleb/env_path.py` & `tcex-4.0.0/tcex/pleb/env_path.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,37 +1,39 @@
-"""ENV Str"""
+"""TcEx Framework Module"""
 # standard library
 import os
 import re
+from collections.abc import Generator
 from pathlib import Path
-from typing import Any, Dict, Union
+from typing import Any
 
 
-class _EnvPath(type(Path()), Path):  # pylint: disable=E0241
+# pylint: disable=duplicate-bases
+class _EnvPath(type(Path()), Path):  # type: ignore
     """A stub of Path with additional attribute."""
 
     # store for the original value passed to EnvPath
-    original_value = None
+    original_value: str | None = None
 
 
 class EnvPath(Path):
     """EnvPath custom pydantic model type."""
 
     @classmethod
-    def __modify_schema__(cls, field_schema: Dict[str, Any]):
+    def __modify_schema__(cls, field_schema: dict[str, Any]):
         """."""
         field_schema.update(format='file-path')
 
     @classmethod
-    def __get_validators__(cls) -> 'CallableGenerator':  # noqa: F821
+    def __get_validators__(cls) -> Generator:
         """."""
         yield cls.validate
 
     @classmethod
-    def validate(cls, value: Union[str, 'Path']) -> 'Path':
+    def validate(cls, value: Path | str) -> Path | str:
         """Replace any environment variables in the tcex.json file."""
         if isinstance(value, Path):
             return value
 
         string = str(value)
         for m in re.finditer(r'\${(env|envs|local|remote):(.*?)}', string):
             try:
```

### Comparing `tcex-3.0.9/tcex/pleb/event.py` & `tcex-4.0.0/tcex/pleb/event.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,25 +1,27 @@
-"""Event"""
-# first-party
-from tcex.pleb.singleton import Singleton
+"""TcEx Framework Module"""
+# standard library
+from collections.abc import Callable
+
+from .singleton import Singleton
 
 
 class Event(metaclass=Singleton):
     """Event Class"""
 
     def __init__(self):
-        """."""
+        """Initialize instance properties."""
         self.channels = {}
 
     def send(self, channel: str, **kwargs):
         """Send message to channel."""
         for callback in self.channels.get(channel, []):
             callback(**kwargs)
 
-    def subscribe(self, channel: str, callback: callable):
+    def subscribe(self, channel: str, callback: Callable):
         """Subscribe to a channel with a callback."""
         self.channels.setdefault(channel, [])
         self.channels[channel].append(callback)
 
-    def unsubscribe(self, channel: str, callback: callable):
+    def unsubscribe(self, channel: str, callback: Callable):
         """Subscribe to a channel with a callback."""
         self.channels[channel].remove(callback)
```

### Comparing `tcex-3.0.9/tcex/pleb/registry.py` & `tcex-4.0.0/tcex/registry.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-"""TcEx Registry"""
+"""TcEx Framework Module"""
 # standard library
 import functools
-from collections.abc import Container
-from typing import TYPE_CHECKING, Any, Callable, Tuple, Type, TypeVar, Union
+from collections.abc import Callable, Container
+from typing import TYPE_CHECKING, Any, TypeVar
 
-if TYPE_CHECKING:
-    # third-party
-    from redis import Redis
+# third-party
+from redis import Redis
 
-    # first-party
-    from tcex.exit.exit import ExitService
-    from tcex.input.input import Input
-    from tcex.key_value_store.key_value_api import KeyValueApi
-    from tcex.key_value_store.key_value_redis import KeyValueRedis
-    from tcex.playbook.playbook import Playbook
-    from tcex.sessions.tc_session import TcSession
-    from tcex.tokens import Tokens
+if TYPE_CHECKING:
+    from .app.app import App
+    from .app.playbook.playbook import Playbook
+    from .app.token import Token
+    from .exit.exit import Exit
+    from .input.input import Input
+    from .logger.logger import Logger
+    from .requests_tc import RequestsTc, TcSession
 
 T = TypeVar('T')
 
 
 class Registry(Container):
     """Dynamic service registry that supports raw values, factories, and factory providers.
 
@@ -28,18 +27,18 @@
             type or name.
         Factory - A callable that can return an instance that fulfills a type or name.
         Provider - An object with one or more members that are factories (as denoted by the
             @factory decorator)
     """
 
     def __init__(self):
-        """Initialize class properties."""
+        """Initialize instance properties."""
         self._values = {}
 
-    def add_service(self, type_or_name: Union[str, Type], value: Any):
+    def add_service(self, type_or_name: str | type, value: Any):
         """Add an instance of a type to this registry.
 
         A service is a single instance of the given type.
 
         Args:
             type_or_name: the concrete type of the provided service, or a name (MyClass or
             'MyClass')
@@ -51,15 +50,15 @@
         """Add an instance method to the registry.
 
         Args:
             method: A instance method to add to the registry.
         """
         self._add(method.__name__, method)
 
-    def add_factory(self, type_or_name: Union[str, Type], factory: Callable, singleton=False):
+    def add_factory(self, type_or_name: str | type, factory: Callable, singleton=False):
         """Add a factory for a service.
 
         A factory is any callable that can be invoked to provide the given type of service.
 
         Args:
             type_or_name: the concrete type of the provided service, or a name (MyClass or
             'MyClass')
@@ -94,23 +93,33 @@
                             singleton,
                         )
                     else:
                         self.add_service(provided_type, provider_function)
             except KeyError:
                 pass
 
-    def _add(self, type_or_name: Union[str, Type], value: Union[Type, Tuple[bool, Callable]]):
+    def _add(self, type_or_name: str | type, value: Callable | type | tuple[bool, Callable]):
+        """Add a service to the registry."""
         key = type_or_name if isinstance(type_or_name, str) else type_or_name.__name__
-        if key in self._values:
-            raise RuntimeError(f'A service has already been provided for {key}.')
-
         self._values[key] = value
 
     def __getattr__(self, type_or_name):
         """Enable property-access style access to registered services, i.e., registry.MyClass."""
+        return self._retrieve_registered_value(type_or_name)
+
+    def __contains__(self, item: Any) -> bool:
+        """Enable the syntax MyClass in registry."""
+        try:
+            self.__getattr__(item)
+            return True
+        except RuntimeError:
+            return False
+
+    def _retrieve_registered_value(self, type_or_name):
+        """Retrieve or create a value, if already registered."""
         key = type_or_name if isinstance(type_or_name, str) else type_or_name.__name__
         if key in self._values:
             value = self._values[key]
             if isinstance(value, tuple):
                 singleton, factory = value
                 if not singleton:
                     return factory()
@@ -118,84 +127,79 @@
                 value = factory()
                 self._values[key] = value
 
             return value
 
         raise RuntimeError(f'No provider for type: {key}')
 
-    def __contains__(self, item: object) -> bool:
-        """Enable the syntax MyClass in registry."""
-        try:
-            self.__getattr__(item)
-            return True
-        except RuntimeError:
-            return False
-
     def _reset(self):
         """Only used during testing to reset registry."""
         self._values = {}
 
     @staticmethod
-    def factory(type_or_name: Type[T], singleton: bool = False) -> Callable[..., T]:
+    def factory(type_or_name: str | type, singleton: bool = False) -> Callable[[T], T]:
         """Decorate a function that can be treated as a factory that provides a service.
 
-        Note: does NOT work with @property.
-
         Args:
             type_or_name: the concrete type of the provided service, or a name (MyClass or
             'MyClass')
             singleton: if True, the factory will be invoked exactly once.  If False, the factory
             will be invoked every time the service is requested.
         """
 
-        def _decorator(original: Callable[..., T]) -> Callable[..., T]:
+        def _decorator(original: T) -> T:
             setattr(original, 'factory_provider', (type_or_name, singleton))
             return original
 
         return _decorator
 
     #
     # The below are convenience-wrappers that make it easier to retrieve services from the registry.
     #
 
     @property
-    def exit(self) -> 'ExitService':
-        """@cblades"""
-        return self.__getattr__('ExitService')
+    def app(self) -> 'App':
+        """Return App object."""
+        return self.App
 
     @property
-    def handle_error(self) -> 'Callable':
-        """Return a handle_error function."""
-        return self.__getattr__('handle_error')
+    def exit(self) -> 'Exit':
+        """Return Exit object."""
+        return self.Exit
 
     @property
     def inputs(self) -> 'Input':
         """Return an Inputs object."""
         return self.Input
 
     @property
-    def key_value_store(self) -> Union['KeyValueRedis', 'KeyValueApi']:
-        """Return a KeyValue object, either an API version or a Redis one."""
-        return self.KeyValueStore
+    def logger(self) -> 'Logger':
+        """Return an Inputs object."""
+        return self.Logger
 
     @property
     def playbook(self) -> 'Playbook':
         """Return a Playbook object."""
-        return self.Playbook
+        return self.app.playbook
 
     @property
-    def redis_client(self) -> 'Redis':
+    def redis_client(self) -> Redis:
         """Return a Redis client object (redis.Redis)."""
-        return self.RedisClient
+        return self.app.key_value_store.redis_client
+
+    @property
+    def request_tc(self) -> 'RequestsTc':
+        """Return a TcSession."""
+        return self.RequestsTc
 
     @property
     def session_tc(self) -> 'TcSession':
         """Return a TcSession."""
-        return self.TcSession
+        return self.request_tc.session
 
     @property
-    def token(self) -> 'Tokens':
-        """Return a Tokens."""
-        return self.Tokens
+    def token(self) -> 'Token':
+        """Return a Token."""
+        return self.app.token
 
 
 registry = Registry()
```

### Comparing `tcex-3.0.9/tcex/pleb/scoped_property.py` & `tcex-4.0.0/tcex/pleb/scoped_property.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,13 +1,14 @@
-"""Declares a scoped_property decorator"""
+"""Declares a scoped_property decorator."""
 
 # standard library
 import os
 import threading
-from typing import Any, Callable, Generic, TypeVar
+from collections.abc import Callable
+from typing import Any, Generic, TypeVar
 
 T = TypeVar('T')
 
 
 class scoped_property(Generic[T]):
     """Makes a value unique for each thread and also acts as a @property decorator.
 
@@ -18,50 +19,59 @@
     Note that this also provides a cache: each thread will re-use the value previously created
     for it.
     """
 
     instances = []
 
     def __init__(self, wrapped: Callable[..., T]):
-        """Initialize."""
-
+        """Initialize the instance properties."""
         scoped_property.instances.append(self)
         self.wrapped = wrapped
         self.value = threading.local()
 
     def __del__(self):
         """Remove instance from the instances class variable when it's destroyed."""
         scoped_property.instances = [i for i in scoped_property.instances if i != self]
 
-    def __get__(self, instance: Any, owner: Any) -> T:
+    def __get__(self, instance: Any, _: Any) -> T:
         """Return a thread-and-process-local value.
 
         Implementation per the descriptor protocol.
 
         Args:
             instance: the instance this property is being resolved for.
             owner: same as instance.
         """
         if hasattr(self.value, 'data'):
             # A value has been created for this thread already, but we have to make sure we're in
             # the same process (threads are duplicated when a process is forked).
-            pid, value = self.value.data
-            if pid != os.getpid():
-                return self._create_value(self.wrapped, instance)
+            pid, value, stored_instance = self.value.data
+
+            # create a new instance if the following are not true:
+            # 1. Check for same pid
+            # 2. Check to ensure stored instance is the same as the current instance
+            if pid != os.getpid() or stored_instance is not instance:
+                return self._create_value(instance, self.wrapped)
 
             return value
 
         # A value has *not* been created for the calling thread
         # yet, so use the factory to create a new one.
-        new_value = self._create_value(self.wrapped, instance)
+        new_value = self._create_value(instance, self.wrapped)
         return new_value
 
-    def _create_value(self, wrapped, *args, **kwargs) -> T:
+    def _create_value(self, instance, wrapped, *args, **kwargs) -> T:
         """Call the wrapped factory function to get a new value."""
-        data = wrapped(*args, **kwargs)
-        setattr(self.value, 'data', (os.getpid(), data))
+        if instance:
+            data = wrapped(instance, *args, **kwargs)
+        else:
+            data = wrapped(*args, **kwargs)
+
+        # add data to threat.local
+        setattr(self.value, 'data', (os.getpid(), data, instance))
+
         return data
 
     @staticmethod
     def _reset():
         for i in scoped_property.instances:
             i.value = threading.local()
```

### Comparing `tcex-3.0.9/tcex/pleb/threading.py` & `tcex-4.0.0/tcex/pleb/exception_thread.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-"""Internal Threading Logic"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import threading
 
-logger = logging.getLogger('tcex')
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 
 class ExceptionThread(threading.Thread):
     """Thread that saves any uncaught exception into an instance variable for further inspection"""
 
     def __init__(self, *args, **kwargs):
         """Initialize thread"""
@@ -16,10 +16,10 @@
 
     def run(self):
         """Run thread logic"""
         try:
             super().run()
         except Exception as ex:
             self.exception = ex
-            logger.exception(f'Unexpected exception occurred in thread with name: {self.name}')
+            _logger.exception(f'Unexpected exception occurred in thread with name: {self.name}')
             # let exception logic continue as normal
             raise ex
```

### Comparing `tcex-3.0.9/tcex/services/api_service.py` & `tcex-4.0.0/tcex/app/service/api_service.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,39 +1,46 @@
-"""TcEx Framework API Service module."""
+"""TcEx Framework Module"""
 # standard library
 import concurrent.futures
 import json
 import sys
 import threading
 import traceback
+from collections.abc import Callable
 from functools import reduce
 from io import BytesIO
-from typing import Any, Callable, Optional
+from typing import Any
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
-from tcex.services.common_service import CommonService
+from tcex.app.key_value_store.key_value_store import KeyValueStore
+from tcex.app.service.common_service import CommonService
+from tcex.app.token import Token
+from tcex.input.field_type.sensitive import Sensitive
+from tcex.input.model.module_app_model import ModuleAppModel
+from tcex.logger.logger import Logger
 
 
 class ApiService(CommonService):
     """TcEx Framework API Service module."""
 
-    def __init__(self, tcex: object):
-        """Initialize the Class properties.
-
-        Args:
-            tcex: Instance of TcEx.
-        """
-        super().__init__(tcex)
+    def __init__(
+        self,
+        key_value_store: KeyValueStore,
+        logger: Logger,
+        model: ModuleAppModel,
+        token: Token,
+    ):
+        """Initialize the Class properties."""
+        super().__init__(key_value_store, logger, model, token)
 
         # properties
         self._metrics = {'Errors': 0, 'Requests': 0, 'Responses': 0}
 
         # config callbacks
-        self.api_event_callback = None
+        self.api_event_callback: Any = None
 
         # thread pool to handle HTTP requests
         self.request_thread_pool = concurrent.futures.ThreadPoolExecutor(max_workers=5)
 
     @property
     def command_map(self) -> dict:
         """Return the command map for the current Service type."""
@@ -81,15 +88,15 @@
             self.log.error(
                 f'feature=api-service, event=bad-headers-provided, '
                 f'headers={headers}, error="""{e})"""'
             )
             self.log.trace(traceback.format_exc())
         return headers_
 
-    def format_response_headers(self, headers: dict) -> dict:
+    def format_response_headers(self, headers: dict) -> list[dict]:
         """Convert name/value array to a query string.
 
         Args:
             headers: The dict header data to be converted to key/value pairs.
 
         Returns:
             dict: The restructured header data.
@@ -108,29 +115,29 @@
 
     def process_run_service_response(self, *args, **kwargs):
         """Handle service event responses.
 
         ('200 OK', [('content-type', 'application/json'), ('content-length', '103')])
         """
         self.log.info('feature=api-service, event=response-received, status=waiting-for-body')
-        kwargs.get('event').wait(30)  # wait for thread event - (set on body write)
+        kwargs['event'].wait(30)  # wait for thread event - (set on body write)
         self.log.trace(f'feature=api-service, event=response, args={args}')
         try:
             status_code, status = args[0].split(' ', 1)
             response = {
                 'bodyVariable': 'response.body',
                 'command': 'Acknowledged',
                 'headers': self.format_response_headers(args[1]),
                 'requestKey': kwargs.get('request_key'),  # pylint: disable=cell-var-from-loop
                 'status': status,
                 'statusCode': status_code,
                 'type': 'RunService',
             }
             self.log.info('feature=api-service, event=response-sent')
-            self.message_broker.publish(json.dumps(response), self.args.tc_svc_client_topic)
+            self.message_broker.publish(json.dumps(response), self.model.tc_svc_client_topic)
             self.increment_metric('Responses')
         except Exception as e:
             self.log.error(
                 f'feature=api-service, event=failed-creating-response-body, error="""{e}"""'
             )
             self.log.trace(traceback.format_exc())
             self.increment_metric('Errors')
@@ -157,36 +164,36 @@
             }
 
         Args:
             message: The message payload from the server topic.
         """
         # register config apiToken (before any logging)
         self.token.register_token(
-            self.thread_name, Sensitive(message.get('apiToken')), message.get('expireSeconds')
+            self.thread_name, Sensitive(message['apiToken']), message.get('expireSeconds')
         )
         self.log.info(f'feature=api-service, event=runservice-command, message="{message}"')
 
         # thread event used to block response until body is written
         event = threading.Event()
 
         # process message
-        request_key: str = message.get('requestKey')
+        request_key: str = message['requestKey']
         body = None
         try:
             # read body from redis
             body_variable: str = message.pop('bodyVariable', None)
             if body_variable is not None:
-                body: Any = self.key_value_store.read(request_key, body_variable)
+                body: Any = self.key_value_store.client.read(request_key, body_variable)
                 if body is not None:
                     # for API service the data in Redis is not b64 encoded
                     body = BytesIO(body)
         except Exception as e:
             self.log.error(f'feature=api-service, event=failed-reading-body, error="""{e}"""')
             self.log.trace(traceback.format_exc())
-        headers: dict = self.format_request_headers(message.pop('headers'))
+        headers = self.format_request_headers(message.pop('headers'))
         method: str = message.pop('method')
         params: dict = message.pop('queryParams')
         path: str = message.pop('path')
 
         try:
             environ = {
                 'wsgi.errors': sys.stderr,
@@ -220,16 +227,16 @@
 
             for header, value in headers.items():
                 environ[f'HTTP_{header}'.upper()] = value
 
             # make values from message available in env in camel
             # case (e.g., falcon -> req.env.get('request_url))
             for key, value in message.items():
-                if key not in environ and self.tcex.utils.camel_to_snake(key) not in environ:
-                    environ[self.tcex.utils.camel_to_snake(key)] = value
+                if key not in environ and self.util.camel_to_snake(key) not in environ:
+                    environ[self.util.camel_to_snake(key)] = value
 
             self.log.trace(f'feature=api-service, environ={environ}')
             self.increment_metric('Requests')
         except Exception as e:
             self.log.error(f'feature=api-service, event=failed-building-environ, error="""{e}"""')
             self.log.trace(traceback.format_exc())
             self.increment_metric('Errors')
@@ -252,15 +259,15 @@
                     environ, response_handler
                 )
                 if body_data:
                     body_data = reduce(lambda a, b: a + b, body_data)
 
                 # write body to Redis
                 if body_data:
-                    self.key_value_store.create(request_key, 'response.body', body_data)
+                    self.key_value_store.client.create(request_key, 'response.body', body_data)
 
                     # set thread event to True to trigger response
                     self.log.info('feature=api-service, event=response-body-written')
 
                 # release event lock
                 event.set()
             except Exception as e:
@@ -277,19 +284,19 @@
         """Handle shutdown command."""
         super().process_shutdown_command(message)
         self.request_thread_pool.shutdown()
 
     def service_thread(
         self,
         name: str,
-        target: Callable[[], bool],
-        args: Optional[tuple] = None,
-        kwargs: Optional[dict] = None,
-        session_id: Optional[str] = None,
-        trigger_id: Optional[int] = None,
+        target: Callable[..., bool | None],
+        args: tuple | None = None,
+        kwargs: dict | None = None,
+        session_id: str | None = None,
+        trigger_id: int | None = None,
     ):
         """If this is a run-service command, run it with the thread pool.
 
         For everything else, use parent's implementation.
 
         Args:
             name: The name of the thread.
@@ -300,17 +307,15 @@
             trigger_id: The current trigger id.
         """
         args = args or ()
         kwargs = kwargs or {}
 
         def _thread_wrapper():
             t = threading.current_thread()
-            t.setName(name)
-            t.session_id = session_id
-            t.trigger_id = trigger_id
+            t.name = name
             target(*args, **kwargs)
 
         if target is self.process_run_service_command:
             self.log.info(f'feature=service, event=request-thread-creation, name={name}')
             self.request_thread_pool.submit(_thread_wrapper)
         else:
             super().service_thread(name, target, args, kwargs, session_id, trigger_id)
```

### Comparing `tcex-3.0.9/tcex/services/common_service.py` & `tcex-4.0.0/tcex/app/service/common_service.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,110 +1,111 @@
-"""TcEx Framework Service Common module"""
+"""TcEx Framework Module"""
 # standard library
 import json
 import logging
 import threading
 import time
 import traceback
 import uuid
+from collections.abc import Callable
 from datetime import datetime
-from typing import TYPE_CHECKING, Callable, Optional, Union
 
 # first-party
-from tcex.services.mqtt_message_broker import MqttMessageBroker
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.app_config import InstallJson
+from tcex.app.config import InstallJson
+from tcex.app.key_value_store.key_value_store import KeyValueStore
+from tcex.app.playbook.playbook import Playbook
+from tcex.app.service.mqtt_message_broker import MqttMessageBroker
+from tcex.app.token import Token
+from tcex.input.model.module_app_model import ModuleAppModel
+from tcex.logger.logger import Logger
+from tcex.logger.trace_logger import TraceLogger
+from tcex.util.util import Util
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class CommonService:
     """TcEx Framework Service Common module
 
     Shared service logic between the supported service types:
     * API Service
     * Custom Trigger Service
     * Webhook Trigger Service
     """
 
-    def __init__(self, tcex: object):
-        """Initialize the Class properties.
-
-        Args:
-            tcex: Instance of TcEx.
-        """
-        self.tcex = tcex
-
+    def __init__(
+        self,
+        key_value_store: KeyValueStore,
+        logger: Logger,
+        model: ModuleAppModel,
+        token: Token,
+    ):
+        """Initialize the Class properties."""
         # properties
         self._ready = False
         self._start_time = datetime.now()
-        self.args: object = tcex.inputs.model
+        self.model = model
         self.configs = {}
         self.heartbeat_max_misses = 3
         self.heartbeat_sleep_time = 1
         self.heartbeat_watchdog = 0
-        self.ij: 'InstallJson' = tcex.ij
-        self.key_value_store = self.tcex.key_value_store
-        self.log = logger
-        self.logger = tcex.logger
+        self.ij = InstallJson()
+        self.key_value_store = key_value_store
+        self.log = _logger
+        self.logger = logger
         self.message_broker = MqttMessageBroker(
-            broker_host=self.args.tc_svc_broker_host,
-            broker_port=self.args.tc_svc_broker_port,
-            broker_timeout=self.args.tc_svc_broker_conn_timeout,
-            broker_token=self.args.tc_svc_broker_token,
-            broker_cacert=self.args.tc_svc_broker_cacert_file,
+            broker_host=self.model.tc_svc_broker_host,
+            broker_port=self.model.tc_svc_broker_port,
+            broker_timeout=self.model.tc_svc_broker_conn_timeout,
+            broker_token=self.model.tc_svc_broker_token,
+            broker_cacert=self.model.tc_svc_broker_cacert_file,
         )
         self.ready = False
-        self.redis_client = self.tcex.redis_client
-        self.token = tcex.token
+        self.redis_client = self.key_value_store.redis_client
+        self.token = token
+        self.util = Util()
 
         # config callbacks
         self.shutdown_callback = None
 
-    def _create_logging_handler(self):
-        """Create a logging handler."""
-        if self.logger.handler_exist(self.thread_name):
-            return
+    def get_playbook(
+        self, context: str | None = None, output_variables: list | None = None
+    ) -> Playbook:
+        """Return a new instance of playbook module.
 
-        # create trigger id logging filehandler
-        self.logger.add_pattern_file_handler(
-            name=self.thread_name,
-            filename=f'''{datetime.today().strftime('%Y%m%d')}/{self.session_id}.log''',
-            level=self.args.tc_log_level,
-            path=self.args.tc_log_path,
-            # uuid4 pattern for session_id
-            pattern=r'^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}.log$',
-            handler_key=self.session_id,
-            thread_key='session_id',
-        )
+        Args:
+            context: The KV Store context/session_id. For PB Apps the context is provided on
+                startup, but for service Apps each request gets a different context.
+            output_variables: The requested output variables. For PB Apps outputs are provided on
+                startup, but for service Apps each request gets different outputs.
+        """
+        return Playbook(self.key_value_store, context, output_variables)
 
-    def process_acknowledged_command(self, message: dict):  # pylint: disable=unused-argument
+    def process_acknowledged_command(self, message: dict):
         """Process the Acknowledge command.
 
         Args:
             message: The message payload from the server topic.
         """
         self.log.info(f'feature=service, event=acknowledge, message={message}')
 
-    def add_metric(self, label: str, value: Union[int, str]):
+    def add_metric(self, label: str, value: int | str):
         """Add a metric.
 
         Metrics are reported in heartbeat message.
 
         Args:
             label: The metric label (e.g., hits) to add.
             value: The value for the metric.
         """
         self._metrics[label] = value
 
     @property
-    def command_map(self) -> dict:
+    def command_map(self) -> dict[str, Callable[[dict], None]]:
         """Return the command map for the current Service type."""
         return {
             'acknowledged': self.process_acknowledged_command,
             'brokercheck': self.process_broker_check,
             'heartbeat': self.process_heartbeat_command,
             'loggingchange': self.process_logging_change_command,
             'shutdown': self.process_shutdown_command,
@@ -127,61 +128,61 @@
         """Send self check message to ensure communications with message broker."""
         message = {
             'command': 'BrokerCheck',
             'date': str(datetime.now()),
             'heartbeat_watchdog': self.heartbeat_watchdog,
         }
         self.message_broker.publish(
-            message=json.dumps(message), topic=self.args.tc_svc_server_topic
+            message=json.dumps(message), topic=self.model.tc_svc_server_topic
         )
 
         # allow time for message to be received
         time.sleep(5)
 
     def heartbeat_monitor(self):
         """Publish heartbeat on timer."""
         self.log.info('feature=service, event=heartbeat-monitor-started')
         while True:
             # check heartbeat is not missed
             if self.heartbeat_watchdog > (
-                int(self.args.tc_svc_hb_timeout_seconds) / int(self.heartbeat_sleep_time)
+                int(self.model.tc_svc_hb_timeout_seconds) / int(self.heartbeat_sleep_time)
             ):
                 # send self check message
                 self.heartbeat_broker_check()
 
                 self.log.error(
                     'feature=service, event=missed-heartbeat, action=shutting-service-down'
                 )
                 self.process_shutdown_command({'reason': 'Missed heartbeat commands.'})
                 break
             time.sleep(self.heartbeat_sleep_time)
             self.heartbeat_watchdog += 1
 
-    def increment_metric(self, label: str, value: Optional[int] = 1):
+    def increment_metric(self, label: str, value: int = 1):
         """Increment a metric if already exists.
 
         Args:
             label: The metric label (e.g., hits) to increment.
             value: The increment value. Defaults to 1.
         """
         if self._metrics.get(label) is not None:
             self._metrics[label] += value
 
     def listen(self):
         """List for message coming from broker."""
         self.message_broker.add_on_connect_callback(self.on_connect_handler)
         self.message_broker.add_on_message_callback(
-            self.on_message_handler, topics=[self.args.tc_svc_server_topic]
+            self.on_message_handler, topics=[self.model.tc_svc_server_topic]
         )
         self.message_broker.register_callbacks()
 
         # start listener thread
         self.service_thread(name='broker-listener', target=self.message_broker.connect)
 
-    def loop_forever(self, sleep: Optional[int] = 1) -> bool:
+    def loop_forever(self, sleep: int = 1) -> bool:
         """Block and wait for shutdown.
 
         Args:
             sleep: The amount of time to sleep between iterations. Defaults to 1.
 
         Returns:
             Bool: Returns True until shutdown received.
@@ -192,50 +193,52 @@
                 if self.message_broker.shutdown:
                     return False
                 time.sleep(1)
             return True
 
     @property
     def metrics(self) -> dict:
-        """Return current metrics."""
+        """Return current metric."""
         # TODO: move to trigger command and handle API Service
         if self._metrics.get('Active Playbooks') is not None:
             self.update_metric('Active Playbooks', len(self.configs))
         return self._metrics
 
     @metrics.setter
     def metrics(self, metrics: dict):
-        """Return current metrics."""
+        """Return current metric."""
         if isinstance(metrics, dict):
             self._metrics = metrics
         else:
-            self.log.error('feature=service, event=invalid-metrics')
+            self.log.error('feature=service, event=invalid-metric')
 
     def on_connect_handler(self, client, userdata, flags, rc):  # pylint: disable=unused-argument
         """On connect method for mqtt broker."""
         self.log.info(
-            f'feature=service, event=topic-subscription, topic={self.args.tc_svc_server_topic}'
+            f'feature=service, event=topic-subscription, topic={self.model.tc_svc_server_topic}'
         )
-        self.message_broker.client.subscribe(self.args.tc_svc_server_topic)
+        self.message_broker.client.subscribe(self.model.tc_svc_server_topic)
         self.message_broker.client.disable_logger()
 
     def on_message_handler(self, client, userdata, message):  # pylint: disable=unused-argument
         """On message for mqtt."""
         try:
             # messages on server topic must be json objects
             m = json.loads(message.payload)
+            if m.get('triggerId') is not None:
+                m['triggerId'] = int(m['triggerId'])
         except ValueError:
             self.log.warning(
                 f'feature=service, event=parsing-issue, message="""{message.payload}"""'
             )
             return
 
         # use the command to call the appropriate method defined in command_map
-        command: str = m.get('command', 'invalid').lower()
-        trigger_id: Optional[int] = m.get('triggerId')
+        command = m.get('command', 'invalid').lower()
+        trigger_id = m.get('triggerId')
         if trigger_id is not None:
             # coerce trigger_id to int in case a string was provided (testing framework)
             trigger_id = int(trigger_id)
         self.log.info(f'feature=service, event=command-received, command="{command}"')
 
         # create unique session id to be used as thread name
         # and stored as property of thread for logging emit
@@ -286,17 +289,17 @@
             message: The message payload from the server topic.
         """
         self.heartbeat_watchdog = 0
 
         # send heartbeat -acknowledge- command
         response = {'command': 'Heartbeat', 'metric': self.metrics}
         self.message_broker.publish(
-            message=json.dumps(response), topic=self.args.tc_svc_client_topic
+            message=json.dumps(response), topic=self.model.tc_svc_client_topic
         )
-        self.log.info(f'feature=service, event=heartbeat-sent, metrics={self.metrics}')
+        self.log.info(f'feature=service, event=heartbeat-sent, metric={self.metrics}')
 
     def process_logging_change_command(self, message: dict):
         """Process the LoggingChange command.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
@@ -305,15 +308,15 @@
                 "command": "LoggingChange",
                 "level": "DEBUG"
             }
 
         Args:
             message: The message payload from the server topic.
         """
-        level: str = message.get('level')
+        level = message['level']
         self.log.info(f'feature=service, event=logging-change, level={level}')
         self.logger.update_handler_level(level)
 
     def process_invalid_command(self, message: dict):
         """Process all invalid commands.
 
         Args:
@@ -342,40 +345,35 @@
             'A shutdown command was received on server topic. Service is shutting down.'
         )
         self.log.info(f'feature=service, event=shutdown, reason={reason}')
 
         # acknowledge shutdown command
         self.message_broker.publish(
             json.dumps({'command': 'Acknowledged', 'type': 'Shutdown'}),
-            self.args.tc_svc_client_topic,
+            self.model.tc_svc_client_topic,
         )
 
         # call App shutdown callback
         if callable(self.shutdown_callback):
             try:
                 # call callback for shutdown and handle exceptions to protect thread
                 self.shutdown_callback()  # pylint: disable=not-callable
             except Exception as e:
                 self.log.error(
                     f'feature=service, event=shutdown-callback-error, error="""({e})""".'
                 )
                 self.log.trace(traceback.format_exc())
 
         # unsubscribe and disconnect from the broker
-        self.message_broker.client.unsubscribe(self.args.tc_svc_server_topic)
+        self.message_broker.client.unsubscribe(self.model.tc_svc_server_topic)
         self.message_broker.client.disconnect()
 
         # update shutdown flag
         self.message_broker.shutdown = True
 
-        # TODO: [review] this doesn't help if MainThread does not die.
-        # # delay shutdown to give App time to cleanup
-        # time.sleep(5)
-        # self.tcex.exit(ExitCode.SUCCESS)  # final shutdown in case App did not
-
     @property
     def ready(self) -> bool:
         """Return ready boolean."""
         return self._ready
 
     @ready.setter
     def ready(self, bool_val: bool):
@@ -384,30 +382,30 @@
             # wait until connected to send ready command
             while not self.message_broker._connected:
                 if self.message_broker.shutdown:
                     break
                 time.sleep(1)
             else:  # pylint: disable=useless-else-on-loop
                 self.log.info('feature=service, event=service-ready')
-                ready_command = {'command': 'Ready'}
+                ready_command: dict[str, list[str] | str] = {'command': 'Ready'}
                 if self.ij.model.is_api_service_app and self.ij.model.service:
                     ready_command['discoveryTypes'] = self.ij.model.service.discovery_types
                 self.message_broker.publish(
-                    json.dumps(ready_command), self.args.tc_svc_client_topic
+                    json.dumps(ready_command), self.model.tc_svc_client_topic
                 )
                 self._ready = True
 
     def service_thread(
         self,
         name: str,
-        target: Callable[[], bool],
-        args: Optional[tuple] = None,
-        kwargs: Optional[dict] = None,
-        session_id: Optional[str] = None,
-        trigger_id: Optional[int] = None,
+        target: Callable[..., bool | None],
+        args: tuple | None = None,
+        kwargs: dict | None = None,
+        session_id: str | None = None,
+        trigger_id: int | None = None,
     ):
         """Start a message thread.
 
         Args:
             name: The name of the thread.
             target: The method to call for the thread.
             args: The args to pass to the target method.
@@ -415,45 +413,34 @@
             session_id: The current session id.
             trigger_id: The current trigger id.
         """
         self.log.info(f'feature=service, event=service-thread-creation, name={name}')
         args = args or ()
         try:
             t = threading.Thread(name=name, target=target, args=args, kwargs=kwargs, daemon=True)
-            # add session_id to thread to use in logger emit
-            t.session_id = session_id
-            # add trigger_id to thread to use in logger emit
-            t.trigger_id = trigger_id
+            t.session_id = session_id  # type: ignore
+            # trigger id is used in Token module for the unique key for a token
+            t.trigger_id = str(trigger_id)  # type: ignore
             t.start()
         except Exception:
             self.log.trace(traceback.format_exc())
 
     @property
-    def session_id(self) -> Optional[str]:
+    def session_id(self) -> str:
         """Return the current session_id."""
         if not hasattr(threading.current_thread(), 'session_id'):
-            threading.current_thread().session_id = self.create_session_id()
-        return threading.current_thread().session_id
+            threading.current_thread().session_id = self.create_session_id()  # type: ignore
+        return threading.current_thread().session_id  # type: ignore
 
     @property
     def thread_name(self) -> str:
         """Return a uuid4 session id."""
         return threading.current_thread().name
 
-    @property
-    def trigger_id(self) -> Optional[int]:
-        """Return the current trigger_id."""
-        trigger_id = None
-        if hasattr(threading.current_thread(), 'trigger_id'):
-            trigger_id = threading.current_thread().trigger_id
-            if trigger_id is not None:
-                trigger_id = int(trigger_id)
-        return trigger_id
-
-    def update_metric(self, label: str, value: Union[int, str]):
+    def update_metric(self, label: str, value: int | str):
         """Update a metric if already exists.
 
         Args:
             label: The metric label (e.g., hits) to update.
             value: The updated value for the metric.
         """
         if self._metrics.get(label) is not None:
```

### Comparing `tcex-3.0.9/tcex/services/common_service_trigger.py` & `tcex-4.0.0/tcex/app/service/common_service_trigger.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,61 +1,70 @@
-"""TcEx Framework Service Trigger Common module."""
+"""TcEx Framework Module"""
 # standard library
 import json
 import os
 import threading
 import traceback
-from typing import Any, Callable, Optional, Union
+from collections.abc import Callable
+from typing import Any
 
 # first-party
-from tcex.pleb.registry import registry
-from tcex.services.common_service import CommonService
+from tcex.app.key_value_store.key_value_store import KeyValueStore
+from tcex.app.playbook import Playbook
+from tcex.app.service.common_service import CommonService
+from tcex.app.token import Token
+from tcex.input.field_type.sensitive import Sensitive
+from tcex.input.model.create_config_model import CreateConfigModel
+from tcex.input.model.module_app_model import ModuleAppModel
+from tcex.logger.logger import Logger
+from tcex.registry import registry
 
 
 class CommonServiceTrigger(CommonService):
     """TcEx Framework Service Trigger Common module.
 
     Shared service logic between the supported service types:
     * Custom Trigger Service
     * Webhook Trigger Service
     """
 
-    def __init__(self, tcex: object):
-        """Initialize the Class properties.
-
-        Args:
-            tcex: Instance of TcEx.
-        """
-        super().__init__(tcex)
+    def __init__(
+        self,
+        key_value_store: KeyValueStore,
+        logger: Logger,
+        model: ModuleAppModel,
+        token: Token,
+    ):
+        """Initialize the Class properties."""
+        super().__init__(key_value_store, logger, model, token)
 
         # properties
         self._metrics = {'Active Playbooks': 0, 'Errors': 0, 'Hits': 0, 'Misses': 0}
-        self.configs = {}
+        self.configs: dict[int, CreateConfigModel] = {}
         self.config_thread = None
 
         # config callbacks
-        self.create_config_callback = None
+        self.create_config_callback: Callable[..., bool | dict | None]
         self.delete_config_callback = None
-        self.trigger_input_model = None
+        self.trigger_input_model = CreateConfigModel
 
     def _tcex_testing(self, session_id: str, trigger_id: int):
         """Write data required for testing framework to Redis.
 
         Args:
             session_id: The context/session id value for the current operation.
             trigger_id: The trigger ID for the current playbook.
         """
-        if self.args.tcex_testing_context is not None:
-            _context_tracker: str = (
-                self.redis_client.hget(self.args.tcex_testing_context, '_context_tracker') or '[]'
+        if self.model.tcex_testing_context is not None:
+            _context_tracker: list[str] = json.loads(
+                self.redis_client.hget(self.model.tcex_testing_context, '_context_tracker') or '[]'
             )
-            _context_tracker = json.loads(_context_tracker)
             _context_tracker.append(session_id)
             self.redis_client.hset(
-                self.args.tcex_testing_context,
+                self.model.tcex_testing_context,
                 '_context_tracker',
                 json.dumps(_context_tracker),
             )
             self.redis_client.hset(session_id, '_trigger_id', trigger_id)
 
             # log
             self.log.info(
@@ -66,15 +75,15 @@
     def _tcex_testing_fired_events(self, session_id: str, fired: bool):
         """Write fired event data to KV Store to be used in test validation.
 
         Args:
             session_id: The context/session id value for the current operation.
             fired: The value to increment the count by.
         """
-        if self.args.tcex_testing_context is not None:
+        if self.model.tcex_testing_context is not None:
             self.redis_client.hset(
                 session_id, '#Trigger:9876:_fired!String', json.dumps(str(fired).lower())
             )
 
     @property
     def command_map(self) -> dict:
         """Return the command map for the current Service type."""
@@ -93,17 +102,17 @@
         Args:
             trigger_id: The trigger ID for the current config.
             message: A simple message for the action.
             status: The passed/fail status for the App handling of config.
             logfile: The CreateConfig logfile to return in response ack.
         """
         try:
-            if status is not True and self.configs.get(str(trigger_id)) is not None:
+            if status is not True and self.configs.get(trigger_id) is not None:
                 # add config to configs
-                del self.configs[str(trigger_id)]
+                del self.configs[trigger_id]
 
             # send ack response
             self.message_broker.publish(
                 json.dumps(
                     {
                         'command': 'Acknowledged',
                         'logFile': os.path.join(
@@ -112,24 +121,24 @@
                         ),
                         'message': message,
                         'status': 'Success' if status is True else 'Failed',
                         'type': 'CreateConfig',
                         'triggerId': trigger_id,
                     }
                 ),
-                self.args.tc_svc_client_topic,
+                self.model.tc_svc_client_topic,
             )
         except Exception as e:
             self.log.error(
                 'feature=service, event=create-config-callback-exception, '
                 f'trigger-id={trigger_id}, error="""{e}"""'
             )
             self.log.trace(traceback.format_exc())
 
-    def delete_config(self, trigger_id: int, message: str, status: str):
+    def delete_config(self, trigger_id: int, message: str, status: bool | str):
         """Delete config item from config object.
 
         Args:
             trigger_id: The trigger ID for the current config.
             message: A simple message for the action.
             status: The passed/fail status for the App handling of config.
         """
@@ -144,35 +153,34 @@
                         'command': 'Acknowledged',
                         'message': message,
                         'status': 'Success' if status is True else 'Failed',
                         'type': 'DeleteConfig',
                         'triggerId': trigger_id,
                     }
                 ),
-                self.args.tc_svc_client_topic,
+                self.model.tc_svc_client_topic,
             )
-        except Exception as e:
-            self.log.error(
-                'feature=service, event=delete-config-callback-exception, '
-                f'trigger-id={trigger_id}, error="""{e}"""'
+        except Exception:
+            self.log.exception(
+                f'feature=service, event=delete-config-callback-exception, trigger-id={trigger_id}'
             )
-            # self.log.trace(traceback.format_exc())
 
-    def fire_event(self, callback: Callable[[], bool], **kwargs):
+    def fire_event(self, callback: Callable[..., bool], **kwargs):
         """Trigger a FireEvent command.
 
         Args:
             callback: The trigger method in the App to call.
             trigger_ids: A list of trigger ids to trigger.
+            **kwargs: Additional keyword arguments.
         """
         if not callable(callback):
             raise RuntimeError('Callback method (callback) is not a callable.')
 
         # get developer passed trigger_ids
-        trigger_ids: Optional[list] = kwargs.pop('trigger_ids', None)
+        trigger_ids: list | None = kwargs.pop('trigger_ids', None)
 
         for trigger_id, config in list(self.configs.items()):
             if trigger_ids is not None and trigger_id not in trigger_ids:
                 # skip config that don't match developer provided trigger ids
                 continue
 
             try:
@@ -180,20 +188,18 @@
                 session_id: str = self.create_session_id()
 
                 # only required for testing in tcex framework
                 self._tcex_testing(session_id, trigger_id)
 
                 # get an instance of PB module with current
                 # session_id and outputs to pass to callback
-                outputs: Union[list, str] = config.tc_playbook_out_variables or []
+                outputs: list | str = config.tc_playbook_out_variables or []
                 if isinstance(outputs, str):
                     outputs = outputs.split(',')
-                playbook: object = self.tcex.get_playbook(
-                    context=session_id, output_variables=outputs
-                )
+                playbook = self.get_playbook(context=session_id, output_variables=outputs)
 
                 self.log.info(f'feature=trigger-service, event=fire-event, trigger-id={session_id}')
 
                 # current thread has session_id as name
                 self.service_thread(
                     name=session_id,
                     target=self.fire_event_trigger,
@@ -224,19 +230,17 @@
             'command': 'UpdateTriggerValue',
             'triggerId': trigger_id,
             'inputName': input_name,
             'inputValue': new_value,
         }
 
         self.log.info(f'feature=service, event=update-trigger-value, msg={msg}')
-        self.message_broker.publish(json.dumps(msg), self.args.tc_svc_client_topic)
+        self.message_broker.publish(json.dumps(msg), self.model.tc_svc_client_topic)
 
-    def fire_event_publish(
-        self, trigger_id: int, session_id: str, request_key: Optional[str] = None
-    ):
+    def fire_event_publish(self, trigger_id: int, session_id: str, request_key: str | None = None):
         """Send FireEvent command.
 
         Args:
             trigger_id: The ID of the trigger.
             session_id: The generated session for this fired event.
             request_key: The request key for this response.
         """
@@ -246,35 +250,36 @@
             'sessionId': session_id,  # session for the playbook execution
         }
         if request_key is not None:
             msg['requestKey'] = request_key  # reference for a specific playbook execution
         self.log.info(f'feature=service, event=fire-event, msg={msg}')
 
         # publish FireEvent command to client topic
-        self.message_broker.publish(json.dumps(msg), self.args.tc_svc_client_topic)
+        self.message_broker.publish(json.dumps(msg), self.model.tc_svc_client_topic)
 
     def fire_event_trigger(
         self,
-        callback: Callable[[], bool],
-        playbook: object,
+        callback: Callable[..., bool],
+        playbook: Playbook,
         session_id: str,
         trigger_id: int,
         config: dict,
         **kwargs: str,
     ):
         """Fire event for trigger.
 
         Args:
             callback: The App callback method for firing an event.
             playbook: A configure playbook instance for using to interact with KvStore.
             session_id: The current session Id.
             trigger_id: The current trigger Id.
             config: A dict containing the configuration information.
+            **kwargs: Additional keyword arguments.
         """
-        self._create_logging_handler()
+        # self._create_logging_handler()
         self.log.info('feature=trigger-service, event=fire-event-trigger')
 
         try:
             if callback(playbook, trigger_id, config, **kwargs):
                 self.increment_metric('Hits')
                 self.fire_event_publish(trigger_id, session_id)
 
@@ -291,30 +296,29 @@
                 self._tcex_testing_fired_events(session_id, False)
         except Exception as e:
             self.increment_metric('Errors')
             self.log.error(
                 f'feature=trigger-service, event=fire-event-callback-exception, error="""{e}"""'
             )
             self.log.trace(traceback.format_exc())
-        finally:
-            self.logger.remove_handler_by_name(self.thread_name)
 
-    def log_config(self, trigger_id: str, config: dict):
+    def log_config(self, trigger_id: int, config: dict):
         """Log the config while hiding encrypted values.
 
         Args:
             trigger_id: The current trigger Id.
             config: The configuration to be logged.
         """
 
         logged_config = config.copy()
 
-        for param in self.ij.model.params:
-            if param.encrypt and config.__contains__(param.name):
-                logged_config[param.get('name')] = '***'
+        for param in self.ij.model.params or []:
+            if param.encrypt and param.name in config:
+                logged_config[param.name] = '***'
+
         self.log.info(
             f'feature=service, event=create-config, trigger_id={trigger_id}, config={logged_config}'
         )
 
     def process_create_config_command(self, message: dict):
         """Process the CreateConfig command.
 
@@ -335,70 +339,53 @@
                 "apiToken": "SVC:8:QQuyIp:1596817138182:387:+9vBOAT8Y56caHRcjLa4IwAqABoatsYOU ... ",
                 "expireSeconds": 1596817138
             }
 
         Args:
             message: The message payload from the server topic.
         """
-        config: dict = message.get('config')
+        config: dict[str, bytes | str | Sensitive] = message['config']
         status = True
-        trigger_id = int(message.get('triggerId'))
-
-        # create trigger id logging filehandler
-        self.logger.add_thread_file_handler(
-            backup_count=1,  # required for logs to be rotated
-            name=self.thread_name,
-            filename=self.trigger_logfile,
-            level=self.args.tc_log_level,
-            max_bytes=1048576,  # 1Mb
-            path=self.args.tc_log_path,
-            handler_key=trigger_id,
-            thread_key='trigger_id',
-        )
+        trigger_id = message['triggerId']
 
         # log the config
         self.log_config(trigger_id, config)
 
         # register config apiToken
-        self.token.register_token(trigger_id, message.get('apiToken'), message.get('expireSeconds'))
+        self.token.register_token(
+            str(trigger_id), message.get('apiToken'), message.get('expireSeconds')
+        )
+
+        # Resolve any variables in config
+        updated_config = {
+            k: (registry.inputs.resolve_variable(str(v)) if self.util.is_tc_variable(str(v)) else v)
+            for k, v in config.items()
+        }
+        updated_config['trigger_id'] = trigger_id
 
         # temporarily add config, will be removed if callback fails
-        self.configs[trigger_id] = config
+        self.configs[trigger_id] = CreateConfigModel(**updated_config)  # type: ignore
 
         msg = 'Create Config'
         if callable(self.create_config_callback):
-
             kwargs = {}
             if self.ij.model.is_webhook_trigger_app:
                 # only webhook triggers get and require the PB url
                 kwargs['url'] = message.get('url')
 
             try:
-                # Resolve any variables in config
-                updated_config = {
-                    k: (
-                        registry.inputs.resolve_variable(v)
-                        if registry.inputs.utils.is_tc_variable(v)
-                        else v
-                    )
-                    for k, v in config.items()
-                }
-                updated_config['trigger_id'] = trigger_id
-
-                # Instantiate trigger input model
-                # pylint: disable=not-callable
-                config_input = self.trigger_input_model(**updated_config)
-
+                # convert config data from message to TriggerInputModel
+                config_input = self.trigger_input_model(**updated_config)  # type: ignore
                 self.configs[trigger_id] = config_input
+
                 # call callback for create config and handle exceptions to protect thread
-                # pylint: disable=not-callable
-                response: Optional[dict] = self.create_config_callback(config_input, **kwargs)
+                response = self.create_config_callback(config_input, **kwargs)
                 if isinstance(response, dict):
                     status = response.get('status', False)
-                    msg = response.get('msg')
+                    msg = response.get('msg') or msg
 
                 # if callback does not return a boolean value assume it worked
                 if not isinstance(status, bool):
                     status = True
             except Exception as e:
                 status = False
                 msg = str(e)
@@ -424,48 +411,45 @@
                 "triggerId": 1
             }
 
         Args:
             message: The message payload from the server topic.
         """
         status = True
-        trigger_id = int(message.get('triggerId'))
+        trigger_id = int(message['triggerId'])
         self.log.info(f'feature=service, event=delete-config, trigger_id={trigger_id}')
 
         # unregister config apiToken
-        self.token.unregister_token(trigger_id)
+        self.token.unregister_token(str(trigger_id))
 
         msg = 'Delete Config'
         if callable(self.delete_config_callback):
             try:
                 # call callback for delete config and handle exceptions to protect thread
                 # pylint: disable=not-callable
-                status: Optional[bool] = self.delete_config_callback(trigger_id)
+                status: bool | None = self.delete_config_callback(trigger_id)
 
                 # if callback does not return a boolean value assume it worked
                 if not isinstance(status, bool):
                     status = True
             except Exception as e:
                 self.log.error(
                     f'feature=service, event=delete-config-callback-exception, error="""{e}"""'
                 )
                 self.log.trace(traceback.format_exc())
                 status = False
 
         # delete config
         self.delete_config(trigger_id, msg, status)
 
-        # remove temporary logging file handler
-        self.logger.remove_handler_by_name(self.thread_name)
-
     @property
     def trigger_logfile(self) -> str:
         """Return the logfile name based on date and thread name."""
         return f'''trigger-id-{self.thread_trigger_id}.log'''
 
     @property
-    def thread_trigger_id(self) -> Optional[str]:
+    def thread_trigger_id(self) -> str | None:
         """Return the current thread trigger id."""
         trigger_id = None
         if hasattr(threading.current_thread(), 'trigger_id'):
-            trigger_id = threading.current_thread().trigger_id
+            trigger_id = threading.current_thread().trigger_id  # type: ignore
         return trigger_id
```

### Comparing `tcex-3.0.9/tcex/services/mqtt_message_broker.py` & `tcex-4.0.0/tcex/app/service/mqtt_message_broker.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,37 @@
-"""TcEx Framework MQTT message broker module."""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import ssl
 import time
 import traceback
-from typing import TYPE_CHECKING, List, Optional
+from collections.abc import Callable
 
 # third-party
 import paho.mqtt.client as mqtt
 
-if TYPE_CHECKING:
-    # first-party
-    from tcex.input.field_types.sensitive import Sensitive
+# first-party
+from tcex.input.field_type.sensitive import Sensitive
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 class MqttMessageBroker:
     """TcEx Framework MQTT message broker module."""
 
     def __init__(
         self,
         broker_host: str,
         broker_port: int,
         broker_timeout: int,
-        broker_token: Optional['Sensitive'] = None,
-        broker_cacert: Optional[str] = None,
+        broker_token: Sensitive | None = None,
+        broker_cacert: str | None = None,
     ):
         """Initialize the Class properties.
 
         Args:
             broker_host: The MQTT server host (IP).
             broker_port: The MQTT server port.
             broker_timeout: The MQTT connection timeout.
@@ -41,127 +42,127 @@
         self.broker_host = broker_host
         self.broker_port = int(broker_port)
         self.broker_timeout = int(broker_timeout)
         self.broker_token = broker_token
         self.broker_cacert = broker_cacert
 
         # properties
-        self._client = None
         self._connected = False
-        self._on_connect_callbacks: List[callable] = []
-        self._on_disconnect_callbacks: List[callable] = []
-        self._on_log_callbacks: List[callable] = []
-        self._on_message_callbacks: List[callable] = []
-        self._on_publish_callbacks: List[callable] = []
-        self._on_subscribe_callbacks: List[callable] = []
-        self._on_unsubscribe_callbacks: List[callable] = []
-        self.log = logger
+        self._on_connect_callbacks: list[Callable] = []
+        self._on_disconnect_callbacks: list[Callable] = []
+        self._on_log_callbacks: list[Callable] = []
+        self._on_message_callbacks: list[dict[str, Callable | list[str]]] = []
+        self._on_publish_callbacks: list[Callable] = []
+        self._on_subscribe_callbacks: list[Callable] = []
+        self._on_unsubscribe_callbacks: list[Callable] = []
+        self.log = _logger
         self.shutdown = False  # used in service App for shutdown flag
 
-    def add_on_connect_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_connect_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_connect events.
 
         Args:
             callback: A callback that matches signature of an on_connect event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_connect_callbacks)
         self._on_connect_callbacks.insert(index, callback)
 
-    def add_on_disconnect_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_disconnect_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_disconnect events.
 
         Args:
             callback: A callback that matches signature of an on_disconnect event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_disconnect_callbacks)
-        self._on_disconnect_callbacks.insert(callback)
+        self._on_disconnect_callbacks.insert(index, callback)
 
-    def add_on_log_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_log_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_log events.
 
         Args:
             callback: A callback that matches signature of an on_log event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_log_callbacks)
-        self._on_log_callbacks.insert(callback)
+        self._on_log_callbacks.insert(index, callback)
 
     def add_on_message_callback(
-        self, callback: callable, index: Optional[int] = None, topics: Optional[List[str]] = None
+        self, callback: Callable, index: int | None = None, topics: list[str] | None = None
     ):
         """Add a callback for on_message events.
 
         Args:
             callback: A callback that matches signature of an on_message event.
             index: The index value to insert the callback into the list.
             topics: A optional list of topics to call callback. If value is None then callback
                 will always be called.
         """
         index = index or len(self._on_message_callbacks)
+        topics = topics or []
         self._on_message_callbacks.insert(index, {'callback': callback, 'topics': topics})
 
-    def add_on_publish_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_publish_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_publish events.
 
         Args:
             callback: A callback that matches signature of an on_publish event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_publish_callbacks)
         self._on_publish_callbacks.insert(index, callback)
 
-    def add_on_subscribe_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_subscribe_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_subscribe events.
 
         Args:
             callback: A callback that matches signature of an on_subscribe event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_subscribe_callbacks)
         self._on_subscribe_callbacks.insert(index, callback)
 
-    def add_on_unsubscribe_callback(self, callback: callable, index: Optional[int] = None):
+    def add_on_unsubscribe_callback(self, callback: Callable, index: int | None = None):
         """Add a callback for on_unsubscribe events.
 
         Args:
             callback: A callback that matches signature of an on_unsubscribe event.
             index: The index value to insert the callback into the list.
         """
         index = index or len(self._on_unsubscribe_callbacks)
         self._on_unsubscribe_callbacks.insert(index, callback)
 
-    @property
-    def client(self) -> object:
+    @cached_property
+    def client(self) -> mqtt.Client:
         """Return MQTT client."""
-        if self._client is None:
-            try:
-                self._client = mqtt.Client(client_id='', clean_session=True)
-                self._client.reconnect_delay_set(min_delay=1, max_delay=5)
-                self._client.connect(self.broker_host, self.broker_port, self.broker_timeout)
-                if self.broker_cacert is not None:
-                    self._client.tls_set(
-                        ca_certs=self.broker_cacert,
-                        cert_reqs=ssl.CERT_REQUIRED,
-                        tls_version=ssl.PROTOCOL_TLSv1_2,
-                    )
-                    self._client.tls_insecure_set(False)
-                # add logger when logging in TRACE
-                if self.log.getEffectiveLevel() == 5:
-                    self._client.enable_logger(logger=self.log)
-                # username must be a empty string
-                if self.broker_token is not None:
-                    self._client.username_pw_set('', password=self.broker_token.value)
-            except Exception as e:
-                self.log.error(f'feature=message-broker, event=failed-connection, error="""{e}"""')
-                self.log.trace(traceback.format_exc())
-                self.shutdown = True
+        _client = mqtt.Client(client_id='', clean_session=True)
+        try:
+            _client.reconnect_delay_set(min_delay=1, max_delay=5)
+            _client.connect(self.broker_host, self.broker_port, self.broker_timeout)
+            if self.broker_cacert is not None:
+                _client.tls_set(
+                    ca_certs=self.broker_cacert,
+                    cert_reqs=ssl.CERT_REQUIRED,
+                    tls_version=ssl.PROTOCOL_TLSv1_2,
+                )
+                _client.tls_insecure_set(False)
+            # add logger when logging in TRACE
+            if self.log.getEffectiveLevel() == 5:
+                _client.enable_logger(logger=self.log)
+            # username must be a empty string
+            if self.broker_token is not None:
+                _client.username_pw_set('', password=self.broker_token.value)
+
+        except Exception as e:
+            self.log.error(f'feature=message-broker, event=failed-connection, error="""{e}"""')
+            self.log.trace(traceback.format_exc())
+            self.shutdown = True
 
-        return self._client
+        return _client
 
     def connect(self):
         """Listen for message coming from broker."""
         try:
             # handle connection issues by not using loop_forever. give the service X seconds to
             # connect to message broker, else timeout and log generic connection error.
             self.client.loop_start()
@@ -204,15 +205,16 @@
         mp = message.payload.decode().replace('\n', '')
         self.log.trace(
             f'''feature=message-broker, message-topic={message.topic}, message-payload={mp}'''
         )
         for cd in self._on_message_callbacks:
             topics = cd.get('topics')
             if topics is None or message.topic in topics:
-                cd.get('callback')(client, userdata, message)
+                if callable(cd['callback']):
+                    cd['callback'](client, userdata, message)
 
     def on_publish(self, client, userdata, result):
         """Handle MQTT on_publish events."""
         # self.log.trace(f'feature=message-broker, event=on_publish, result={result}')
         for callback in self._on_publish_callbacks:
             callback(client, userdata, result)
 
@@ -233,15 +235,15 @@
     def publish(self, message: str, topic: str):
         """Publish a message on client topic.
 
         Args:
             message: The message to be sent on client topic.
             topic: The broker topic.
         """
-        r: object = self.client.publish(topic, message)
+        r = self.client.publish(topic, message)
         self.log.debug(
             f'feature=service, event=publish-message, topic="{topic}", '
             f'message={message}, response={r}'
         )
 
     def register_callbacks(self):
         """Register all the message broker callbacks."""
```

### Comparing `tcex-3.0.9/tcex/services/webhook_trigger_service.py` & `tcex-4.0.0/tcex/app/service/webhook_trigger_service.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,39 @@
-"""TcEx Framework Webhook Service Trigger module."""
+"""TcEx Framework Module"""
 # standard library
 import base64
 import json
 import traceback
-from typing import Any, Callable, Optional, Union
+from collections.abc import Callable
+from typing import Any
 
-from .common_service_trigger import CommonServiceTrigger
+# first-party
+from tcex.app.key_value_store.key_value_store import KeyValueStore
+from tcex.app.service.common_service_trigger import CommonServiceTrigger
+from tcex.app.token import Token
+from tcex.input.model.create_config_model import CreateConfigModel
+from tcex.input.model.module_app_model import ModuleAppModel
+from tcex.logger.logger import Logger
 
 
 class WebhookTriggerService(CommonServiceTrigger):
     """TcEx Framework Webhook Service Trigger module."""
 
-    def __init__(self, tcex: object):
-        """Initialize the Class properties.
-
-        Args:
-            tcex: Instance of TcEx.
-        """
-        super().__init__(tcex)
+    def __init__(
+        self,
+        key_value_store: KeyValueStore,
+        logger: Logger,
+        model: ModuleAppModel,
+        token: Token,
+    ):
+        """Initialize the Class properties."""
+        super().__init__(key_value_store, logger, model, token)
 
         # config callbacks
-        self.webhook_event_callback = None
+        self.webhook_event_callback: Callable  # set in run.py of the App
         self.webhook_marshall_event_callback = None
 
     def callback_response_handler(self, callback_response: Any, message: dict):
         """Handle the different types of callback responses.
 
         # Webhook App (default)
 
@@ -72,19 +81,19 @@
         """
         if isinstance(callback_response, dict):
             # webhook responses are for providers that require a subscription req/resp.
             self.publish_webhook_event_response(message, callback_response)
         elif callback_response is True:
             self.increment_metric('Hits')
             self.fire_event_publish(
-                message.get('triggerId'), self.session_id, message.get('requestKey')
+                message['triggerId'], self.session_id, message.get('requestKey')
             )
 
             # only required for testing in tcex framework
-            self._tcex_testing(self.session_id, message.get('triggerId'))
+            self._tcex_testing(self.session_id, message['triggerId'])
 
             # capture fired status for testing framework
             self._tcex_testing_fired_events(self.session_id, True)
         else:
             self.increment_metric('Misses')
 
             # capture fired status for testing framework
@@ -171,43 +180,38 @@
                     }
                 ]
             }
 
         Args:
             message: The message payload from the server topic.
         """
-        self._create_logging_handler()
         self.log.trace(
             f'feature=webhook-trigger-service, event=process-webhook-event, message={message}'
         )
 
         # acknowledge webhook event (nothing is currently done with this message on the core side)
         self.publish_webhook_event_acknowledge(message)
 
         # get config using triggerId passed in WebhookEvent data
-        config = None
-        outputs = {}
+        config: CreateConfigModel | None = None
+        outputs: list = []
         if not self.ij.has_feature('webhookserviceendpoint'):
-            config: dict = self.configs.get(message.get('triggerId'))
+            config = self.configs.get(message['triggerId'])
             if config is None:
                 self.log.error(
                     '''feature=webhook-trigger-service, event=missing-config, '''
                     f'''trigger-id={message.get('triggerId')}'''
                 )
                 return
-
-            # get an instance of playbooks for App
-            outputs: Union[list, str] = config.get('tc_playbook_out_variables') or []
-            if isinstance(outputs, str):
-                outputs = outputs.split(',')
+            outputs = config.tc_playbook_out_variables
 
         # get a context aware pb instance for the App callback method
-        playbook: object = self.tcex.pb(context=self.session_id, output_variables=outputs)
+        playbook = self.get_playbook(context=self.session_id, output_variables=outputs)
         try:
-            body: Any = self.key_value_store.read(message.get('requestKey'), 'request.body')
+            body: Any = self.key_value_store.client.read(message['requestKey'], 'request.body')
             if body is not None:
                 body = base64.b64decode(body).decode()
             # pylint: disable=not-callable
             callback_data = {
                 'body': body,
                 'headers': message.get('headers'),
                 'method': message.get('method'),
@@ -224,27 +228,25 @@
                     {
                         'config': config,
                         'playbook': playbook,
                         'trigger_id': message.get('triggerId'),
                     }
                 )
 
-            callback_response: Union[bool, Callable[..., Any], dict] = self.webhook_event_callback(
+            callback_response: bool | Callable[..., Any] | dict = self.webhook_event_callback(
                 **callback_data
             )
             self.callback_response_handler(callback_response, message)
         except Exception as e:
             self.increment_metric('Errors')
             self.log.error(
                 'feature=webhook-trigger-service, event=webhook-callback-exception, '
                 f'error="""{e}"""'
             )
             self.log.trace(traceback.format_exc())
-        finally:
-            self.logger.remove_handler_by_name(self.thread_name)
 
     def process_webhook_marshall_event_command(self, message: dict):
         """Process the WebhookMarshallEvent command.
 
         .. code-block:: python
             :linenos:
             :lineno-start: 1
@@ -263,37 +265,38 @@
                 "statusCode": 200,
                 "triggerId": 1234
             }
 
         Args:
             message: The message payload from the server topic.
         """
-        self._create_logging_handler()
         self.log.trace(
             'feature=webhook-trigger-service, event=process-webhook-marshall-event, '
             f'message={message}'
         )
 
         # acknowledge webhook event (nothing is currently done with this message on the core side)
         self.publish_webhook_marshall_event_acknowledge(message)
 
         # get config using triggerId passed in WebhookMarshallEvent data
-        config: dict = self.configs.get(message.get('triggerId'))
+        config = self.configs.get(message['triggerId'])
         if config is None:
             self.log.error(
                 '''feature=webhook-trigger-service, event=missing-config, '''
                 f'''trigger-id={message.get('triggerId')}'''
             )
             return
 
         body = None
-        request_key: str = message.get('requestKey')
+        request_key = message.get('requestKey')
 
         try:
-            body: Any = self.key_value_store.read(request_key, 'request.body')
+            body: Any = self.key_value_store.client.read(
+                request_key, 'request.body'  # type: ignore
+            )
             if body is not None:
                 body = base64.b64decode(body).decode()
         except Exception as e:
             self.increment_metric('Errors')
             self.log.error(
                 'feature=webhook-trigger-service, event=webhook-marshall-callback-exception, '
                 f'error="""{e}"""'
@@ -305,18 +308,17 @@
             'body': body,
             'headers': message.get('headers'),
             'status_code': message.get('statusCode'),
         }
 
         if callable(self.webhook_marshall_event_callback):
             try:
-
                 # call callback method
                 # pylint: disable=not-callable
-                callback_response: Optional[dict] = self.webhook_marshall_event_callback(
+                callback_response: dict | None = self.webhook_marshall_event_callback(
                     body=body,
                     headers=message.get('headers'),
                     request_key=request_key,
                     status_code=message.get('statusCode'),
                     trigger_id=message.get('triggerId'),
                 )
                 if isinstance(callback_response, dict):
@@ -324,16 +326,14 @@
             except Exception as e:
                 self.increment_metric('Errors')
                 self.log.error(
                     'feature=webhook-trigger-service, event=webhook-marshall-callback-exception, '
                     f'error="""{e}"""'
                 )
                 self.log.trace(traceback.format_exc())
-            finally:
-                self.logger.remove_handler_by_name(self.thread_name)
 
         # webhook responses are for providers that require a subscription req/resp.
         self.publish_webhook_event_response(message, response)
 
     def publish_webhook_event_acknowledge(self, message: dict):
         """Publish the WebhookEventResponse message.
 
@@ -345,15 +345,15 @@
                 {
                     'command': 'Acknowledged',
                     'requestKey': message.get('requestKey'),
                     'triggerId': message.get('triggerId'),
                     'type': 'WebhookEvent',
                 }
             ),
-            self.args.tc_svc_client_topic,
+            self.model.tc_svc_client_topic,
         )
 
     def publish_webhook_marshall_event_acknowledge(self, message: dict):
         """Publish the WebhookEventResponse message.
 
         .. code-block:: python
             :linenos:
@@ -374,32 +374,32 @@
                 {
                     'command': 'Acknowledged',
                     'requestKey': message.get('requestKey'),
                     'triggerId': message.get('triggerId'),
                     'type': 'WebhookMarshallEvent',
                 }
             ),
-            self.args.tc_svc_client_topic,
+            self.model.tc_svc_client_topic,
         )
 
     def publish_webhook_event_response(self, message: dict, callback_response: dict):
         """Publish the WebhookEventResponse message.
 
         Args:
             message: The message from the broker.
             callback_response: The data from the callback method.
             playbook: Configure instance of Playbook used to write body.
         """
-        playbook: object = self.tcex.pb(context=self.session_id, output_variables=[])
+        playbook = self.get_playbook(context=self.session_id, output_variables=[])
 
         # write response body to redis
         if callback_response.get('body') is not None:
-            playbook.create_string(
+            playbook.create.string(
                 'response.body',
-                base64.b64encode(callback_response.get('body').encode('utf-8')).decode('utf-8'),
+                base64.b64encode(callback_response['body'].encode('utf-8')).decode('utf-8'),
             )
 
         # publish response
         self.message_broker.publish(
             json.dumps(
                 {
                     'sessionId': self.session_id,  # session/context
@@ -407,9 +407,9 @@
                     'command': 'WebhookEventResponse',
                     'triggerId': message.get('triggerId'),
                     'bodyVariable': 'response.body',
                     'headers': callback_response.get('headers', []),
                     'statusCode': callback_response.get('status_code', 200),
                 }
             ),
-            self.args.tc_svc_client_topic,
+            self.model.tc_svc_client_topic,
         )
```

### Comparing `tcex-3.0.9/tcex/sessions/auth/hmac_auth.py` & `tcex-4.0.0/tcex/requests_tc/auth/hmac_auth.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,50 +1,43 @@
-"""TcEx HMAC Authorization"""
+"""TcEx Framework Module"""
 # standard library
 import hmac
 import time
 from base64 import b64encode
 from hashlib import sha256
-from typing import TYPE_CHECKING
 
 # third-party
-from requests import auth
+from requests import PreparedRequest, auth
 
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from requests import request
-
-    # first-party
-    from tcex.input.field_types.sensitive import Sensitive
+from ...input.field_type.sensitive import Sensitive  # type: ignore # pylint: disable=import-error
 
 
 class HmacAuth(auth.AuthBase):
     """ThreatConnect HMAC Authorization"""
 
-    def __init__(self, tc_api_access_id: str, tc_api_secret_key: 'Sensitive'):
+    def __init__(self, tc_api_access_id: str, tc_api_secret_key: Sensitive):
         """Initialize the Class properties."""
-        # super().__init__()
         auth.AuthBase.__init__(self)
         self.tc_api_access_id = tc_api_access_id
         self.tc_api_secret_key = tc_api_secret_key
 
-    def _hmac_header(self, r: 'request', timestamp: 'time.time'):
+    def _hmac_header(self, r: PreparedRequest, timestamp: float):
         """Return HMAC Authorization header value."""
         # define the signature using "full" path, HTTP method, and current timestamp
         signature = f'{r.path_url}:{r.method}:{timestamp}'
 
         # generate the sha256 signature using the tc secret key, encoded signature
         hmac_signature = hmac.new(
             self.tc_api_secret_key.value.encode(), signature.encode(), digestmod=sha256
         ).digest()
 
         # return the header value with access_id and b64 signature value
         return f'TC {self.tc_api_access_id}:{b64encode(hmac_signature).decode()}'
 
-    def __call__(self, r: 'request') -> 'request':
+    def __call__(self, r: PreparedRequest) -> PreparedRequest:
         """Add the authorization headers to the request."""
         timestamp = int(time.time())
 
         # Add required headers to auth.
         r.headers['Authorization'] = self._hmac_header(r, timestamp)
-        r.headers['Timestamp'] = timestamp
+        r.headers['Timestamp'] = str(timestamp)
         return r
```

### Comparing `tcex-3.0.9/tcex/sessions/auth/tc_auth.py` & `tcex-4.0.0/tcex/requests_tc/auth/tc_auth.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,42 +1,40 @@
-"""ThreatConnect Requests Session"""
+"""TcEx Framework Module"""
 # standard library
 import time
-from typing import TYPE_CHECKING, Callable, Optional, Union
+from collections.abc import Callable
 
-# first-party
-from tcex.sessions.auth.hmac_auth import HmacAuth
-from tcex.sessions.auth.token_auth import TokenAuth
-
-if TYPE_CHECKING:  # pragma: no cover
-    # first-party
-    from tcex.input.field_types.sensitive import Sensitive
+from ...input.field_type.sensitive import Sensitive  # type: ignore # pylint: disable=import-error
+from .hmac_auth import HmacAuth
+from .token_auth import TokenAuth
 
 
 class TcAuth(HmacAuth, TokenAuth):
     """ThreatConnect Token Authorization"""
 
     def __init__(
         self,
-        tc_api_access_id: Optional[str] = None,
-        tc_api_secret_key: Optional['Sensitive'] = None,
-        tc_token: Optional[Union[Callable, str, 'Sensitive']] = None,
+        tc_api_access_id: str | None = None,
+        tc_api_secret_key: Sensitive | None = None,
+        tc_token: Callable | str | Sensitive | None = None,
     ):
-        """Initialize Class Properties."""
-        # super(HmacAuth).__init__(tc_api_access_id, tc_api_secret_key)
-        # super(TokenAuth, self).__init__(tc_token)
-        HmacAuth.__init__(self, tc_api_access_id, tc_api_secret_key)
-        TokenAuth.__init__(self, tc_token)
+        """Initialize instance properties."""
+        if tc_api_access_id is not None and tc_api_secret_key is not None:
+            HmacAuth.__init__(self, tc_api_access_id, tc_api_secret_key)
+            self.auth_type = 'hmac'
+        elif tc_token is not None:
+            TokenAuth.__init__(self, tc_token)
+            self.auth_type = 'token'
+        else:  # pragma: no cover
+            raise RuntimeError('No valid ThreatConnect API credentials provided.')
 
     def __call__(self, r):
         """Add the authorization headers to the request."""
         timestamp = int(time.time())
-        if self.tc_api_access_id is not None and self.tc_api_secret_key is not None:
+        if self.auth_type == 'hmac':
             r.headers['Authorization'] = self._hmac_header(r, timestamp)
-        elif self.tc_token is not None:
+        elif self.auth_type == 'token':
             r.headers['Authorization'] = self._token_header()
-        else:  # pragma: no cover
-            raise RuntimeError('No valid ThreatConnect API credentials provided.')
 
         # Add required headers to auth.
-        r.headers['Timestamp'] = timestamp
+        r.headers['Timestamp'] = str(timestamp)
         return r
```

### Comparing `tcex-3.0.9/tcex/sessions/auth/token_auth.py` & `tcex-4.0.0/tcex/requests_tc/auth/token_auth.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,53 +1,43 @@
-"""ThreatConnect HMAC Authorization"""
+"""TcEx Framework Module"""
 # standard library
 import time
-from typing import TYPE_CHECKING, Callable, Union
+from collections.abc import Callable
 
 # third-party
+from requests import Request  # TYPE-CHECKING
 from requests import auth
 
-# first-party
-from tcex.input.field_types.sensitive import Sensitive
-
-if TYPE_CHECKING:  # pragma: no cover
-    # third-party
-    from requests import request
+from ...input.field_type.sensitive import Sensitive
 
 
 class TokenAuth(auth.AuthBase):
     """ThreatConnect HMAC Authorization"""
 
-    def __init__(self, tc_token: Union[Callable, str, 'Sensitive']):
+    def __init__(self, tc_token: Callable[..., Sensitive | str] | Sensitive | str):
         """Initialize the Class properties."""
-        # super().__init__()
         auth.AuthBase.__init__(self)
         self.tc_token = tc_token
 
     def _token_header(self):
         """Return HMAC Authorization header value."""
-        _token = None
-        if hasattr(self.tc_token, 'token'):
-            # Token Module - The token module is provided that will handle authentication.
-            _token = self.tc_token.token.value
-        elif callable(self.tc_token):
-            # Callabe - A callable method is provided that will return the token as a plain
+        _token = self.tc_token
+        if callable(self.tc_token):
+            # Callable - A callable method is provided that will return the token as a plain
             #     string. The callable will have to handle token renewal.
             _token = self.tc_token()
-        elif isinstance(self.tc_token, Sensitive):
+
+        if isinstance(_token, Sensitive):
             # Sensitive - A sensitive string type was passed. Likely no support for renewal.
-            _token = self.tc_token.value
-        else:
-            # String - A string type was passed. Likely no support for renewal.
-            _token = self.tc_token
+            _token = _token.value
 
         # Return formatted token
         return f'TC-Token {_token}'
 
-    def __call__(self, r: 'request') -> 'request':
+    def __call__(self, r: Request) -> Request:
         """Add the authorization headers to the request."""
         timestamp = int(time.time())
 
         # Add required headers to auth.
         r.headers['Authorization'] = self._token_header()
         r.headers['Timestamp'] = timestamp
         return r
```

### Comparing `tcex-3.0.9/tcex/sessions/external_session.py` & `tcex-4.0.0/tcex/requests_external/external_session.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,73 +1,73 @@
-"""ThreatConnect Requests Session"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import time
-from typing import Callable, Optional
+from collections.abc import Callable
 
 # third-party
 import urllib3
 from requests import Response, Session, adapters, exceptions
 from requests.adapters import DEFAULT_POOLBLOCK, DEFAULT_POOLSIZE, DEFAULT_RETRIES
 from urllib3.util.retry import Retry
 
 # first-party
-from tcex.sessions.rate_limit_handler import RateLimitHandler
-from tcex.utils.requests_to_curl import RequestsToCurl
-from tcex.utils.utils import Utils
+from tcex.requests_external.rate_limit_handler import RateLimitHandler
+from tcex.util.requests_to_curl import RequestsToCurl
+from tcex.util.util import Util
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 # disable ssl warning message
-urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
+urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)  # type: ignore
 
 
-def default_too_many_requests_handler(response: 'Response') -> float:
+def default_too_many_requests_handler(response: Response) -> float:
     """Implement 429 response handling that uses the Retry-After header.
 
     Will return the value in Retry-After.  See: https://tools.ietf.org/html/rfc6585#page-3.
 
     Assumptions:
         - Response has a Retry-After header.
 
     Args:
         response: The 429 response.
 
     Returns:
         The number of seconds to wait before sending the next request, from the Retry-After header.
     """
-    utils = Utils()
+    util = Util()
     # the Retry-After value can be a str/int/float. as a string
     # it can be a full date (e.g., "2022-03-26T00:00:00Z")
     retry_after = response.headers.get('Retry-After', 0)
     try:
         # always convert value to seconds if possible
-        seconds = utils.any_to_datetime(retry_after).timestamp() - time.time()
+        seconds = util.any_to_datetime(retry_after).timestamp() - time.time()
     except RuntimeError:
         # retry_after must be in seconds
         seconds = retry_after
 
     # handle negative values
-    if seconds < 0:
+    if isinstance(seconds, float | int) and seconds < 0:
         seconds = retry_after
 
     return float(seconds)
 
 
 class CustomAdapter(adapters.HTTPAdapter):
     """Custom Adapter to properly handle retries."""
 
     def __init__(
         self,
-        rate_limit_handler: Optional[RateLimitHandler] = None,
-        pool_connections=DEFAULT_POOLSIZE,
-        pool_maxsize=DEFAULT_POOLSIZE,
-        max_retries=DEFAULT_RETRIES,
-        pool_block=DEFAULT_POOLBLOCK,
+        rate_limit_handler: RateLimitHandler | None = None,
+        pool_connections: int = DEFAULT_POOLSIZE,
+        pool_maxsize: int = DEFAULT_POOLSIZE,
+        max_retries: int = DEFAULT_RETRIES,
+        pool_block: bool = DEFAULT_POOLBLOCK,
     ):
         """Initialize CustomAdapter.
 
         Args:
             rate_limit_handler: RateLimitHandler responsible for throttling.
             pool_connections: passed to super
             pool_maxsize: passed to super
@@ -99,30 +99,29 @@
 
         if self.rate_limit_handler:
             self.rate_limit_handler.post_send(response)
 
         return response
 
     @property
-    def rate_limit_handler(self) -> 'RateLimitHandler':
+    def rate_limit_handler(self) -> RateLimitHandler | None:
         """Get the RateLimitHandler."""
         return self._rate_limit_handler
 
     @rate_limit_handler.setter
-    def rate_limit_handler(self, rate_limit_handler: 'RateLimitHandler'):
+    def rate_limit_handler(self, rate_limit_handler: RateLimitHandler):
         """Set the RateLimitHandler."""
         self._rate_limit_handler = rate_limit_handler
 
 
 class ExternalSession(Session):
     """ThreatConnect REST API Requests Session for external requests
 
     Args:
-        base_url (Optional[str] = None): The base URL for all requests.
-        logger (Optional[object] = None): An instance of Logger.
+        base_url: The base URL for all requests.
     """
 
     __attrs__ = [
         'adapters',
         'auth',
         'cert',
         'cookies',
@@ -135,40 +134,40 @@
         'verify',
         'trust_env',
         # custom attrs
         '_base_url',
         '_mask_headers',
         '_mask_patterns',
         'log',
-        'utils',
+        'util',
     ]
 
-    def __init__(self, base_url: Optional[str] = None):
+    def __init__(self, base_url: str | None = None):
         """Initialize the Class properties."""
         super().__init__()
         self._base_url = base_url
 
-        self._custom_adapter: Optional[CustomAdapter] = None
-        self.utils: object = Utils()
+        self._custom_adapter: CustomAdapter | None = None
+        self.util = Util()
 
         # properties
         self._log_curl: bool = False
         self._mask_body = False
         self._mask_headers = True
         self._mask_patterns = None
         self._rate_limit_handler = RateLimitHandler()
         self._too_many_requests_handler = None
-        self.log = logger
+        self.log = _logger
         self.requests_to_curl = RequestsToCurl()
 
         # Add default Retry
         self.retry()
 
     @property
-    def base_url(self) -> str:
+    def base_url(self) -> str | None:
         """Return the base url."""
         return self._base_url
 
     @base_url.setter
     def base_url(self, url):
         """Set base_url."""
         self._base_url = url.strip('/')
@@ -200,25 +199,25 @@
 
     @mask_headers.setter
     def mask_headers(self, mask_bool: bool):
         """Set property"""
         self._mask_headers = mask_bool
 
     @property
-    def mask_patterns(self) -> list:
+    def mask_patterns(self) -> list[str] | None:
         """Return property"""
         return self._mask_patterns
 
     @mask_patterns.setter
     def mask_patterns(self, patterns: list):
         """Set property"""
         self._mask_patterns = patterns
 
     @property
-    def too_many_requests_handler(self) -> Callable[['Response'], float]:
+    def too_many_requests_handler(self) -> Callable[[Response], float]:
         """Get the too_many_requests_handler.
 
         The too_many_requests_handler is responsible for determining how long to sleep (in seconds)
         on a 429 response.  The default returns the value in the `Retry-After` header.
         """
         if not self._too_many_requests_handler:
             self._too_many_requests_handler = default_too_many_requests_handler
@@ -234,15 +233,15 @@
         Args:
             too_many_requests_handler: callable that returns the number of seconds to wait on a
                 429 response.
         """
         self._too_many_requests_handler = too_many_requests_handler
 
     @property
-    def rate_limit_handler(self) -> 'RateLimitHandler':
+    def rate_limit_handler(self) -> RateLimitHandler:
         """Return the RateLimitHandler.
 
         The RateLimitHandler is responsible for throttling request frequency.  The default
         implementation uses X-RateLimit-Remaining and X-RateLimit-Reset headers.
         """
         return self._rate_limit_handler
 
@@ -264,14 +263,15 @@
         self, method: str, url: str, **kwargs
     ) -> object:
         """Override request method disabling verify on token renewal if disabled on session.
 
         Args:
             method (str): The HTTP method
             url (str): The URL or path for the request.
+            kwargs: The keyword arguments to pass to the request.
 
         Returns:
             object: The requests Response object .
         """
         if self.base_url is not None and not url.startswith('https'):
             url = f'{self.base_url}{url}'
 
@@ -328,44 +328,48 @@
         """
         self.rate_limit_handler.limit_remaining_header = limit_remaining_header
         self.rate_limit_handler.limit_reset_header = limit_reset_header
         self.rate_limit_handler.remaining_threshold = remaining_threshold
 
     def retry(
         self,
-        retries: Optional[int] = 3,
-        backoff_factor: Optional[float] = 0.3,
-        status_forcelist: Optional[list] = None,
+        retries: int = 3,
+        backoff_factor: float = 0.3,
+        status_forcelist: list | None = None,
         **kwargs,
     ):
         """Add retry to Requests Session
 
         https://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html#urllib3.util.retry.Retry
 
         Args:
-            retries (Optional[int] = 3): The number of retry attempts.
-            backoff_factor (Optional[float] = 0.3): The backoff factor for retries.
-            status_forcelist (Optional[list] = [500, 502, 504]): A list of status code to retry on.
-            urls (list, kwargs): An optional URL to apply the retry. If not provided the retry
+            retries: The number of retry attempts.
+            backoff_factor: The backoff factor for retries.
+            status_forcelist: A list of status code to retry on.
+            **kwargs: Additional keyword arguments to pass to the Retry object.
+
+        Keyword Args:
+            urls: An optional URL to apply the retry. If not provided the retry
                 applies to all request with "https://".
         """
-        retry_object: object = Retry(
+        retry_object = Retry(
             total=retries,
             read=retries,
             connect=retries,
             backoff_factor=backoff_factor,
             status_forcelist=status_forcelist or [500, 502, 504],
         )
         urls = kwargs.get('urls') or ['https://']
 
         if self._custom_adapter:
             self._custom_adapter.max_retries = retry_object
         else:
+            # TODO: @cblades - max_retries is typed as int and Retry is being passed
             self._custom_adapter = CustomAdapter(
-                rate_limit_handler=self.rate_limit_handler, max_retries=retry_object
+                rate_limit_handler=self.rate_limit_handler, max_retries=retry_object  # type: ignore
             )
 
         # mount the custom adapter
         for url in urls:
             self.log.info(
                 f'feature=external-session, action=applying-retry, retries={retries}, '
                 f'backoff-factor={backoff_factor}, status-forcelist={status_forcelist}, url={url}'
```

### Comparing `tcex-3.0.9/tcex/sessions/rate_limit_handler.py` & `tcex-4.0.0/tcex/requests_external/rate_limit_handler.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,29 @@
-"""The RateLimitHandler implements request throttling based on X-RateLimit headers.
+"""TcEx Framework Module
 
 See https://tools.ietf.org/id/draft-polli-ratelimit-headers-00.html for implementation details.
 """
 # standard library
 import time
-from typing import Optional
 
 # third-party
 from requests import PreparedRequest, Response
 
 # first-party
-from tcex.utils import Utils
+from tcex.util import Util
 
 
 class RateLimitHandler:
-    """Rate-limiting implementation using X-RateLimit-<X> headers."""
+    """The RateLimitHandler implements request throttling based on X-RateLimit headers."""
 
     def __init__(
         self,
-        limit_remaining_header: Optional[str] = 'X-RateLimit-Remaining',
-        limit_reset_header: Optional[str] = 'X-RateLimit-Reset',
-        remaining_threshold: Optional[int] = 0,
+        limit_remaining_header: str = 'X-RateLimit-Remaining',
+        limit_reset_header: str = 'X-RateLimit-Reset',
+        remaining_threshold: int = 0,
     ):
         """Rate-limiting implementation using X-RateLimit-<X> headers.
 
         See https://tools.ietf.org/id/draft-polli-ratelimit-headers-00.html for implementation
         details.  Uses X-RateLimit-Remaining and X-RateLimit-Reset to rate-limit requests by
         waiting until X-RateLimit-Reset when X-RateLimit-Remaining is less than or equal to
         remaining_threshold.
@@ -34,44 +33,45 @@
             limit_reset_header: Name of the header that contains the limit reset value.
             remaining_threshold: Number of remaining requests available that will trigger a pause.
         """
         self._limit_remaining_header = limit_remaining_header
         self._limit_reset_header = limit_reset_header
         self._remaining_threshold = remaining_threshold
 
-        self._last_limit_remaining_value = None
-        self._last_limit_reset_value = None
+        # properties
+        self._last_limit_remaining_value: int | None = None
+        self._last_limit_reset_value: int | None = None
 
     @property
-    def last_limit_remaining_value(self) -> Optional[int]:
+    def last_limit_remaining_value(self) -> int | None:
         """Get the last value received in the limit_remaining_header."""
         return self._last_limit_remaining_value
 
     @property
-    def last_limit_reset_value(self) -> Optional[int]:
+    def last_limit_reset_value(self) -> int | None:
         """Get the last value received in the limit_reset_header."""
         return self._last_limit_reset_value
 
     @property
     def limit_remaining_header(self) -> str:
         """Get the name of the header that contains the remaining requests."""
         return self._limit_remaining_header
 
     @limit_remaining_header.setter
-    def limit_remaining_header(self, limit_remaining_header):
+    def limit_remaining_header(self, limit_remaining_header: str):
         """Set the name of the header that contains the remaining requests."""
         self._limit_remaining_header = limit_remaining_header
 
     @property
     def limit_reset_header(self) -> str:
         """Get the name of the header that contains the rate limit reset timestamp."""
         return self._limit_reset_header
 
     @limit_reset_header.setter
-    def limit_reset_header(self, limit_reset_header):
+    def limit_reset_header(self, limit_reset_header: str):
         self._limit_reset_header = limit_reset_header
 
     @property
     def remaining_threshold(self) -> int:
         """Get the threshold for remaining requests."""
         return self._remaining_threshold
 
@@ -90,15 +90,18 @@
             response.ok
             and self.limit_remaining_header in response.headers
             and self.limit_reset_header in response.headers
         ):
             self._last_limit_remaining_value = int(
                 response.headers.get(self.limit_remaining_header, 0)
             )
-            self._last_limit_reset_value = response.headers.get(self.limit_reset_header)
+            # TODO: [high] - @cblades - what should this be?
+            self._last_limit_reset_value = response.headers.get(
+                self.limit_reset_header
+            )  # type: ignore
 
     def pre_send(self, request: PreparedRequest):
         """Call before request is sent and provides an opportunity to pause for rate limiting.
 
         Compares rate-limit values from prior requests to determine if we should wait before sending
         request.  Calls self.sleep() if we should wait.
 
@@ -108,23 +111,24 @@
         if (
             self.last_limit_remaining_value is not None
             and self.last_limit_reset_value
             and self.last_limit_remaining_value <= self.remaining_threshold
         ):
             self.sleep(request)
 
-    def sleep(self, request: PreparedRequest):  # pylint: disable=unused-argument
+    def sleep(self, _: PreparedRequest):  # pylint: disable=unused-argument
         """Sleeps to rate-limit.
 
         Sleeps until the time specified in X-RateLimit-Reset.
 
         Args:
             request:  The request that will be sent.
         """
-        utils = Utils()
-        wait_until = self.last_limit_reset_value
-        try:
-            seconds = utils.any_to_datetime(wait_until).timestamp() - time.time()
-        except RuntimeError:
-            seconds = wait_until
+        util = Util()
+        seconds = self.last_limit_reset_value
+        if seconds is not None:
+            try:
+                seconds = util.any_to_datetime(seconds).timestamp() - time.time()
+            except RuntimeError:
+                pass
 
-        time.sleep(float(seconds))
+            time.sleep(float(seconds))
```

### Comparing `tcex-3.0.9/tcex/sessions/tc_session.py` & `tcex-4.0.0/tcex/requests_tc/tc_session.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,59 +1,52 @@
-"""ThreatConnect Requests Session"""
+"""TcEx Framework Module"""
 # standard library
 import logging
-from typing import TYPE_CHECKING, Dict, Optional, Union
 
 # third-party
 import urllib3
+from requests import Response  # TYPE-CHECKING
 from requests import Session, adapters
 from urllib3.util.retry import Retry
 
-# first-party
-from tcex.utils.requests_to_curl import RequestsToCurl
-from tcex.utils.utils import Utils
-
-if TYPE_CHECKING:
-    # third-party
-    from requests import Response
-
-    # first-party
-    from tcex.sessions.auth.hmac_auth import HmacAuth
-    from tcex.sessions.auth.tc_auth import TcAuth
-    from tcex.sessions.auth.token_auth import TokenAuth
+from ..util.requests_to_curl import RequestsToCurl  # type: ignore # pylint: disable=import-error
+from ..util.util import Util  # type: ignore # pylint: disable=import-error
+from .auth.hmac_auth import HmacAuth
+from .auth.tc_auth import TcAuth
+from .auth.token_auth import TokenAuth
 
-# get tcex logger
-logger = logging.getLogger('tcex')
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
 # disable ssl warning message
-urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
+urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)  # type: ignore
 
 
 class TcSession(Session):
     """ThreatConnect REST API Requests Session"""
 
     def __init__(
         self,
-        auth: Union['HmacAuth', 'TokenAuth', 'TcAuth'],
-        base_url: str = None,
-        log_curl: Optional[bool] = False,
-        proxies: Optional[Dict[str, str]] = None,
-        proxies_enabled: Optional[bool] = False,
-        user_agent: Optional[dict] = None,
-        verify: Optional[Union[bool, str]] = True,
+        auth: HmacAuth | TokenAuth | TcAuth,
+        base_url: str | None = None,
+        log_curl: bool | None = False,
+        proxies: dict[str, str] | None = None,
+        proxies_enabled: bool | None = False,
+        user_agent: dict | None = None,
+        verify: bool | str | None = True,
     ):
         """Initialize the Class properties."""
         super().__init__()
-        self.base_url = base_url.strip('/')
-        self.log = logger
+        self.base_url = base_url.strip('/') if base_url is not None else base_url
+        self.log = _logger
         self.log_curl = log_curl
 
         # properties
         self.requests_to_curl = RequestsToCurl()
-        self.utils = Utils()
+        self.util = Util()
 
         # configure auth
         self.auth = auth
 
         # configure optional headers
         if user_agent:
             self.headers.update(user_agent)
@@ -64,20 +57,19 @@
 
         # configure verify
         self.verify = verify
 
         # Add Retry
         self.retry()
 
-    def _log_curl(self, response: 'Response'):
+    def _log_curl(self, response: Response):
         """Log the curl equivalent command."""
 
         # don't show curl message for logging commands
-        if '/v2/logs/app' not in response.request.url:
-
+        if response.request.url is not None and '/v2/logs/app' not in response.request.url:
             # APP-79 - adding logging of request as curl commands
             if not response.ok or self.log_curl:
                 try:
                     self.log.debug(
                         self.requests_to_curl.convert(
                             response.request, proxies=self.proxies, verify=self.verify
                         )
```

### Comparing `tcex-3.0.9/tcex/tcex.py` & `tcex-4.0.0/tcex/app/config/app_spec_yml.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,535 +1,475 @@
-"""TcEx Framework"""
-
+"""TcEx Framework Module"""
 # standard library
-import inspect
+import json
 import logging
 import os
-import platform
-import signal
-import threading
-from typing import TYPE_CHECKING, Dict, Optional, Union
+from functools import cached_property
+from pathlib import Path
 
 # third-party
-from redis import Redis
-from requests import Session
+import yaml
 
-# first-party
-from tcex.api import API
-from tcex.api.tc.utils.threat_intel_utils import ThreatIntelUtils
-from tcex.api.tc.v2.v2 import V2
-from tcex.api.tc.v3.v3 import V3
-from tcex.app_config.install_json import InstallJson
-from tcex.app_feature import AdvancedRequest
-from tcex.backports import cached_property
-from tcex.exit.exit import ExitCode, ExitService
-from tcex.input.field_types.sensitive import Sensitive
-from tcex.input.input import Input
-from tcex.key_value_store import KeyValueApi, KeyValueMock, KeyValueRedis, RedisClient
-from tcex.logger.logger import Logger  # pylint: disable=no-name-in-module
-from tcex.playbook import Playbook
-from tcex.pleb.proxies import proxies
-from tcex.pleb.registry import registry
-from tcex.pleb.scoped_property import scoped_property
-from tcex.sessions.auth.tc_auth import TcAuth
-from tcex.sessions.external_session import ExternalSession
-from tcex.sessions.tc_session import TcSession
-from tcex.tokens import Tokens
-from tcex.utils import Utils
-from tcex.utils.file_operations import FileOperations
-
-if TYPE_CHECKING:
-    # first-party
-    from tcex.logger.trace_logger import TraceLogger  # pylint: disable=no-name-in-module
-    from tcex.services.api_service import ApiService
-    from tcex.services.common_service_trigger import CommonServiceTrigger
-    from tcex.services.webhook_trigger_service import WebhookTriggerService
-    from tcex.sessions.auth.hmac_auth import HmacAuth
-    from tcex.sessions.auth.token_auth import TokenAuth
-
-
-class TcEx:
-    """Provides basic functionality for all types of TxEx Apps.
-
-    Args:
-        config (dict, kwargs): A dictionary containing configuration items typically used by
-            external Apps.
-        config_file (str, kwargs): A filename containing JSON configuration items typically used
-            by external Apps.
-    """
-
-    def __init__(self, **kwargs):
-        """Initialize Class Properties."""
-        # catch interrupt signals specifically based on thread name
-        signal.signal(signal.SIGINT, self._signal_handler)
-        if platform.system() != 'Windows':
-            signal.signal(signal.SIGHUP, self._signal_handler)
-        signal.signal(signal.SIGTERM, self._signal_handler)
-
-        # Property defaults
-        self._config: dict = kwargs.get('config') or {}
-        self._log = None
-        self._jobs = None
-        self._redis_client = None
-        self._service = None
-        self.ij = InstallJson()
-        self.main_os_pid = os.getpid()
-
-        # init inputs
-        self.inputs = Input(self._config, kwargs.get('config_file'))
-
-        # add methods to registry
-        registry.add_method(self.inputs.resolve_variable)
-
-        # add methods to registry
-        registry.register(self)
-        registry.add_service(Input, self.inputs)
-
-        # log standard App info early so it shows at the top of the logfile
-        self.logger.log_info(self.inputs.model_unresolved)
-
-    def _signal_handler(self, signal_interrupt: int, _):
-        """Handle signal interrupt."""
-        call_file: str = os.path.basename(inspect.stack()[1][0].f_code.co_filename)
-        call_module: str = inspect.stack()[1][0].f_globals['__name__'].lstrip('Functions.')
-        call_line: int = inspect.stack()[1][0].f_lineno
-        self.log.error(
-            f'App interrupted - file: {call_file}, method: {call_module}, line: {call_line}.'
-        )
-        exit_code = ExitCode.SUCCESS
-        if threading.current_thread().name == 'MainThread' and signal_interrupt in (2, 15):
-            exit_code = ExitCode.FAILURE
+try:
+    # third-party
+    from yaml import CDumper as Dumper
+    from yaml import CLoader as Loader
+except ImportError:
+    from yaml import Dumper, Loader
 
-        self.exit(exit_code, 'The App received an interrupt signal and will now exit.')
+from .install_json import InstallJson
+from .model.app_spec_yml_model import AppSpecYmlModel
+from .tcex_json import TcexJson
 
-    @property
-    def _user_agent(self):
-        """Return a User-Agent string."""
-        return {
-            'User-Agent': (
-                f'TcEx/{__import__(__name__).__version__}, '
-                f'{self.ij.model.display_name}/{self.ij.model.program_version}'
-            )
-        }
+# get logger
+_logger = logging.getLogger(__name__.split('.', maxsplit=1)[0])
 
-    def advanced_request(
-        self,
-        session: Session,
-        output_prefix: str,
-        timeout: Optional[int] = 600,
-    ) -> 'AdvancedRequest':
-        """Return instance of AdvancedRequest.
-
-        Args:
-            session: An instance of requests.Session.
-            output_prefix: A value to prepend to outputs.
-            timeout: The number of second before timing out the request.
-        """
-        return AdvancedRequest(self.inputs, self.playbook, session, output_prefix, timeout)
 
-    @property
-    def api(self) -> 'API':
-        """Return instance of Threat Intel Utils."""
-        return API(self.inputs, self.session_tc)
-
-    def exit(self, code: Optional[ExitCode] = None, msg: Optional[str] = None):
-        """Application exit method with proper exit code
-
-        The method will run the Python standard sys.exit() with the exit code
-        previously defined via :py:meth:`~tcex.tcex.TcEx.exit_code` or provided
-        during the call of this method.
-
-        Args:
-            code: The exit code value for the app.
-            msg: A message to log and add to message tc output.
-        """
-        # get correct code
-        self.exit_service.exit(code, msg)  # pylint: disable=no-member
+class AppSpecYml:
+    """Class object for app_spec.yml configuration file"""
 
-    @property
-    def exit_code(self) -> 'ExitCode':
-        """Return the current exit code."""
-        return self.exit_service.exit_code  # pylint: disable=no-member
-
-    @exit_code.setter
-    def exit_code(self, code: 'ExitCode'):
-        """Set the App exit code.
-
-        For TC Exchange Apps there are 3 supported exit codes.
-        * 0 indicates a normal exit
-        * 1 indicates a failure during execution
-        * 3 indicates a partial failure
-
-        Args:
-            code (int): The exit code value for the app.
-        """
-        self.exit_service.exit_code = code
-
-    @registry.factory(ExitService)
-    @scoped_property
-    def exit_service(self) -> 'ExitService':
-        """Return an ExitService object."""
-        # TODO: [high] @cblades - inputs being required for exit prevents AOT from exiting
-        return self.get_exit_service(self.inputs)
-
-    @cached_property
-    def file_operations(self) -> 'FileOperations':  # pylint: disable=no-self-use
-        """Include the Utils module."""
-        return FileOperations(
-            out_path=self.inputs.model_unresolved.tc_out_path,
-            temp_path=self.inputs.model_unresolved.tc_temp_path,
-        )
+    def __init__(
+        self,
+        filename: str | None = None,
+        path: str | None = None,
+        logger: logging.Logger | None = None,
+    ):
+        """Initialize instance properties."""
+        filename = filename or 'app_spec.yml'
+        path = path or os.getcwd()
+        self.log = logger or _logger
+
+        # properties
+        self.fqfn = Path(os.path.join(path, filename))
+        self.ij = InstallJson(logger=self.log)
+        self.tj = TcexJson(logger=self.log)
 
-    @staticmethod
-    def get_exit_service(inputs) -> 'ExitService':
-        """Create an ExitService object."""
-        return ExitService(inputs)
-
-    def get_playbook(
-        self, context: Optional[str] = None, output_variables: Optional[list] = None
-    ) -> 'Playbook':
-        """Return a new instance of playbook module.
-
-        Args:
-            context: The KV Store context/session_id. For PB Apps the context is provided on
-                startup, but for service Apps each request gets a different context.
-            output_variables: The requested output variables. For PB Apps outputs are provided on
-                startup, but for service Apps each request gets different outputs.
-        """
-        return Playbook(self.key_value_store, context, output_variables)
+    @property
+    def _feature_data_advanced_request_inputs(self):
+        """Return all inputs for advanced request."""
+        return [
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'label': 'API Endpoint/Path',
+                'name': 'tc_adv_req_path',
+                'note': 'The API Path request.',
+                'playbookDataType': ['String'],
+                'required': True,
+                'type': 'String',
+                'validValues': ['${TEXT}'],
+            },
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'default': 'GET',
+                'label': 'HTTP Method',
+                'name': 'tc_adv_req_http_method',
+                'note': 'HTTP method to use.',
+                'required': True,
+                'type': 'Choice',
+                'validValues': ['GET', 'POST', 'DELETE', 'PUT', 'HEAD', 'PATCH', 'OPTIONS'],
+            },
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'label': 'Query Parameters',
+                'name': 'tc_adv_req_params',
+                'note': (
+                    'Query parameters to append to the URL. For sensitive information like API '
+                    'keys, using variables is recommended to ensure that the Playbook will not '
+                    'export sensitive data.'
+                ),
+                'playbookDataType': ['String', 'StringArray'],
+                'required': False,
+                'type': 'KeyValueList',
+                'validValues': ['${KEYCHAIN}', '${TEXT}'],
+            },
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'label': 'Exclude Empty/Null Parameters',
+                'name': 'tc_adv_req_exclude_null_params',
+                'note': (
+                    '''Some API endpoint don't handle null/empty query parameters properly '''
+                    '''(e.g., ?name=&type=String). If selected this options will exclude any '''
+                    '''query parameters that has a null/empty value.'''
+                ),
+                'type': 'Boolean',
+            },
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'label': 'Headers',
+                'name': 'tc_adv_req_headers',
+                'note': (
+                    'Headers to include in the request. When using Multi-part Form/File data, '
+                    'do **not** add a **Content-Type** header. For sensitive information like '
+                    'API keys, using variables is recommended to ensure that the Playbook will '
+                    'not export sensitive data.'
+                ),
+                'playbookDataType': ['String'],
+                'required': False,
+                'type': 'KeyValueList',
+                'validValues': ['${KEYCHAIN}', '${TEXT}'],
+            },
+            {
+                'display': (
+                    '''tc_action in ('Advanced Request') AND tc_adv_req_http_method '''
+                    '''in ('POST', 'PUT', 'DELETE', 'PATCH')'''
+                ),
+                'label': 'Body',
+                'name': 'tc_adv_req_body',
+                'note': 'Content of the HTTP request.',
+                'playbookDataType': ['String', 'Binary'],
+                'required': False,
+                'type': 'String',
+                'validValues': ['${KEYCHAIN}', '${TEXT}'],
+                'viewRows': 4,
+            },
+            {
+                'display': (
+                    '''tc_action in ('Advanced Request') AND tc_adv_req_http_method '''
+                    '''in ('POST', 'PUT', 'DELETE', 'PATCH')'''
+                ),
+                'label': 'URL Encode JSON Body',
+                'name': 'tc_adv_req_urlencode_body',
+                'note': (
+                    '''URL encode a JSON-formatted body. Typically used for'''
+                    ''' 'x-www-form-urlencoded' data, where the data can be configured in the '''
+                    '''body as a JSON string.'''
+                ),
+                'type': 'Boolean',
+            },
+            {
+                'display': '''tc_action in ('Advanced Request')''',
+                'default': True,
+                'label': 'Fail for Status',
+                'name': 'tc_adv_req_fail_on_error',
+                'note': 'Fail if the response status code is 4XX - 5XX.',
+                'type': 'Boolean',
+            },
+        ]
 
     @staticmethod
-    def get_redis_client(
-        host: str, port: int, db: int = 0, blocking_pool: bool = False, **kwargs
-    ) -> Redis:
-        """Return a *new* instance of Redis client.
-
-        For a full list of kwargs see https://redis-py.readthedocs.io/en/latest/#redis.Connection.
-
-        Args:
-            host: The REDIS host. Defaults to localhost.
-            port: The REDIS port. Defaults to 6379.
-            db: The REDIS db. Defaults to 0.
-            blocking_pool: Use BlockingConnectionPool instead of ConnectionPool.
-            **kwargs: Additional keyword arguments.
-
-        Keyword Args:
-            errors (str): The REDIS errors policy (e.g. strict).
-            max_connections (int): The maximum number of connections to REDIS.
-            password (Sensitive): The REDIS password.
-            socket_timeout (int): The REDIS socket timeout.
-            timeout (int): The REDIS Blocking Connection Pool timeout value.
-            username (str): The REDIS username.
-        """
-        # get value from Sensitive value before passing to Redis
-        password = kwargs.get('password')
-        kwargs['password'] = password.value if isinstance(password, Sensitive) else password
-        return RedisClient(
-            host=host, port=port, db=db, blocking_pool=blocking_pool, **kwargs
-        ).client
-
-    def get_session_tc(
-        self,
-        auth: Optional[Union['HmacAuth', 'TokenAuth', 'TcAuth']] = None,
-        base_url: Optional[str] = None,
-        log_curl: Optional[bool] = None,
-        proxies: Optional[Dict[str, str]] = None,  # pylint: disable=redefined-outer-name
-        proxies_enabled: Optional[bool] = None,
-        verify: Optional[Union[bool, str]] = None,
-    ) -> 'TcSession':
-        """Return an instance of Requests Session configured for the ThreatConnect API.
-
-        No args are required to get a working instance of TC Session instance.
+    def _feature_data_advanced_request_outputs(prefix: str) -> dict:
+        """Return all outputs for advanced request."""
+        return {
+            'display': 'tc_action in (\'Advanced Request\')',
+            'outputVariables': [
+                {
+                    'name': f'{prefix}.request.content',
+                },
+                {
+                    'name': f'{prefix}.request.content.binary',
+                    'type': 'Binary',
+                },
+                {
+                    'name': f'{prefix}.request.headers',
+                },
+                {
+                    'name': f'{prefix}.request.ok',
+                },
+                {
+                    'name': f'{prefix}.request.reason',
+                },
+                {
+                    'name': f'{prefix}.request.status_code',
+                },
+                {
+                    'name': f'{prefix}.request.url',
+                },
+            ],
+        }
 
-        This method allows for getting a new instance of TC Session instance. This can be
-        very useful when connecting between multiple TC instances (e.g., migrating data).
-        """
-        if log_curl is None:
-            log_curl = self.inputs.model_unresolved.tc_log_curl
+    def _migrate_schema_100_to_110(self, contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        # moved app.* to top level
+        self._migrate_schema_100_to_110_app(contents)
 
-        if proxies_enabled is None:
-            proxies_enabled = self.inputs.model_unresolved.tc_proxy_tc
+        # migrate app.feeds to app.organization.feeds
+        self._migrate_schema_100_to_110_organization_feeds(contents)
 
-        if verify is None:
-            verify = self.inputs.model_unresolved.tc_verify
+        # migrate app.feeds to app.organization.repeating_minutes
+        self._migrate_schema_100_to_110_organization_repeating_minutes(contents)
 
-        if self.ij.is_external_app is True:
-            auth = auth or TcAuth(
-                tc_api_access_id=self.inputs.model_unresolved.tc_api_access_id,
-                tc_api_secret_key=self.inputs.model_unresolved.tc_api_secret_key,
-            )
-        else:
-            auth = auth or TcAuth(
-                tc_api_access_id=self.inputs.model_unresolved.tc_api_access_id,
-                tc_api_secret_key=self.inputs.model_unresolved.tc_api_secret_key,
-                tc_token=self.token,
-            )
+        # migrate app.feeds to app.organization.publish_out_files
+        self._migrate_schema_100_to_110_organization_publish_out_files(contents)
 
-        return TcSession(
-            auth=auth,
-            base_url=base_url or self.inputs.model_unresolved.tc_api_path,
-            log_curl=log_curl,
-            proxies=proxies or self.proxies,
-            proxies_enabled=proxies_enabled,
-            user_agent=self._user_agent,
-            verify=verify,
-        )
+        # migrate app.inputGroup to new schema
+        self._migrate_schema_100_to_110_input_groups(contents)
 
-    def get_session_external(self) -> 'ExternalSession':
-        """Return an instance of Requests Session configured for the ThreatConnect API."""
-        _session_external = ExternalSession()
-
-        # add User-Agent to headers
-        _session_external.headers.update(self._user_agent)
-
-        # add proxy support if requested
-        if self.inputs.model_unresolved.tc_proxy_external:
-            _session_external.proxies = self.proxies
-            self.log.info(
-                f'Using proxy host {self.inputs.model_unresolved.tc_proxy_host}:'
-                f'{self.inputs.model_unresolved.tc_proxy_port} for external session.'
-            )
+        # migrate app.note to app.notePerAction with new schema
+        self._migrate_schema_100_to_110_notes_per_action(contents)
 
-        if self.inputs.model_unresolved.tc_log_curl:
-            _session_external.log_curl = True
+        # migrate app.outputGroups to outputData with new schema
+        self._migrate_schema_100_to_110_output_groups(contents)
 
-        return _session_external
+        # migrate app.playbookType to category
+        contents['category'] = contents.pop('playbookType', '')
 
-    # def get_ti(self) -> 'ThreatIntelligence':
-    #     """Include the Threat Intel Module."""
-    #     return ThreatIntelligence(session=self.get_session_tc())
-
-    @registry.factory('KeyValueStore')
-    @scoped_property
-    def key_value_store(self) -> Union['KeyValueApi', 'KeyValueRedis']:
-        """Return the correct KV store for this execution.
+        # migrate app.jira to internalNotes schema
+        self._migrate_schema_100_to_110_jira_notes(contents)
 
-        The TCKeyValueAPI KV store is limited to two operations (create and read),
-        while the Redis kvstore wraps a few other Redis methods.
-        """
-        if self.inputs.model_unresolved.tc_kvstore_type == 'Redis':
-            return KeyValueRedis(self.redis_client)
+        # migrate app.releaseNotes to new schema
+        self._migrate_schema_100_to_110_release_notes(contents)
 
-        if self.inputs.model_unresolved.tc_kvstore_type == 'TCKeyValueAPI':
-            return KeyValueApi(self.session_tc)
+        # migrate app.retry to playbook.retry
+        self._migrate_schema_100_to_110_retry(contents)
 
-        if self.inputs.model_unresolved.tc_kvstore_type == 'Mock':
-            self.log.warning(
-                'Using mock key-value store.  '
-                'This should *never* happen when running in-platform.'
-            )
-            return KeyValueMock()
+        # update the schema version
+        contents['schemaVersion'] = contents.get('schemaVersion') or '1.1.0'
 
-        raise RuntimeError(
-            f'Invalid KV Store Type: ({self.inputs.model_unresolved.tc_kvstore_type})'
-        )
+        # dict -> mode -> dict (filtered)
+        self.rewrite_contents(contents)
 
-    @property
-    def log(self) -> 'TraceLogger':
-        """Return a valid logger."""
-        if self._log is None:
-            self._log = self.logger.log
-        return self._log
-
-    @log.setter
-    def log(self, log: object):
-        """Return a valid logger."""
-        if isinstance(log, logging.Logger):
-            self._log = log
+    @staticmethod
+    def _migrate_schema_100_to_110_app(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        # remove "app" top level
+        for k, v in dict(contents).get('app', {}).items():
+            contents[k] = v
+
+        # assure minServerVersion exists
+        if contents.get('minServerVersion') is None:
+            contents['minServerVersion'] = '6.0.0'
 
-    @cached_property
-    def logger(self) -> 'Logger':
-        """Return logger."""
-        _logger = Logger(logger_name='tcex')
+        # remove "app" from "app_spec"
+        del contents['app']
 
-        # set logger to prevent recursion issue on get_session_tc
-        self._log = _logger.log
+    @staticmethod
+    def _migrate_schema_100_to_110_organization_feeds(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        if contents.get('feeds') is not None and contents['runtimeLevel'].lower() == 'organization':
+            contents.setdefault('organization', {})
+            contents['organization']['feeds'] = contents.pop('feeds', [])
 
-        # add api handler
+    @staticmethod
+    def _migrate_schema_100_to_110_organization_repeating_minutes(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
         if (
-            self.inputs.contents.get('tc_token') is not None
-            and self.inputs.contents.get('tc_log_to_api') is True
+            contents.get('repeatingMinutes') is not None
+            and contents['runtimeLevel'].lower() == 'organization'
         ):
-            _logger.add_api_handler(
-                session_tc=self.get_session_tc(), level=self.inputs.model_unresolved.tc_log_level
-            )
-
-        # add rotating log handler
-        _logger.add_rotating_file_handler(
-            name='rfh',
-            filename=self.inputs.model_unresolved.tc_log_file,
-            path=self.inputs.model_unresolved.tc_log_path,
-            backup_count=self.inputs.model_unresolved.tc_log_backup_count,
-            max_bytes=self.inputs.model_unresolved.tc_log_max_bytes,
-            level=self.inputs.model_unresolved.tc_log_level,
-        )
-
-        # set logging level
-        _logger.update_handler_level(level=self.inputs.model_unresolved.tc_log_level)
-        _logger.log.setLevel(_logger.log_level(self.inputs.model_unresolved.tc_log_level))
-
-        # replay cached log events
-        _logger.replay_cached_events(handler_name='cache')
-
-        return _logger
+            contents.setdefault('organization', {})
+            contents['organization']['repeatingMinutes'] = contents.pop('repeatingMinutes', [])
 
-    @registry.factory(Playbook)
-    @scoped_property
-    def playbook(self) -> 'Playbook':
-        """Return an instance of Playbooks module.
-
-        This property defaults context and outputvariables to arg values.
-
-        Returns:
-            tcex.playbook.Playbooks: An instance of Playbooks
-        """
-        return self.get_playbook(
-            context=self.inputs.model_unresolved.tc_playbook_kvstore_context,
-            output_variables=self.inputs.model_unresolved.tc_playbook_out_variables,
-        )
+    @staticmethod
+    def _migrate_schema_100_to_110_organization_publish_out_files(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        if (
+            contents.get('publishOutFiles') is not None
+            and contents['runtimeLevel'].lower() == 'organization'
+        ):
+            contents.setdefault('organization', {})
+            contents['organization']['publishOutFiles'] = contents.pop('publishOutFiles', [])
 
-    @cached_property
-    def proxies(self) -> dict:
-        """Format the proxy configuration for Python Requests module.
+    @staticmethod
+    def _migrate_schema_100_to_110_input_groups(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        contents['sections'] = contents.pop('inputGroups', {})
+        for section in contents.get('sections') or []:
+            section['sectionName'] = section.pop('group')
+            section['params'] = section.pop('inputs')
+
+            # add missing name
+            for param in section['params']:
+                if param.get('name') is None:
+                    param['name'] = param.get('label')
 
-        Generates a dictionary for use with the Python Requests module format
-        when proxy is required for remote connections.
+                if 'sequence' in param:
+                    del param['sequence']
 
-        **Example Response**
-        ::
+                if param.get('type') is None:
+                    param['type'] = 'String'
 
-            {"http": "http://user:pass@10.10.1.10:3128/"}
+    @staticmethod
+    def _migrate_schema_100_to_110_notes_per_action(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        contents['notePerAction'] = contents.pop('notes', {})
+        note_per_action = []
+        for action, note in contents['notePerAction'].items():
+            note_per_action.append({'action': action, 'note': note})
+        contents['notePerAction'] = note_per_action
 
-        Returns:
-           (dict): Dictionary of proxy settings
-        """
-        return proxies(
-            proxy_host=self.inputs.model_unresolved.tc_proxy_host,
-            proxy_port=self.inputs.model_unresolved.tc_proxy_port,
-            proxy_user=self.inputs.model_unresolved.tc_proxy_username,
-            proxy_pass=self.inputs.model_unresolved.tc_proxy_password,
-        )
+    @staticmethod
+    def _migrate_schema_100_to_110_retry(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        if contents['runtimeLevel'].lower() == 'playbook':
+            contents.setdefault('playbook', {})
+            if contents.get('playbook', {}).get('retry'):
+                contents['playbook']['retry'] = contents.pop('retry', {})
 
-    @registry.factory(RedisClient)
-    @scoped_property
-    def redis_client(self) -> Redis:
-        """Return redis client instance configure for Playbook/Service Apps."""
-        return self.get_redis_client(
-            host=self.inputs.contents.get('tc_kvstore_host'),
-            port=self.inputs.contents.get('tc_kvstore_port'),
-            db=0,
-            username=self.inputs.contents.get('tc_kvstore_user'),
-            password=self.inputs.contents.get('tc_kvstore_pass'),
-        )
+    @staticmethod
+    def _migrate_schema_100_to_110_output_groups(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        outputs = []
+        contents['outputData'] = contents.pop('outputGroups', {})
+        for display, group in contents.get('outputData', {}).items():
+            output_data = {'display': display, 'outputVariables': []}
+
+            # fix schema when output type is assumed
+            if isinstance(group, list):
+                group = {'String': group}
+
+            for variable_type, variables in group.items():
+                for name in variables:
+                    disabled = False
+                    if name.startswith('~'):
+                        name = name.replace('~', '')
+                        disabled = True
+
+                    output_data['outputVariables'].append(
+                        {
+                            'disabled': disabled,
+                            'encrypt': False,
+                            'intelTypes': [],
+                            'name': name,
+                            'note': None,
+                            'type': variable_type,
+                        }
+                    )
+            outputs.append(output_data)
+        contents['outputData'] = outputs
 
-    def results_tc(self, key: str, value: str):
-        """Write data to results_tc file in TcEX specified directory.
+    @staticmethod
+    def _migrate_schema_100_to_110_jira_notes(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        jira_notes = []
+        for k, v in contents.get('jira', {}).items():
+            # look for the trailer to find our items
+            if k == '_TRAILER_':
+                for item in v:
+                    jira_notes.append(item)
+        contents['internalNotes'] = jira_notes
 
-        The TcEx platform support persistent values between executions of the App.  This
-        method will store the values for TC to read and put into the Database.
+    @staticmethod
+    def _migrate_schema_100_to_110_release_notes(contents: dict):
+        """Migrate 1.0.0 schema to 1.1.0 schema."""
+        release_notes = []
+        # need to see if this exist, older apps it might not
+        if contents.get('releaseNotes'):
+            for k, v in contents.get('releaseNotes', {}).items():
+                release_notes.append({'version': k, 'notes': v})
+        contents['releaseNotes'] = release_notes
 
-        Args:
-            key: The data key to be stored.
-            value: The data value to be stored.
-        """
-        if os.access(self.inputs.model_unresolved.tc_out_path, os.W_OK):
-            results_file = f'{self.inputs.model_unresolved.tc_out_path}/results.tc'
-        else:
-            results_file = 'results.tc'
+    @cached_property
+    def contents(self) -> dict:
+        """Return install.json file contents."""
 
-        new = True
-        # ensure file exists
-        open(results_file, 'a').close()  # pylint: disable=consider-using-with
-        with open(results_file, 'r+') as fh:
-            results = ''
-            for line in fh.read().strip().split('\n'):
-                if not line:
-                    continue
+        def _load_contents() -> dict:
+            """Load contents from file."""
+            contents = {}
+            if self.fqfn.is_file():
                 try:
-                    k, v = line.split(' = ')
-                except ValueError:
-                    # handle null/empty value (e.g., "name =")
-                    k, v = line.split(' =')
-                if k == key:
-                    v = value
-                    new = False
-                if v is not None:
-                    results += f'{k} = {v}\n'
-            if new and value is not None:  # indicates the key/value pair didn't already exist
-                results += f'{key} = {value}\n'
-            fh.seek(0)
-            fh.write(results)
-            fh.truncate()
-
-    @cached_property
-    def service(self) -> Union['ApiService', 'CommonServiceTrigger', 'WebhookTriggerService']:
-        """Include the Service Module."""
-        if self.ij.model.is_api_service_app:
-            from .services import ApiService as Service
-        elif self.ij.model.is_trigger_app and not self.ij.model.is_webhook_trigger_app:
-            from .services import CommonServiceTrigger as Service
-        elif self.ij.model.is_webhook_trigger_app:
-            from .services import WebhookTriggerService as Service
+                    with self.fqfn.open(encoding='utf-8') as fh:
+                        contents = yaml.load(fh, Loader=Loader)  # nosec
+                except (OSError, ValueError):  # pragma: no cover
+                    self.log.error(
+                        f'feature=app-spec-yml, exception=failed-reading-file, filename={self.fqfn}'
+                    )
+            else:  # pragma: no cover
+                self.log.error(
+                    f'feature=app-spec-yml, exception=file-not-found, filename={self.fqfn}'
+                )
+
+            return contents
+
+        contents = _load_contents()
+
+        # migrate schema from 1.0.0 to 1.1.0
+        if contents.get('schemaVersion', '1.0.0') == '1.0.0':
+            self._migrate_schema_100_to_110(contents)
         else:
-            self.exit(1, 'Could not determine the service type.')
+            # reformat file
+            self.rewrite_contents(contents)
+
+        # migrate schema
+        return _load_contents()
 
-        return Service(self)
+    @staticmethod
+    def dict_to_yaml(data: dict) -> str:
+        """Convert dict to yaml."""
+        return yaml.dump(
+            data,
+            Dumper=Dumper,
+            default_flow_style=False,
+            sort_keys=False,
+        )
 
-    @registry.factory(TcSession)
-    @scoped_property
-    def session_tc(self) -> 'TcSession':
-        """Return an instance of Requests Session configured for the ThreatConnect API."""
-        return self.get_session_tc()
-
-    @scoped_property
-    def session_external(self) -> 'ExternalSession':
-        """Return an instance of Requests Session configured for the ThreatConnect API."""
-        return self.get_session_external()
-
-    def set_exit_code(self, exit_code: int):
-        """Set the exit code (registry)"""
-        self.exit_code = exit_code
+    @property
+    def has_spec(self):
+        """Return True if App has app_spec.yml file."""
+        return self.fqfn.is_file()
 
-    @registry.factory(Tokens, singleton=True)
     @cached_property
-    def token(self) -> 'Tokens':
-        """Return token object."""
-        _proxies = None
-        if self.inputs.model_unresolved.tc_proxy_tc is True:
-            _proxies = self.proxies
-
-        _tokens = Tokens(
-            self.inputs.model_unresolved.tc_api_path,
-            self.inputs.model_unresolved.tc_verify,
-            _proxies,
-        )
+    def model(self) -> AppSpecYmlModel:
+        """Return the Install JSON model.
 
-        # register token for Apps that pass token on start
-        if all(
-            [self.inputs.model_unresolved.tc_token, self.inputs.model_unresolved.tc_token_expires]
+        If writing app_spec.yml file after the method then the model will include
+        advancedRequest inputs/outputs, etc.
+        """
+        _contents = self.contents
+        # special case for dynamic handling of advancedRequest feature
+        if 'advancedRequest' in _contents.get('features', []):
+            # look for a Configure section which required for Advanced Request
+            if 'Configure' not in [
+                section.get('sectionName') for section in _contents.get('sections', [])
+            ]:
+                raise RuntimeError('The advancedRequest feature requires a Configure section.')
+
+            # Add "Advanced Request" action to Valid Values
+            # when "advancedRequest" feature is enabled
+            for section in _contents.get('sections', []):
+                for param in section.get('params', []):
+                    if param.get('name') == 'tc_action' and 'Advanced Request' not in param.get(
+                        'validValues', []
+                    ):
+                        param['validValues'].append('Advanced Request')
+
+                if section.get('sectionName') == 'Configure':
+                    section['params'].extend(self._feature_data_advanced_request_inputs)
+
+            # add outputs
+            prefix = _contents.get('outputPrefix', '')
+            _contents['outputData'].append(self._feature_data_advanced_request_outputs(prefix))
+
+        return AppSpecYmlModel(**self.contents)
+
+    def fix_contents(self, contents: dict):
+        """Fix missing data"""
+        # fix for null appId value
+        if 'appId' in contents and contents.get('appId') is None:
+            del contents['appId']
+
+        # fix missing packageName
+        if contents.get('packageName') is None:
+            contents['packageName'] = self.tj.model.package.app_name
+
+        # fix missing outputPrefix
+        if contents.get('outputPrefix') is None and 'advancedRequest' in contents.get(
+            'features', []
         ):
-            _tokens.register_token(
-                key=threading.current_thread().name,
-                token=self.inputs.model_unresolved.tc_token,
-                expires=self.inputs.model_unresolved.tc_token_expires,
-            )
-        return _tokens
+            if self.ij.model.playbook is not None:
+                contents['outputPrefix'] = self.ij.model.playbook.output_prefix
 
-    @property
-    def ti_utils(self) -> 'ThreatIntelUtils':
-        """Return instance of Threat Intel Utils."""
-        return ThreatIntelUtils(self.session_tc)
+    def rewrite_contents(self, contents: dict):
+        """Rewrite app_spec.yml file."""
+        self.fix_contents(contents)
+
+        # exclude_defaults - if False then all unused fields are added in - not good.
+        # exclude_none - this should be safe to leave as True.
+        # exclude_unset - this should be False to ensure that all fields are included.
+        contents = json.loads(
+            AppSpecYmlModel(**contents).json(
+                by_alias=True,
+                exclude_defaults=True,
+                exclude_none=True,
+                exclude_unset=False,
+                sort_keys=True,
+            )
+        )
 
-    @cached_property
-    def utils(self) -> 'Utils':  # pylint: disable=no-self-use
-        """Include the Utils module."""
-        return Utils()
+        # write the new contents to the file
+        self.write(contents)
 
-    @cached_property
-    def v2(self) -> 'V2':
-        """Return a case management instance."""
-        return V2(self.inputs, self.session_tc)
+        return contents
 
-    @cached_property
-    def v3(self) -> 'V3':
-        """Return a case management instance."""
-        return V3(self.session_tc)
+    def write(self, contents: dict):
+        """Write yaml to file."""
+        with self.fqfn.open(mode='w', encoding='utf-8') as fh:
+            fh.write(self.dict_to_yaml(contents))
```

### Comparing `tcex-3.0.9/tcex/tokens/tokens.py` & `tcex-4.0.0/tcex/app/token/token.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-"""TcEx Framework Service module"""
+"""TcEx Framework Module"""
 # standard library
 import logging
 import os
 import threading
 import time
-from typing import Optional
 
 # third-party
 from requests import Session, exceptions
 from requests.adapters import HTTPAdapter
 from urllib3.util.retry import Retry
 
 # first-party
-from tcex.input.field_types.sensitive import Sensitive
-from tcex.pleb.threading import ExceptionThread
-from tcex.utils import Utils
+from tcex.input.field_type.sensitive import Sensitive
+from tcex.logger.trace_logger import TraceLogger
+from tcex.pleb.cached_property import cached_property
+from tcex.pleb.exception_thread import ExceptionThread
 
 # get tcex logger
-logger = logging.getLogger('tcex')
+_logger: TraceLogger = logging.getLogger(__name__.split('.', maxsplit=1)[0])  # type: ignore
 
 
 def retry_session(retries=3, backoff_factor=0.8, status_forcelist=(500, 502, 504)):
     """Add retry to Requests Session.
 
     https://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html#urllib3.util.retry.Retry
     """
@@ -34,81 +34,110 @@
         status_forcelist=status_forcelist,
     )
     # mount all https requests
     session.mount('https://', HTTPAdapter(max_retries=retries))
     return session
 
 
-class Tokens:
-    """Service methods for customer Service (e.g., Triggers)."""
+class Token:
+    """TcEx Module"""
 
     def __init__(
         self,
-        token_url: Optional[str],
-        verify: Optional[bool] = True,
-        proxies: Optional[dict] = None,
+        token_url: str,
+        verify: bool = True,
+        proxies: dict | None = None,
     ):
         """Initialize the Class properties.
 
         Args:
             token_url: The ThreatConnect URL for token renewal.
             verify: A boolean to enable/disable SSL verification.
             proxies: A dictionary of proxy settings.
         """
+        self.proxies = proxies
         self.token_url = token_url
         self.verify = verify
 
         # validation for singleton
-        if not token_url:
+        if not token_url:  # pragma: no cover
             raise ValueError('A value for token_url is required.')
 
         # properties
-        #
+        self._shutdown = False
+
         # Threading event that is used as a barrier that determines whether a token can be retrieved
         # from this module or not (via the token property). The barrier only blocks access to the
         # token property whenever token renewal is taking place in order to keep from returning
         # stale tokens.
         self._barrier = threading.Event()
         # Setting barrier event to True disables barrier, which makes the token property
         # accessible (default behavior)
         self._barrier.set()
-
         # threading event that denotes whether renewal monitor should sleep after a renewal cycle
         self._monitor_sleep_interval = threading.Event()
-
-        self.log = logger
-        self.monitor_thread = None
+        self.log = _logger
+        self.monitor_thread: ExceptionThread
         # session with retry for token renewal
-        self.session: Session = retry_session()
-        self.session.proxies = proxies  # add proxies to session
         self.sleep_interval = int(os.getenv('TC_TOKEN_SLEEP_INTERVAL', '150'))
-        self._shutdown = False  # shutdown boolean
         # token map for storing keys -> tokens -> threads
         self.token_map = {}
         # amount of time to wait before starting renewal process (after enabling barrier)
         # buffer allows any other threads using a token to possibly finish their work
         self.token_renewal_buffer_time = 5
         self.token_window = 600  # seconds to pad before token renewal
-        self.utils = Utils
 
         # start token renewal process
         self.token_renewal()
 
+    def get_token(self) -> Sensitive | None:
+        """Return token for current thread."""
+        # wait until renewal barrier is set to True (meaning no renewal
+        # is in progress). If already true, then simply proceed.
+
+        # perform three attempts - safety net in case of heavily overloaded monitor. If
+        # we cannot retrieve a token after three attempts, there must be an issue
+        for i in range(3):
+            if self._barrier.wait(timeout=self.token_renewal_buffer_time + 10):
+                return self.token_map.get(self.key, {}).get('token')
+
+            self.log.debug(
+                'Timeout expired while waiting for token renewal barrier to be disabled. '
+                f'Attempts: {i + 1}'
+            )
+
+            if not self.monitor_thread.is_alive():
+                break
+
+        self.log.error(
+            'Could not retrieve TC token. Token renewal monitor did not disable token barrier. '
+            f'Token renewal monitor thread alive: {self.monitor_thread.is_alive()}'
+        )
+
+        # timeout expired, monitor likely offline
+        exc = RuntimeError(
+            'Timeout expired while waiting for renewal thread to disable token barrier.'
+        )
+        if self.monitor_thread.exception is not None:
+            raise exc from self.monitor_thread.exception
+
+        raise exc  # pragma: no cover
+
     @property
     def key(self) -> str:
         """Return the current key"""
         key = 'MainThread'  # default Python parent thread name
         if self.thread_name in self.token_map:
             # for Job, Playbook, and ApiService Apps the key is the thread name.
-            key: str = self.thread_name
-        elif self.trigger_id in self.token_map:
-            key: str = self.trigger_id
+            key = self.thread_name
+        elif self.trigger_id is not None and self.trigger_id in self.token_map:
+            key = str(self.trigger_id)
         return key
 
-    def register_token(self, key: str, token: Sensitive, expires: int):
+    def register_token(self, key: str, token: Sensitive | str | None, expires: int | None):
         """Register a token.
 
         Args:
             key: The key to use to identify a token. Typically a thread name or a config id.
             token: The ThreatConnect API token.
             expires: The token expiration timestamp.
         """
@@ -129,15 +158,16 @@
 
         This method will renew a token and update the token_map with new token and expiration.
 
         Args:
             token: The ThreatConnect API token.
         """
         api_token_data = {}
-        self.log.in_token_renewal = True  # pause API logging
+        # pause API logging
+        self.log.in_token_renewal = True  # type: ignore
 
         # log token information
         try:
             params = {'expiredToken': token.value}
             url = f'{self.token_url}/appAuth'
             r = self.session.get(url, params=params, verify=self.verify)
 
@@ -154,18 +184,26 @@
 
         # process response for token
         try:
             api_token_data = r.json()
         except (AttributeError, ValueError) as e:  # pragma: no cover
             raise RuntimeError(f'Token renewal failed ({e}).')
         finally:
-            self.log.in_token_renewal = False
+            self.log.in_token_renewal = False  # type: ignore
 
         return api_token_data
 
+    @cached_property
+    def session(self) -> Session:
+        """Return the session."""
+        session = retry_session()
+        if self.proxies:
+            session.proxies = self.proxies
+        return session
+
     @property
     def shutdown(self) -> bool:
         """Retrieve shutdown property"""
         return self._shutdown
 
     @shutdown.setter
     def shutdown(self, value: bool):
@@ -181,54 +219,25 @@
 
     @property
     def thread_name(self) -> str:
         """Return the current thread name."""
         return threading.current_thread().name
 
     @property
-    def token(self) -> Optional['Sensitive']:
+    def token(self) -> Sensitive | None:
         """Return token for current thread."""
-        # wait until renewal barrier is set to True (meaning no renewal is in progress). If already
-        # true, then simply proceed.
-
-        # perform three attempts - safety net in case of heavily overloaded monitor. If we cannot
-        # retrieve a token after three attempts, there must be an issue
-        for i in range(3):
-            if self._barrier.wait(timeout=self.token_renewal_buffer_time + 10):
-                return self.token_map.get(self.key, {}).get('token')
-
-            self.log.debug(
-                'Timeout expired while waiting for token renewal barrier to be disabled. '
-                f'Attempts: {i + 1}'
-            )
-
-            if not self.monitor_thread.is_alive():
-                break
-
-        self.log.error(
-            'Could not retrieve TC token. Token renewal monitor did not disable token barrier. '
-            f'Token renewal monitor thread alive: {self.monitor_thread.is_alive()}'
-        )
-
-        # timeout expired, monitor likely offline
-        exc = RuntimeError(
-            'Timeout expired while waiting for renewal thread to disable token barrier.'
-        )
-        if self.monitor_thread.exception is not None:
-            raise exc from self.monitor_thread.exception
-
-        raise exc
+        return self.get_token()
 
     @token.setter
-    def token(self, token: 'Sensitive'):
+    def token(self, token: Sensitive | str):
         """Set token for current thread."""
         self.token_map.setdefault(self.key, {})['token'] = Sensitive(token)
 
     @property
-    def token_expires(self) -> Optional[int]:
+    def token_expires(self) -> int | None:
         """Return token_expires for current thread."""
         return self.token_map.get(self.key, {}).get('token_expires')
 
     @token_expires.setter
     def token_expires(self, expires):
         """Set token expires for current thread."""
         self.token_map.setdefault(self.key, {})['token_expires'] = int(expires)
@@ -242,16 +251,16 @@
 
     def token_renewal_monitor(self):
         """Monitor token expiration and renew when required."""
         self.log.debug('feature=token, event=renewal-monitor-started')
         self._barrier.set()
         self._monitor_sleep_interval.wait(self.sleep_interval)
         while True:
-            # Clear renewal barrier (setting it to False), which blocks access to token via
-            # the token property.
+            # Clear renewal barrier (setting it to False), which
+            # blocks access to token via # the token property.
             self._barrier.clear()
             self.log.debug('Token renewal barrier enabled.')
             self._monitor_sleep_interval.wait(self.token_renewal_buffer_time)
             for key, token_data in dict(self.token_map).items():
                 # calculate the time left to sleep
                 sleep_seconds = (
                     token_data.get('token_expires') - int(time.time()) - self.token_window
@@ -280,33 +289,34 @@
                 except RuntimeError as e:
                     self.log.error(e)
                     try:
                         del self.token_map[key]
                         self.log.error(f'feature=token, event=token-removal-failure, key={key}')
                     except KeyError:  # pragma: no cover
                         pass
+
             # renewal loop is finished, grant access to token via token property once again
             self._barrier.set()
             self.log.debug('Token renewal barrier disabled.')
 
             # if monitor has not been shutdown, renewal monitor will sleep for sleep_interval
             # seconds. If monitor has been shutdown, monitor does not sleep and proceeds to
-            # the shutdown logic within the if statement below. If the monitor is already sleeping,
-            # the monitor wakes up and proceeds to the shutdown logic.
+            # the shutdown logic within the if statement below. If the monitor is already
+            # sleeping, the monitor wakes up and proceeds to the shutdown logic.
             self._monitor_sleep_interval.wait(self.sleep_interval)
-            if self.shutdown is True:
+            if self.shutdown is True:  # pragma: no cover
                 self.log.debug('Token renewal monitor shutdown signal received')
                 break
 
     @property
-    def trigger_id(self) -> Optional[int]:
+    def trigger_id(self) -> int | None:
         """Return the current trigger_id."""
         trigger_id = None
         if hasattr(threading.current_thread(), 'trigger_id'):
-            trigger_id = threading.current_thread().trigger_id
+            trigger_id = threading.current_thread().trigger_id  # type: ignore
         if trigger_id is not None:
             trigger_id = int(trigger_id)
         return trigger_id
 
     def unregister_token(self, key: str):
         """Unregister a token.
```

### Comparing `tcex-3.0.9/tcex/utils/aes_operations.py` & `tcex-4.0.0/tcex/util/aes_operation.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-"""TcEx Utilities AES Operations Module"""
+"""TcEx Framework Module"""
 # standard library
-from typing import Optional, Union
+from typing import cast
 
 # third-party
 import pyaes
 
 
-class AesOperations:
+class AesOperation:
     """TcEx Utilities AES Operations Class"""
 
     @staticmethod
     def decrypt_aes_cbc(
-        key: bytes, ciphertext: Union[bytes, str], iv: Optional[bytes] = None
+        key: bytes | str, ciphertext: bytes | str, iv: bytes | str | None = None
     ) -> bytes:
         """Return AES CBC decrypted string.
 
         Args:
             key: The encryption key.
             ciphertext: The ciphertext to decrypt.
             iv: The CBC initial vector.
@@ -29,19 +29,19 @@
         # ensure iv is bytes
         if isinstance(iv, str):
             iv = iv.encode()
 
         aes_cbc_decrypt = pyaes.Decrypter(pyaes.AESModeOfOperationCBC(key, iv=iv))
         decrypted = aes_cbc_decrypt.feed(ciphertext)
         decrypted += aes_cbc_decrypt.feed()
-        return decrypted
+        return cast(bytes, decrypted)
 
     @staticmethod
     def encrypt_aes_cbc(
-        key: bytes, plaintext: Union[bytes, str], iv: Optional[bytes] = None
+        key: bytes | str, plaintext: bytes | str, iv: bytes | str | None = None
     ) -> bytes:
         """Return AES CBC encrypted string.
 
         Args:
             key: The encryption key.
             plaintext: The text to encrypt.
             iv: The CBC initial vector.
@@ -59,8 +59,8 @@
         # ensure iv is bytes
         if isinstance(iv, str):
             iv = iv.encode()
 
         aes_cbc_encrypt = pyaes.Encrypter(pyaes.AESModeOfOperationCBC(key, iv=iv))
         encrypted = aes_cbc_encrypt.feed(plaintext)
         encrypted += aes_cbc_encrypt.feed()
-        return encrypted
+        return cast(bytes, encrypted)
```

### Comparing `tcex-3.0.9/tcex/utils/datetime_operations.py` & `tcex-4.0.0/tcex/util/datetime_operation.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,35 +1,40 @@
-"""TcEx Utilities Datetime Operations Module"""
+"""TcEx Framework Module"""
 # standard library
+from collections.abc import Generator
 from datetime import datetime
-from typing import Any, Optional, Tuple, Union
 
 # third-party
 import arrow as _arrow
+from arrow import Arrow
 from dateutil import parser
 from dateutil.relativedelta import relativedelta
 
 
-class DatetimeOperations:
+class DatetimeOperation:
     """TcEx Utilities Datetime Operations Class"""
 
     @classmethod
-    def any_to_datetime(cls, datetime_expression: str, tz: Optional[str] = None) -> '_arrow.Arrow':
+    def any_to_datetime(
+        cls,
+        datetime_expression: int | str | datetime | Arrow,
+        tz: str | None = None,
+    ) -> Arrow:
         """Return a arrow object from datetime expression.
 
         Args:
-            datetime_expression: the datetime expression to parse into an Arrow datetime object.
-
-            tz: if provided, the parsed Arrow datetime object will be converted to the timezone
-            resulting from this timezone expression. Accepts values like 'US/Pacific', '-07:00',
-            'UTC'.
-            When this parameter is None, the returned Arrow datetime object will retain
-            its timezone information if datetime_expression is timezone-aware. If
-            datetime_expression is not timezone-aware, then the returned Arrow datetime object
-            will have UTC timezone info.
+            datetime_expression: The datetime expression to parse into an Arrow datetime object.
+            tz: If provided, the parsed Arrow datetime object will be converted to the timezone
+                resulting from this timezone expression. Accepts values like 'US/Pacific', '-07:00',
+                'UTC'.
+
+                When this parameter is None, the returned Arrow datetime object will retain
+                its timezone information if datetime_expression is timezone-aware. If
+                datetime_expression is not timezone-aware, then the returned Arrow datetime object
+                will have UTC timezone info.
         """
         value = str(datetime_expression)
 
         # note: order matters. For example, _parse_timestamp could parse inputs that would have
         # been meant for one of the default parser formats
         parser_methods = [
             cls._parse_default_arrow_formats,
@@ -45,97 +50,93 @@
             except Exception:  # nosec
                 # value could not be parsed by current method.
                 pass
             else:
                 # convert timezone if tz arg provided, else return parsed object
                 return cls._convert_timezone(parsed, tz) if tz is not None else parsed
 
-        raise RuntimeError(
+        raise RuntimeError(  # pragma: no cover
             f'Value "{value}" of type "{type(datetime_expression)}" '
             'could not be parsed as a date time object.'
         )
 
     @property
     def arrow(self):
         """Return arrow for use in Apps."""
         return _arrow
 
     def chunk_date_range(
         self,
-        start_date: Union[int, str, datetime, '_arrow.Arrow'],
-        end_date: Union[int, str, datetime, '_arrow.Arrow'],
-        chunk_size: int,
-        chunk_unit: Optional[str] = 'months',
-        date_format: Optional[str] = None,
-    ) -> Tuple[Union['_arrow.Arrow', str], Union['_arrow.Arrow', str]]:
+        start_date: int | str | datetime | Arrow,
+        end_date: int | str | datetime | Arrow,
+        chunk_size: int = 1,
+        chunk_unit: str = 'months',
+        date_format: str | None = None,
+    ) -> Generator[tuple[Arrow | str, Arrow | str], None, None]:
         """Chunk a date range based on unit and size
 
         Args:
             start_date: Date time expression or datetime object.
             end_date: Date time expression or datetime object.
             chunk_size: Chunk size for the provided units.
             chunk_unit: A value of year, quarter, month, day, week, hour, minute, second (plural
             versions of valid values also acceptable)
             date_format: If None datetime object will be returned. Any other value
                 must be a valid strftime format (%s for epoch seconds).
-
-        Returns:
-            Tuple[Union[arrow.Arrow, str], Union[arrow.Arrow, str]]: Either a datetime object
-                or a string representation of the date.
         """
         start_date = self.any_to_datetime(start_date)
         end_date = self.any_to_datetime(end_date)
         interval_args = {
             'frame': chunk_unit,
             'start': start_date,
             'end': end_date,
             'interval': chunk_size,
             'bounds': '[]',
             'exact': True,
         }
 
         try:
-            for range_tuple in _arrow.Arrow.interval(**interval_args):
+            for range_tuple in Arrow.interval(**interval_args):
                 if date_format is not None:
-                    yield range_tuple[0].strftime(date_format), range_tuple[1].strftime(date_format)
-                else:
-                    yield range_tuple
-        except Exception as ex:
+                    range_tuple = range_tuple[0].strftime(date_format), range_tuple[1].strftime(
+                        date_format
+                    )
+                yield range_tuple
+        except Exception as ex:  # pragma: no cover
             raise RuntimeError(
                 'Could not generate date range. Please verify that chunk_size, chunk_unit, '
                 'and date_format values are valid.'
             ) from ex
 
-    def timedelta(self, time_input1: str, time_input2: str) -> dict:
+    def timedelta(
+        self, time_input1: int | str | datetime | Arrow, time_input2: int | str | datetime | Arrow
+    ) -> dict:
         """Calculate the time delta between two time expressions.
 
         Args:
-            time_input1: The time input string (see formats above).
-            time_input2: The time input string (see formats above).
-
-        Returns:
-            (dict): Dict with delta values.
+            time_input1: The end time expression (larger time value).
+            time_input2: The start time input string (smaller time value).
         """
-        time_input1: datetime = self.any_to_datetime(time_input1).datetime
-        time_input2: datetime = self.any_to_datetime(time_input2).datetime
+        time_input1_ = self.any_to_datetime(time_input1).datetime
+        time_input2_ = self.any_to_datetime(time_input2).datetime
 
-        diff = time_input1 - time_input2  # timedelta
-        delta: object = relativedelta(time_input1, time_input2)  # relativedelta
+        diff = time_input1_ - time_input2_  # timedelta
+        delta = relativedelta(time_input1_, time_input2_)  # relativedelta
 
         # totals
         total_months = (delta.years * 12) + delta.months
         total_weeks = (delta.years * 52) + (total_months * 4) + delta.weeks
         total_days = diff.days  # handles leap days
         total_hours = (total_days * 24) + delta.hours
         total_minutes = (total_hours * 60) + delta.minutes
         total_seconds = (total_minutes * 60) + delta.seconds
         total_microseconds = (total_seconds * 1000) + delta.microseconds
         return {
-            'datetime_1': time_input1.isoformat(),
-            'datetime_2': time_input2.isoformat(),
+            'datetime_1': time_input1_.isoformat(),
+            'datetime_2': time_input2_.isoformat(),
             'years': delta.years,
             'months': delta.months,
             'weeks': delta.weeks,
             'days': delta.days,
             'hours': delta.hours,
             'minutes': delta.minutes,
             'seconds': delta.seconds,
@@ -146,30 +147,30 @@
             'total_hours': total_hours,
             'total_minutes': total_minutes,
             'total_seconds': total_seconds,
             'total_microseconds': total_microseconds,
         }
 
     @classmethod
-    def _convert_timezone(cls, arrow_dt: '_arrow.Arrow', tz: str):
+    def _convert_timezone(cls, arrow_dt: Arrow, tz: str):
         """Convert Arrow datetime's timezone
 
         Args:
             arrow_dt: Arrow datetime object that will have its timezone converted
             tz: timezone expression. Accepts values like 'US/Pacific', '-07:00', 'UTC'.
         """
         try:
             return arrow_dt.to(tz)
-        except Exception as ex:
+        except Exception as ex:  # pragma: no cover
             raise RuntimeError(
                 f'Could not convert datetime to timezone "{tz}". Please verify timezone input.'
             ) from ex
 
     @staticmethod
-    def _parse_default_arrow_formats(value: Any) -> '_arrow.Arrow':
+    def _parse_default_arrow_formats(value: str) -> Arrow:
         """Attempt to parse value using default Arrow formats.
 
         The value is simply passed into Arrow's "get" method. The following are the default
         date formats (found in arrow.parser.DateTimeParser.parse_iso):
 
         "YYYY-MM-DD",
         "YYYY-M-DD",
@@ -191,15 +192,15 @@
         "YYYY",
         # ISO week date: 2011-W05-4, 2019-W17
         "W"
         """
         return _arrow.get(value)
 
     @staticmethod
-    def _parse_humanized_input(value: Any) -> '_arrow.Arrow':
+    def _parse_humanized_input(value: str) -> Arrow:
         """Attempt to dehumanize time inputs. Example: 'Two hours ago'."""
         now = _arrow.utcnow()
         plurals = {
             'second': 'seconds',
             'minute': 'minutes',
             'hour': 'hours',
             'day': 'days',
@@ -215,15 +216,15 @@
         # pluralize singular time terms as applicable. Arrow does not support singular terms
         terms = [plurals.get(term, term) for term in value.split()]
         value = ' '.join(terms)
 
         return now.dehumanize(value)
 
     @staticmethod
-    def _parse_non_default_arrow_formats(value: Any) -> '_arrow.Arrow':
+    def _parse_non_default_arrow_formats(value: str) -> Arrow:
         """Attempt to parse value using non-default Arrow formats
 
         These are formats that Arrow provides constants for but are not used in the "get"
         method (Arrow method that parses values into datetimes) by default.
 
         Note: passing formats to test against overrides the default formats. Defaults are not used.
         """
@@ -240,28 +241,28 @@
                 _arrow.FORMAT_RFC3339,
                 _arrow.FORMAT_RSS,
                 _arrow.FORMAT_W3C,
             ],
         )
 
     @staticmethod
-    def _parse_timestamp(value: Any) -> '_arrow.Arrow':
+    def _parse_timestamp(value: str) -> Arrow:
         """Attempt to parse epoch timestamp in seconds, milliseconds, or microseconds.
 
         Note: passing formats to test against overrides the default formats. Defaults are not used.
         """
         # note: order matters. Must try to parse as milliseconds/microseconds first (x)
         # before trying to parse as seconds (X), else error occurs if passing a ms/ns value
         try:
             # attempt to parse as string first using microsecond/millisecond and second specifiers
             return _arrow.get(value, ['x', 'X'])
         except (_arrow.parser.ParserError, ValueError):
             # could not parse as string, try to parse as float
             return _arrow.get(float(value))
 
     @staticmethod
-    def _parse_date_utils(value: Any) -> '_arrow.Arrow':
-        """Attempt to supplement arrows parsing ability with dateutils.
+    def _parse_date_utils(value: str) -> Arrow:
+        """Attempt to supplement arrows parsing ability with date util.
 
         Arrow doesn't support RFC_5322 used in HTTP 409 headers
         """
         return _arrow.get(parser.parse(value))
```

### Comparing `tcex-3.0.9/tcex/utils/file_operations.py` & `tcex-4.0.0/tcex/util/file_operation.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,209 +1,201 @@
-"""TcEx Utilities File Operations Module"""
+"""TcEx Framework Module"""
 # standard library
 import gzip
 import json
 import tempfile
 import uuid
 from pathlib import Path
-from typing import Optional, Union
+from typing import Literal
 
+COMPRESS_LEVEl = Literal[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
+MODE = Literal['w', 'wb', 'wt']
 
-class FileOperations:
+
+class FileOperation:
     """TcEx Utilities File Operations Class
 
     Args:
         out_path: The path of the defined "out" directory.
         temp_path: The path of the defined "temp" directory.
     """
 
     def __init__(
         self,
-        out_path: Optional[Union[Path, str]] = None,
-        temp_path: Optional[Union[Path, str]] = None,
+        out_path: Path | str | None = None,
+        temp_path: Path | str | None = None,
     ):
         """Initialize the Class properties."""
-        self.out_path = Path(out_path or tempfile.gettempdir() or '/tmp')  # nosec
-        self.temp_path = Path(temp_path or tempfile.gettempdir() or '/tmp')  # nosec
+        self.out_path = Path(out_path or tempfile.gettempdir())
+        self.temp_path = Path(temp_path or tempfile.gettempdir())
 
-    def _fqfn_out(self, filename: Optional[Union[Path, str]] = None) -> Path:
+    def _fqfn_out(self, filename: Path | str | None = None) -> Path:
         """Return a unique filename for the defined "out" directory."""
         # user provided filename or generate a unique one
         filename = filename if filename is not None else str(uuid.uuid4())
 
         # define the fully qualified path name
         return self.out_path / filename
 
-    def _fqfn_temp(self, filename: Optional[Union[Path, str]] = None) -> Path:
+    def _fqfn_temp(self, filename: Path | str | None = None) -> Path:
         """Return a unique filename for the defined "temp" directory."""
         # user provided filename or generate a unique one
         filename = filename if filename is not None else str(uuid.uuid4())
 
         # define the fully qualified path name
         return self.temp_path / filename
 
     @staticmethod
     def write_file(
-        content: Union[bytes, str],
-        fqfn: Union[Path, str],
-        mode: Optional[str] = 'w',
-        encoding: Optional[str] = 'utf-8',
-        compress_level: Optional[int] = None,
+        content: bytes | dict | list | str,
+        fqfn: Path | str,
+        mode: MODE = 'w',
+        encoding: str | None = None,
+        compress_level: COMPRESS_LEVEl | None = None,
     ) -> Path:
         """Write file content to a out directory, compressing if compress level provided.
 
         If passing binary data the mode needs to be set to 'wb'. If
         compress_level is provided mode is automatically set to 'wt'.
 
         Args:
             content: The file content.
             fqfn: A fully qualified file name.
-            mode: The write mode ('w' or 'wb').
+            mode: The write mode ('w', 'wb', 'wt').
             encoding: The encoding to use when writing the file.
             compress_level: The compression level to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
-        content = json.dumps(content) if isinstance(content, (dict, list)) else content
+        # encoding is not supported when writing binary data
+        encoding = encoding or 'utf-8'
+        if mode == 'wb':
+            encoding = None
+
+        content = json.dumps(content) if isinstance(content, dict | list) else content
         fqfn = fqfn if isinstance(fqfn, Path) else Path(fqfn)
 
         # ensure output directory exists
         fqfn.parent.mkdir(parents=True, exist_ok=True)
 
         # write file, either normal or compressed
         if compress_level is not None:
-            mode = 'wt'
+            # overwrite mode if compressing
+            mode = 'wb' if isinstance(content, bytes) else 'wt'
             with gzip.open(
                 fqfn,
                 mode,
                 compresslevel=compress_level,
                 encoding=encoding,
             ) as fh:
-                fh.write(content)
+                fh.write(content)  # type: ignore
         else:
             with fqfn.open(mode, encoding=encoding) as fh:
                 fh.write(content)
 
         # return the fully qualified path name
         return fqfn
 
     def write_out_binary_file(
         self,
         content: bytes,
-        filename: Optional[str] = None,
+        filename: str | None = None,
     ) -> Path:
         """Write content to a file in the defined "out" directory.
 
         Args:
             content: The file content.
             filename: The filename to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
-        return self.write_file(content, self._fqfn_out(filename), mode='wb', encoding=None)
+        return self.write_file(content, self._fqfn_out(filename), mode='wb')
 
     def write_out_compressed_file(
         self,
-        content: Union[bytes, dict, str],
-        filename: Optional[Union[Path, str]] = None,
-        compress_level: Optional[int] = 9,
+        content: bytes | dict | str,
+        filename: Path | str | None = None,
+        compress_level: COMPRESS_LEVEl = 9,
     ) -> Path:
         """Write content to a file in the defined "out" directory.
 
         Args:
             content: The file content.
             filename: The filename to use when writing the file.
             compress_level: The compression level to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
         return self.write_file(
             content, self._fqfn_out(filename), mode='wt', compress_level=compress_level
         )
 
     def write_out_file(
         self,
-        content: Union[bytes, dict, str],
-        filename: Optional[str] = None,
-        mode: Optional[str] = 'w',
-        encoding: Optional[str] = 'utf-8',
-        compress_level: Optional[int] = None,
+        content: bytes | dict | str,
+        filename: str | None = None,
+        mode: MODE = 'w',
+        encoding: str = 'utf-8',
+        compress_level: COMPRESS_LEVEl | None = None,
     ) -> Path:
         """Write content to a file in the defined "out" directory.
 
         If passing binary data the mode needs to be set to 'wb'. If
         compress_level is provided mode is automatically set to 'wt'.
 
         Args:
             content: The file content.
             filename: A filename to use when writing the file.
             mode: The write mode ('w' or 'wb').
             encoding: The encoding to use when writing the file.
             compress_level: The compression level to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
-        encoding = encoding if mode != 'wb' else None
+        # TODO: [high] fix this type ignore
+        encoding = encoding if mode != 'wb' else None  # type: ignore
         return self.write_file(content, self._fqfn_out(filename), mode, encoding, compress_level)
 
     def write_temp_binary_file(
         self,
         content: bytes,
-        filename: Optional[str] = None,
+        filename: str | None = None,
     ) -> Path:
         """Write content to a file in the defined "temp" directory.
 
         Args:
             content: The file content.
             filename: The filename to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
         return self.write_file(content, self._fqfn_temp(filename), mode='wb', encoding=None)
 
     def write_temp_compressed_file(
         self,
-        content: Union[bytes, dict, str],
-        filename: Optional[str] = None,
-        compress_level: Optional[int] = 9,
+        content: bytes | dict | str,
+        filename: str | None = None,
+        compress_level: COMPRESS_LEVEl = 9,
     ) -> Path:
         """Write content to a file in the defined "temp" directory.
 
         Args:
             content: The file content.
             filename: The filename to use when writing the file.
             compress_level: The compression level to use when writing the file.
-
-        Returns:
-            Path: Fully qualified path name for the file.
         """
         return self.write_file(
             content, self._fqfn_temp(filename), mode='wt', compress_level=compress_level
         )
 
     def write_temp_file(
         self,
-        content: Union[bytes, dict, str],
-        filename: Optional[Union[Path, str]] = None,
-        mode: Optional[str] = 'w',
-        encoding: Optional[str] = 'utf-8',
-        compress_level: Optional[int] = None,
+        content: bytes | dict | str,
+        filename: Path | str | None = None,
+        mode: MODE = 'w',
+        encoding: str = 'utf-8',
+        compress_level: COMPRESS_LEVEl | None = None,
     ) -> Path:
         """Write content to a file in the defined "temp" directory.
 
         If passing binary data the mode needs to be set to 'wb'.
 
         Args:
             content: The file content.
             filename: The filename to use when writing the file.
             mode: The write mode ('w' or 'wb').
-
-        Returns:
-            str: Fully qualified path name for the file.
+            encoding: The encoding to use when writing the file.
+            compress_level: The compression level to use when writing the file.
         """
-        encoding = encoding if mode != 'wb' else None
+        # TODO: [high] fix this type ignore
+        encoding = encoding if mode != 'wb' else None  # type: ignore
         return self.write_file(content, self._fqfn_temp(filename), mode, encoding, compress_level)
```

### Comparing `tcex-3.0.9/tcex/utils/string_operations.py` & `tcex-4.0.0/tcex/util/string_operation.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,156 +1,127 @@
-"""TcEx Utilities String Operations Module"""
+"""TcEx Framework Module"""
 # standard library
 import random
 import re
-import string
-from functools import reduce
-from typing import List, Optional, Union
+from functools import cached_property, reduce
+from string import ascii_letters
 
-# first-party
-from tcex.backports import cached_property
+# third-party
+import inflect
 
 
-class StringOperations:
+class StringOperation:
     """TcEx Utilities String Operations Class"""
 
     @staticmethod
-    def camel_string(string_: str) -> 'CamelString':
-        """Return custom str with custom properties/methods."""
-        return CamelString(string_)
-
-    def camel_to_snake(self, camel_string: str) -> str:
-        """Return snake case string from a camel case string.
-
-        Args:
-            camel_string: The camel case input string.
-        """
-        return self._camel_pattern.sub('_', camel_string).lower()
-
-    def camel_to_space(self, camel_string: str) -> str:
-        """Return space case string from a camel case string.
-
-        Args:
-            camel_string: The camel case input string.
-        """
-        return self._camel_pattern.sub(' ', camel_string).lower()
+    def camel_string(string: str) -> 'CamelString':
+        """Return str with custom properties/methods."""
+        return CamelString(string)
+
+    def camel_to_snake(self, string: str) -> str:
+        """Return snake_case string from a camelCase string."""
+        return self._camel_pattern.sub('_', string).lower()
+
+    def camel_to_space(self, string: str) -> str:
+        """Return space case string from a camelCase string."""
+        return self._camel_pattern.sub(' ', string).lower()
 
     @cached_property
-    def inflect(self) -> 'inflect.engine':  # pylint: disable=no-self-use
+    def inflect(self) -> inflect.engine:
         """Return instance of inflect."""
-        # third-party
-        import inflect
-
         return inflect.engine()
 
     @staticmethod
     def random_string(string_length: int = 10) -> str:
-        """Generate a random string of fixed length
-
-        Args:
-            string_length: The length of the string.
-        """
-        return ''.join(random.choice(string.ascii_letters) for _ in range(string_length))  # nosec
+        """Generate a random string of fixed length."""
+        return ''.join(random.choice(ascii_letters) for _ in range(string_length))  # nosec
 
     @staticmethod
-    def snake_string(string_: str) -> 'SnakeString':
+    def snake_string(string: str) -> 'SnakeString':
         """Return custom str with custom properties/methods."""
-        return SnakeString(string_)
+        return SnakeString(string)
 
     @staticmethod
-    def snake_to_pascal(snake_string: str) -> str:
-        """Convert snake_case to PascalCase
-
-        Args:
-            snake_string: The snake case input string.
-        """
-        return snake_string.replace('_', ' ').title().replace(' ', '')
+    def snake_to_pascal(string: str) -> str:
+        """Convert snake_case to PascalCase."""
+        return string.replace('_', ' ').title().replace(' ', '')
 
     @staticmethod
-    def snake_to_camel(snake_string: str) -> str:
-        """Convert snake_case to camelCase
-
-        Args:
-            snake_string: The snake case input string.
-        """
-        components = snake_string.split('_')
+    def snake_to_camel(string: str) -> str:
+        """Convert snake_case to camelCase."""
+        components = string.split('_')
         return components[0] + ''.join(x.title() for x in components[1:])
 
     @staticmethod
-    def to_bool(value: Union[bool, int, str]) -> bool:
-        """Convert value to bool.
-
-        Args:
-            value: The value to convert to boolean.
-        """
+    def to_bool(value: bool | int | str) -> bool:
+        """Convert value to bool."""
         return str(value).lower() in ['1', 't', 'true', 'y', 'yes']
 
     @staticmethod
     def truncate_string(
-        t_string: str,
+        string: str,
         length: int,
-        append_chars: Optional[str] = '',
-        spaces: Optional[bool] = False,
+        append_chars: str | None = '',
+        spaces: bool = False,
     ) -> str:
         """Truncate a string to a given length.
 
         Args:
-            t_string: The input string to truncate.
+            string: The input string to truncate.
             length: The length of the truncated string.
             append_chars: Any character that should be appended to the
                 string. Typically used for ellipsis (e.g. ...).
             spaces: If True truncation will be done at the
                 nearest space before the truncation length to avoid chopping words.
         """
-        if t_string is None:
-            t_string = ''
+        if string is None:
+            string = ''
 
         if length is None:
-            length = len(t_string)
+            length = len(string)
 
-        if len(t_string) <= length:
-            return t_string
+        if len(string) <= length:
+            return string
 
         # set sane default for append_chars
         append_chars = str(append_chars or '')
 
         # ensure append_chars is not longer than length
         if len(append_chars) > length:  # pragma: no cover
             raise RuntimeError('Append chars cannot exceed the truncation length.')
 
-        output = t_string[0 : length - len(append_chars)]  # noqa: E203
+        output = string[0 : length - len(append_chars)]
         if spaces is True:
             if not output.endswith(' '):
                 # split output on spaces and drop last item to terminate string on word
                 output = ' '.join(output.split(' ')[:-1])
 
         return f'{output.rstrip()}{append_chars}'
 
     @property
-    def _camel_pattern(self) -> 're.Pattern':
-        """Return compiled re pattern."""
+    def _camel_pattern(self) -> re.Pattern:
+        """Return compiled re pattern for converting to camelCase."""
         return re.compile(r'(?<!^)(?=[A-Z])')
 
     @staticmethod
     def wrap_string(
         line: str,
-        wrap_chars: Optional[List[str]] = None,
+        wrap_chars: list[str] | None = None,
         length: int = 100,
-        force_wrap=True,
+        force_wrap: bool = True,
     ) -> str:
         """Wrap a long string to a given length.
 
         Lines will only be broken on instances of strings from wrap_chars.
 
-        Params:
-            line - the string to break into lines
-            wrap_chars - list of strings line should be broken on
-            length - max length for any single line
-            force_wrap - if True, line will be broken even if no string from wrap_chars is
-                available
+        Args:
+            line: the string to break into lines
+            wrap_chars: list of strings line should be broken on
+            length: max length for any single line
+            force_wrap: if True, line will be broken even if no string from wrap_chars is available.
         """
         wrap_chars = wrap_chars or [' ']
 
         # if line is already shorter than max length, we're all good!
         if len(line) < length:
             return line
 
@@ -180,72 +151,66 @@
         return '\n'.join(lines).strip()
 
 
 class CamelString(str):
     """Power String"""
 
     # properties
-    so = StringOperations()
+    so = StringOperation()
 
     def pascal_case(self):
-        """Return camel case version of string."""
+        """Return a PascalCase version of a camelCase string."""
         return CamelString(self.so.camel_to_space(self).title().replace(' ', ''))
 
     def plural(self):
-        """Return inflect.plural spelling of string."""
+        """Return the plural spelling of a camelCase string."""
         return CamelString(self.so.inflect.plural(self.singular()))
 
     def singular(self):
-        """Return inflect.singular spelling of string."""
-        try:
-            _singular = self.so.inflect.singular(self)
-        except Exception:
-            _singular = self.so.inflect.singular_noun(self)
+        """Return the singular spelling of a camelCase string."""
+        _singular = self.so.inflect.singular_noun(self)
 
         if not _singular:
             _singular = self
         return CamelString(_singular)
 
     def snake_case(self):
-        """Return camel case version of string."""
+        """Return a snake_case version of a camelCase string."""
         return CamelString(self.so.camel_to_snake(self))
 
     def space_case(self):
-        """Return string snake to camel."""
-        return CamelString(self.so.camel_to_space(self))  # type: ignore
+        """Return a "space case" version of a camelCase string."""
+        return CamelString(self.so.camel_to_space(self))
 
 
 class SnakeString(str):
     """Power String"""
 
     # properties
-    so = StringOperations()
+    so = StringOperation()
 
     def camel_case(self):
-        """Return camel case version of string."""
+        """Return a camelCase version of a snake_case string."""
         return SnakeString(self.so.snake_to_camel(self))
 
     def pascal_case(self):
-        """Return camel case version of string."""
+        """Return a PascalCase version of a snake_case string."""
         return SnakeString(self.so.snake_to_pascal(self))
 
     def plural(self):
-        """Return inflect.plural spelling of string."""
+        """Return the plural spelling of a snake_case string."""
         return SnakeString(self.so.inflect.plural(self.singular()))
 
     def singular(self):
-        """Return inflect.singular spelling of string."""
-        try:
-            _singular = self.so.inflect.singular(self)
-        except Exception:
-            _singular = self.so.inflect.singular_noun(self)
+        """Return the singular spelling of a snake_case string."""
+        _singular = self.so.inflect.singular_noun(self)
 
         if not _singular:
             _singular = self
         return SnakeString(_singular)
 
-    def space_case(self):
-        """Return a space case version of a string
-
-        _ will be replaced with spaces.
-        """
-        return self.replace('_', ' ').title()
+    def space_case(self, title: bool = True):
+        """Return a "space case" version of a snake_case string."""
+        space_string = self.replace('_', ' ')
+        if title is True:
+            space_string = space_string.title()
+        return space_string
```

### Comparing `tcex-3.0.9/tcex/utils/variables.py` & `tcex-4.0.0/tcex/util/variable.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,38 +1,48 @@
-"""TcEx Utilities Variables Operations Module"""
+"""TcEx Framework Module"""
 # standard library
 import re
-from typing import Any, List
 
-# first-party
-from tcex.utils.models import PlaybookVariableModel
+from .model.playbook_variable_model import PlaybookVariableModel
 
 
 class BinaryVariable(bytes):
     """Bytes object with internal variable type field. Used when reading playbook variables"""
 
     _variable_type = 'Binary'
 
 
 class StringVariable(str):
     """String object with internal variable type field. Used when reading playbook variables"""
 
     _variable_type = 'String'
 
 
-class Variables:
+class Variable:
     """TcEx Utilities Variables Class"""
 
-    def get_playbook_variable_model(self, variable: str) -> 'PlaybookVariableModel':
+    def contains_playbook_variable(self, key: str) -> bool:
+        """Return True if provided key contains a properly formatted playbook variable."""
+        if not isinstance(key, str):
+            return False
+
+        if re.search(self.variable_playbook_pattern, key):
+            return True
+        return False
+
+    def get_playbook_variable_model(self, variable: str | None) -> PlaybookVariableModel | None:
         """Return data model of playbook variable (e.g., #App:1234:output!String)."""
+        if variable is None:
+            return None
+
         data = None
-        if variable is not None:
-            variable = variable.strip()
-            if re.match(self.variable_playbook_match, variable):
-                var = re.search(self.variable_playbook_parse, variable)
+        variable = variable.strip()
+        if re.match(self.variable_playbook_match, variable):
+            var = re.search(self.variable_playbook_parse, variable)
+            if var is not None:
                 data = PlaybookVariableModel(**var.groupdict())
         return data
 
     def get_playbook_variable_type(self, variable: str) -> str:
         """Get variable type"""
         model = self.get_playbook_variable_model(variable)
         return 'String' if model is None else model.type
@@ -50,19 +60,19 @@
         if not isinstance(key, str):
             return False
         if re.match(self.variable_tc_match, key):
             return True
         return False
 
     @property
-    def variable_expansion_pattern(self):
-        """Regex pattern to match and parse a playbook variable.
+    def variable_expansion_pattern(self) -> re.Pattern:
+        """Regex pattern to match and parse a playbook or ThreatConnect variable.
 
-        Playbook Variable: #App:334:example.service_input!String
-        TC Variable: &{TC:TEXT:4dc9202e-6945-4364-aa40-4b47655046d2}
+        Playbook Variable : #App:334:example.service_input!String
+        TC Variable       : &{TC:TEXT:4dc9202e-6945-4364-aa40-4b47655046d2}
         """
         return re.compile(
             # Origin:
             # PB-Variable: "#"
             # TC-Variable: "&"
             r'(?P<origin>#|&)'
             r'(?:\{)?'  # drop "{"
@@ -88,43 +98,59 @@
             r'|String|Binary|KeyValue|TCEntity|TCEnhancedEntity'
             r'|(?:(?!String)(?!Binary)(?!KeyValue)'
             r'(?!TCEntity)(?!TCEnhancedEntity)'
             r'[A-Za-z0-9_-]+)))?'  # variable type (custom)
         )
 
     @property
-    def variable_playbook_match(self) -> Any:
-        """Return compiled re pattern."""
+    def variable_playbook_array_types(self) -> list[str]:
+        """Return list of standard playbook array variable types."""
+        return [
+            'BinaryArray',
+            'KeyValueArray',
+            'StringArray',
+            'TCEntityArray',
+            'TCEnhancedEntityArray',
+        ]
+
+    @property
+    def variable_playbook_match(self) -> re.Pattern:
+        """Return compiled re pattern for exact match of variable."""
         return re.compile(fr'^{self.variable_playbook_pattern}$')
 
-    def variable_playbook_method_name(self, variable: str) -> str:
+    def variable_playbook_method_name(self, variable: str) -> str | None:
         """Convert variable name to a valid method name.
 
         #App:9876:string.operation!String -> string_operation_string
-
-        Args:
-            variable: The variable name to convert.
         """
         method_name = None
         if variable is not None:
             variable = variable.strip()
             if re.match(self.variable_playbook_match, variable):
                 var = re.search(self.variable_playbook_parse, variable)
-                variable_name = var.group(3).replace('.', '_').lower()
-                variable_type = var.group(4).lower()
-                method_name = f'{variable_name}_{variable_type}'
+                if var is not None:
+                    variable_name = var.group(3).replace('.', '_').lower()
+                    variable_type = var.group(4).lower()
+                    method_name = f'{variable_name}_{variable_type}'
         return method_name
 
     @property
+    def variable_playbook_parse(self) -> re.Pattern:
+        """Return compiled re pattern."""
+        return re.compile(self.variable_playbook_pattern)
+
+    @property
     def variable_playbook_pattern(self) -> str:
-        """Regex pattern to match and parse a playbook variable."""
+        """Regex pattern to match and parse a playbook variable.
+
+        Parse this string -> #App:334:example.service_input!String
+        """
         return (
             # App Type: one of the following types (APP|Trigger)
             r'#(?P<app_type>[A-Za-z]+)'
-            # TODO: [high] confirm this is correct
             # Job ID: the Id of the running job (e.g, 7979).
             r':(?P<job_id>[\d]+)'
             # Key: the variable key (e.g., api_token)
             r':(?P<key>[A-Za-z0-9_\.\-\[\]]+)'
             # Type: one of the following types
             #     (Binary|BinaryArray|KeyValue|KeyValueArray|
             #      String|StringArray|TCEntity|TCEntityArray|
@@ -134,68 +160,50 @@
             r'|String|Binary|KeyValue|TCEntity|TCEnhancedEntity'
             r'|(?:(?!String)(?!Binary)(?!KeyValue)'
             r'(?!TCEntity)(?!TCEnhancedEntity)'
             r'[A-Za-z0-9_-]+))'  # variable type (custom)
         )
 
     @property
-    def variable_playbook_parse(self) -> Any:
-        """Return compiled re pattern."""
-        return re.compile(self.variable_playbook_pattern)
+    def variable_playbook_single_types(self) -> list[str]:
+        """Return list of standard playbook single variable types."""
+        return [
+            'Binary',
+            'KeyValue',
+            'String',
+            'TCEntity',
+            'TCEnhancedEntity',
+        ]
 
     @property
-    def variable_playbook_keyvalue_embedded(self) -> Any:
-        """Return compiled re pattern."""
-        return re.compile(fr'(?:\"\:\s?)[^\"]?{self.variable_playbook_pattern}')
+    def variable_playbook_types(self) -> list[str]:
+        """Return list of standard playbook variable types."""
+        return self.variable_playbook_single_types + self.variable_playbook_array_types
 
     @property
-    def variable_tc_match(self):
-        """Return regex pattern for tc variable match."""
+    def variable_tc_match(self) -> re.Pattern:
+        """Return regex pattern for tc variable EXACT match."""
         return re.compile(fr'^{self.variable_tc_pattern}$')
 
     @property
-    def variable_tc_pattern(self):
-        """Return regex pattern for tc variable."""
+    def variable_tc_parse(self) -> re.Pattern:
+        """Return regex pattern for tc variable search."""
+        return re.compile(self.variable_tc_pattern)
+
+    @property
+    def variable_tc_pattern(self) -> str:
+        """Return regex pattern for tc variable.
+
+        Parse this string -> &{TC:TEXT:4dc9202e-6945-4364-aa40-4b47655046d2}
+        """
         return (
             # Origin "&"
             r'(?:&)'
             r'(?:\{)'
             # Provider: who provides the variable (e.g. TC|Vault)
             r'(?P<provider>[A-Za-z]+):'
             # Type: one of (FILE|KEYCHAIN|TEXT)
             r'(?P<type>FILE|KEYCHAIN|TEXT):'
             # Key: variable id (e.g., 4dc9202e-6945-4364-aa40-4b47655046d2)
             r'(?P<key>[A-Za-z0-9_\.\-\[\]]+)'
             r'(?:\})'
         )
-
-    @property
-    def variable_tc_parse(self):
-        """Return regex pattern for tc variable search."""
-        return re.compile(self.variable_tc_pattern)
-
-    @property
-    def variable_playbook_array_types(self) -> List[str]:
-        """Return list of standard playbook array variable types."""
-        return [
-            'BinaryArray',
-            'KeyValueArray',
-            'StringArray',
-            'TCEntityArray',
-            'TCEnhancedEntityArray',
-        ]
-
-    @property
-    def variable_playbook_single_types(self) -> List[str]:
-        """Return list of standard playbook single variable types."""
-        return [
-            'Binary',
-            'KeyValue',
-            'String',
-            'TCEntity',
-            'TCEnhancedEntity',
-        ]
-
-    @property
-    def variable_playbook_types(self) -> List[str]:
-        """Return list of standard playbook variable types."""
-        return self.variable_playbook_single_types + self.variable_playbook_array_types
```

### Comparing `tcex-3.0.9/tcex.egg-info/PKG-INFO` & `tcex-4.0.0/PKG-INFO`

 * *Files 25% similar despite different names*

```diff
@@ -1,95 +1,84 @@
 Metadata-Version: 2.1
 Name: tcex
-Version: 3.0.9
+Version: 4.0.0
 Summary: ThreatConnect Exchange App Framework
-Home-page: https://github.com/ThreatConnect-Inc/tcex
-Download-URL: https://github.com/ThreatConnect-Inc/tcex/tarball/3.0.9
-Author: ThreatConnect (support@threatconnect.com)
-Author-email: support@threatconnect.com
-License: Apache License, Version 2
-Project-URL: Documentation, https://github.com/ThreatConnect-Inc/tcex
+Author-email: ThreatConnect <support@threatconnect.com>
+License: Apache-2.0
+Project-URL: Documentation, https://threatconnect.readme.io/docs/overview
+Project-URL: Release Notes, https://threatconnect.readme.io/docs/release-notes
 Project-URL: Source, https://github.com/ThreatConnect-Inc/tcex
+Keywords: exchange,tcex,threatconnect
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Natural Language :: English
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Classifier: Topic :: Security
-Requires-Python: >=3.6
+Requires-Python: >=3.11
 Description-Content-Type: text/markdown
 Provides-Extra: dev
-Provides-Extra: develop
-Provides-Extra: development
+Provides-Extra: test
 License-File: LICENSE
 
 # tcex - ThreatConnect Exchange App Framework
 
 The ThreatConnect&trade; TcEx App Framework provides functionality for writing ThreatConnect Exchange Apps.
 
 ## Requirements
 
  * arrow (https://pypi.python.org/pypi/arrow)
- * backports.cached-property (https://pypi.org/project/backports.cached-property/)
- * colorama (https://pypi.python.org/pypi/colorama)
- * future (https://pypi.org/project/future/)
+ * black (https://pypi.org/project/black/)
  * inflect (https://pypi.python.org/pypi/inflect)
+ * isort (https://pypi.org/project/isort/)
  * jmespath (https://pypi.org/project/jmespath/)
  * paho-mqtt (https://pypi.org/project/paho-mqtt/)
  * pyaes (https://pypi.org/project/pyaes/)
  * pydantic (https://pypi.org/project/pydantic/)
  * python-dateutil (https://pypi.python.org/pypi/python-dateutil)
+ * pyyaml (https://pypi.python.org/pypi/pyyaml)
  * redis (https://pypi.python.org/pypi/redis)
- * requests (http://docs.python-requests.org/en/latest)
+ * requests (https://pypi.python.org/pypi/requests)
+ * rich (https://pypi.python.org/pypi/rich)
  * semantic_version (https://pypi.org/project/semantic-version/)
- * stdlib-list (https://pypi.org/project/stdlib-list/)
- * tinydb (https://pypi.python.org/pypi/tinydb)
- * typer (https://pypi.python.org/pypi/typer)
  * wrapt (https://pypi.org/project/wrapt/)
 
 ### Development Requirements
 
  * bandit (https://pypi.org/project/bandit/)
- * black (https://pypi.org/project/black/)
- * codespell (https://pypi.org/project/codespell/)
  * deepdiff (https://pypi.org/project/deepdiff/)
- * flake8 (https://pypi.org/project/flake8/)
- * isort (https://pypi.org/project/isort/)
- * mako (https://pypi.org/project/mako/)
+ * fakeredis (https://pypi.org/project/fakeredis/)
  * pre-commit (https://pypi.org/project/pre-commit/)
  * pydocstyle (https://pypi.org/project/pydocstyle/)
  * pylint (https://pypi.org/project/pylint/)
+ * pyright (https://pypi.org/project/pyright/)
+ * pyupgrade (https://pypi.org/project/pyupgrade/)
+ * typer (https://pypi.python.org/pypi/typer)
+
+### Test Requirements
+
  * pytest (https://pypi.org/project/pytest/)
  * pytest-cov (https://pypi.org/project/pytest-cov/)
  * pytest-html (https://pypi.org/project/pytest-html/)
+ * pytest-ordering (https://pypi.org/project/pytest-ordering/)
  * pytest-xdist (https://pypi.org/project/pytest-xdist/)
- * pyupgrade (https://pypi.org/project/pyupgrade/)
 
 ## Installation
 
-**Using pip**
-
 ```
 pip install tcex
-pip install tcex[development]
 ```
 
-**Manually**
+### Development / Testing
 
-```
-cd tcex
-python setup.py install --force
-```
+pip install tcex[dev,test]
 
 ## Documentation
 
 https://threatconnect.readme.io/docs/overview
 
 ## Release Notes
```

### Comparing `tcex-3.0.9/tcex.egg-info/SOURCES.txt` & `tcex-4.0.0/tcex.egg-info/SOURCES.txt`

 * *Files 7% similar despite different names*

```diff
@@ -1,91 +1,88 @@
 LICENSE
 README.md
 pyproject.toml
-setup.cfg
-setup.py
-bin/tcex
 tcex/__init__.py
 tcex/__metadata__.py
+tcex/registry.py
 tcex/tcex.py
 tcex.egg-info/PKG-INFO
 tcex.egg-info/SOURCES.txt
 tcex.egg-info/dependency_links.txt
 tcex.egg-info/requires.txt
 tcex.egg-info/top_level.txt
-tcex.egg-info/zip-safe
 tcex/api/__init__.py
 tcex/api/api.py
 tcex/api/tc/__init__.py
 tcex/api/tc/tc.py
 tcex/api/tc/ti_transform/__init__.py
-tcex/api/tc/ti_transform/formatters.py
+tcex/api/tc/ti_transform/formatter.py
 tcex/api/tc/ti_transform/ti_transform.py
 tcex/api/tc/ti_transform/transform_abc.py
 tcex/api/tc/ti_transform/model/__init__.py
 tcex/api/tc/ti_transform/model/transform_model.py
-tcex/api/tc/utils/__init__.py
-tcex/api/tc/utils/threat_intel_utils.py
+tcex/api/tc/util/__init__.py
+tcex/api/tc/util/threat_intel_util.py
 tcex/api/tc/v2/__init__.py
 tcex/api/tc/v2/v2.py
 tcex/api/tc/v2/batch/__init__.py
 tcex/api/tc/v2/batch/attribute.py
 tcex/api/tc/v2/batch/batch.py
 tcex/api/tc/v2/batch/batch_submit.py
 tcex/api/tc/v2/batch/batch_writer.py
 tcex/api/tc/v2/batch/group.py
 tcex/api/tc/v2/batch/indicator.py
 tcex/api/tc/v2/batch/security_label.py
 tcex/api/tc/v2/batch/tag.py
 tcex/api/tc/v2/datastore/__init__.py
 tcex/api/tc/v2/datastore/cache.py
 tcex/api/tc/v2/datastore/datastore.py
-tcex/api/tc/v2/metrics/__init__.py
-tcex/api/tc/v2/metrics/metrics.py
-tcex/api/tc/v2/notifications/__init__.py
-tcex/api/tc/v2/notifications/notifications.py
+tcex/api/tc/v2/metric/__init__.py
+tcex/api/tc/v2/metric/metric.py
+tcex/api/tc/v2/notification/__init__.py
+tcex/api/tc/v2/notification/notification.py
 tcex/api/tc/v2/threat_intelligence/__init__.py
 tcex/api/tc/v2/threat_intelligence/tcex_ti_tc_request.py
 tcex/api/tc/v2/threat_intelligence/threat_intelligence.py
-tcex/api/tc/v2/threat_intelligence/mappings/__init__.py
-tcex/api/tc/v2/threat_intelligence/mappings/filters.py
-tcex/api/tc/v2/threat_intelligence/mappings/mappings.py
-tcex/api/tc/v2/threat_intelligence/mappings/owner.py
-tcex/api/tc/v2/threat_intelligence/mappings/security_label.py
-tcex/api/tc/v2/threat_intelligence/mappings/tag.py
-tcex/api/tc/v2/threat_intelligence/mappings/tags.py
-tcex/api/tc/v2/threat_intelligence/mappings/task.py
-tcex/api/tc/v2/threat_intelligence/mappings/victim.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/__init__.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/__init__.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/adversary.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/attack_pattern.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/campaign.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/course_of_action.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/document.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/email.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/event.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/incident.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/intrusion_set.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/malware.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/report.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/signature.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tactic.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/threat.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/tool.py
-tcex/api/tc/v2/threat_intelligence/mappings/group/group_types/vulnerability.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/__init__.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/__init__.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/address.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/email_address.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/file.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/host.py
-tcex/api/tc/v2/threat_intelligence/mappings/indicator/indicator_types/url.py
+tcex/api/tc/v2/threat_intelligence/mapping/__init__.py
+tcex/api/tc/v2/threat_intelligence/mapping/filters.py
+tcex/api/tc/v2/threat_intelligence/mapping/mapping.py
+tcex/api/tc/v2/threat_intelligence/mapping/owner.py
+tcex/api/tc/v2/threat_intelligence/mapping/security_label.py
+tcex/api/tc/v2/threat_intelligence/mapping/tag.py
+tcex/api/tc/v2/threat_intelligence/mapping/tags.py
+tcex/api/tc/v2/threat_intelligence/mapping/task.py
+tcex/api/tc/v2/threat_intelligence/mapping/victim.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/__init__.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/__init__.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/adversary.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/attack_pattern.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/campaign.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/course_of_action.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/document.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/email.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/event.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/incident.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/intrusion_set.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/malware.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/report.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/signature.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/tactic.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/threat.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/tool.py
+tcex/api/tc/v2/threat_intelligence/mapping/group/group_type/vulnerability.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/__init__.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/__init__.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/address.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/email_address.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/file.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/host.py
+tcex/api/tc/v2/threat_intelligence/mapping/indicator/indicator_type/url.py
 tcex/api/tc/v3/__init__.py
 tcex/api/tc/v3/api_endpoints.py
 tcex/api/tc/v3/filter_abc.py
 tcex/api/tc/v3/object_abc.py
 tcex/api/tc/v3/object_collection_abc.py
 tcex/api/tc/v3/v3.py
 tcex/api/tc/v3/v3_model_abc.py
@@ -93,17 +90,17 @@
 tcex/api/tc/v3/_gen/__init__.py
 tcex/api/tc/v3/_gen/_gen.py
 tcex/api/tc/v3/_gen/_gen_abc.py
 tcex/api/tc/v3/_gen/_gen_args_abc.py
 tcex/api/tc/v3/_gen/_gen_filter_abc.py
 tcex/api/tc/v3/_gen/_gen_model_abc.py
 tcex/api/tc/v3/_gen/_gen_object_abc.py
-tcex/api/tc/v3/_gen/models/__init__.py
-tcex/api/tc/v3/_gen/models/_filter_model.py
-tcex/api/tc/v3/_gen/models/_property_model.py
+tcex/api/tc/v3/_gen/model/__init__.py
+tcex/api/tc/v3/_gen/model/_filter_model.py
+tcex/api/tc/v3/_gen/model/_property_model.py
 tcex/api/tc/v3/adversary_assets/__init__.py
 tcex/api/tc/v3/artifact_types/__init__.py
 tcex/api/tc/v3/artifact_types/artifact_type.py
 tcex/api/tc/v3/artifact_types/artifact_type_filter.py
 tcex/api/tc/v3/artifact_types/artifact_type_model.py
 tcex/api/tc/v3/artifacts/__init__.py
 tcex/api/tc/v3/artifacts/artifact.py
@@ -209,143 +206,145 @@
 tcex/api/tc/v3/workflow_events/workflow_event.py
 tcex/api/tc/v3/workflow_events/workflow_event_filter.py
 tcex/api/tc/v3/workflow_events/workflow_event_model.py
 tcex/api/tc/v3/workflow_templates/__init__.py
 tcex/api/tc/v3/workflow_templates/workflow_template.py
 tcex/api/tc/v3/workflow_templates/workflow_template_filter.py
 tcex/api/tc/v3/workflow_templates/workflow_template_model.py
-tcex/app_config/__init__.py
-tcex/app_config/app_spec_yml.py
-tcex/app_config/install_json.py
-tcex/app_config/install_json_update.py
-tcex/app_config/install_json_validate.py
-tcex/app_config/job_json.py
-tcex/app_config/layout_json.py
-tcex/app_config/permutation.py
-tcex/app_config/tcex_json.py
-tcex/app_config/tcex_json_update.py
-tcex/app_config/models/__init__.py
-tcex/app_config/models/app_spec_yml_model.py
-tcex/app_config/models/install_json_model.py
-tcex/app_config/models/job_json_model.py
-tcex/app_config/models/layout_json_model.py
-tcex/app_config/models/tcex_json_model.py
-tcex/app_config/models/template_config_model.py
-tcex/app_feature/__init__.py
-tcex/app_feature/advanced_request.py
-tcex/backports/__init__.py
-tcex/bin/__init__.py
-tcex/bin/bin_abc.py
-tcex/bin/dep.py
-tcex/bin/deploy.py
-tcex/bin/package.py
-tcex/bin/spec_tool.py
-tcex/bin/spec_tool_app_input.py
-tcex/bin/spec_tool_app_input_static.py
-tcex/bin/spec_tool_app_spec_yml.py
-tcex/bin/spec_tool_install_json.py
-tcex/bin/spec_tool_job_json.py
-tcex/bin/spec_tool_layout_json.py
-tcex/bin/spec_tool_readme_md.py
-tcex/bin/spec_tool_tcex_json.py
-tcex/bin/template.py
-tcex/bin/validate.py
-tcex/decorators/__init__.py
-tcex/decorators/benchmark.py
-tcex/decorators/debug.py
-tcex/decorators/fail_on_output.py
-tcex/decorators/on_exception.py
-tcex/decorators/on_success.py
-tcex/decorators/output.py
+tcex/app/__init__.py
+tcex/app/app.py
+tcex/app/config/__init__.py
+tcex/app/config/app_spec_yml.py
+tcex/app/config/install_json.py
+tcex/app/config/install_json_update.py
+tcex/app/config/install_json_validate.py
+tcex/app/config/job_json.py
+tcex/app/config/layout_json.py
+tcex/app/config/permutation.py
+tcex/app/config/tcex_json.py
+tcex/app/config/tcex_json_update.py
+tcex/app/config/model/__init__.py
+tcex/app/config/model/app_spec_yml_model.py
+tcex/app/config/model/install_json_model.py
+tcex/app/config/model/job_json_model.py
+tcex/app/config/model/layout_json_model.py
+tcex/app/config/model/tcex_json_model.py
+tcex/app/decorator/__init__.py
+tcex/app/decorator/benchmark.py
+tcex/app/decorator/debug.py
+tcex/app/decorator/fail_on_output.py
+tcex/app/decorator/on_exception.py
+tcex/app/decorator/on_success.py
+tcex/app/decorator/output.py
+tcex/app/key_value_store/__init__.py
+tcex/app/key_value_store/key_value_abc.py
+tcex/app/key_value_store/key_value_api.py
+tcex/app/key_value_store/key_value_mock.py
+tcex/app/key_value_store/key_value_redis.py
+tcex/app/key_value_store/key_value_store.py
+tcex/app/key_value_store/redis_client.py
+tcex/app/playbook/__init__.py
+tcex/app/playbook/advanced_request.py
+tcex/app/playbook/playbook.py
+tcex/app/playbook/playbook_create.py
+tcex/app/playbook/playbook_delete.py
+tcex/app/playbook/playbook_output.py
+tcex/app/playbook/playbook_read.py
+tcex/app/service/__init__.py
+tcex/app/service/api_service.py
+tcex/app/service/common_service.py
+tcex/app/service/common_service_trigger.py
+tcex/app/service/mqtt_message_broker.py
+tcex/app/service/webhook_trigger_service.py
+tcex/app/token/__init__.py
+tcex/app/token/token.py
 tcex/exit/__init__.py
-tcex/exit/error_codes.py
+tcex/exit/error_code.py
 tcex/exit/exit.py
 tcex/input/__init__.py
 tcex/input/input.py
-tcex/input/field_types/__init__.py
-tcex/input/field_types/binary.py
-tcex/input/field_types/case_management_entity.py
-tcex/input/field_types/choice.py
-tcex/input/field_types/datetime.py
-tcex/input/field_types/edit_choice.py
-tcex/input/field_types/exception.py
-tcex/input/field_types/group_entity.py
-tcex/input/field_types/indicator_entity.py
-tcex/input/field_types/integer.py
-tcex/input/field_types/ip_address.py
-tcex/input/field_types/key_value.py
-tcex/input/field_types/sensitive.py
-tcex/input/field_types/string.py
-tcex/input/field_types/tc_entity.py
-tcex/input/field_types/validators.py
-tcex/input/models/__init__.py
-tcex/input/models/advanced_request_model.py
-tcex/input/models/aot_execution_enabled_model.py
-tcex/input/models/api_model.py
-tcex/input/models/batch_model.py
-tcex/input/models/cal_settings_model.py
-tcex/input/models/create_config_model.py
-tcex/input/models/logging_model.py
-tcex/input/models/model_map.py
-tcex/input/models/organization_model.py
-tcex/input/models/path_model.py
-tcex/input/models/playbook_common_model.py
-tcex/input/models/playbook_model.py
-tcex/input/models/proxy_model.py
-tcex/input/models/service_model.py
-tcex/input/models/smtp_settings_model.py
-tcex/key_value_store/__init__.py
-tcex/key_value_store/key_value_abc.py
-tcex/key_value_store/key_value_api.py
-tcex/key_value_store/key_value_mock.py
-tcex/key_value_store/key_value_redis.py
-tcex/key_value_store/redis_client.py
+tcex/input/field_type/__init__.py
+tcex/input/field_type/binary.py
+tcex/input/field_type/case_management_entity.py
+tcex/input/field_type/choice.py
+tcex/input/field_type/datetime.py
+tcex/input/field_type/edit_choice.py
+tcex/input/field_type/exception.py
+tcex/input/field_type/group_entity.py
+tcex/input/field_type/indicator_entity.py
+tcex/input/field_type/integer.py
+tcex/input/field_type/ip_address.py
+tcex/input/field_type/key_value.py
+tcex/input/field_type/sensitive.py
+tcex/input/field_type/string.py
+tcex/input/field_type/tc_entity.py
+tcex/input/field_type/validator.py
+tcex/input/model/__init__.py
+tcex/input/model/advanced_request_model.py
+tcex/input/model/aot_execution_enabled_model.py
+tcex/input/model/api_model.py
+tcex/input/model/app_api_service_model.py
+tcex/input/model/app_external_model.py
+tcex/input/model/app_feed_api_service_model.py
+tcex/input/model/app_organization_model.py
+tcex/input/model/app_playbook_model.py
+tcex/input/model/app_trigger_service_model.py
+tcex/input/model/app_webhook_trigger_service_model.py
+tcex/input/model/batch_model.py
+tcex/input/model/cal_setting_model.py
+tcex/input/model/common_advanced_model.py
+tcex/input/model/common_model.py
+tcex/input/model/create_config_model.py
+tcex/input/model/logging_model.py
+tcex/input/model/model_map.py
+tcex/input/model/module_app_model.py
+tcex/input/model/module_requests_session_model.py
+tcex/input/model/organization_model.py
+tcex/input/model/path_model.py
+tcex/input/model/playbook_common_model.py
+tcex/input/model/playbook_model.py
+tcex/input/model/proxy_model.py
+tcex/input/model/service_model.py
+tcex/input/model/smtp_setting_model.py
 tcex/logger/__init__.py
 tcex/logger/api_handler.py
 tcex/logger/cache_handler.py
 tcex/logger/logger.py
-tcex/logger/pattern_file_handler.py
 tcex/logger/rotating_file_handler_custom.py
 tcex/logger/sensitive_filter.py
-tcex/logger/thread_file_handler.py
 tcex/logger/trace_logger.py
-tcex/playbook/__init__.py
-tcex/playbook/playbook.py
-tcex/playbook/playbook_create.py
-tcex/playbook/playbook_delete.py
-tcex/playbook/playbook_output.py
-tcex/playbook/playbook_read.py
 tcex/pleb/__init__.py
+tcex/pleb/cached_property.py
 tcex/pleb/env_path.py
 tcex/pleb/event.py
+tcex/pleb/exception_thread.py
 tcex/pleb/none_model.py
 tcex/pleb/proxies.py
-tcex/pleb/registry.py
 tcex/pleb/scoped_property.py
 tcex/pleb/singleton.py
-tcex/pleb/threading.py
-tcex/services/__init__.py
-tcex/services/api_service.py
-tcex/services/common_service.py
-tcex/services/common_service_trigger.py
-tcex/services/mqtt_message_broker.py
-tcex/services/webhook_trigger_service.py
-tcex/sessions/__init__.py
-tcex/sessions/external_session.py
-tcex/sessions/rate_limit_handler.py
-tcex/sessions/tc_session.py
-tcex/sessions/auth/__init__.py
-tcex/sessions/auth/hmac_auth.py
-tcex/sessions/auth/tc_auth.py
-tcex/sessions/auth/token_auth.py
-tcex/tokens/__init__.py
-tcex/tokens/tokens.py
-tcex/utils/__init__.py
-tcex/utils/aes_operations.py
-tcex/utils/datetime_operations.py
-tcex/utils/file_operations.py
-tcex/utils/requests_to_curl.py
-tcex/utils/string_operations.py
-tcex/utils/utils.py
-tcex/utils/variables.py
-tcex/utils/models/__init__.py
-tcex/utils/models/playbook_variable_model.py
+tcex/requests_external/__init__.py
+tcex/requests_external/external_session.py
+tcex/requests_external/rate_limit_handler.py
+tcex/requests_external/requests_external.py
+tcex/requests_tc/__init__.py
+tcex/requests_tc/requests_tc.py
+tcex/requests_tc/tc_session.py
+tcex/requests_tc/auth/__init__.py
+tcex/requests_tc/auth/hmac_auth.py
+tcex/requests_tc/auth/tc_auth.py
+tcex/requests_tc/auth/token_auth.py
+tcex/util/__init__.py
+tcex/util/aes_operation.py
+tcex/util/code_operation.py
+tcex/util/datetime_operation.py
+tcex/util/file_operation.py
+tcex/util/requests_to_curl.py
+tcex/util/string_operation.py
+tcex/util/util.py
+tcex/util/variable.py
+tcex/util/model/__init__.py
+tcex/util/model/playbook_variable_model.py
+tcex/util/render/__init__.py
+tcex/util/render/render.py
+tcex/util/render/render_panel.py
+tcex/util/render/render_prompt.py
+tcex/util/render/render_table.py
```

