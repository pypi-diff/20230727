# Comparing `tmp/bittensor-5.3.1.tar.gz` & `tmp/bittensor-5.3.2.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "bittensor-5.3.1.tar", last modified: Mon Jul 17 20:03:22 2023, max compression
+gzip compressed data, was "bittensor-5.3.2.tar", last modified: Wed Jul 26 22:40:30 2023, max compression
```

## Comparing `bittensor-5.3.1.tar` & `bittensor-5.3.2.tar`

### file list

```diff
@@ -1,146 +1,146 @@
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.113470 bittensor-5.3.1/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1087 2023-07-13 19:44:57.000000 bittensor-5.3.1/LICENSE
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    23565 2023-07-17 20:03:22.113257 bittensor-5.3.1/PKG-INFO
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    22539 2023-07-13 19:50:20.000000 bittensor-5.3.1/README.md
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.081961 bittensor-5.3.1/bin/
--rwxr-xr-x   0 cameronfairchild   (501) staff       (20)     1297 2023-07-13 19:44:57.000000 bittensor-5.3.1/bin/btcli
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.082223 bittensor-5.3.1/bittensor/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    15302 2023-07-13 19:50:20.000000 bittensor-5.3.1/bittensor/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.083581 bittensor-5.3.1/bittensor/_axon/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    17038 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_axon/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.083779 bittensor-5.3.1/bittensor/_blacklist/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4770 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_blacklist/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.084117 bittensor-5.3.1/bittensor/_cli/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7377 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4431 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/cli_impl.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.091877 bittensor-5.3.1/bittensor/_cli/commands/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)      739 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    24532 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/delegates.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7982 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/inspect.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3900 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/list.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7371 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/metagraph.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5572 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/misc.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    16284 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/overview.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7397 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/register.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    17951 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/senate.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    10872 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/stake.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4285 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/transfer.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    11002 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/unstake.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7692 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/utils.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    17326 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_cli/commands/wallets.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.093243 bittensor-5.3.1/bittensor/_dataset/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    11200 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dataset/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    26660 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dataset/dataset_impl.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5443 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dataset/dataset_mock.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3581 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dataset/thread_queue.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.094160 bittensor-5.3.1/bittensor/_dendrite/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dendrite/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    10132 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dendrite/dendrite.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.095682 bittensor-5.3.1/bittensor/_dendrite/text_prompting/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dendrite/text_prompting/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7861 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dendrite/text_prompting/dendrite.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5215 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_dendrite/text_prompting/dendrite_pool.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.096551 bittensor-5.3.1/bittensor/_ipfs/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_ipfs/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     2890 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_ipfs/ipfs_impl.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.096989 bittensor-5.3.1/bittensor/_logging/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    13313 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_logging/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.097456 bittensor-5.3.1/bittensor/_metagraph/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    12895 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_metagraph/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.099523 bittensor-5.3.1/bittensor/_neuron/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_neuron/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5752 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_neuron/base_huggingface_miner.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    10128 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_neuron/base_miner_neuron.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3186 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_neuron/base_prompting_miner.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.099689 bittensor-5.3.1/bittensor/_priority/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3529 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_priority/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.099841 bittensor-5.3.1/bittensor/_prometheus/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     8337 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_prometheus/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.100400 bittensor-5.3.1/bittensor/_proto/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_proto/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    28340 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_proto/bittensor_pb2.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4422 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_proto/bittensor_pb2_grpc.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.100738 bittensor-5.3.1/bittensor/_serializer/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     6062 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_serializer/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    10739 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_serializer/serializer_impl.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.102339 bittensor-5.3.1/bittensor/_subtensor/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    13873 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    26055 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/chain_data.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     2467 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/errors.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.104582 bittensor-5.3.1/bittensor/_subtensor/extrinsics/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1119 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    14116 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/delegation.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    26886 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/log_utilities.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5736 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/prometheus.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    12590 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/registration.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    10609 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/senate.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     9835 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/serving.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5624 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/set_weights.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    17833 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/staking.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     6109 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/transfer.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    14947 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/extrinsics/unstaking.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    69611 2023-07-13 19:50:20.000000 bittensor-5.3.1/bittensor/_subtensor/subtensor_impl.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    52059 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/subtensor_mock.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1505 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_subtensor/types.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.104859 bittensor-5.3.1/bittensor/_synapse/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_synapse/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     6959 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_synapse/synapse.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.105142 bittensor-5.3.1/bittensor/_synapse/text_prompting/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_synapse/text_prompting/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5329 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_synapse/text_prompting/synapse.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.105702 bittensor-5.3.1/bittensor/_threadpool/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4730 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_threadpool/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     8594 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_threadpool/priority_thread_pool_impl.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.105961 bittensor-5.3.1/bittensor/_tokenizer/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     2485 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/_tokenizer/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.108136 bittensor-5.3.1/bittensor/utils/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     6492 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3443 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/_register_cuda.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     8699 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/balance.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4445 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/codes.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)      518 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/formatting.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7999 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/networking.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    37871 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/registration.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    33019 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/registratrion_old.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3351 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/stats.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)      630 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/test_utils.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    75481 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/tokenizer_utils.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     9966 2023-07-13 19:44:57.000000 bittensor-5.3.1/bittensor/utils/weight_utils.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.083376 bittensor-5.3.1/bittensor.egg-info/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    23565 2023-07-17 20:03:22.000000 bittensor-5.3.1/bittensor.egg-info/PKG-INFO
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4105 2023-07-17 20:03:22.000000 bittensor-5.3.1/bittensor.egg-info/SOURCES.txt
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        1 2023-07-17 20:03:22.000000 bittensor-5.3.1/bittensor.egg-info/dependency_links.txt
--rw-r--r--   0 cameronfairchild   (501) staff       (20)      908 2023-07-17 20:03:22.000000 bittensor-5.3.1/bittensor.egg-info/requires.txt
--rw-r--r--   0 cameronfairchild   (501) staff       (20)       16 2023-07-17 20:03:22.000000 bittensor-5.3.1/bittensor.egg-info/top_level.txt
--rw-r--r--   0 cameronfairchild   (501) staff       (20)       38 2023-07-17 20:03:22.113535 bittensor-5.3.1/setup.cfg
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3429 2023-07-13 19:44:57.000000 bittensor-5.3.1/setup.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.108298 bittensor-5.3.1/tests/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1197 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.108551 bittensor-5.3.1/tests/helpers/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1246 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/helpers/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     5671 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/helpers/helpers.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.109754 bittensor-5.3.1/tests/integration_tests/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/integration_tests/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    81518 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/integration_tests/test_cli.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    37492 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/integration_tests/test_cli_no_network.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)      920 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/integration_tests/test_ipfs.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     3474 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/integration_tests/test_metagraph_integration.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1645 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/integration_tests/test_priority_thread_pool.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1331 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/integration_tests/test_prometheus.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    23570 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/integration_tests/test_subtensor_integration.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.109997 bittensor-5.3.1/tests/unit_tests/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/__init__.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.111553 bittensor-5.3.1/tests/unit_tests/bittensor_tests/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    13529 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_axon.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    15160 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_balance.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4331 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_config.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     1761 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_metagraph.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    12319 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_serialization.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     7098 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_subtensor.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4886 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_synapse.py
-drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-17 20:03:22.112938 bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/
--rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/__init__.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     4916 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_network_utils.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)    34082 2023-07-13 19:50:20.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_utils.py
--rw-r--r--   0 cameronfairchild   (501) staff       (20)     2931 2023-07-13 19:44:57.000000 bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_weight_utils.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.718769 bittensor-5.3.2/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1087 2023-07-13 19:44:57.000000 bittensor-5.3.2/LICENSE
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    23700 2023-07-26 22:40:30.717763 bittensor-5.3.2/PKG-INFO
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    22674 2023-07-26 22:21:01.000000 bittensor-5.3.2/README.md
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.662386 bittensor-5.3.2/bin/
+-rwxr-xr-x   0 cameronfairchild   (501) staff       (20)     1297 2023-07-13 19:44:57.000000 bittensor-5.3.2/bin/btcli
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.662560 bittensor-5.3.2/bittensor/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    15269 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.663467 bittensor-5.3.2/bittensor/_axon/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    17340 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_axon/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.663841 bittensor-5.3.2/bittensor/_blacklist/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4771 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_blacklist/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.671583 bittensor-5.3.2/bittensor/_cli/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     7239 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4389 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/cli_impl.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.673737 bittensor-5.3.2/bittensor/_cli/commands/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)      818 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    26908 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/delegates.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8519 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/inspect.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4140 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/list.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8316 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/metagraph.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6115 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/misc.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    19918 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/overview.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     7705 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/register.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    18920 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/senate.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    11573 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/stake.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4519 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/transfer.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    11648 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/unstake.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8338 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/utils.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    18238 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_cli/commands/wallets.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.674448 bittensor-5.3.2/bittensor/_dataset/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    12379 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dataset/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    28422 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dataset/dataset_impl.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5476 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dataset/dataset_mock.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3576 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dataset/thread_queue.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.674701 bittensor-5.3.2/bittensor/_dendrite/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_dendrite/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    10414 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dendrite/dendrite.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.675113 bittensor-5.3.2/bittensor/_dendrite/text_prompting/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_dendrite/text_prompting/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     7933 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dendrite/text_prompting/dendrite.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5059 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_dendrite/text_prompting/dendrite_pool.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.675357 bittensor-5.3.2/bittensor/_ipfs/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_ipfs/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     2981 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_ipfs/ipfs_impl.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.675504 bittensor-5.3.2/bittensor/_logging/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    13552 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_logging/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.675650 bittensor-5.3.2/bittensor/_metagraph/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    14672 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_metagraph/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.676229 bittensor-5.3.2/bittensor/_neuron/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_neuron/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6781 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_neuron/base_huggingface_miner.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    10229 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_neuron/base_miner_neuron.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3279 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_neuron/base_prompting_miner.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.676365 bittensor-5.3.2/bittensor/_priority/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3472 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_priority/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.677017 bittensor-5.3.2/bittensor/_prometheus/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8708 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_prometheus/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.677611 bittensor-5.3.2/bittensor/_proto/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_proto/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    35330 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_proto/bittensor_pb2.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4514 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_proto/bittensor_pb2_grpc.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.677928 bittensor-5.3.2/bittensor/_serializer/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6090 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_serializer/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    10579 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_serializer/serializer_impl.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.678866 bittensor-5.3.2/bittensor/_subtensor/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    15625 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    26825 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/chain_data.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     2404 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/errors.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.682382 bittensor-5.3.2/bittensor/_subtensor/extrinsics/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1120 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    15299 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/delegation.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    30638 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/log_utilities.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6124 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/prometheus.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    13751 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/registration.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    11488 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/senate.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    10100 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/serving.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6198 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/set_weights.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    19392 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/staking.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6408 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/transfer.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    16524 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/extrinsics/unstaking.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    72174 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/subtensor_impl.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    52131 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/subtensor_mock.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1510 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_subtensor/types.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.682872 bittensor-5.3.2/bittensor/_synapse/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_synapse/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     7252 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_synapse/synapse.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.683178 bittensor-5.3.2/bittensor/_synapse/text_prompting/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/_synapse/text_prompting/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5281 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_synapse/text_prompting/synapse.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.683456 bittensor-5.3.2/bittensor/_threadpool/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5061 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_threadpool/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8603 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_threadpool/priority_thread_pool_impl.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.683612 bittensor-5.3.2/bittensor/_tokenizer/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     2458 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/_tokenizer/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.693901 bittensor-5.3.2/bittensor/utils/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6562 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3527 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/_register_cuda.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     8692 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/balance.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4432 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/codes.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)      553 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/formatting.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     7975 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/networking.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    39297 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/registration.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    34816 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/registratrion_old.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3302 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/stats.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)      630 2023-07-13 19:44:57.000000 bittensor-5.3.2/bittensor/utils/test_utils.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    77419 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/tokenizer_utils.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     9940 2023-07-26 22:21:01.000000 bittensor-5.3.2/bittensor/utils/weight_utils.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.663329 bittensor-5.3.2/bittensor.egg-info/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    23700 2023-07-26 22:40:30.000000 bittensor-5.3.2/bittensor.egg-info/PKG-INFO
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4105 2023-07-26 22:40:30.000000 bittensor-5.3.2/bittensor.egg-info/SOURCES.txt
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        1 2023-07-26 22:40:30.000000 bittensor-5.3.2/bittensor.egg-info/dependency_links.txt
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)      922 2023-07-26 22:40:30.000000 bittensor-5.3.2/bittensor.egg-info/requires.txt
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)       16 2023-07-26 22:40:30.000000 bittensor-5.3.2/bittensor.egg-info/top_level.txt
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)       38 2023-07-26 22:40:30.719449 bittensor-5.3.2/setup.cfg
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3425 2023-07-26 22:21:01.000000 bittensor-5.3.2/setup.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.694038 bittensor-5.3.2/tests/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1198 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.694304 bittensor-5.3.2/tests/helpers/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1275 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/helpers/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5423 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/helpers/helpers.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.707263 bittensor-5.3.2/tests/integration_tests/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.2/tests/integration_tests/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    80151 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_cli.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    42657 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_cli_no_network.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)      969 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_ipfs.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     3427 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_metagraph_integration.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1642 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_priority_thread_pool.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1440 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_prometheus.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    24522 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/integration_tests/test_subtensor_integration.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.707443 bittensor-5.3.2/tests/unit_tests/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.2/tests/unit_tests/__init__.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.716968 bittensor-5.3.2/tests/unit_tests/bittensor_tests/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    13893 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_axon.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    16019 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_balance.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4320 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_config.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     1725 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_metagraph.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    13762 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_serialization.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     6810 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_subtensor.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     4947 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_synapse.py
+drwxr-xr-x   0 cameronfairchild   (501) staff       (20)        0 2023-07-26 22:40:30.717521 bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)        0 2023-07-13 19:50:20.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/__init__.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     5327 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_network_utils.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)    35864 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_utils.py
+-rw-r--r--   0 cameronfairchild   (501) staff       (20)     2914 2023-07-26 22:21:01.000000 bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_weight_utils.py
```

### Comparing `bittensor-5.3.1/LICENSE` & `bittensor-5.3.2/LICENSE`

 * *Files identical despite different names*

### Comparing `bittensor-5.3.1/PKG-INFO` & `bittensor-5.3.2/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: bittensor
-Version: 5.3.1
+Version: 5.3.2
 Summary: bittensor
 Home-page: https://github.com/opentensor/bittensor
 Author: bittensor.com
 Author-email: 
 License: MIT
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Developers
@@ -437,14 +437,17 @@
 # Send a prompt to this endpoint
 dendrite.forward( roles = ['user'], messages = ['what are you?'] )
 ```
 
 ## Release
 The release manager should follow the instructions of the [RELEASE_GUIDELINES.md](./RELEASE_GUIDELINES.md) document.
 
+## Contributions
+Please review the [contributing guide](./contrib/CONTRIBUTING.md) for more information before making a pull request.
+
 ## License
 The MIT License (MIT)
 Copyright © 2021 Yuma Rao
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
 The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
```

### Comparing `bittensor-5.3.1/README.md` & `bittensor-5.3.2/README.md`

 * *Files 1% similar despite different names*

```diff
@@ -410,14 +410,17 @@
 # Send a prompt to this endpoint
 dendrite.forward( roles = ['user'], messages = ['what are you?'] )
 ```
 
 ## Release
 The release manager should follow the instructions of the [RELEASE_GUIDELINES.md](./RELEASE_GUIDELINES.md) document.
 
+## Contributions
+Please review the [contributing guide](./contrib/CONTRIBUTING.md) for more information before making a pull request.
+
 ## License
 The MIT License (MIT)
 Copyright © 2021 Yuma Rao
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
 The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
```

### Comparing `bittensor-5.3.1/bin/btcli` & `bittensor-5.3.2/bin/btcli`

 * *Files identical despite different names*

### Comparing `bittensor-5.3.1/bittensor/__init__.py` & `bittensor-5.3.2/bittensor/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -20,65 +20,87 @@
 from rich.console import Console
 from rich.traceback import install
 from prometheus_client import Info
 from langchain.llms.base import LLM
 from typing import Optional, List, Mapping, Any, Tuple
 
 import nest_asyncio
+
 nest_asyncio.apply()
 
 # Bittensor code and protocol version.
-__version__ = '5.3.1'
+__version__ = "5.3.2"
 version_split = __version__.split(".")
-__version_as_int__ = (100 * int(version_split[0])) + (10 * int(version_split[1])) + (1 * int(version_split[2]))
+__version_as_int__ = (
+    (100 * int(version_split[0]))
+    + (10 * int(version_split[1]))
+    + (1 * int(version_split[2]))
+)
 __new_signature_version__ = 360
 
 # Turn off rich console locals trace.
 from rich.traceback import install
+
 install(show_locals=False)
 
 # Rich console.
 __console__ = Console()
 __use_console__ = True
 
 # Remove overdue locals in debug training.
 install(show_locals=False)
 
+
 def turn_console_off():
     from io import StringIO
+
     __use_console__ = False
     __console__ = Console(file=StringIO(), stderr=False)
 
 
 # Vocabulary dimension.
-#__vocab_size__ = len( tokenizer ) + len( tokenizer.additional_special_tokens) + 100 # Plus 100 for eventual token size increase.
+# __vocab_size__ = len( tokenizer ) + len( tokenizer.additional_special_tokens) + 100 # Plus 100 for eventual token size increase.
 __vocab_size__ = 50258
 
 # Tensor dimension.
 # NOTE (const): if/when this increases peers must be responsible for trimming or expanding output to this size.
-__network_dim__ = 1024 # All network responses have shape = [ __batch_size__, __sequence_dim__, __network_dim__ ]
+__network_dim__ = 1024  # All network responses have shape = [ __batch_size__, __sequence_dim__, __network_dim__ ]
 
 # Substrate chain block time (seconds).
 __blocktime__ = 12
 
 # Pip address for versioning
-__pipaddress__ = 'https://pypi.org/pypi/bittensor/json'
+__pipaddress__ = "https://pypi.org/pypi/bittensor/json"
 
 # Raw github url for delegates registry file
 __delegates_details_url__: str = "https://raw.githubusercontent.com/opentensor/bittensor-delegates/main/public/delegates.json"
 
 # Substrate ss58_format
 __ss58_format__ = 42
 
 # Wallet ss58 address length
 __ss58_address_length__ = 48
 
-__networks__ = [ 'local', 'finney']
+__networks__ = ["local", "finney"]
 
-__datasets__ = ['ArXiv', 'BookCorpus2', 'Books3', 'DMMathematics', 'EnronEmails', 'EuroParl', 'Gutenberg_PG', 'HackerNews', 'NIHExPorter', 'OpenSubtitles', 'PhilPapers', 'UbuntuIRC', 'YoutubeSubtitles']
+__datasets__ = [
+    "ArXiv",
+    "BookCorpus2",
+    "Books3",
+    "DMMathematics",
+    "EnronEmails",
+    "EuroParl",
+    "Gutenberg_PG",
+    "HackerNews",
+    "NIHExPorter",
+    "OpenSubtitles",
+    "PhilPapers",
+    "UbuntuIRC",
+    "YoutubeSubtitles",
+]
 
 __finney_entrypoint__ = "wss://entrypoint-finney.opentensor.ai:443"
 
 __finney_test_entrypoint__ = "wss://test.finney.opentensor.ai:443/"
 
 # Needs to use wss://
 __bellagene_entrypoint__ = "wss://parachain.opentensor.ai:443"
@@ -91,41 +113,47 @@
 
 # Mock Testing Constant
 __GLOBAL_MOCK_STATE__ = {}
 
 # Block Explorers map network to explorer url
 ## Must all be polkadotjs explorer urls
 __network_explorer_map__ = {
-    'local': "https://explorer.finney.opentensor.ai/#/explorer",
-    'endpoint': "https://explorer.finney.opentensor.ai/#/explorer",
-    'finney': "https://explorer.finney.opentensor.ai/#/explorer"
+    "local": "https://explorer.finney.opentensor.ai/#/explorer",
+    "endpoint": "https://explorer.finney.opentensor.ai/#/explorer",
+    "finney": "https://explorer.finney.opentensor.ai/#/explorer",
 }
 
 # --- Type Registry ---
 __type_registry__ = {
-    'types': {
-        'Balance': 'u64', # Need to override default u128
+    "types": {
+        "Balance": "u64",  # Need to override default u128
     },
 }
 
 # --- Prometheus ---
 __prometheus_version__ = "0.1.0"
 prometheus_version__split = __prometheus_version__.split(".")
-__prometheus_version__as_int__ = (100 * int(prometheus_version__split[0])) + (10 * int(prometheus_version__split[1])) + (1 * int(prometheus_version__split[2]))
+__prometheus_version__as_int__ = (
+    (100 * int(prometheus_version__split[0]))
+    + (10 * int(prometheus_version__split[1]))
+    + (1 * int(prometheus_version__split[2]))
+)
 try:
-    bt_promo_info = Info("bittensor_info", "Information about the installed bittensor package.")
-    bt_promo_info.info (
+    bt_promo_info = Info(
+        "bittensor_info", "Information about the installed bittensor package."
+    )
+    bt_promo_info.info(
         {
-            '__version__': str(__version__),
-            '__version_as_int__': str(__version_as_int__),
-            '__vocab_size__': str(__vocab_size__),
-            '__network_dim__': str(__network_dim__),
-            '__blocktime__': str(__blocktime__),
-            '__prometheus_version__': str(__prometheus_version__),
-            '__prometheus_version__as_int__': str(__prometheus_version__as_int__),
+            "__version__": str(__version__),
+            "__version_as_int__": str(__version_as_int__),
+            "__vocab_size__": str(__vocab_size__),
+            "__network_dim__": str(__network_dim__),
+            "__blocktime__": str(__blocktime__),
+            "__prometheus_version__": str(__prometheus_version__),
+            "__prometheus_version__as_int__": str(__prometheus_version__as_int__),
         }
     )
 except ValueError:
     # This can silently fail if we import bittensor twice in the same process.
     # We simply pass over this error.
     pass
 
@@ -160,15 +188,15 @@
 from bittensor._metagraph import metagraph as metagraph
 from bittensor._prometheus import prometheus as prometheus
 from bittensor._subtensor import subtensor as subtensor
 from bittensor._tokenizer import tokenizer as tokenizer
 from bittensor._serializer import serializer as serializer
 from bittensor._dataset import dataset as dataset
 from bittensor._threadpool import prioritythreadpool as prioritythreadpool
-from bittensor._blacklist import blacklist  as blacklist
+from bittensor._blacklist import blacklist as blacklist
 from bittensor._priority import priority as priority
 
 # ---- Classes -----
 from bittensor._cli.cli_impl import CLI as CLI
 from bittensor_config.config_impl import Config as Config
 from bittensor._subtensor.chain_data import DelegateInfo as DelegateInfo
 from bittensor_wallet import Wallet as Wallet
@@ -179,15 +207,17 @@
 from bittensor._subtensor.chain_data import PrometheusInfo as PrometheusInfo
 from bittensor._subtensor.chain_data import ProposalCallData as ProposalCallData
 from bittensor._subtensor.chain_data import ProposalVoteData as ProposalVoteData
 from bittensor._subtensor.subtensor_impl import Subtensor as Subtensor
 from bittensor._serializer.serializer_impl import Serializer as Serializer
 from bittensor._subtensor.chain_data import SubnetInfo as SubnetInfo
 from bittensor._dataset.dataset_impl import Dataset as Dataset
-from bittensor._threadpool.priority_thread_pool_impl import PriorityThreadPoolExecutor as PriorityThreadPoolExecutor
+from bittensor._threadpool.priority_thread_pool_impl import (
+    PriorityThreadPoolExecutor as PriorityThreadPoolExecutor,
+)
 from bittensor._ipfs.ipfs_impl import Ipfs as Ipfs
 
 # ---- Errors and Exceptions -----
 from bittensor_wallet import KeyFileError as KeyFileError
 
 from bittensor._proto.bittensor_pb2 import ForwardTextPromptingRequest
 from bittensor._proto.bittensor_pb2 import ForwardTextPromptingResponse
@@ -198,181 +228,195 @@
 from bittensor._synapse.synapse import Synapse
 from bittensor._synapse.synapse import SynapseCall
 from bittensor._synapse.text_prompting.synapse import TextPromptingSynapse
 
 # ---- Dendrites -----
 from bittensor._dendrite.dendrite import Dendrite
 from bittensor._dendrite.dendrite import DendriteCall
-from bittensor._dendrite.text_prompting.dendrite import TextPromptingDendrite as text_prompting
-from bittensor._dendrite.text_prompting.dendrite_pool import TextPromptingDendritePool as text_prompting_pool
+from bittensor._dendrite.text_prompting.dendrite import (
+    TextPromptingDendrite as text_prompting,
+)
+from bittensor._dendrite.text_prompting.dendrite_pool import (
+    TextPromptingDendritePool as text_prompting_pool,
+)
 
 # ---- Base Miners -----
 from bittensor._neuron.base_miner_neuron import BaseMinerNeuron
 from bittensor._neuron.base_prompting_miner import BasePromptingMiner
 from bittensor._neuron.base_huggingface_miner import HuggingFaceMiner
 
 # DEFAULTS
 defaults = Config()
 defaults.netuid = 1
-subtensor.add_defaults( defaults )
-axon.add_defaults( defaults )
-prioritythreadpool.add_defaults( defaults )
-prometheus.add_defaults( defaults )
-wallet.add_defaults( defaults, prefix = 'wallet' )
-dataset.add_defaults( defaults )
-logging.add_defaults( defaults )
+subtensor.add_defaults(defaults)
+axon.add_defaults(defaults)
+prioritythreadpool.add_defaults(defaults)
+prometheus.add_defaults(defaults)
+wallet.add_defaults(defaults, prefix="wallet")
+dataset.add_defaults(defaults)
+logging.add_defaults(defaults)
+
 
 # Logging helpers.
 def trace():
     logging.set_trace(True)
 
+
 def debug():
     logging.set_debug(True)
 
-default_prompt = '''
+
+default_prompt = """
 You are Chattensor.
 Chattensor is a research project by Opentensor Cortex.
 Chattensor is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Chattensor is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
-'''
+"""
 
-default_prompting_validator_key = '5F4tQyWrhfGVcNhoqeiNsR6KjD4wMZ2kfhLj4oHYuyHbZAc3'
+default_prompting_validator_key = "5F4tQyWrhfGVcNhoqeiNsR6KjD4wMZ2kfhLj4oHYuyHbZAc3"
 
 __context_prompting_llm = None
+
+
 def prompt(
-        content: Union[ str, List[str], List[Dict[ str ,str ]]],
-        wallet_name: str = "default",
-        hotkey: str = default_prompting_validator_key,
-        subtensor_: Optional['Subtensor'] = None,
-        axon_: Optional['axon_info'] = None,
-        return_all: bool = False,
-    ) -> str:
+    content: Union[str, List[str], List[Dict[str, str]]],
+    wallet_name: str = "default",
+    hotkey: str = default_prompting_validator_key,
+    subtensor_: Optional["Subtensor"] = None,
+    axon_: Optional["axon_info"] = None,
+    return_all: bool = False,
+) -> str:
     global __context_prompting_llm
     if __context_prompting_llm == None:
         __context_prompting_llm = prompting(
-            wallet_name = wallet_name,
-            hotkey = hotkey,
-            subtensor_ = subtensor_,
-            axon_ = axon_,
+            wallet_name=wallet_name,
+            hotkey=hotkey,
+            subtensor_=subtensor_,
+            axon_=axon_,
         )
-    return __context_prompting_llm( content = content, return_all = return_all )
+    return __context_prompting_llm(content=content, return_all=return_all)
+
 
-class prompting ( torch.nn.Module ):
-    _axon: 'axon_info'
-    _dendrite: 'Dendrite'
-    _subtensor: 'Subtensor'
+class prompting(torch.nn.Module):
+    _axon: "axon_info"
+    _dendrite: "Dendrite"
+    _subtensor: "Subtensor"
     _hotkey: str
-    _keypair: 'Keypair'
+    _keypair: "Keypair"
 
     def __init__(
         self,
         wallet_name: str = "default",
         hotkey: str = default_prompting_validator_key,
-        subtensor_: Optional['Subtensor'] = None,
-        axon_: Optional['axon_info'] = None,
-        use_coldkey: bool = False
+        subtensor_: Optional["Subtensor"] = None,
+        axon_: Optional["axon_info"] = None,
+        use_coldkey: bool = False,
     ):
         super(prompting, self).__init__()
         self._hotkey = hotkey
         self._subtensor = subtensor() if subtensor_ is None else subtensor_
         if use_coldkey:
-            self._keypair = wallet( name = wallet_name ).create_if_non_existent().coldkey
+            self._keypair = wallet(name=wallet_name).create_if_non_existent().coldkey
         else:
-            self._keypair = wallet( name = wallet_name ).create_if_non_existent().hotkey
+            self._keypair = wallet(name=wallet_name).create_if_non_existent().hotkey
 
         if axon_ is not None:
             self._axon = axon_
         else:
-            self._metagraph = metagraph( 1 )
-            self._axon = self._metagraph.axons[ self._metagraph.hotkeys.index( self._hotkey ) ]
-        self._dendrite = text_prompting(
-            keypair = self._keypair,
-            axon = self._axon
-        )
+            self._metagraph = metagraph(1)
+            self._axon = self._metagraph.axons[
+                self._metagraph.hotkeys.index(self._hotkey)
+            ]
+        self._dendrite = text_prompting(keypair=self._keypair, axon=self._axon)
 
     @staticmethod
-    def format_content( content: Union[ str, List[str], List[Dict[ str ,str ]]] ) -> Tuple[ List[str], List[str ]]:
-        if isinstance( content, str ):
-            return ['system', 'user'], [ default_prompt, content ]
-        elif isinstance( content, list ):
-            if isinstance( content[0], str ):
-                return ['user' for _ in content ], content
-            elif isinstance( content[0], dict ):
-                return [ dictitem[ list(dictitem.keys())[0] ] for dictitem in content ], [ dictitem[ list(dictitem.keys())[1] ] for dictitem in content ]
+    def format_content(
+        content: Union[str, List[str], List[Dict[str, str]]]
+    ) -> Tuple[List[str], List[str]]:
+        if isinstance(content, str):
+            return ["system", "user"], [default_prompt, content]
+        elif isinstance(content, list):
+            if isinstance(content[0], str):
+                return ["user" for _ in content], content
+            elif isinstance(content[0], dict):
+                return [dictitem[list(dictitem.keys())[0]] for dictitem in content], [
+                    dictitem[list(dictitem.keys())[1]] for dictitem in content
+                ]
             else:
-                raise ValueError('content has invalid type {}'.format( type( content )))
+                raise ValueError("content has invalid type {}".format(type(content)))
         else:
-            raise ValueError('content has invalid type {}'.format( type( content )))
+            raise ValueError("content has invalid type {}".format(type(content)))
 
     def forward(
-            self,
-            content: Union[ str, List[str], List[Dict[ str ,str ]]],
-            timeout: float = 24,
-            return_call: bool = False,
-            return_all: bool = False,
-        ) -> Union[str, List[str]]:
-        roles, messages = self.format_content( content )
+        self,
+        content: Union[str, List[str], List[Dict[str, str]]],
+        timeout: float = 24,
+        return_call: bool = False,
+        return_all: bool = False,
+    ) -> Union[str, List[str]]:
+        roles, messages = self.format_content(content)
         if not return_all:
             return self._dendrite.forward(
-                roles = roles,
-                messages = messages,
-                timeout = timeout
+                roles=roles, messages=messages, timeout=timeout
             ).completion
         else:
             return self._dendrite.multi_forward(
-                roles = roles,
-                messages = messages,
-                timeout = timeout
+                roles=roles, messages=messages, timeout=timeout
             ).multi_completions
 
-
     async def async_forward(
-            self,
-            content: Union[ str, List[str], List[Dict[ str ,str ]]],
-            timeout: float = 24,
-            return_all: bool = False,
-        ) -> Union[str, List[str]]:
-        roles, messages = self.format_content( content )
+        self,
+        content: Union[str, List[str], List[Dict[str, str]]],
+        timeout: float = 24,
+        return_all: bool = False,
+    ) -> Union[str, List[str]]:
+        roles, messages = self.format_content(content)
         if not return_all:
             return await self._dendrite.async_forward(
-                    roles = roles,
-                    messages = messages,
-                    timeout = timeout
-                ).completion
+                roles=roles, messages=messages, timeout=timeout
+            ).completion
         else:
             return self._dendrite.async_multi_forward(
-                roles = roles,
-                messages = messages,
-                timeout = timeout
+                roles=roles, messages=messages, timeout=timeout
             ).multi_completions
 
+
 class BittensorLLM(LLM):
     """Wrapper around Bittensor Prompting Subnetwork.
-This Python file implements the BittensorLLM class, a wrapper around the Bittensor Prompting Subnetwork for easy integration into language models. The class provides a query method to receive responses from the subnetwork for a given user message and an implementation of the _call method to return the best response. The class can be initialized with various parameters such as the wallet name and chain endpoint.
+    This Python file implements the BittensorLLM class, a wrapper around the Bittensor Prompting Subnetwork for easy integration into language models. The class provides a query method to receive responses from the subnetwork for a given user message and an implementation of the _call method to return the best response. The class can be initialized with various parameters such as the wallet name and chain endpoint.
 
-    Example:
-        .. code-block:: python
+        Example:
+            .. code-block:: python
 
-            from bittensor import BittensorLLM
-            btllm = BittensorLLM(wallet_name="default")
+                from bittensor import BittensorLLM
+                btllm = BittensorLLM(wallet_name="default")
     """
 
-    wallet_name: str = 'default'
+    wallet_name: str = "default"
     hotkey: str = default_prompting_validator_key
     llm: prompting = None
-    def __init__(self, subtensor_: Optional['Subtensor'] = None, axon_: Optional['axon_info'] = None, **data):
+
+    def __init__(
+        self,
+        subtensor_: Optional["Subtensor"] = None,
+        axon_: Optional["axon_info"] = None,
+        **data
+    ):
         super().__init__(**data)
-        self.llm = prompting(wallet_name=self.wallet_name, hotkey=self.hotkey, subtensor_=subtensor_, axon_=axon_ )
+        self.llm = prompting(
+            wallet_name=self.wallet_name,
+            hotkey=self.hotkey,
+            subtensor_=subtensor_,
+            axon_=axon_,
+        )
 
     @property
     def _identifying_params(self) -> Mapping[str, Any]:
         """Get the identifying parameters."""
         return {"wallet_name": self.wallet_name, "hotkey_name": self.hotkey}
 
     @property
     def _llm_type(self) -> str:
         return "BittensorLLM"
 
     def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
         """Call the LLM with the given prompt and stop tokens."""
         return self.llm(prompt)
-
-
```

### Comparing `bittensor-5.3.1/bittensor/_axon/__init__.py` & `bittensor-5.3.2/bittensor/_axon/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -27,29 +27,30 @@
 
 from concurrent import futures
 from dataclasses import dataclass
 from substrateinterface import Keypair
 import bittensor.utils.networking as net
 from typing import Dict, Optional, Tuple
 
+
 class axon:
-    """ Axon object for serving synapse receptors. """
+    """Axon object for serving synapse receptors."""
 
-    def info(self) -> 'axon_info':
+    def info(self) -> "axon_info":
         """Returns the axon info object associate with this axon."""
         return axon_info(
-            version = bittensor.__version_as_int__,
-            ip = self.external_ip,
-            ip_type = 4,
-            port = self.external_port,
-            hotkey = self.wallet.hotkey.ss58_address,
-            coldkey = self.wallet.coldkeypub.ss58_address,
-            protocol = 4,
-            placeholder1 = 0,
-            placeholder2 = 0,
+            version=bittensor.__version_as_int__,
+            ip=self.external_ip,
+            ip_type=4,
+            port=self.external_port,
+            hotkey=self.wallet.hotkey.ss58_address,
+            coldkey=self.wallet.coldkeypub.ss58_address,
+            protocol=4,
+            placeholder1=0,
+            placeholder2=0,
         )
 
     def __init__(
         self,
         wallet: "bittensor.Wallet",
         metagraph: Optional["bittensor.Metagraph"] = None,
         config: Optional["bittensor.config"] = None,
@@ -85,50 +86,67 @@
 
         # Build and check config.
         if config is None:
             config = axon.config()
         config = copy.deepcopy(config)
         config.axon.port = port if port is not None else config.axon.port
         config.axon.ip = ip if ip is not None else config.axon.ip
-        config.axon.external_ip = external_ip if external_ip is not None else config.axon.external_ip
+        config.axon.external_ip = (
+            external_ip if external_ip is not None else config.axon.external_ip
+        )
         config.axon.external_port = (
             external_port if external_port is not None else config.axon.external_port
         )
-        config.axon.max_workers = max_workers if max_workers is not None else config.axon.max_workers
+        config.axon.max_workers = (
+            max_workers if max_workers is not None else config.axon.max_workers
+        )
         config.axon.maximum_concurrent_rpcs = (
             maximum_concurrent_rpcs
             if maximum_concurrent_rpcs is not None
             else config.axon.maximum_concurrent_rpcs
         )
         axon.check_config(config)
         self.config = config
 
         # Build axon objects.
         self.ip = self.config.axon.ip
         self.port = self.config.axon.port
-        self.external_ip = self.config.axon.external_ip if self.config.axon.external_ip != None else bittensor.utils.networking.get_external_ip()
-        self.external_port = self.config.axon.external_port if self.config.axon.external_port != None else self.config.axon.port
+        self.external_ip = (
+            self.config.axon.external_ip
+            if self.config.axon.external_ip != None
+            else bittensor.utils.networking.get_external_ip()
+        )
+        self.external_port = (
+            self.config.axon.external_port
+            if self.config.axon.external_port != None
+            else self.config.axon.port
+        )
         self.full_address = str(self.config.axon.ip) + ":" + str(self.config.axon.port)
         self.started = False
 
         # Build priority thread pool
         self.priority_threadpool = bittensor.prioritythreadpool(config=self.config.axon)
 
         # Build interceptor.
         self.receiver_hotkey = self.wallet.hotkey.ss58_address
         self.auth_interceptor = AuthInterceptor(receiver_hotkey=self.receiver_hotkey)
 
         # Build grpc server
         if server is None:
-            self.thread_pool = futures.ThreadPoolExecutor(max_workers=self.config.axon.max_workers)
+            self.thread_pool = futures.ThreadPoolExecutor(
+                max_workers=self.config.axon.max_workers
+            )
             self.server = grpc.server(
                 self.thread_pool,
                 interceptors=(self.auth_interceptor,),
                 maximum_concurrent_rpcs=self.config.axon.maximum_concurrent_rpcs,
-                options=[("grpc.keepalive_time_ms", 100000), ("grpc.keepalive_timeout_ms", 500000)],
+                options=[
+                    ("grpc.keepalive_time_ms", 100000),
+                    ("grpc.keepalive_timeout_ms", 500000),
+                ],
             )
             self.server.add_insecure_port(self.full_address)
         else:
             self.server = server
             self.thread_pool = server._state.thread_pool
             self.server.add_insecure_port(self.full_address)
 
@@ -206,25 +224,31 @@
     @classmethod
     def add_defaults(cls, defaults):
         """Adds parser defaults to object from enviroment variables."""
         defaults.axon = bittensor.Config()
         defaults.axon.port = (
             os.getenv("BT_AXON_PORT") if os.getenv("BT_AXON_PORT") is not None else 8091
         )
-        defaults.axon.ip = os.getenv("BT_AXON_IP") if os.getenv("BT_AXON_IP") is not None else "[::]"
+        defaults.axon.ip = (
+            os.getenv("BT_AXON_IP") if os.getenv("BT_AXON_IP") is not None else "[::]"
+        )
         defaults.axon.external_port = (
             os.getenv("BT_AXON_EXTERNAL_PORT")
             if os.getenv("BT_AXON_EXTERNAL_PORT") is not None
             else None
         )
         defaults.axon.external_ip = (
-            os.getenv("BT_AXON_EXTERNAL_IP") if os.getenv("BT_AXON_EXTERNAL_IP") is not None else None
+            os.getenv("BT_AXON_EXTERNAL_IP")
+            if os.getenv("BT_AXON_EXTERNAL_IP") is not None
+            else None
         )
         defaults.axon.max_workers = (
-            os.getenv("BT_AXON_MAX_WORERS") if os.getenv("BT_AXON_MAX_WORERS") is not None else 10
+            os.getenv("BT_AXON_MAX_WORERS")
+            if os.getenv("BT_AXON_MAX_WORERS") is not None
+            else 10
         )
         defaults.axon.maximum_concurrent_rpcs = (
             os.getenv("BT_AXON_MAXIMUM_CONCURRENT_RPCS")
             if os.getenv("BT_AXON_MAXIMUM_CONCURRENT_RPCS") is not None
             else 400
         )
 
@@ -267,28 +291,24 @@
             self.server.stop(grace=1)
         self.started = False
 
 
 class AuthInterceptor(grpc.ServerInterceptor):
     """Creates a new server interceptor that authenticates incoming messages from passed arguments."""
 
-    def __init__(
-        self,
-        receiver_hotkey: str,
-    ):
+    def __init__(self, receiver_hotkey: str):
         r"""Creates a new server interceptor that authenticates incoming messages from passed arguments.
         Args:
             receiver_hotkey(str):
                 the SS58 address of the hotkey which should be targeted by RPCs
         """
         super().__init__()
         self.nonces = {}
         self.receiver_hotkey = receiver_hotkey
 
-
     def parse_signature_v2(self, signature: str) -> Optional[Tuple[int, str, str, str]]:
         r"""Attempts to parse a signature using the v2 format"""
         parts = signature.split(".")
         if len(parts) != 4:
             return None
         try:
             nonce = int(parts[0])
@@ -298,30 +318,26 @@
         signature = parts[2]
         receptor_uuid = parts[3]
         return (nonce, sender_hotkey, signature, receptor_uuid)
 
     def parse_signature(self, metadata: Dict[str, str]) -> Tuple[int, str, str, str]:
         r"""Attempts to parse a signature from the metadata"""
         signature = metadata.get("bittensor-signature")
-        version = metadata.get('bittensor-version')
+        version = metadata.get("bittensor-version")
         if signature is None:
             raise Exception("Request signature missing")
         if int(version) < 510:
             raise Exception("Incorrect Version")
         parts = self.parse_signature_v2(signature)
         if parts is not None:
             return parts
         raise Exception("Unknown signature format")
 
     def check_signature(
-        self,
-        nonce: int,
-        sender_hotkey: str,
-        signature: str,
-        receptor_uuid: str,
+        self, nonce: int, sender_hotkey: str, signature: str, receptor_uuid: str
     ):
         r"""verification of signature in metadata. Uses the pubkey and nonce"""
         keypair = Keypair(ss58_address=sender_hotkey)
         # Build the expected message which was used to build the signature.
         message = f"{nonce}.{sender_hotkey}.{self.receiver_hotkey}.{receptor_uuid}"
 
         # Build the key which uniquely identifies the endpoint that has signed
@@ -339,87 +355,96 @@
         self.nonces[endpoint_key] = nonce
 
     def intercept_service(self, continuation, handler_call_details):
         r"""Authentication between bittensor nodes. Intercepts messages and checks them"""
         metadata = dict(handler_call_details.invocation_metadata)
 
         try:
-            (
-                nonce,
-                sender_hotkey,
-                signature,
-                receptor_uuid,
-            ) = self.parse_signature(metadata)
+            (nonce, sender_hotkey, signature, receptor_uuid) = self.parse_signature(
+                metadata
+            )
 
             # signature checking
-            self.check_signature(
-                nonce, sender_hotkey, signature, receptor_uuid
-            )
+            self.check_signature(nonce, sender_hotkey, signature, receptor_uuid)
 
             return continuation(handler_call_details)
 
         except Exception as e:
             message = str(e)
             abort = lambda _, ctx: ctx.abort(grpc.StatusCode.UNAUTHENTICATED, message)
             return grpc.unary_unary_rpc_method_handler(abort)
 
 
 METADATA_BUFFER_SIZE = 250
 
+
 @dataclass
 class axon_info:
-
     version: int
     ip: str
     port: int
     ip_type: int
     hotkey: str
     coldkey: str
-    protocol:int = 4,
-    placeholder1:int = 0,
-    placeholder2:int = 0,
+    protocol: int = (4,)
+    placeholder1: int = (0,)
+    placeholder2: int = (0,)
 
     @property
     def is_serving(self) -> bool:
-        """ True if the endpoint is serving. """
-        if self.ip == '0.0.0.0': return False
-        else:return True
+        """True if the endpoint is serving."""
+        if self.ip == "0.0.0.0":
+            return False
+        else:
+            return True
 
     def ip_str(self) -> str:
-        """ Return the whole ip as string """
+        """Return the whole ip as string"""
         return net.ip__str__(self.ip_type, self.ip, self.port)
 
-    def __eq__ (self, other: 'axon_info'):
-        if other == None: return False
-        if self.version == other.version and self.ip == other.ip and self.port == other.port and self.ip_type == other.ip_type and self.coldkey == other.coldkey and self.hotkey == other.hotkey: return True
-        else: return False
+    def __eq__(self, other: "axon_info"):
+        if other == None:
+            return False
+        if (
+            self.version == other.version
+            and self.ip == other.ip
+            and self.port == other.port
+            and self.ip_type == other.ip_type
+            and self.coldkey == other.coldkey
+            and self.hotkey == other.hotkey
+        ):
+            return True
+        else:
+            return False
 
     def __str__(self):
-        return "axon_info( {}, {}, {}, {} )".format( str(self.ip_str()), str(self.hotkey), str(self.coldkey), self.version)
+        return "axon_info( {}, {}, {}, {} )".format(
+            str(self.ip_str()), str(self.hotkey), str(self.coldkey), self.version
+        )
 
     def __repr__(self):
         return self.__str__()
 
     @classmethod
-    def from_neuron_info(cls, neuron_info: dict ) -> 'axon_info':
-        """ Converts a dictionary to an axon_info object. """
+    def from_neuron_info(cls, neuron_info: dict) -> "axon_info":
+        """Converts a dictionary to an axon_info object."""
         return cls(
-            version = neuron_info['axon_info']['version'],
-            ip = bittensor.utils.networking.int_to_ip(int(neuron_info['axon_info']['ip'])),
-            port = neuron_info['axon_info']['port'],
-            ip_type = neuron_info['axon_info']['ip_type'],
-            hotkey = neuron_info['hotkey'],
-            coldkey = neuron_info['coldkey'],
+            version=neuron_info["axon_info"]["version"],
+            ip=bittensor.utils.networking.int_to_ip(
+                int(neuron_info["axon_info"]["ip"])
+            ),
+            port=neuron_info["axon_info"]["port"],
+            ip_type=neuron_info["axon_info"]["ip_type"],
+            hotkey=neuron_info["hotkey"],
+            coldkey=neuron_info["coldkey"],
         )
 
-    def to_parameter_dict( self ) -> 'torch.nn.ParameterDict':
-        r""" Returns a torch tensor of the subnet info.
-        """
-        return torch.nn.ParameterDict(
-            self.__dict__
-        )
+    def to_parameter_dict(self) -> "torch.nn.ParameterDict":
+        r"""Returns a torch tensor of the subnet info."""
+        return torch.nn.ParameterDict(self.__dict__)
 
     @classmethod
-    def from_parameter_dict( cls, parameter_dict: 'torch.nn.ParameterDict' ) -> 'axon_info':
-        r""" Returns an axon_info object from a torch parameter_dict.
-        """
-        return cls( **dict(parameter_dict) )
+    def from_parameter_dict(
+        cls, parameter_dict: "torch.nn.ParameterDict"
+    ) -> "axon_info":
+        r"""Returns an axon_info object from a torch parameter_dict."""
+        return cls(**dict(parameter_dict))
```

### Comparing `bittensor-5.3.1/bittensor/_blacklist/__init__.py` & `bittensor-5.3.2/bittensor/_blacklist/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,100 +15,105 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 import argparse
 import bittensor
 from typing import Union, Tuple
 
-class blacklist:
 
-    def __init__( self, config: "bittensor.Config" = None ):
+class blacklist:
+    def __init__(self, config: "bittensor.Config" = None):
         self.config = config or blacklist.config()
 
     @classmethod
-    def config( cls ) -> "bittensor.Config":
+    def config(cls) -> "bittensor.Config":
         parser = argparse.ArgumentParser()
         blacklist.add_args(parser)
-        return bittensor.config( parser )
+        return bittensor.config(parser)
 
     @classmethod
     def help(cls):
         parser = argparse.ArgumentParser()
         cls.add_args(parser)
-        print( cls.__new__.__doc__ )
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser, prefix: str = None ):
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
         prefix_str = "" if prefix is None else prefix + "."
         parser.add_argument(
-            '--' + prefix_str + 'blacklist.blacklisted_keys', 
-            type = str, 
-            required = False, 
-            nargs = '*', 
-            action = 'store',
-            help = 'List of ss58 addresses which are always disallowed pass through.', default=[]
+            "--" + prefix_str + "blacklist.blacklisted_keys",
+            type=str,
+            required=False,
+            nargs="*",
+            action="store",
+            help="List of ss58 addresses which are always disallowed pass through.",
+            default=[],
         )
         parser.add_argument(
-            '--' + prefix_str + 'blacklist.whitelisted_keys', 
-            type = str, 
-            required = False, 
-            nargs = '*', 
-            action = 'store',
-            help = 'List of ss58 addresses which are always allowed pass through.', default=[]
+            "--" + prefix_str + "blacklist.whitelisted_keys",
+            type=str,
+            required=False,
+            nargs="*",
+            action="store",
+            help="List of ss58 addresses which are always allowed pass through.",
+            default=[],
         )
         parser.add_argument(
-            '--' + prefix_str + 'blacklist.allow_non_registered',
-            action = 'store_true',
-            help = 'If True, the miner will allow non-registered hotkeys to pass blacklist.',
-            default = False
+            "--" + prefix_str + "blacklist.allow_non_registered",
+            action="store_true",
+            help="If True, the miner will allow non-registered hotkeys to pass blacklist.",
+            default=False,
         )
         parser.add_argument(
-            '--' + prefix_str + 'blacklist.min_allowed_stake',
-            type = float,
-            help = 'Minimum stake required to pass blacklist.',
-            default = 0.0
+            "--" + prefix_str + "blacklist.min_allowed_stake",
+            type=float,
+            help="Minimum stake required to pass blacklist.",
+            default=0.0,
         )
         parser.add_argument(
-            '--' + prefix_str + 'blacklist.vpermit_required',
-            action = 'store_true',
-            help = 'If True, the miner will require a vpermit to pass blacklist.',
-            default = False
+            "--" + prefix_str + "blacklist.vpermit_required",
+            action="store_true",
+            help="If True, the miner will require a vpermit to pass blacklist.",
+            default=False,
         )
 
-    def blacklist( 
-            self, 
-            forward_call: "bittensor.SynapseCall",
-            metagraph: "bittensor.Metagraph" = None,
-        ) -> Union[ Tuple[bool, str], bool ]:
-
+    def blacklist(
+        self,
+        forward_call: "bittensor.SynapseCall",
+        metagraph: "bittensor.Metagraph" = None,
+    ) -> Union[Tuple[bool, str], bool]:
         # Check for blacklisted keys which take priority over all other checks.
         src_hotkey = forward_call.src_hotkey
         if src_hotkey in self.config.blacklist.blacklisted_keys:
-            return True, 'blacklisted key'
+            return True, "blacklisted key"
 
         # Check for whitelisted keys which take priority over all remaining checks.
         if src_hotkey in self.config.blacklist.whitelisted_keys:
-            return False, 'whitelisted key'
+            return False, "whitelisted key"
 
         # Check if pubkey is registered.
         is_registered = False
         if metagraph is not None:
             is_registered = src_hotkey in metagraph.hotkeys
 
         if not is_registered and not self.config.blacklist.allow_non_registered:
-            return True, 'pubkey not registered'
+            return True, "pubkey not registered"
 
         # Check for stake amount.
         if is_registered and self.config.blacklist.min_allowed_stake > 0.0:
             uid = metagraph.hotkeys.index(src_hotkey)
             stake = metagraph.S[uid].item()
             if stake < self.config.blacklist.min_allowed_stake:
-                return True, 'pubkey stake below min_allowed_stake'
+                return True, "pubkey stake below min_allowed_stake"
 
         # Check for vpermit.
-        if metagraph is not None and self.config.blacklist.vpermit_required and is_registered:
+        if (
+            metagraph is not None
+            and self.config.blacklist.vpermit_required
+            and is_registered
+        ):
             uid = metagraph.hotkeys.index(src_hotkey)
             return metagraph.neurons[uid].validator_permit
 
         # All checks passed.
-        return False, 'passed blacklist'
+        return False, "passed blacklist"
```

### Comparing `bittensor-5.3.1/bittensor/_cli/__init__.py` & `bittensor-5.3.2/bittensor/_cli/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -21,152 +21,155 @@
 
 import sys
 import argparse
 import bittensor
 from . import cli_impl
 from .commands import *
 from typing import List, Optional
+
 console = bittensor.__console__
 
 # Turn off rich console locals trace.
 from rich.traceback import install
+
 install(show_locals=False)
 
+
 class cli:
     """
     Create and init the CLI class, which handles the coldkey, hotkey and tao transfer
     """
+
     def __new__(
-            cls,
-            config: Optional['bittensor.Config'] = None,
-            args: Optional[List[str]] = None,
-        ) -> 'bittensor.CLI':
-        r""" Creates a new bittensor.cli from passed arguments.
-            Args:
-                config (:obj:`bittensor.Config`, `optional`):
-                    bittensor.cli.config()
-                args (`List[str]`, `optional`):
-                    The arguments to parse from the command line.
+        cls,
+        config: Optional["bittensor.Config"] = None,
+        args: Optional[List[str]] = None,
+    ) -> "bittensor.CLI":
+        r"""Creates a new bittensor.cli from passed arguments.
+        Args:
+            config (:obj:`bittensor.Config`, `optional`):
+                bittensor.cli.config()
+            args (`List[str]`, `optional`):
+                The arguments to parse from the command line.
         """
         if config == None:
-            config = cli.config( args )
-        cli.check_config( config )
+            config = cli.config(args)
+        cli.check_config(config)
 
-        return cli_impl.CLI( config = config)
+        return cli_impl.CLI(config=config)
 
     @staticmethod
-    def __create_parser__() -> 'argparse.ArgumentParser':
-        """ Creates the argument parser for the bittensor cli.
-        """
+    def __create_parser__() -> "argparse.ArgumentParser":
+        """Creates the argument parser for the bittensor cli."""
         parser = argparse.ArgumentParser(
             description=f"bittensor cli v{bittensor.__version__}",
             usage="btcli <command> <command args>",
-            add_help=True)
-
-        cmd_parsers = parser.add_subparsers(dest='command')
-        ListCommand.add_args( cmd_parsers )
-        StakeCommand.add_args( cmd_parsers )
-        UpdateCommand.add_args( cmd_parsers )
-        InspectCommand.add_args( cmd_parsers )
-        UnStakeCommand.add_args( cmd_parsers )
-        OverviewCommand.add_args( cmd_parsers )
-        RegisterCommand.add_args( cmd_parsers )
-        TransferCommand.add_args( cmd_parsers )
-        NominateCommand.add_args( cmd_parsers )
-        NewHotkeyCommand.add_args( cmd_parsers )
-        MetagraphCommand.add_args( cmd_parsers )
-        NewColdkeyCommand.add_args( cmd_parsers )
-        MyDelegatesCommand.add_args( cmd_parsers )
-        ListSubnetsCommand.add_args( cmd_parsers )
-        RegenHotkeyCommand.add_args( cmd_parsers )
-        RegenColdkeyCommand.add_args( cmd_parsers )
-        DelegateStakeCommand.add_args( cmd_parsers )
-        DelegateUnstakeCommand.add_args( cmd_parsers )
-        ListDelegatesCommand.add_args( cmd_parsers )
-        RegenColdkeypubCommand.add_args( cmd_parsers )
-        RecycleRegisterCommand.add_args( cmd_parsers )
-        SenateCommand.add_args( cmd_parsers )
-        ProposalsCommand.add_args( cmd_parsers )
-        ShowVotesCommand.add_args( cmd_parsers )
-        SenateRegisterCommand.add_args( cmd_parsers )
-        SenateLeaveCommand.add_args( cmd_parsers )
-        VoteCommand.add_args( cmd_parsers )
+            add_help=True,
+        )
 
+        cmd_parsers = parser.add_subparsers(dest="command")
+        ListCommand.add_args(cmd_parsers)
+        StakeCommand.add_args(cmd_parsers)
+        UpdateCommand.add_args(cmd_parsers)
+        InspectCommand.add_args(cmd_parsers)
+        UnStakeCommand.add_args(cmd_parsers)
+        OverviewCommand.add_args(cmd_parsers)
+        RegisterCommand.add_args(cmd_parsers)
+        TransferCommand.add_args(cmd_parsers)
+        NominateCommand.add_args(cmd_parsers)
+        NewHotkeyCommand.add_args(cmd_parsers)
+        MetagraphCommand.add_args(cmd_parsers)
+        NewColdkeyCommand.add_args(cmd_parsers)
+        MyDelegatesCommand.add_args(cmd_parsers)
+        ListSubnetsCommand.add_args(cmd_parsers)
+        RegenHotkeyCommand.add_args(cmd_parsers)
+        RegenColdkeyCommand.add_args(cmd_parsers)
+        DelegateStakeCommand.add_args(cmd_parsers)
+        DelegateUnstakeCommand.add_args(cmd_parsers)
+        ListDelegatesCommand.add_args(cmd_parsers)
+        RegenColdkeypubCommand.add_args(cmd_parsers)
+        RecycleRegisterCommand.add_args(cmd_parsers)
+        SenateCommand.add_args(cmd_parsers)
+        ProposalsCommand.add_args(cmd_parsers)
+        ShowVotesCommand.add_args(cmd_parsers)
+        SenateRegisterCommand.add_args(cmd_parsers)
+        SenateLeaveCommand.add_args(cmd_parsers)
+        VoteCommand.add_args(cmd_parsers)
 
         return parser
 
     @staticmethod
-    def config(args: List[str]) -> 'bittensor.config':
-        """ From the argument parser, add config to bittensor.executor and local config
-            Return: bittensor.config object
+    def config(args: List[str]) -> "bittensor.config":
+        """From the argument parser, add config to bittensor.executor and local config
+        Return: bittensor.config object
         """
         parser = cli.__create_parser__()
 
         # If no arguments are passed, print help text.
         if len(args) == 0:
             parser.print_help()
             sys.exit()
 
-        return bittensor.config( parser, args=args )
+        return bittensor.config(parser, args=args)
 
     @staticmethod
-    def check_config (config: 'bittensor.Config'):
-        """ Check if the essential config exist under different command
-        """
+    def check_config(config: "bittensor.Config"):
+        """Check if the essential config exist under different command"""
         if config.command == "transfer":
-            TransferCommand.check_config( config )
+            TransferCommand.check_config(config)
         elif config.command == "register":
-            RegisterCommand.check_config( config )
+            RegisterCommand.check_config(config)
         elif config.command == "unstake":
-            UnStakeCommand.check_config( config )
+            UnStakeCommand.check_config(config)
         elif config.command == "stake":
-            StakeCommand.check_config( config )
+            StakeCommand.check_config(config)
         elif config.command == "overview":
-            OverviewCommand.check_config( config )
+            OverviewCommand.check_config(config)
         elif config.command == "new_coldkey":
-            NewColdkeyCommand.check_config( config )
+            NewColdkeyCommand.check_config(config)
         elif config.command == "new_hotkey":
-            NewHotkeyCommand.check_config( config )
+            NewHotkeyCommand.check_config(config)
         elif config.command == "regen_coldkey":
-            RegenColdkeyCommand.check_config( config )
+            RegenColdkeyCommand.check_config(config)
         elif config.command == "regen_coldkeypub":
-            RegenColdkeypubCommand.check_config( config )
+            RegenColdkeypubCommand.check_config(config)
         elif config.command == "regen_hotkey":
-            RegenHotkeyCommand.check_config( config )
+            RegenHotkeyCommand.check_config(config)
         elif config.command == "metagraph":
-            MetagraphCommand.check_config( config )
+            MetagraphCommand.check_config(config)
         elif config.command == "list":
-            ListCommand.check_config( config )
+            ListCommand.check_config(config)
         elif config.command == "inspect":
-            InspectCommand.check_config( config )
+            InspectCommand.check_config(config)
         elif config.command == "update":
-            UpdateCommand.check_config( config )
+            UpdateCommand.check_config(config)
         elif config.command == "nominate":
-            NominateCommand.check_config( config )
+            NominateCommand.check_config(config)
         elif config.command == "list_delegates":
-            ListDelegatesCommand.check_config( config )
+            ListDelegatesCommand.check_config(config)
         elif config.command == "list_subnets":
-            ListSubnetsCommand.check_config( config )
+            ListSubnetsCommand.check_config(config)
         elif config.command == "delegate":
-            DelegateStakeCommand.check_config( config )
+            DelegateStakeCommand.check_config(config)
         elif config.command == "undelegate":
-            DelegateUnstakeCommand.check_config( config )
+            DelegateUnstakeCommand.check_config(config)
         elif config.command == "my_delegates":
-            MyDelegatesCommand.check_config( config )
+            MyDelegatesCommand.check_config(config)
         elif config.command == "recycle_register":
-            RecycleRegisterCommand.check_config( config )
+            RecycleRegisterCommand.check_config(config)
         elif config.command == "senate":
-            SenateCommand.check_config( config )
+            SenateCommand.check_config(config)
         elif config.command == "proposals":
-            ProposalsCommand.check_config( config )
+            ProposalsCommand.check_config(config)
         elif config.command == "proposal_votes":
-            ShowVotesCommand.check_config( config )
+            ShowVotesCommand.check_config(config)
         elif config.command == "senate_register":
-            SenateRegisterCommand.check_config( config )
+            SenateRegisterCommand.check_config(config)
         elif config.command == "senate_leave":
-            SenateLeaveCommand.check_config( config )
+            SenateLeaveCommand.check_config(config)
         elif config.command == "senate_vote":
-            VoteCommand.check_config( config )
+            VoteCommand.check_config(config)
         else:
-            console.print(":cross_mark:[red]Unknown command: {}[/red]".format(config.command))
+            console.print(
+                ":cross_mark:[red]Unknown command: {}[/red]".format(config.command)
+            )
             sys.exit()
-
```

### Comparing `bittensor-5.3.1/bittensor/_cli/cli_impl.py` & `bittensor-5.3.2/bittensor/_cli/cli_impl.py`

 * *Files 24% similar despite different names*

```diff
@@ -15,83 +15,85 @@
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 
 import bittensor
 from .commands import *
 
+
 class CLI:
     """
     Implementation of the CLI class, which handles the coldkey, hotkey and money transfer
     """
-    def __init__(self, config: 'bittensor.Config' ):
-        r""" Initialized a bittensor.CLI object.
-            Args:
-                config (:obj:`bittensor.Config`, `required`):
-                    bittensor.cli.config()
+
+    def __init__(self, config: "bittensor.Config"):
+        r"""Initialized a bittensor.CLI object.
+        Args:
+            config (:obj:`bittensor.Config`, `required`):
+                bittensor.cli.config()
         """
         # (d)efaults to True if config.no_version_checking is not set.
         if not config.get("no_version_checking", d=True):
             try:
                 bittensor.utils.version_checking()
             except:
-                raise RuntimeError("To avoid internet based version checking pass --no_version_checking while running the CLI.")
+                raise RuntimeError(
+                    "To avoid internet based version checking pass --no_version_checking while running the CLI."
+                )
         self.config = config
 
-    def run ( self ):
-        """ Execute the command from config
-        """
+    def run(self):
+        """Execute the command from config"""
         if self.config.command == "transfer":
-            TransferCommand.run( self )
+            TransferCommand.run(self)
         elif self.config.command == "register":
-            RegisterCommand.run( self )
+            RegisterCommand.run(self)
         elif self.config.command == "unstake":
-            UnStakeCommand.run( self )
+            UnStakeCommand.run(self)
         elif self.config.command == "stake":
-            StakeCommand.run( self )
+            StakeCommand.run(self)
         elif self.config.command == "overview":
-            OverviewCommand.run( self )
+            OverviewCommand.run(self)
         elif self.config.command == "list":
-            ListCommand.run( self )
+            ListCommand.run(self)
         elif self.config.command == "new_coldkey":
-            NewColdkeyCommand.run( self )
+            NewColdkeyCommand.run(self)
         elif self.config.command == "new_hotkey":
-            NewHotkeyCommand.run( self )
+            NewHotkeyCommand.run(self)
         elif self.config.command == "regen_coldkey":
-            RegenColdkeyCommand.run( self )
+            RegenColdkeyCommand.run(self)
         elif self.config.command == "regen_coldkeypub":
-            RegenColdkeypubCommand.run( self )
+            RegenColdkeypubCommand.run(self)
         elif self.config.command == "regen_hotkey":
-            RegenHotkeyCommand.run( self )
+            RegenHotkeyCommand.run(self)
         elif self.config.command == "metagraph":
-            MetagraphCommand.run( self )
+            MetagraphCommand.run(self)
         elif self.config.command == "inspect":
-            InspectCommand.run( self )
-        elif self.config.command == 'update':
-            UpdateCommand.run( self )
-        elif self.config.command == 'nominate':
-            NominateCommand.run( self )
-        elif self.config.command == 'delegate':
-            DelegateStakeCommand.run( self )
-        elif self.config.command == 'undelegate':
-            DelegateUnstakeCommand.run( self )
-        elif self.config.command == 'my_delegates':
-            MyDelegatesCommand.run( self )
-        elif self.config.command == 'list_delegates':
-            ListDelegatesCommand.run( self )
-        elif self.config.command == 'list_subnets':
-            ListSubnetsCommand.run( self )
-        elif self.config.command == 'recycle_register':
-            RecycleRegisterCommand.run( self )
+            InspectCommand.run(self)
+        elif self.config.command == "update":
+            UpdateCommand.run(self)
+        elif self.config.command == "nominate":
+            NominateCommand.run(self)
+        elif self.config.command == "delegate":
+            DelegateStakeCommand.run(self)
+        elif self.config.command == "undelegate":
+            DelegateUnstakeCommand.run(self)
+        elif self.config.command == "my_delegates":
+            MyDelegatesCommand.run(self)
+        elif self.config.command == "list_delegates":
+            ListDelegatesCommand.run(self)
+        elif self.config.command == "list_subnets":
+            ListSubnetsCommand.run(self)
+        elif self.config.command == "recycle_register":
+            RecycleRegisterCommand.run(self)
         elif self.config.command == "senate":
-            SenateCommand.run( self )
+            SenateCommand.run(self)
         elif self.config.command == "proposals":
-            ProposalsCommand.run( self )
+            ProposalsCommand.run(self)
         elif self.config.command == "proposal_votes":
-            ShowVotesCommand.run( self )
+            ShowVotesCommand.run(self)
         elif self.config.command == "senate_register":
-            SenateRegisterCommand.run( self )
+            SenateRegisterCommand.run(self)
         elif self.config.command == "senate_leave":
-            SenateLeaveCommand.run( self )
+            SenateLeaveCommand.run(self)
         elif self.config.command == "senate_vote":
-            VoteCommand.run( self )
-
+            VoteCommand.run(self)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/list.py` & `bittensor-5.3.2/bittensor/_cli/commands/transfer.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
+# Copyright © 2022 Opentensor Foundation
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
 # The above copyright notice and this permission notice shall be included in all copies or substantial portions of
@@ -11,79 +12,100 @@
 
 # THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
-import os
+import sys
 import argparse
 import bittensor
-from rich import print
-from rich.tree import Tree
-console = bittensor.__console__
+from rich.prompt import Prompt
 
-class ListCommand:
-    @staticmethod
-    def run (cli):
-        r""" Lists wallets."""
-        try:
-            wallets = next(os.walk(os.path.expanduser(cli.config.wallet.path)))[1]
-        except StopIteration:
-            # No wallet files found.
-            wallets = []
-
-        root = Tree("Wallets")
-        for w_name in wallets:
-            wallet_for_name = bittensor.wallet( path = cli.config.wallet.path, name = w_name)
-            try:
-                if wallet_for_name.coldkeypub_file.exists_on_device() and not wallet_for_name.coldkeypub_file.is_encrypted():
-                    coldkeypub_str = wallet_for_name.coldkeypub.ss58_address
-                else:
-                    coldkeypub_str = '?'
-            except:
-                coldkeypub_str = '?'
-
-            wallet_tree = root.add("\n[bold white]{} ({})".format(w_name, coldkeypub_str))
-            hotkeys_path = os.path.join(cli.config.wallet.path, w_name, 'hotkeys')
-            try:
-                hotkeys = next(os.walk(os.path.expanduser(hotkeys_path)))
-                if len( hotkeys ) > 1:
-                    for h_name in hotkeys[2]:
-                        hotkey_for_name = bittensor.wallet( path = cli.config.wallet.path, name = w_name, hotkey = h_name)
-                        try:
-                            if hotkey_for_name.hotkey_file.exists_on_device() and not hotkey_for_name.hotkey_file.is_encrypted():
-                                hotkey_str = hotkey_for_name.hotkey.ss58_address
-                            else:
-                                hotkey_str = '?'
-                        except:
-                            hotkey_str = '?'
-                        wallet_tree.add("[bold grey]{} ({})".format(h_name, hotkey_str))
-            except:
-                continue
+console = bittensor.__console__
 
-        if len(wallets) == 0:
-            root.add("[bold red]No wallets found.")
 
-        # Uses rich print to display the tree.
-        print(root)
+class TransferCommand:
+    @staticmethod
+    def run(cli):
+        r"""Transfer token of amount to destination."""
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor = bittensor.subtensor(config=cli.config)
+        subtensor.transfer(
+            wallet=wallet,
+            dest=cli.config.dest,
+            amount=cli.config.amount,
+            wait_for_inclusion=True,
+            prompt=not cli.config.no_prompt,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        pass
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
+            config.wallet.name = str(wallet_name)
+
+        # Get destination.
+        if not config.dest:
+            dest = Prompt.ask("Enter destination public key: (ss58 or ed2519)")
+            if not bittensor.utils.is_valid_bittensor_address_or_public_key(dest):
+                sys.exit()
+            else:
+                config.dest = str(dest)
+
+        # Get current balance and print to user.
+        if not config.no_prompt:
+            wallet = bittensor.wallet(config)
+            subtensor = bittensor.subtensor(config)
+            with bittensor.__console__.status(":satellite: Checking Balance..."):
+                account_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
+                bittensor.__console__.print(
+                    "Balance: [green]{}[/green]".format(account_balance)
+                )
+
+        # Get amount.
+        if not config.get("amount"):
+            if not config.no_prompt:
+                amount = Prompt.ask("Enter TAO amount to transfer")
+                try:
+                    config.amount = float(amount)
+                except ValueError:
+                    console.print(
+                        ":cross_mark:[red] Invalid TAO amount[/red] [bold white]{}[/bold white]".format(
+                            amount
+                        )
+                    )
+                    sys.exit()
+            else:
+                console.print(
+                    ":cross_mark:[red] Invalid TAO amount[/red] [bold white]{}[/bold white]".format(
+                        amount
+                    )
+                )
+                sys.exit(1)
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
-        list_parser = parser.add_parser(
-            'list',
-            help='''List wallets'''
+    def add_args(parser: argparse.ArgumentParser):
+        transfer_parser = parser.add_parser(
+            "transfer", help="""Transfer Tao between accounts."""
+        )
+        transfer_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
+        )
+        transfer_parser.add_argument("--dest", dest="dest", type=str, required=False)
+        transfer_parser.add_argument(
+            "--amount", dest="amount", type=float, required=False
         )
-        list_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+        transfer_parser.add_argument(
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        list_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
-        bittensor.wallet.add_args( list_parser )
-        bittensor.subtensor.add_args( list_parser )
+        bittensor.wallet.add_args(transfer_parser)
+        bittensor.subtensor.add_args(transfer_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/metagraph.py` & `bittensor-5.3.2/bittensor/_cli/commands/metagraph.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
@@ -17,27 +16,35 @@
 # DEALINGS IN THE SOFTWARE.
 
 import argparse
 import bittensor
 from rich.prompt import Prompt
 from rich.table import Table
 from .utils import check_netuid_set
+
 console = bittensor.__console__
 
+
 class MetagraphCommand:
     @staticmethod
-    def run (cli):
-        r""" Prints an entire metagraph."""
+    def run(cli):
+        r"""Prints an entire metagraph."""
         console = bittensor.__console__
-        subtensor = bittensor.subtensor( config = cli.config )
-        console.print(":satellite: Syncing with chain: [white]{}[/white] ...".format(cli.config.subtensor.network))
-        metagraph: bittensor.metagraph = subtensor.metagraph( netuid = cli.config.netuid )
+        subtensor = bittensor.subtensor(config=cli.config)
+        console.print(
+            ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+                cli.config.subtensor.network
+            )
+        )
+        metagraph: bittensor.metagraph = subtensor.metagraph(netuid=cli.config.netuid)
         metagraph.save()
-        difficulty = subtensor.difficulty( cli.config.netuid )
-        subnet_emission = bittensor.Balance.from_tao(subtensor.get_emission_value_by_subnet(cli.config.netuid))
+        difficulty = subtensor.difficulty(cli.config.netuid)
+        subnet_emission = bittensor.Balance.from_tao(
+            subtensor.get_emission_value_by_subnet(cli.config.netuid)
+        )
         total_issuance = bittensor.Balance.from_tao(subtensor.total_issuance())
 
         TABLE_DATA = []
         total_stake = 0.0
         total_rank = 0.0
         total_validator_trust = 0.0
         total_trust = 0.0
@@ -46,86 +53,164 @@
         total_dividends = 0.0
         total_emission = 0
         for uid in metagraph.uids:
             neuron = metagraph.neurons[uid]
             ep = metagraph.axons[uid]
             row = [
                 str(neuron.uid),
-                '{:.5f}'.format( metagraph.total_stake[uid]),
-                '{:.5f}'.format( metagraph.ranks[uid]),
-                '{:.5f}'.format( metagraph.trust[uid]),
-                '{:.5f}'.format( metagraph.consensus[uid]),
-                '{:.5f}'.format( metagraph.incentive[uid]),
-                '{:.5f}'.format( metagraph.dividends[uid]),
-                '{}'.format( int(metagraph.emission[uid] * 1000000000)),
-                '{:.5f}'.format( metagraph.validator_trust[uid]),
-                '*' if metagraph.validator_permit[uid] else '',
+                "{:.5f}".format(metagraph.total_stake[uid]),
+                "{:.5f}".format(metagraph.ranks[uid]),
+                "{:.5f}".format(metagraph.trust[uid]),
+                "{:.5f}".format(metagraph.consensus[uid]),
+                "{:.5f}".format(metagraph.incentive[uid]),
+                "{:.5f}".format(metagraph.dividends[uid]),
+                "{}".format(int(metagraph.emission[uid] * 1000000000)),
+                "{:.5f}".format(metagraph.validator_trust[uid]),
+                "*" if metagraph.validator_permit[uid] else "",
                 str((metagraph.block.item() - metagraph.last_update[uid].item())),
-                str( metagraph.active[uid].item() ),
-                ep.ip + ':' + str(ep.port) if ep.is_serving else '[yellow]none[/yellow]',
+                str(metagraph.active[uid].item()),
+                ep.ip + ":" + str(ep.port)
+                if ep.is_serving
+                else "[yellow]none[/yellow]",
                 ep.hotkey[:10],
-                ep.coldkey[:10]
+                ep.coldkey[:10],
             ]
             total_stake += metagraph.total_stake[uid]
             total_rank += metagraph.ranks[uid]
             total_validator_trust += metagraph.validator_trust[uid]
             total_trust += metagraph.trust[uid]
             total_consensus += metagraph.consensus[uid]
             total_incentive += metagraph.incentive[uid]
             total_dividends += metagraph.dividends[uid]
             total_emission += int(metagraph.emission[uid] * 1000000000)
             TABLE_DATA.append(row)
         total_neurons = len(metagraph.uids)
         table = Table(show_footer=False)
-        table.title = (
-            "[white]Metagraph: net: {}:{}, block: {}, N: {}/{}, stake: {}, issuance: {}, difficulty: {}".format(subtensor.network, metagraph.netuid, metagraph.block.item(), sum(metagraph.active.tolist()), metagraph.n.item(), bittensor.Balance.from_tao(total_stake), total_issuance, difficulty )
+        table.title = "[white]Metagraph: net: {}:{}, block: {}, N: {}/{}, stake: {}, issuance: {}, difficulty: {}".format(
+            subtensor.network,
+            metagraph.netuid,
+            metagraph.block.item(),
+            sum(metagraph.active.tolist()),
+            metagraph.n.item(),
+            bittensor.Balance.from_tao(total_stake),
+            total_issuance,
+            difficulty,
+        )
+        table.add_column(
+            "[overline white]UID",
+            str(total_neurons),
+            footer_style="overline white",
+            style="yellow",
+        )
+        table.add_column(
+            "[overline white]STAKE(\u03C4)",
+            "\u03C4{:.5f}".format(total_stake),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]RANK",
+            "{:.5f}".format(total_rank),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]TRUST",
+            "{:.5f}".format(total_trust),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]CONSENSUS",
+            "{:.5f}".format(total_consensus),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]INCENTIVE",
+            "{:.5f}".format(total_incentive),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
         )
-        table.add_column("[overline white]UID",  str(total_neurons), footer_style = "overline white", style='yellow')
-        table.add_column("[overline white]STAKE(\u03C4)", '\u03C4{:.5f}'.format(total_stake), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]RANK", '{:.5f}'.format(total_rank), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]TRUST", '{:.5f}'.format(total_trust), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]CONSENSUS", '{:.5f}'.format(total_consensus), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]INCENTIVE", '{:.5f}'.format(total_incentive), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]DIVIDENDS", '{:.5f}'.format(total_dividends), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]EMISSION(\u03C1)", '\u03C1{}'.format(int(total_emission)), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]VTRUST", '{:.5f}'.format(total_validator_trust), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]VAL", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]UPDATED", justify='right', no_wrap=True)
-        table.add_column("[overline white]ACTIVE", justify='right', style='green', no_wrap=True)
-        table.add_column("[overline white]AXON", justify='left', style='dim blue', no_wrap=True)
-        table.add_column("[overline white]HOTKEY", style='dim blue', no_wrap=False)
-        table.add_column("[overline white]COLDKEY", style='dim purple', no_wrap=False)
+        table.add_column(
+            "[overline white]DIVIDENDS",
+            "{:.5f}".format(total_dividends),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]EMISSION(\u03C1)",
+            "\u03C1{}".format(int(total_emission)),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]VTRUST",
+            "{:.5f}".format(total_validator_trust),
+            footer_style="overline white",
+            justify="right",
+            style="green",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]VAL", justify="right", style="green", no_wrap=True
+        )
+        table.add_column("[overline white]UPDATED", justify="right", no_wrap=True)
+        table.add_column(
+            "[overline white]ACTIVE", justify="right", style="green", no_wrap=True
+        )
+        table.add_column(
+            "[overline white]AXON", justify="left", style="dim blue", no_wrap=True
+        )
+        table.add_column("[overline white]HOTKEY", style="dim blue", no_wrap=False)
+        table.add_column("[overline white]COLDKEY", style="dim purple", no_wrap=False)
         table.show_footer = True
 
         for row in TABLE_DATA:
             table.add_row(*row)
         table.box = None
         table.pad_edge = False
         table.width = None
         console.print(table)
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        check_netuid_set( config, subtensor = bittensor.subtensor( config = config ) )
+    def check_config(config: "bittensor.Config"):
+        check_netuid_set(config, subtensor=bittensor.subtensor(config=config))
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
-        metagraph_parser = parser.add_parser(
-            'metagraph',
-            help='''Metagraph commands'''
-        )
+    def add_args(parser: argparse.ArgumentParser):
+        metagraph_parser = parser.add_parser("metagraph", help="""Metagraph commands""")
         metagraph_parser.add_argument(
-            '--netuid',
-            dest='netuid',
+            "--netuid",
+            dest="netuid",
             type=int,
-            help='''Set the netuid to get the metagraph of''',
+            help="""Set the netuid to get the metagraph of""",
+            default=False,
+        )
+        metagraph_parser.add_argument(
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         metagraph_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
             default=False,
         )
-        metagraph_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
-        bittensor.subtensor.add_args( metagraph_parser )
+        bittensor.subtensor.add_args(metagraph_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/misc.py` & `bittensor-5.3.2/bittensor/_cli/commands/misc.py`

 * *Files 10% similar despite different names*

```diff
@@ -18,105 +18,142 @@
 import os
 import sys
 import argparse
 import bittensor
 from typing import List
 from rich.prompt import Prompt
 from rich.table import Table
+
 console = bittensor.__console__
 
 
 class UpdateCommand:
     @staticmethod
-    def run (cli):
-        if cli.config.no_prompt or cli.config.answer == 'Y':
-            os.system(' (cd ~/.bittensor/bittensor/ ; git checkout master ; git pull --ff-only )')
-            os.system('pip install -e ~/.bittensor/bittensor/')
+    def run(cli):
+        if cli.config.no_prompt or cli.config.answer == "Y":
+            os.system(
+                " (cd ~/.bittensor/bittensor/ ; git checkout master ; git pull --ff-only )"
+            )
+            os.system("pip install -e ~/.bittensor/bittensor/")
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
+    def check_config(config: "bittensor.Config"):
         if not config.no_prompt:
-            answer = Prompt.ask('This will update the local bittensor package', choices = ['Y','N'], default = 'Y')
+            answer = Prompt.ask(
+                "This will update the local bittensor package",
+                choices=["Y", "N"],
+                default="Y",
+            )
             config.answer = answer
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         update_parser = parser.add_parser(
-            'update',
-            add_help=False,
-            help='''Update bittensor '''
+            "update", add_help=False, help="""Update bittensor """
+        )
+        update_parser.add_argument(
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to skip prompt from update.""",
+            default=False,
         )
         update_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to skip prompt from update.''',
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
             default=False,
         )
-        update_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
-        bittensor.subtensor.add_args( update_parser )
+        bittensor.subtensor.add_args(update_parser)
+
 
 class ListSubnetsCommand:
     @staticmethod
-    def run (cli):
-        r"""List all subnet netuids in the network. """
-        subtensor = bittensor.subtensor( config = cli.config )
+    def run(cli):
+        r"""List all subnet netuids in the network."""
+        subtensor = bittensor.subtensor(config=cli.config)
         subnets: List[bittensor.SubnetInfo] = subtensor.get_all_subnets_info()
 
         rows = []
         total_neurons = 0
 
         for subnet in subnets:
             total_neurons += subnet.max_n
             # netuid, N, Max N, difficulty, network connect, tempo, emission, burn rate
-            rows.append((
-                str(subnet.netuid),
-                str(subnet.subnetwork_n),
-                str(bittensor.utils.formatting.millify(subnet.max_n)),
-                str(bittensor.utils.formatting.millify(subnet.difficulty)),
-                str(subnet.tempo),
-                str([ f'{cr[0]}: {cr[1] * 100:.1f}%' for cr in subnet.connection_requirements.items()] if len(subnet.connection_requirements) > 0 else None ),
-                f'{subnet.emission_value / bittensor.utils.RAOPERTAO * 100:0.2f}%',
-                f'{subnet.burn!s:8.8}',
-            ))
-
-        table = Table(show_footer=True, width=cli.config.get('width', None), pad_edge=True, box=None, show_edge=True)
-        table.title = (
-            "[white]Subnets - {}".format(subtensor.network)
+            rows.append(
+                (
+                    str(subnet.netuid),
+                    str(subnet.subnetwork_n),
+                    str(bittensor.utils.formatting.millify(subnet.max_n)),
+                    str(bittensor.utils.formatting.millify(subnet.difficulty)),
+                    str(subnet.tempo),
+                    str(
+                        [
+                            f"{cr[0]}: {cr[1] * 100:.1f}%"
+                            for cr in subnet.connection_requirements.items()
+                        ]
+                        if len(subnet.connection_requirements) > 0
+                        else None
+                    ),
+                    f"{subnet.emission_value / bittensor.utils.RAOPERTAO * 100:0.2f}%",
+                    f"{subnet.burn!s:8.8}",
+                )
+            )
+
+        table = Table(
+            show_footer=True,
+            width=cli.config.get("width", None),
+            pad_edge=True,
+            box=None,
+            show_edge=True,
         )
+        table.title = "[white]Subnets - {}".format(subtensor.network)
         # netuid, N, Max N, difficulty, network connect, tempo, emission, burn rate
-        table.add_column("[overline white]NETUID",  str(len(subnets)), footer_style = "overline white", style='bold green', justify='center')
-        table.add_column("[overline white]NEURONS", str(total_neurons), footer_style = "overline white", style='white', justify='center')
-        table.add_column("[overline white]MAX_N", style='white', justify='center')
-        table.add_column("[overline white]DIFFICULTY", style='white', justify='center')
-        #table.add_column("[overline white]IMMUNITY", style='white')
-        #table.add_column("[overline white]BATCH SIZE", style='white')
-        #table.add_column("[overline white]SEQ_LEN", style='white')
-        table.add_column("[overline white]TEMPO", style='white', justify='center')
-        #table.add_column("[overline white]MODALITY", style='white')
-        table.add_column("[overline white]CON_REQ", style='white', justify='center')
-        table.add_column("[overline white]EMISSION", style='white', justify='center') # sums to 100%
-        table.add_column("[overline white]BURN(\u03C4)", style='white')
+        table.add_column(
+            "[overline white]NETUID",
+            str(len(subnets)),
+            footer_style="overline white",
+            style="bold green",
+            justify="center",
+        )
+        table.add_column(
+            "[overline white]NEURONS",
+            str(total_neurons),
+            footer_style="overline white",
+            style="white",
+            justify="center",
+        )
+        table.add_column("[overline white]MAX_N", style="white", justify="center")
+        table.add_column("[overline white]DIFFICULTY", style="white", justify="center")
+        # table.add_column("[overline white]IMMUNITY", style='white')
+        # table.add_column("[overline white]BATCH SIZE", style='white')
+        # table.add_column("[overline white]SEQ_LEN", style='white')
+        table.add_column("[overline white]TEMPO", style="white", justify="center")
+        # table.add_column("[overline white]MODALITY", style='white')
+        table.add_column("[overline white]CON_REQ", style="white", justify="center")
+        table.add_column(
+            "[overline white]EMISSION", style="white", justify="center"
+        )  # sums to 100%
+        table.add_column("[overline white]BURN(\u03C4)", style="white")
 
         for row in rows:
             table.add_row(*row)
 
         bittensor.__console__.print(table)
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
+    def check_config(config: "bittensor.Config"):
         pass
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         list_subnets_parser = parser.add_parser(
-            'list_subnets',
-            help='''List all subnets on the network'''
+            "list_subnets", help="""List all subnets on the network"""
         )
         list_subnets_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        bittensor.subtensor.add_args( list_subnets_parser )
+        bittensor.subtensor.add_args(list_subnets_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/overview.py` & `bittensor-5.3.2/bittensor/_cli/commands/overview.py`

 * *Files 26% similar despite different names*

```diff
@@ -14,102 +14,144 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 import argparse
 import bittensor
 from tqdm import tqdm
+from concurrent.futures import ProcessPoolExecutor
 from fuzzywuzzy import fuzz
 from rich.align import Align
 from rich.table import Table
 from rich.prompt import Prompt
-from typing import List, Optional, Dict
-from .utils import get_hotkey_wallets_for_wallet, get_coldkey_wallets_for_path, get_all_wallets_for_path
-console = bittensor.__console__
+from typing import List, Optional, Dict, Tuple
+from .utils import (
+    get_hotkey_wallets_for_wallet,
+    get_coldkey_wallets_for_path,
+    get_all_wallets_for_path,
+)
 
-class OverviewCommand:
+console = bittensor.__console__
 
 
+class OverviewCommand:
     @staticmethod
-    def run( cli ):
-        r""" Prints an overview for the wallet's colkey.
-        """
+    def run(cli):
+        r"""Prints an overview for the wallet's colkey."""
         console = bittensor.__console__
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor: 'bittensor.Subtensor' = bittensor.subtensor( config = cli.config )
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor: "bittensor.Subtensor" = bittensor.subtensor(config=cli.config)
 
         all_hotkeys = []
         total_balance = bittensor.Balance(0)
 
         # We are printing for every coldkey.
-        if cli.config.get( 'all', d=None ):
+        if cli.config.get("all", d=None):
             cold_wallets = get_coldkey_wallets_for_path(cli.config.wallet.path)
             for cold_wallet in tqdm(cold_wallets, desc="Pulling balances"):
-                if cold_wallet.coldkeypub_file.exists_on_device() and not cold_wallet.coldkeypub_file.is_encrypted():
-                    total_balance = total_balance + subtensor.get_balance( cold_wallet.coldkeypub.ss58_address )
-            all_hotkeys = get_all_wallets_for_path( cli.config.wallet.path )
+                if (
+                    cold_wallet.coldkeypub_file.exists_on_device()
+                    and not cold_wallet.coldkeypub_file.is_encrypted()
+                ):
+                    total_balance = total_balance + subtensor.get_balance(
+                        cold_wallet.coldkeypub.ss58_address
+                    )
+            all_hotkeys = get_all_wallets_for_path(cli.config.wallet.path)
         else:
             # We are only printing keys for a single coldkey
-            coldkey_wallet = bittensor.wallet( config = cli.config )
-            if coldkey_wallet.coldkeypub_file.exists_on_device() and not coldkey_wallet.coldkeypub_file.is_encrypted():
-                total_balance = subtensor.get_balance( coldkey_wallet.coldkeypub.ss58_address )
+            coldkey_wallet = bittensor.wallet(config=cli.config)
+            if (
+                coldkey_wallet.coldkeypub_file.exists_on_device()
+                and not coldkey_wallet.coldkeypub_file.is_encrypted()
+            ):
+                total_balance = subtensor.get_balance(
+                    coldkey_wallet.coldkeypub.ss58_address
+                )
             if not coldkey_wallet.coldkeypub_file.exists_on_device():
                 console.print("[bold red]No wallets found.")
                 return
-            all_hotkeys = get_hotkey_wallets_for_wallet( coldkey_wallet )
+            all_hotkeys = get_hotkey_wallets_for_wallet(coldkey_wallet)
 
         # We are printing for a select number of hotkeys from all_hotkeys.
 
-        if cli.config.get('hotkeys', []):
-            if not cli.config.get('all_hotkeys', False):
+        if cli.config.get("hotkeys", []):
+            if not cli.config.get("all_hotkeys", False):
                 # We are only showing hotkeys that are specified.
-                all_hotkeys = [hotkey for hotkey in all_hotkeys if hotkey.hotkey_str in cli.config.hotkeys]
+                all_hotkeys = [
+                    hotkey
+                    for hotkey in all_hotkeys
+                    if hotkey.hotkey_str in cli.config.hotkeys
+                ]
             else:
                 # We are excluding the specified hotkeys from all_hotkeys.
-                all_hotkeys = [hotkey for hotkey in all_hotkeys if hotkey.hotkey_str not in cli.config.hotkeys]
+                all_hotkeys = [
+                    hotkey
+                    for hotkey in all_hotkeys
+                    if hotkey.hotkey_str not in cli.config.hotkeys
+                ]
 
         # Check we have keys to display.
         if len(all_hotkeys) == 0:
             console.print("[red]No wallets found.[/red]")
             return
 
         # Pull neuron info for all keys.
-        neurons: Dict[str, List[bittensor.NeuronInfoLite, bittensor.Wallet]] = {}
+        neurons: Dict[str, List[bittensor.NeuronInfoLite, str]] = {}
         block = subtensor.block
 
         netuids = subtensor.get_all_subnet_netuids()
         if cli.config.netuid != []:
             netuids = [netuid for netuid in netuids if netuid in cli.config.netuid]
         for netuid in netuids:
             neurons[str(netuid)] = []
-        netuids_copy = netuids.copy()
 
-        with console.status(":satellite: Syncing with chain: [white]{}[/white] ...".format(cli.config.subtensor.get('network', bittensor.defaults.subtensor.network))):
-            for netuid in tqdm(netuids_copy, desc="Checking each subnet"):
-                all_neurons: List[bittensor.NeuronInfoLite] = subtensor.neurons_lite( netuid = netuid )
-                # Map the hotkeys to uids
-                hotkey_to_neurons = {n.hotkey: n.uid for n in all_neurons}
-                for hot_wallet in all_hotkeys:
-                    uid = hotkey_to_neurons.get(hot_wallet.hotkey.ss58_address)
-                    if uid is not None:
-                        nn = all_neurons[uid]
-                        neurons[str(netuid)].append( (nn, hot_wallet) )
-
-                if len(neurons[str(netuid)]) == 0:
-                    # Remove netuid from overview if no neurons are found.
-                    netuids.remove(netuid)
+        with console.status(
+            ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+                cli.config.subtensor.get(
+                    "network", bittensor.defaults.subtensor.network
+                )
+            )
+        ):
+            hotkey_addr_to_wallet = {
+                hotkey.hotkey.ss58_address: hotkey for hotkey in all_hotkeys
+            }
+            all_hotkey_addresses = list(hotkey_addr_to_wallet.keys())
+
+            # Pull neuron info for all keys.
+            ## Max len(netuids) or 5 threads.
+            with ProcessPoolExecutor(max_workers=max(len(netuids), 5)) as executor:
+                results = executor.map(
+                    OverviewCommand._get_neurons_for_netuid,
+                    [(cli.config, netuid, all_hotkey_addresses) for netuid in netuids],
+                )
+                executor.shutdown(wait=True)  # wait for all complete
+
+                for result in results:
+                    netuid, neurons_result, err_msg = result
+                    if err_msg is not None:
+                        console.print(err_msg)
+
+                    if len(neurons_result) == 0:
+                        # Remove netuid from overview if no neurons are found.
+                        netuids.remove(netuid)
+                        del neurons[str(netuid)]
+                    else:
+                        # Add neurons to overview.
+                        neurons[str(netuid)] = neurons_result
 
         # Setup outer table.
         grid = Table.grid(pad_edge=False)
 
         title: str = ""
-        if not cli.config.get( 'all', d=None ):
-            title = ( "[bold white italic]Wallet - {}:{}".format(cli.config.wallet.name, wallet.coldkeypub.ss58_address) )
+        if not cli.config.get("all", d=None):
+            title = "[bold white italic]Wallet - {}:{}".format(
+                cli.config.wallet.name, wallet.coldkeypub.ss58_address
+            )
         else:
-            title = ( "[bold whit italic]All Wallets:" )
+            title = "[bold whit italic]All Wallets:"
 
         # Add title
         grid.add_row(Align(title, vertical="middle", align="center"))
 
         # Generate rows per netuid
         hotkeys_seen = set()
         total_neurons = 0
@@ -122,45 +164,50 @@
             total_trust = 0.0
             total_consensus = 0.0
             total_validator_trust = 0.0
             total_incentive = 0.0
             total_dividends = 0.0
             total_emission = 0
 
-            for nn, hotwallet in neurons[str(netuid)]:
+            for nn, hotwallet_addr in neurons[str(netuid)]:
+                hotwallet = hotkey_addr_to_wallet[hotwallet_addr]
                 nn: bittensor.NeuronInfoLite
                 uid = nn.uid
                 active = nn.active
                 stake = nn.total_stake.tao
                 rank = nn.rank
                 trust = nn.trust
                 consensus = nn.consensus
                 validator_trust = nn.validator_trust
                 incentive = nn.incentive
                 dividends = nn.dividends
                 emission = int(nn.emission / (subnet_tempo + 1) * 1e9)
-                last_update = int(block -  nn.last_update)
+                last_update = int(block - nn.last_update)
                 validator_permit = nn.validator_permit
                 row = [
                     hotwallet.name,
                     hotwallet.hotkey_str,
                     str(uid),
                     str(active),
-                    '{:.5f}'.format(stake),
-                    '{:.5f}'.format(rank),
-                    '{:.5f}'.format(trust),
-                    '{:.5f}'.format(consensus),
-                    '{:.5f}'.format(incentive),
-                    '{:.5f}'.format(dividends),
-                    '{:_}'.format(emission),
-                    '{:.5f}'.format(validator_trust),
-                    '*' if validator_permit else '',
+                    "{:.5f}".format(stake),
+                    "{:.5f}".format(rank),
+                    "{:.5f}".format(trust),
+                    "{:.5f}".format(consensus),
+                    "{:.5f}".format(incentive),
+                    "{:.5f}".format(dividends),
+                    "{:_}".format(emission),
+                    "{:.5f}".format(validator_trust),
+                    "*" if validator_permit else "",
                     str(last_update),
-                    bittensor.utils.networking.int_to_ip( nn.axon_info.ip) + ':' + str(nn.axon_info.port) if nn.axon_info.port != 0 else '[yellow]none[/yellow]',
-                    nn.hotkey
+                    bittensor.utils.networking.int_to_ip(nn.axon_info.ip)
+                    + ":"
+                    + str(nn.axon_info.port)
+                    if nn.axon_info.port != 0
+                    else "[yellow]none[/yellow]",
+                    nn.hotkey,
                 ]
 
                 total_rank += rank
                 total_trust += trust
                 total_consensus += consensus
                 total_incentive += incentive
                 total_dividends += dividends
@@ -173,60 +220,147 @@
                     total_stake += stake
                     total_neurons += 1
                 TABLE_DATA.append(row)
 
             # Add subnet header
             grid.add_row(f"Subnet: [bold white]{netuid}[/bold white]")
 
-            table = Table(show_footer=False, width=cli.config.get('width', None), pad_edge=False, box=None)
+            table = Table(
+                show_footer=False,
+                width=cli.config.get("width", None),
+                pad_edge=False,
+                box=None,
+            )
             if last_subnet:
-                table.add_column("[overline white]COLDKEY",  str(total_neurons), footer_style = "overline white", style='bold white')
-                table.add_column("[overline white]HOTKEY",  str(total_neurons), footer_style = "overline white", style='white')
+                table.add_column(
+                    "[overline white]COLDKEY",
+                    str(total_neurons),
+                    footer_style="overline white",
+                    style="bold white",
+                )
+                table.add_column(
+                    "[overline white]HOTKEY",
+                    str(total_neurons),
+                    footer_style="overline white",
+                    style="white",
+                )
             else:
                 # No footer for non-last subnet.
-                table.add_column("[overline white]COLDKEY", style='bold white')
-                table.add_column("[overline white]HOTKEY", style='white')
-            table.add_column("[overline white]UID",  str(total_neurons), footer_style = "overline white", style='yellow')
-            table.add_column("[overline white]ACTIVE", justify='right', style='green', no_wrap=True)
+                table.add_column("[overline white]COLDKEY", style="bold white")
+                table.add_column("[overline white]HOTKEY", style="white")
+            table.add_column(
+                "[overline white]UID",
+                str(total_neurons),
+                footer_style="overline white",
+                style="yellow",
+            )
+            table.add_column(
+                "[overline white]ACTIVE", justify="right", style="green", no_wrap=True
+            )
             if last_subnet:
-                table.add_column("[overline white]STAKE(\u03C4)", '\u03C4{:.5f}'.format(total_stake), footer_style = "overline white", justify='right', style='green', no_wrap=True)
+                table.add_column(
+                    "[overline white]STAKE(\u03C4)",
+                    "\u03C4{:.5f}".format(total_stake),
+                    footer_style="overline white",
+                    justify="right",
+                    style="green",
+                    no_wrap=True,
+                )
             else:
                 # No footer for non-last subnet.
-                table.add_column("[overline white]STAKE(\u03C4)", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]RANK", '{:.5f}'.format(total_rank), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]TRUST", '{:.5f}'.format(total_trust), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]CONSENSUS", '{:.5f}'.format(total_consensus), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]INCENTIVE", '{:.5f}'.format(total_incentive), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]DIVIDENDS", '{:.5f}'.format(total_dividends), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]EMISSION(\u03C1)", '\u03C1{:_}'.format(total_emission), footer_style = "overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]VTRUST", '{:.5f}'.format(total_validator_trust), footer_style="overline white", justify='right', style='green', no_wrap=True)
-            table.add_column("[overline white]VPERMIT", justify='right', no_wrap=True)
-            table.add_column("[overline white]UPDATED", justify='right', no_wrap=True)
-            table.add_column("[overline white]AXON", justify='left', style='dim blue', no_wrap=True)
-            table.add_column("[overline white]HOTKEY_SS58", style='dim blue', no_wrap=False)
+                table.add_column(
+                    "[overline white]STAKE(\u03C4)",
+                    justify="right",
+                    style="green",
+                    no_wrap=True,
+                )
+            table.add_column(
+                "[overline white]RANK",
+                "{:.5f}".format(total_rank),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]TRUST",
+                "{:.5f}".format(total_trust),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]CONSENSUS",
+                "{:.5f}".format(total_consensus),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]INCENTIVE",
+                "{:.5f}".format(total_incentive),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]DIVIDENDS",
+                "{:.5f}".format(total_dividends),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]EMISSION(\u03C1)",
+                "\u03C1{:_}".format(total_emission),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column(
+                "[overline white]VTRUST",
+                "{:.5f}".format(total_validator_trust),
+                footer_style="overline white",
+                justify="right",
+                style="green",
+                no_wrap=True,
+            )
+            table.add_column("[overline white]VPERMIT", justify="right", no_wrap=True)
+            table.add_column("[overline white]UPDATED", justify="right", no_wrap=True)
+            table.add_column(
+                "[overline white]AXON", justify="left", style="dim blue", no_wrap=True
+            )
+            table.add_column(
+                "[overline white]HOTKEY_SS58", style="dim blue", no_wrap=False
+            )
             table.show_footer = True
 
-            sort_by: Optional[str] = cli.config.get('sort_by', None)
-            sort_order: Optional[str] = cli.config.get('sort_order', None)
+            sort_by: Optional[str] = cli.config.get("sort_by", None)
+            sort_order: Optional[str] = cli.config.get("sort_order", None)
 
             if sort_by is not None and sort_by != "":
                 column_to_sort_by: int = 0
                 highest_matching_ratio: int = 0
-                sort_descending: bool = False # Default sort_order to ascending
+                sort_descending: bool = False  # Default sort_order to ascending
 
                 for index, column in zip(range(len(table.columns)), table.columns):
                     # Fuzzy match the column name. Default to the first column.
-                    column_name = column.header.lower().replace('[overline white]', '')
+                    column_name = column.header.lower().replace("[overline white]", "")
                     match_ratio = fuzz.ratio(sort_by.lower(), column_name)
                     # Finds the best matching column
-                    if  match_ratio > highest_matching_ratio:
+                    if match_ratio > highest_matching_ratio:
                         highest_matching_ratio = match_ratio
                         column_to_sort_by = index
 
-                if sort_order.lower() in { 'desc', 'descending', 'reverse'}:
+                if sort_order.lower() in {"desc", "descending", "reverse"}:
                     # Sort descending if the sort_order matches desc, descending, or reverse
                     sort_descending = True
 
                 def overview_sort_function(row):
                     data = row[column_to_sort_by]
                     # Try to convert to number if possible
                     try:
@@ -238,107 +372,144 @@
                 TABLE_DATA.sort(key=overview_sort_function, reverse=sort_descending)
 
             for row in TABLE_DATA:
                 table.add_row(*row)
 
             grid.add_row(table)
 
-
         console.clear()
 
-        caption = "[italic][dim][white]Wallet balance: [green]\u03C4" + str(total_balance.tao)
+        caption = "[italic][dim][white]Wallet balance: [green]\u03C4" + str(
+            total_balance.tao
+        )
         grid.add_row(Align(caption, vertical="middle", align="center"))
 
         # Print the entire table/grid
-        console.print(grid, width=cli.config.get('width', None))
+        console.print(grid, width=cli.config.get("width", None))
+
+    @staticmethod
+    def _get_neurons_for_netuid(
+        args_tuple: Tuple["bittensor.Config", int, List[str]]
+    ) -> Tuple[int, List[Tuple["bittensor.NeuronInfoLite", str]], Optional[str]]:
+        subtensor_config, netuid, hot_wallets = args_tuple
+
+        result: List[Tuple["bittensor.NeuronInfoLite", str]] = []
+
+        try:
+            subtensor = bittensor.subtensor(config=subtensor_config)
+
+            all_neurons: List["bittensor.NeuronInfoLite"] = subtensor.neurons_lite(
+                netuid=netuid
+            )
+            # Map the hotkeys to uids
+            hotkey_to_neurons = {n.hotkey: n.uid for n in all_neurons}
+            for hot_wallet_addr in hot_wallets:
+                uid = hotkey_to_neurons.get(hot_wallet_addr)
+                if uid is not None:
+                    nn = all_neurons[uid]
+                    result.append((nn, hot_wallet_addr))
+        except Exception as e:
+            return netuid, [], "Error: {}".format(e)
+
+        return netuid, result, None
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         overview_parser = parser.add_parser(
-            'overview',
-            help='''Show registered account overview.'''
+            "overview", help="""Show registered account overview."""
         )
         overview_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         overview_parser.add_argument(
-            '--all',
-            dest='all',
-            action='store_true',
-            help='''View overview for all wallets.''',
+            "--all",
+            dest="all",
+            action="store_true",
+            help="""View overview for all wallets.""",
             default=False,
         )
         overview_parser.add_argument(
-            '--width',
-            dest='width',
-            action='store',
+            "--width",
+            dest="width",
+            action="store",
             type=int,
-            help='''Set the output width of the overview. Defaults to automatic width from terminal.''',
+            help="""Set the output width of the overview. Defaults to automatic width from terminal.""",
             default=None,
         )
         overview_parser.add_argument(
-            '--sort_by',
-            '--wallet.sort_by',
-            dest='sort_by',
+            "--sort_by",
+            "--wallet.sort_by",
+            dest="sort_by",
             required=False,
-            action='store',
+            action="store",
             default="",
             type=str,
-            help='''Sort the hotkeys by the specified column title (e.g. name, uid, axon).'''
+            help="""Sort the hotkeys by the specified column title (e.g. name, uid, axon).""",
         )
         overview_parser.add_argument(
-            '--sort_order',
-            '--wallet.sort_order',
+            "--sort_order",
+            "--wallet.sort_order",
             dest="sort_order",
             required=False,
-            action='store',
+            action="store",
             default="ascending",
             type=str,
-            help='''Sort the hotkeys in the specified ordering. (ascending/asc or descending/desc/reverse)'''
+            help="""Sort the hotkeys in the specified ordering. (ascending/asc or descending/desc/reverse)""",
         )
         overview_parser.add_argument(
-            '--hotkeys',
-            '--exclude_hotkeys',
-            '--wallet.hotkeys',
-            '--wallet.exclude_hotkeys',
+            "--hotkeys",
+            "--exclude_hotkeys",
+            "--wallet.hotkeys",
+            "--wallet.exclude_hotkeys",
             required=False,
-            action='store',
+            action="store",
             default=[],
             type=str,
-            nargs='*',
-            help='''Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)'''
+            nargs="*",
+            help="""Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)""",
         )
         overview_parser.add_argument(
-            '--all_hotkeys',
-            '--wallet.all_hotkeys',
+            "--all_hotkeys",
+            "--wallet.all_hotkeys",
             required=False,
-            action='store_true',
+            action="store_true",
             default=False,
-            help='''To specify all hotkeys. Specifying hotkeys will exclude them from this all.'''
+            help="""To specify all hotkeys. Specifying hotkeys will exclude them from this all.""",
         )
         overview_parser.add_argument(
-            '--netuid',
-            dest='netuid',
+            "--netuid",
+            dest="netuid",
             type=int,
-            nargs='*',
-            help='''Set the netuid(s) to filter by.''',
+            nargs="*",
+            help="""Set the netuid(s) to filter by.""",
             default=[],
         )
-        overview_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
-        bittensor.wallet.add_args( overview_parser )
-        bittensor.subtensor.add_args( overview_parser )
+        overview_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
+        )
+        bittensor.wallet.add_args(overview_parser)
+        bittensor.subtensor.add_args(overview_parser)
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt and not config.get( 'all', d=None ):
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if (
+            not config.is_set("wallet.name")
+            and not config.no_prompt
+            and not config.get("all", d=None)
+        ):
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
         if config.netuid != []:
             if not isinstance(config.netuid, list):
                 config.netuid = [int(config.netuid)]
             else:
                 config.netuid = [int(netuid) for netuid in config.netuid]
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/register.py` & `bittensor-5.3.2/bittensor/_cli/commands/register.py`

 * *Files 20% similar despite different names*

```diff
@@ -19,154 +19,178 @@
 import argparse
 import bittensor
 from rich.prompt import Prompt, Confirm
 from .utils import check_netuid_set, check_for_cuda_reg_config
 
 console = bittensor.__console__
 
-class RegisterCommand:
 
+class RegisterCommand:
     @staticmethod
-    def run( cli ):
-        r""" Register neuron. """
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor = bittensor.subtensor( config = cli.config )
+    def run(cli):
+        r"""Register neuron."""
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor = bittensor.subtensor(config=cli.config)
 
         # Verify subnet exists
-        if not subtensor.subnet_exists( netuid = cli.config.netuid ):
-            bittensor.__console__.print(f"[red]Subnet {cli.config.netuid} does not exist[/red]")
+        if not subtensor.subnet_exists(netuid=cli.config.netuid):
+            bittensor.__console__.print(
+                f"[red]Subnet {cli.config.netuid} does not exist[/red]"
+            )
             sys.exit(1)
 
         subtensor.register(
-            wallet = wallet,
-            netuid = cli.config.netuid,
-            prompt = not cli.config.no_prompt,
-            TPB = cli.config.subtensor.register.cuda.get('TPB', None),
-            update_interval = cli.config.subtensor.register.get('update_interval', None),
-            num_processes = cli.config.subtensor.register.get('num_processes', None),
-            cuda = cli.config.subtensor.register.cuda.get('use_cuda', bittensor.defaults.subtensor.register.cuda.use_cuda),
-            dev_id = cli.config.subtensor.register.cuda.get('dev_id', None),
-            output_in_place = cli.config.subtensor.register.get('output_in_place', bittensor.defaults.subtensor.register.output_in_place),
-            log_verbose = cli.config.subtensor.register.get('verbose', bittensor.defaults.subtensor.register.verbose),
+            wallet=wallet,
+            netuid=cli.config.netuid,
+            prompt=not cli.config.no_prompt,
+            TPB=cli.config.subtensor.register.cuda.get("TPB", None),
+            update_interval=cli.config.subtensor.register.get("update_interval", None),
+            num_processes=cli.config.subtensor.register.get("num_processes", None),
+            cuda=cli.config.subtensor.register.cuda.get(
+                "use_cuda", bittensor.defaults.subtensor.register.cuda.use_cuda
+            ),
+            dev_id=cli.config.subtensor.register.cuda.get("dev_id", None),
+            output_in_place=cli.config.subtensor.register.get(
+                "output_in_place", bittensor.defaults.subtensor.register.output_in_place
+            ),
+            log_verbose=cli.config.subtensor.register.get(
+                "verbose", bittensor.defaults.subtensor.register.verbose
+            ),
         )
 
-
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         register_parser = parser.add_parser(
-            'register',
-            help='''Register a wallet to a network.'''
+            "register", help="""Register a wallet to a network."""
         )
         register_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         register_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         register_parser.add_argument(
-            '--netuid',
+            "--netuid",
             type=int,
-            help='netuid for subnet to serve this neuron on',
+            help="netuid for subnet to serve this neuron on",
             default=argparse.SUPPRESS,
         )
 
-        bittensor.wallet.add_args( register_parser )
-        bittensor.subtensor.add_args( register_parser )
+        bittensor.wallet.add_args(register_parser)
+        bittensor.subtensor.add_args(register_parser)
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        check_netuid_set( config, subtensor = bittensor.subtensor( config = config ) )
+    def check_config(config: "bittensor.Config"):
+        check_netuid_set(config, subtensor=bittensor.subtensor(config=config))
 
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
         if not config.no_prompt:
             check_for_cuda_reg_config(config)
 
-class RecycleRegisterCommand:
 
+class RecycleRegisterCommand:
     @staticmethod
-    def run( cli ):
-        r""" Register neuron by recycling some TAO. """
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor = bittensor.subtensor( config = cli.config )
+    def run(cli):
+        r"""Register neuron by recycling some TAO."""
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor = bittensor.subtensor(config=cli.config)
 
         # Verify subnet exists
-        if not subtensor.subnet_exists( netuid = cli.config.netuid ):
-            bittensor.__console__.print(f"[red]Subnet {cli.config.netuid} does not exist[/red]")
+        if not subtensor.subnet_exists(netuid=cli.config.netuid):
+            bittensor.__console__.print(
+                f"[red]Subnet {cli.config.netuid} does not exist[/red]"
+            )
             sys.exit(1)
 
         # Check current recycle amount
-        current_recycle = subtensor.burn( netuid = cli.config.netuid )
-        balance = subtensor.get_balance( address = wallet.coldkeypub.ss58_address )
+        current_recycle = subtensor.burn(netuid=cli.config.netuid)
+        balance = subtensor.get_balance(address=wallet.coldkeypub.ss58_address)
 
         # Check balance is sufficient
         if balance < current_recycle:
-            bittensor.__console__.print(f"[red]Insufficient balance {balance} to register neuron. Current recycle is {current_recycle} TAO[/red]")
+            bittensor.__console__.print(
+                f"[red]Insufficient balance {balance} to register neuron. Current recycle is {current_recycle} TAO[/red]"
+            )
             sys.exit(1)
 
         if not cli.config.no_prompt:
-            if Confirm.ask(f"Your balance is: [bold green]{balance}[/bold green]\nThe cost to register by recycle is [bold red]{current_recycle}[/bold red]\nDo you want to continue?", default = False) == False:
+            if (
+                Confirm.ask(
+                    f"Your balance is: [bold green]{balance}[/bold green]\nThe cost to register by recycle is [bold red]{current_recycle}[/bold red]\nDo you want to continue?",
+                    default=False,
+                )
+                == False
+            ):
                 sys.exit(1)
 
         subtensor.burned_register(
-            wallet = wallet,
-            netuid = cli.config.netuid,
-            prompt = not cli.config.no_prompt
+            wallet=wallet, netuid=cli.config.netuid, prompt=not cli.config.no_prompt
         )
 
-
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         recycle_register_parser = parser.add_parser(
-            'recycle_register',
-            help='''Register a wallet to a network.'''
+            "recycle_register", help="""Register a wallet to a network."""
         )
         recycle_register_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         recycle_register_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         recycle_register_parser.add_argument(
-            '--netuid',
+            "--netuid",
             type=int,
-            help='netuid for subnet to serve this neuron on',
+            help="netuid for subnet to serve this neuron on",
             default=argparse.SUPPRESS,
         )
 
-        bittensor.wallet.add_args( recycle_register_parser )
-        bittensor.subtensor.add_args( recycle_register_parser )
+        bittensor.wallet.add_args(recycle_register_parser)
+        bittensor.subtensor.add_args(recycle_register_parser)
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('subtensor.network') and not config.no_prompt:
-            config.subtensor.network = Prompt.ask("Enter subtensor network", choices=bittensor.__networks__, default = bittensor.defaults.subtensor.network)
-
-        check_netuid_set( config, subtensor = bittensor.subtensor( config = config ) )
-
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("subtensor.network") and not config.no_prompt:
+            config.subtensor.network = Prompt.ask(
+                "Enter subtensor network",
+                choices=bittensor.__networks__,
+                default=bittensor.defaults.subtensor.network,
+            )
+
+        check_netuid_set(config, subtensor=bittensor.subtensor(config=config))
+
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/senate.py` & `bittensor-5.3.2/bittensor/_cli/commands/senate.py`

 * *Files 9% similar despite different names*

```diff
@@ -21,441 +21,528 @@
 from rich.prompt import Prompt, Confirm
 from rich.table import Table
 from typing import List, Union, Optional, Dict, Tuple
 from .utils import get_delegates_details, DelegatesDetails
 
 console = bittensor.__console__
 
-class SenateCommand:
 
+class SenateCommand:
     @staticmethod
-    def run( cli ):
-        r""" View Bittensor's governance protocol proposals
-        """
+    def run(cli):
+        r"""View Bittensor's governance protocol proposals"""
         config = cli.config.copy()
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
-        console.print(":satellite: Syncing with chain: [white]{}[/white] ...".format(cli.config.subtensor.network))
+        console.print(
+            ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+                cli.config.subtensor.network
+            )
+        )
 
         senate_members = subtensor.get_senate_members()
-        delegate_info: Optional[Dict[str, DelegatesDetails]] = get_delegates_details(url = bittensor.__delegates_details_url__)
+        delegate_info: Optional[Dict[str, DelegatesDetails]] = get_delegates_details(
+            url=bittensor.__delegates_details_url__
+        )
 
         table = Table(show_footer=False)
-        table.title = (
-            "[white]Senate"
+        table.title = "[white]Senate"
+        table.add_column(
+            "[overline white]NAME",
+            footer_style="overline white",
+            style="rgb(50,163,219)",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]ADDRESS",
+            footer_style="overline white",
+            style="yellow",
+            no_wrap=True,
         )
-        table.add_column("[overline white]NAME", footer_style = "overline white", style="rgb(50,163,219)", no_wrap=True)
-        table.add_column("[overline white]ADDRESS", footer_style = "overline white", style='yellow', no_wrap=True)
         table.show_footer = True
 
         for ss58_address in senate_members:
             table.add_row(
-                delegate_info[ss58_address].name if ss58_address in delegate_info else "",
-                ss58_address
+                delegate_info[ss58_address].name
+                if ss58_address in delegate_info
+                else "",
+                ss58_address,
             )
 
         table.box = None
         table.pad_edge = False
         table.width = None
         console.print(table)
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
+    def check_config(cls, config: "bittensor.Config"):
         None
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         senate_parser = parser.add_parser(
-            'senate',
-            help='''View senate and it's members'''
+            "senate", help="""View senate and it's members"""
         )
         senate_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         senate_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        bittensor.wallet.add_args( senate_parser )
-        bittensor.subtensor.add_args( senate_parser )
+        bittensor.wallet.add_args(senate_parser)
+        bittensor.subtensor.add_args(senate_parser)
+
 
-def format_call_data(call_data: 'bittensor.ProposalCallData') -> str:
+def format_call_data(call_data: "bittensor.ProposalCallData") -> str:
     human_call_data = list()
 
     for arg in call_data["call_args"]:
         arg_value = arg["value"]
 
         # If this argument is a nested call
-        func_args = format_call_data({
-            "call_function": arg_value["call_function"],
-            "call_args": arg_value["call_args"]
-        }) if isinstance(arg_value, dict) and "call_function" in arg_value else str(arg_value)
+        func_args = (
+            format_call_data(
+                {
+                    "call_function": arg_value["call_function"],
+                    "call_args": arg_value["call_args"],
+                }
+            )
+            if isinstance(arg_value, dict) and "call_function" in arg_value
+            else str(arg_value)
+        )
 
         human_call_data.append("{}: {}".format(arg["name"], func_args))
 
     return "{}({})".format(call_data["call_function"], ", ".join(human_call_data))
 
-def display_votes(vote_data: 'bittensor.ProposalVoteData', delegate_info: 'bittensor.DelegateInfo') -> str:
+
+def display_votes(
+    vote_data: "bittensor.ProposalVoteData", delegate_info: "bittensor.DelegateInfo"
+) -> str:
     vote_list = list()
 
     for address in vote_data["ayes"]:
-        vote_list.append("{}: {}".format(delegate_info[address].name if address in delegate_info else address, "[bold green]Aye[/bold green]"))
+        vote_list.append(
+            "{}: {}".format(
+                delegate_info[address].name if address in delegate_info else address,
+                "[bold green]Aye[/bold green]",
+            )
+        )
 
     for address in vote_data["nays"]:
-        vote_list.append("{}: {}".format(delegate_info[address].name if address in delegate_info else address, "[bold red]Nay[/bold red]"))
+        vote_list.append(
+            "{}: {}".format(
+                delegate_info[address].name if address in delegate_info else address,
+                "[bold red]Nay[/bold red]",
+            )
+        )
 
     return "\n".join(vote_list)
 
-class ProposalsCommand:
 
+class ProposalsCommand:
     @staticmethod
-    def run( cli ):
-        r""" View Bittensor's governance protocol proposals
-        """
+    def run(cli):
+        r"""View Bittensor's governance protocol proposals"""
         config = cli.config.copy()
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
-        console.print(":satellite: Syncing with chain: [white]{}[/white] ...".format(cli.config.subtensor.network))
+        console.print(
+            ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+                cli.config.subtensor.network
+            )
+        )
 
         senate_members = subtensor.get_senate_members()
-        proposals = subtensor.get_proposals()      
+        proposals = subtensor.get_proposals()
 
-        registered_delegate_info: Optional[Dict[str, DelegatesDetails]] = get_delegates_details(url = bittensor.__delegates_details_url__)
+        registered_delegate_info: Optional[
+            Dict[str, DelegatesDetails]
+        ] = get_delegates_details(url=bittensor.__delegates_details_url__)
 
         table = Table(show_footer=False)
         table.title = (
-            "[white]Proposals\t\tActive Proposals: {}\t\tSenate Size: {}".format(len(proposals), len(senate_members))
+            "[white]Proposals\t\tActive Proposals: {}\t\tSenate Size: {}".format(
+                len(proposals), len(senate_members)
+            )
+        )
+        table.add_column(
+            "[overline white]HASH",
+            footer_style="overline white",
+            style="yellow",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]THRESHOLD", footer_style="overline white", style="white"
+        )
+        table.add_column(
+            "[overline white]AYES", footer_style="overline white", style="green"
+        )
+        table.add_column(
+            "[overline white]NAYS", footer_style="overline white", style="red"
+        )
+        table.add_column(
+            "[overline white]VOTES",
+            footer_style="overline white",
+            style="rgb(50,163,219)",
+        )
+        table.add_column(
+            "[overline white]END", footer_style="overline white", style="blue"
+        )
+        table.add_column(
+            "[overline white]CALLDATA", footer_style="overline white", style="white"
         )
-        table.add_column("[overline white]HASH", footer_style = "overline white", style='yellow', no_wrap=True)
-        table.add_column("[overline white]THRESHOLD", footer_style = "overline white", style='white')
-        table.add_column("[overline white]AYES", footer_style = "overline white", style='green')
-        table.add_column("[overline white]NAYS", footer_style = "overline white", style='red')
-        table.add_column("[overline white]VOTES", footer_style = "overline white", style='rgb(50,163,219)')
-        table.add_column("[overline white]END", footer_style = "overline white", style='blue')
-        table.add_column("[overline white]CALLDATA", footer_style = "overline white", style='white')
         table.show_footer = True
 
         for hash in proposals:
             call_data, vote_data = proposals[hash]
 
             table.add_row(
                 hash,
                 str(vote_data["threshold"]),
                 str(len(vote_data["ayes"])),
                 str(len(vote_data["nays"])),
                 display_votes(vote_data, registered_delegate_info),
                 str(vote_data["end"]),
-                format_call_data(call_data)
+                format_call_data(call_data),
             )
 
         table.box = None
         table.pad_edge = False
         table.width = None
         console.print(table)
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
+    def check_config(cls, config: "bittensor.Config"):
         None
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         proposals_parser = parser.add_parser(
-            'proposals',
-            help='''View active triumvirate proposals and their status'''
+            "proposals", help="""View active triumvirate proposals and their status"""
         )
         proposals_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         proposals_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        bittensor.wallet.add_args( proposals_parser )
-        bittensor.subtensor.add_args( proposals_parser )
+        bittensor.wallet.add_args(proposals_parser)
+        bittensor.subtensor.add_args(proposals_parser)
 
-class ShowVotesCommand:
 
+class ShowVotesCommand:
     @staticmethod
-    def run( cli ):
-        r""" View Bittensor's governance protocol proposals active votes
-        """
+    def run(cli):
+        r"""View Bittensor's governance protocol proposals active votes"""
         config = cli.config.copy()
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
-        console.print(":satellite: Syncing with chain: [white]{}[/white] ...".format(cli.config.subtensor.network))
+        console.print(
+            ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+                cli.config.subtensor.network
+            )
+        )
 
         proposal_hash = cli.config.proposal_hash
         if len(proposal_hash) == 0:
-            console.print('Aborting: Proposal hash not specified. View all proposals with the "proposals" command.')
+            console.print(
+                'Aborting: Proposal hash not specified. View all proposals with the "proposals" command.'
+            )
             return
 
-        proposal_vote_data = subtensor.get_vote_data( proposal_hash )
+        proposal_vote_data = subtensor.get_vote_data(proposal_hash)
         if proposal_vote_data == None:
             console.print(":cross_mark: [red]Failed[/red]: Proposal not found.")
             return
-        
-        registered_delegate_info: Optional[Dict[str, DelegatesDetails]] = get_delegates_details(url = bittensor.__delegates_details_url__)
+
+        registered_delegate_info: Optional[
+            Dict[str, DelegatesDetails]
+        ] = get_delegates_details(url=bittensor.__delegates_details_url__)
 
         table = Table(show_footer=False)
-        table.title = (
-            "[white]Votes for Proposal {}".format(proposal_hash)
+        table.title = "[white]Votes for Proposal {}".format(proposal_hash)
+        table.add_column(
+            "[overline white]ADDRESS",
+            footer_style="overline white",
+            style="yellow",
+            no_wrap=True,
+        )
+        table.add_column(
+            "[overline white]VOTE", footer_style="overline white", style="white"
         )
-        table.add_column("[overline white]ADDRESS", footer_style = "overline white", style='yellow', no_wrap=True)
-        table.add_column("[overline white]VOTE", footer_style = "overline white", style='white')
         table.show_footer = True
 
         votes = display_votes(proposal_vote_data, registered_delegate_info).split("\n")
         for vote in votes:
-            split_vote_data = vote.split(": ") # Nasty, but will work.
-            table.add_row(
-                split_vote_data[0],
-                split_vote_data[1]
-            )
+            split_vote_data = vote.split(": ")  # Nasty, but will work.
+            table.add_row(split_vote_data[0], split_vote_data[1])
 
         table.box = None
         table.pad_edge = False
         table.min_width = 64
         console.print(table)
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
+    def check_config(cls, config: "bittensor.Config"):
         if config.proposal_hash == "" and not config.no_prompt:
             proposal_hash = Prompt.ask("Enter proposal hash")
             config.proposal_hash = str(proposal_hash)
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         show_votes_parser = parser.add_parser(
-            'proposal_votes',
-            help='''View an active proposal's votes by address.'''
+            "proposal_votes", help="""View an active proposal's votes by address."""
         )
         show_votes_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         show_votes_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         show_votes_parser.add_argument(
-            '--proposal',
-            dest='proposal_hash',
+            "--proposal",
+            dest="proposal_hash",
             type=str,
-            nargs='?',
-            help='''Set the proposal to show votes for.''',
-            default=""
+            nargs="?",
+            help="""Set the proposal to show votes for.""",
+            default="",
         )
-        bittensor.wallet.add_args( show_votes_parser )
-        bittensor.subtensor.add_args( show_votes_parser )
+        bittensor.wallet.add_args(show_votes_parser)
+        bittensor.subtensor.add_args(show_votes_parser)
 
-class SenateRegisterCommand:
 
+class SenateRegisterCommand:
     @staticmethod
-    def run( cli ):
-        r""" Register to participate in Bittensor's governance protocol proposals
-        """
+    def run(cli):
+        r"""Register to participate in Bittensor's governance protocol proposals"""
         config = cli.config.copy()
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
         # Unlock the wallet.
         wallet.hotkey
         wallet.coldkey
 
         # Check if the hotkey is a delegate.
-        if not subtensor.is_hotkey_delegate( wallet.hotkey.ss58_address ):
-            console.print('Aborting: Hotkey {} isn\'t a delegate.'.format(wallet.hotkey.ss58_address))
+        if not subtensor.is_hotkey_delegate(wallet.hotkey.ss58_address):
+            console.print(
+                "Aborting: Hotkey {} isn't a delegate.".format(
+                    wallet.hotkey.ss58_address
+                )
+            )
             return
-        
-        if subtensor.is_senate_member( hotkey_ss58=wallet.hotkey.ss58_address ):
-            console.print('Aborting: Hotkey {} is already a senate member.'.format(wallet.hotkey.ss58_address))
+
+        if subtensor.is_senate_member(hotkey_ss58=wallet.hotkey.ss58_address):
+            console.print(
+                "Aborting: Hotkey {} is already a senate member.".format(
+                    wallet.hotkey.ss58_address
+                )
+            )
             return
-        
-        subtensor.register_senate(
-            wallet = wallet,
-            prompt = not cli.config.no_prompt
-        )
+
+        subtensor.register_senate(wallet=wallet, prompt=not cli.config.no_prompt)
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(cls, config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         senate_register_parser = parser.add_parser(
-            'senate_register',
-            help='''Register as a senate member to participate in proposals'''
+            "senate_register",
+            help="""Register as a senate member to participate in proposals""",
         )
         senate_register_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         senate_register_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        bittensor.wallet.add_args( senate_register_parser )
-        bittensor.subtensor.add_args( senate_register_parser )
+        bittensor.wallet.add_args(senate_register_parser)
+        bittensor.subtensor.add_args(senate_register_parser)
 
-class SenateLeaveCommand:
 
+class SenateLeaveCommand:
     @staticmethod
-    def run( cli ):
-        r""" Discard membership in Bittensor's governance protocol proposals
-        """
+    def run(cli):
+        r"""Discard membership in Bittensor's governance protocol proposals"""
         config = cli.config.copy()
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
         # Unlock the wallet.
         wallet.hotkey
         wallet.coldkey
-        
-        if not subtensor.is_senate_member( hotkey_ss58=wallet.hotkey.ss58_address ):
-            console.print('Aborting: Hotkey {} isn\'t a senate member.'.format(wallet.hotkey.ss58_address))
+
+        if not subtensor.is_senate_member(hotkey_ss58=wallet.hotkey.ss58_address):
+            console.print(
+                "Aborting: Hotkey {} isn't a senate member.".format(
+                    wallet.hotkey.ss58_address
+                )
+            )
             return
-        
-        subtensor.leave_senate(
-            wallet = wallet,
-            prompt = not cli.config.no_prompt
-        )
+
+        subtensor.leave_senate(wallet=wallet, prompt=not cli.config.no_prompt)
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(cls, config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         senate_leave_parser = parser.add_parser(
-            'senate_leave',
-            help='''Discard senate membership in the governance protocol'''
+            "senate_leave",
+            help="""Discard senate membership in the governance protocol""",
         )
         senate_leave_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         senate_leave_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
-        bittensor.wallet.add_args( senate_leave_parser )
-        bittensor.subtensor.add_args( senate_leave_parser )
+        bittensor.wallet.add_args(senate_leave_parser)
+        bittensor.subtensor.add_args(senate_leave_parser)
 
-class VoteCommand:
 
+class VoteCommand:
     @staticmethod
-    def run( cli ):
-        r""" Vote in Bittensor's governance protocol proposals
-        """
+    def run(cli):
+        r"""Vote in Bittensor's governance protocol proposals"""
         config = cli.config.copy()
-        wallet = bittensor.wallet( config = cli.config )
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        wallet = bittensor.wallet(config=cli.config)
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
         proposal_hash = cli.config.proposal_hash
         if len(proposal_hash) == 0:
-            console.print('Aborting: Proposal hash not specified. View all proposals with the "proposals" command.')
+            console.print(
+                'Aborting: Proposal hash not specified. View all proposals with the "proposals" command.'
+            )
             return
-        
-        if not subtensor.is_senate_member( hotkey_ss58=wallet.hotkey.ss58_address ):
-            console.print('Aborting: Hotkey {} isn\'t a senate member.'.format(wallet.hotkey.ss58_address))
+
+        if not subtensor.is_senate_member(hotkey_ss58=wallet.hotkey.ss58_address):
+            console.print(
+                "Aborting: Hotkey {} isn't a senate member.".format(
+                    wallet.hotkey.ss58_address
+                )
+            )
             return
 
         # Unlock the wallet.
         wallet.hotkey
         wallet.coldkey
 
-        vote_data = subtensor.get_vote_data( proposal_hash )
+        vote_data = subtensor.get_vote_data(proposal_hash)
         if vote_data == None:
             console.print(":cross_mark: [red]Failed[/red]: Proposal not found.")
             return
 
         vote = Confirm.ask("Desired vote for proposal")
         subtensor.vote_senate(
-            wallet = wallet,
-            proposal_hash = proposal_hash,
-            proposal_idx = vote_data["index"],
-            vote = vote,
-            prompt = not cli.config.no_prompt
+            wallet=wallet,
+            proposal_hash=proposal_hash,
+            proposal_idx=vote_data["index"],
+            vote=vote,
+            prompt=not cli.config.no_prompt,
         )
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(cls, config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
         if config.proposal_hash == "" and not config.no_prompt:
             proposal_hash = Prompt.ask("Enter proposal hash")
             config.proposal_hash = str(proposal_hash)
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         vote_parser = parser.add_parser(
-            'senate_vote',
-            help='''Vote on an active proposal by hash.'''
+            "senate_vote", help="""Vote on an active proposal by hash."""
         )
         vote_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         vote_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         vote_parser.add_argument(
-            '--proposal',
-            dest='proposal_hash',
+            "--proposal",
+            dest="proposal_hash",
             type=str,
-            nargs='?',
-            help='''Set the proposal to show votes for.''',
-            default=""
+            nargs="?",
+            help="""Set the proposal to show votes for.""",
+            default="",
         )
-        bittensor.wallet.add_args( vote_parser )
-        bittensor.subtensor.add_args( vote_parser )
+        bittensor.wallet.add_args(vote_parser)
+        bittensor.subtensor.add_args(vote_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/stake.py` & `bittensor-5.3.2/bittensor/_cli/commands/stake.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,207 +19,248 @@
 import argparse
 import bittensor
 from tqdm import tqdm
 from rich.prompt import Confirm, Prompt
 from bittensor.utils.balance import Balance
 from typing import List, Union, Optional, Dict, Tuple
 from .utils import get_hotkey_wallets_for_wallet
+
 console = bittensor.__console__
 
-class StakeCommand:
 
+class StakeCommand:
     @staticmethod
-    def run( cli ):
-        r""" Stake token of amount to hotkey(s).
-        """
+    def run(cli):
+        r"""Stake token of amount to hotkey(s)."""
         config = cli.config.copy()
-        wallet = bittensor.wallet( config = config )
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = config )
+        wallet = bittensor.wallet(config=config)
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=config)
 
         # Get the hotkey_names (if any) and the hotkey_ss58s.
         hotkeys_to_stake_to: List[Tuple[Optional[str], str]] = []
-        if config.get('all_hotkeys'):
+        if config.get("all_hotkeys"):
             # Stake to all hotkeys.
-            all_hotkeys: List[bittensor.wallet] = get_hotkey_wallets_for_wallet( wallet = wallet )
+            all_hotkeys: List[bittensor.wallet] = get_hotkey_wallets_for_wallet(
+                wallet=wallet
+            )
             # Get the hotkeys to exclude. (d)efault to no exclusions.
-            hotkeys_to_exclude: List[str] = cli.config.get('hotkeys', d=[])
+            hotkeys_to_exclude: List[str] = cli.config.get("hotkeys", d=[])
             # Exclude hotkeys that are specified.
             hotkeys_to_stake_to = [
-                (wallet.hotkey_str, wallet.hotkey.ss58_address) for wallet in all_hotkeys
-                    if wallet.hotkey_str not in hotkeys_to_exclude
-            ] # definitely wallets
+                (wallet.hotkey_str, wallet.hotkey.ss58_address)
+                for wallet in all_hotkeys
+                if wallet.hotkey_str not in hotkeys_to_exclude
+            ]  # definitely wallets
 
-        elif config.get('hotkeys'):
+        elif config.get("hotkeys"):
             # Stake to specific hotkeys.
-            for hotkey_ss58_or_hotkey_name in config.get('hotkeys'):
-                if bittensor.utils.is_valid_ss58_address( hotkey_ss58_or_hotkey_name ):
+            for hotkey_ss58_or_hotkey_name in config.get("hotkeys"):
+                if bittensor.utils.is_valid_ss58_address(hotkey_ss58_or_hotkey_name):
                     # If the hotkey is a valid ss58 address, we add it to the list.
-                    hotkeys_to_stake_to.append( (None, hotkey_ss58_or_hotkey_name ) )
+                    hotkeys_to_stake_to.append((None, hotkey_ss58_or_hotkey_name))
                 else:
                     # If the hotkey is not a valid ss58 address, we assume it is a hotkey name.
                     #  We then get the hotkey from the wallet and add it to the list.
-                    wallet_ = bittensor.wallet( config = config, hotkey = hotkey_ss58_or_hotkey_name )
-                    hotkeys_to_stake_to.append( (wallet_.hotkey_str, wallet_.hotkey.ss58_address ) )
-        elif config.wallet.get('hotkey'):
+                    wallet_ = bittensor.wallet(
+                        config=config, hotkey=hotkey_ss58_or_hotkey_name
+                    )
+                    hotkeys_to_stake_to.append(
+                        (wallet_.hotkey_str, wallet_.hotkey.ss58_address)
+                    )
+        elif config.wallet.get("hotkey"):
             # Only config.wallet.hotkey is specified.
             #  so we stake to that single hotkey.
-            hotkey_ss58_or_name = config.wallet.get('hotkey')
-            if bittensor.utils.is_valid_ss58_address( hotkey_ss58_or_name ):
-                hotkeys_to_stake_to = [ (None, hotkey_ss58_or_name) ]
+            hotkey_ss58_or_name = config.wallet.get("hotkey")
+            if bittensor.utils.is_valid_ss58_address(hotkey_ss58_or_name):
+                hotkeys_to_stake_to = [(None, hotkey_ss58_or_name)]
             else:
                 # Hotkey is not a valid ss58 address, so we assume it is a hotkey name.
-                wallet_ = bittensor.wallet( config = config, hotkey = hotkey_ss58_or_name )
-                hotkeys_to_stake_to = [ (wallet_.hotkey_str, wallet_.hotkey.ss58_address ) ]
+                wallet_ = bittensor.wallet(config=config, hotkey=hotkey_ss58_or_name)
+                hotkeys_to_stake_to = [
+                    (wallet_.hotkey_str, wallet_.hotkey.ss58_address)
+                ]
         else:
             # Only config.wallet.hotkey is specified.
             #  so we stake to that single hotkey.
             assert config.wallet.hotkey is not None
-            hotkeys_to_stake_to = [ (None, bittensor.wallet( config = config ).hotkey.ss58_address) ]
+            hotkeys_to_stake_to = [
+                (None, bittensor.wallet(config=config).hotkey.ss58_address)
+            ]
 
         # Get coldkey balance
-        wallet_balance: Balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
+        wallet_balance: Balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
         final_hotkeys: List[Tuple[str, str]] = []
         final_amounts: List[Union[float, Balance]] = []
         for hotkey in tqdm(hotkeys_to_stake_to):
-            hotkey: Tuple[Optional[str], str] # (hotkey_name (or None), hotkey_ss58)
-            if not subtensor.is_hotkey_registered_any( hotkey_ss58 = hotkey[1] ):
+            hotkey: Tuple[Optional[str], str]  # (hotkey_name (or None), hotkey_ss58)
+            if not subtensor.is_hotkey_registered_any(hotkey_ss58=hotkey[1]):
                 # Hotkey is not registered.
-                if (len(hotkeys_to_stake_to) == 1):
+                if len(hotkeys_to_stake_to) == 1:
                     # Only one hotkey, error
-                    bittensor.__console__.print(f"[red]Hotkey [bold]{hotkey[1]}[/bold] is not registered. Aborting.[/red]")
+                    bittensor.__console__.print(
+                        f"[red]Hotkey [bold]{hotkey[1]}[/bold] is not registered. Aborting.[/red]"
+                    )
                     return None
                 else:
                     # Otherwise, print warning and skip
-                    bittensor.__console__.print(f"[yellow]Hotkey [bold]{hotkey[1]}[/bold] is not registered. Skipping.[/yellow]")
+                    bittensor.__console__.print(
+                        f"[yellow]Hotkey [bold]{hotkey[1]}[/bold] is not registered. Skipping.[/yellow]"
+                    )
                     continue
 
-
-            stake_amount_tao: float = config.get('amount')
-            if config.get('max_stake'):
+            stake_amount_tao: float = config.get("amount")
+            if config.get("max_stake"):
                 # Get the current stake of the hotkey from this coldkey.
-                hotkey_stake: Balance = subtensor.get_stake_for_coldkey_and_hotkey( hotkey_ss58 = hotkey[1], coldkey_ss58 = wallet.coldkeypub.ss58_address )
-                stake_amount_tao: float = config.get('max_stake') - hotkey_stake.tao
+                hotkey_stake: Balance = subtensor.get_stake_for_coldkey_and_hotkey(
+                    hotkey_ss58=hotkey[1], coldkey_ss58=wallet.coldkeypub.ss58_address
+                )
+                stake_amount_tao: float = config.get("max_stake") - hotkey_stake.tao
 
                 # If the max_stake is greater than the current wallet balance, stake the entire balance.
                 stake_amount_tao: float = min(stake_amount_tao, wallet_balance.tao)
-                if stake_amount_tao <= 0.00001: # Threshold because of fees, might create a loop otherwise
+                if (
+                    stake_amount_tao <= 0.00001
+                ):  # Threshold because of fees, might create a loop otherwise
                     # Skip hotkey if max_stake is less than current stake.
                     continue
                 wallet_balance = Balance.from_tao(wallet_balance.tao - stake_amount_tao)
 
                 if wallet_balance.tao < 0:
                     # No more balance to stake.
                     break
 
             final_amounts.append(stake_amount_tao)
-            final_hotkeys.append(hotkey) # add both the name and the ss58 address.
+            final_hotkeys.append(hotkey)  # add both the name and the ss58 address.
 
         if len(final_hotkeys) == 0:
             # No hotkeys to stake to.
-            bittensor.__console__.print("Not enough balance to stake to any hotkeys or max_stake is less than current stake.")
+            bittensor.__console__.print(
+                "Not enough balance to stake to any hotkeys or max_stake is less than current stake."
+            )
             return None
 
         # Ask to stake
         if not config.no_prompt:
-            if not Confirm.ask(f"Do you want to stake to the following keys from {wallet.name}:\n" + \
-                    "".join([
-                        f"    [bold white]- {hotkey[0] + ':' if hotkey[0] else ''}{hotkey[1]}: {f'{amount} {bittensor.__tao_symbol__}' if amount else 'All'}[/bold white]\n" for hotkey, amount in zip(final_hotkeys, final_amounts)
-                    ])
-                ):
+            if not Confirm.ask(
+                f"Do you want to stake to the following keys from {wallet.name}:\n"
+                + "".join(
+                    [
+                        f"    [bold white]- {hotkey[0] + ':' if hotkey[0] else ''}{hotkey[1]}: {f'{amount} {bittensor.__tao_symbol__}' if amount else 'All'}[/bold white]\n"
+                        for hotkey, amount in zip(final_hotkeys, final_amounts)
+                    ]
+                )
+            ):
                 return None
 
         if len(final_hotkeys) == 1:
             # do regular stake
-            return subtensor.add_stake( wallet=wallet, hotkey_ss58 = final_hotkeys[0][1], amount = None if config.get('stake_all') else final_amounts[0], wait_for_inclusion = True, prompt = not config.no_prompt )
-
-        subtensor.add_stake_multiple( wallet = wallet, hotkey_ss58s=[hotkey_ss58 for _, hotkey_ss58 in final_hotkeys], amounts =  None if config.get('stake_all') else final_amounts, wait_for_inclusion = True, prompt = False )
-
+            return subtensor.add_stake(
+                wallet=wallet,
+                hotkey_ss58=final_hotkeys[0][1],
+                amount=None if config.get("stake_all") else final_amounts[0],
+                wait_for_inclusion=True,
+                prompt=not config.no_prompt,
+            )
+
+        subtensor.add_stake_multiple(
+            wallet=wallet,
+            hotkey_ss58s=[hotkey_ss58 for _, hotkey_ss58 in final_hotkeys],
+            amounts=None if config.get("stake_all") else final_amounts,
+            wait_for_inclusion=True,
+            prompt=False,
+        )
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(cls, config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt and not config.wallet.get('all_hotkeys') and not config.wallet.get('hotkeys'):
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if (
+            not config.is_set("wallet.hotkey")
+            and not config.no_prompt
+            and not config.wallet.get("all_hotkeys")
+            and not config.wallet.get("hotkeys")
+        ):
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
         # Get amount.
-        if not config.get('amount') and not config.get('stake_all') and not config.get('max_stake'):
-            if not Confirm.ask("Stake all Tao from account: [bold]'{}'[/bold]?".format(config.wallet.get('name', bittensor.defaults.wallet.name))):
+        if (
+            not config.get("amount")
+            and not config.get("stake_all")
+            and not config.get("max_stake")
+        ):
+            if not Confirm.ask(
+                "Stake all Tao from account: [bold]'{}'[/bold]?".format(
+                    config.wallet.get("name", bittensor.defaults.wallet.name)
+                )
+            ):
                 amount = Prompt.ask("Enter Tao amount to stake")
                 try:
                     config.amount = float(amount)
                 except ValueError:
-                    console.print(":cross_mark:[red]Invalid Tao amount[/red] [bold white]{}[/bold white]".format(amount))
+                    console.print(
+                        ":cross_mark:[red]Invalid Tao amount[/red] [bold white]{}[/bold white]".format(
+                            amount
+                        )
+                    )
                     sys.exit()
             else:
                 config.stake_all = True
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         stake_parser = parser.add_parser(
-            'stake',
-            help='''Stake to your hotkey accounts.'''
+            "stake", help="""Stake to your hotkey accounts."""
         )
         stake_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
-        )
-        stake_parser.add_argument(
-            '--all',
-            dest="stake_all",
-            action='store_true'
-        )
-        stake_parser.add_argument(
-            '--uid',
-            dest="uid",
-            type=int,
-            required=False
-        )
-        stake_parser.add_argument(
-            '--amount',
-            dest="amount",
-            type=float,
-            required=False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
+        stake_parser.add_argument("--all", dest="stake_all", action="store_true")
+        stake_parser.add_argument("--uid", dest="uid", type=int, required=False)
+        stake_parser.add_argument("--amount", dest="amount", type=float, required=False)
         stake_parser.add_argument(
-            '--max_stake',
+            "--max_stake",
             dest="max_stake",
             type=float,
             required=False,
-            action='store',
+            action="store",
             default=None,
-            help='''Specify the maximum amount of Tao to have staked in each hotkey.'''
+            help="""Specify the maximum amount of Tao to have staked in each hotkey.""",
         )
         stake_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         stake_parser.add_argument(
-            '--hotkeys',
-            '--exclude_hotkeys',
-            '--wallet.hotkeys',
-            '--wallet.exclude_hotkeys',
+            "--hotkeys",
+            "--exclude_hotkeys",
+            "--wallet.hotkeys",
+            "--wallet.exclude_hotkeys",
             required=False,
-            action='store',
+            action="store",
             default=[],
             type=str,
-            nargs='*',
-            help='''Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)'''
+            nargs="*",
+            help="""Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)""",
         )
         stake_parser.add_argument(
-            '--all_hotkeys',
-            '--wallet.all_hotkeys',
+            "--all_hotkeys",
+            "--wallet.all_hotkeys",
             required=False,
-            action='store_true',
+            action="store_true",
             default=False,
-            help='''To specify all hotkeys. Specifying hotkeys will exclude them from this all.'''
+            help="""To specify all hotkeys. Specifying hotkeys will exclude them from this all.""",
         )
-        bittensor.wallet.add_args( stake_parser )
-        bittensor.subtensor.add_args( stake_parser )
+        bittensor.wallet.add_args(stake_parser)
+        bittensor.subtensor.add_args(stake_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/unstake.py` & `bittensor-5.3.2/bittensor/_cli/commands/unstake.py`

 * *Files 12% similar despite different names*

```diff
@@ -18,212 +18,256 @@
 import sys
 import bittensor
 from tqdm import tqdm
 from rich.prompt import Confirm, Prompt
 from bittensor.utils.balance import Balance
 from typing import List, Union, Optional, Tuple
 from .utils import get_hotkey_wallets_for_wallet
+
 console = bittensor.__console__
 
-class UnStakeCommand:
 
-    @classmethod   
-    def check_config( cls, config: 'bittensor.Config' ):        
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+class UnStakeCommand:
+    @classmethod
+    def check_config(cls, config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.get( 'hotkey_ss58address', d=None ) and not config.is_set('wallet.hotkey') and not config.no_prompt and not config.get('all_hotkeys') and not config.get('hotkeys'):
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if (
+            not config.get("hotkey_ss58address", d=None)
+            and not config.is_set("wallet.hotkey")
+            and not config.no_prompt
+            and not config.get("all_hotkeys")
+            and not config.get("hotkeys")
+        ):
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
         # Get amount.
-        if not config.get('hotkey_ss58address') and not config.get('amount') and not config.get('unstake_all') and not config.get('max_stake'):
-            hotkeys: str = ''
-            if config.get('all_hotkeys'):
+        if (
+            not config.get("hotkey_ss58address")
+            and not config.get("amount")
+            and not config.get("unstake_all")
+            and not config.get("max_stake")
+        ):
+            hotkeys: str = ""
+            if config.get("all_hotkeys"):
                 hotkeys = "all hotkeys"
-            elif config.get('hotkeys'):
-                hotkeys = str(config.hotkeys).replace('[', '').replace(']', '')
+            elif config.get("hotkeys"):
+                hotkeys = str(config.hotkeys).replace("[", "").replace("]", "")
             else:
                 hotkeys = str(config.wallet.hotkey)
-            if not Confirm.ask("Unstake all Tao from: [bold]'{}'[/bold]?".format(hotkeys)):
+            if not Confirm.ask(
+                "Unstake all Tao from: [bold]'{}'[/bold]?".format(hotkeys)
+            ):
                 amount = Prompt.ask("Enter Tao amount to unstake")
                 config.unstake_all = False
                 try:
                     config.amount = float(amount)
                 except ValueError:
-                    console.print(":cross_mark:[red] Invalid Tao amount[/red] [bold white]{}[/bold white]".format(amount))
+                    console.print(
+                        ":cross_mark:[red] Invalid Tao amount[/red] [bold white]{}[/bold white]".format(
+                            amount
+                        )
+                    )
                     sys.exit()
             else:
                 config.unstake_all = True
 
     @staticmethod
-    def add_args( command_parser ):
+    def add_args(command_parser):
         unstake_parser = command_parser.add_parser(
-            'unstake',
-            help='''Unstake from hotkey accounts.'''
+            "unstake", help="""Unstake from hotkey accounts."""
         )
         unstake_parser.add_argument(
-            '--no_version_checking',
-            action='store_true',
-            help='''Set false to stop cli version checking''',
-            default = False
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
         unstake_parser.add_argument(
-            '--all',
+            "--all",
             dest="unstake_all",
-            action='store_true',
+            action="store_true",
             default=False,
         )
         unstake_parser.add_argument(
-            '--amount',
-            dest="amount",
-            type=float,
-            required=False
+            "--amount", dest="amount", type=float, required=False
         )
         unstake_parser.add_argument(
-            '--hotkey_ss58address',
-            dest="hotkey_ss58address",
-            type=str,
-            required=False
+            "--hotkey_ss58address", dest="hotkey_ss58address", type=str, required=False
         )
         unstake_parser.add_argument(
-            '--max_stake',
+            "--max_stake",
             dest="max_stake",
             type=float,
             required=False,
-            action='store',
+            action="store",
             default=None,
-            help='''Specify the maximum amount of Tao to have staked in each hotkey.'''
+            help="""Specify the maximum amount of Tao to have staked in each hotkey.""",
         )
         unstake_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         unstake_parser.add_argument(
-            '--hotkeys',
-            '--exclude_hotkeys',
-            '--wallet.hotkeys',
-            '--wallet.exclude_hotkeys',
+            "--hotkeys",
+            "--exclude_hotkeys",
+            "--wallet.hotkeys",
+            "--wallet.exclude_hotkeys",
             required=False,
-            action='store',
+            action="store",
             default=[],
             type=str,
-            nargs='*',
-            help='''Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)'''
+            nargs="*",
+            help="""Specify the hotkeys by name or ss58 address. (e.g. hk1 hk2 hk3)""",
         )
         unstake_parser.add_argument(
-            '--all_hotkeys',
-            '--wallet.all_hotkeys',
+            "--all_hotkeys",
+            "--wallet.all_hotkeys",
             required=False,
-            action='store_true',
+            action="store_true",
             default=False,
-            help='''To specify all hotkeys. Specifying hotkeys will exclude them from this all.'''
+            help="""To specify all hotkeys. Specifying hotkeys will exclude them from this all.""",
         )
-        bittensor.wallet.add_args( unstake_parser )
-        bittensor.subtensor.add_args( unstake_parser )
+        bittensor.wallet.add_args(unstake_parser)
+        bittensor.subtensor.add_args(unstake_parser)
 
     @staticmethod
-    def run( cli ):
-        r""" Unstake token of amount from hotkey(s).
-        """
+    def run(cli):
+        r"""Unstake token of amount from hotkey(s)."""
         config = cli.config.copy()
-        wallet = bittensor.wallet( config = config )
-        subtensor: bittensor.Subtensor = bittensor.subtensor( config = cli.config )
+        wallet = bittensor.wallet(config=config)
+        subtensor: bittensor.Subtensor = bittensor.subtensor(config=cli.config)
 
         # Get the hotkey_names (if any) and the hotkey_ss58s.
         hotkeys_to_unstake_from: List[Tuple[Optional[str], str]] = []
-        if cli.config.get('hotkey_ss58address'):
+        if cli.config.get("hotkey_ss58address"):
             # Stake to specific hotkey.
-            hotkeys_to_unstake_from = [(None, cli.config.get('hotkey_ss58address'))]
-        elif cli.config.get('all_hotkeys'):
+            hotkeys_to_unstake_from = [(None, cli.config.get("hotkey_ss58address"))]
+        elif cli.config.get("all_hotkeys"):
             # Stake to all hotkeys.
-            all_hotkeys: List[bittensor.wallet] = get_hotkey_wallets_for_wallet( wallet = wallet )
+            all_hotkeys: List[bittensor.wallet] = get_hotkey_wallets_for_wallet(
+                wallet=wallet
+            )
             # Get the hotkeys to exclude. (d)efault to no exclusions.
-            hotkeys_to_exclude: List[str] = cli.config.get('hotkeys', d=[])
+            hotkeys_to_exclude: List[str] = cli.config.get("hotkeys", d=[])
             # Exclude hotkeys that are specified.
             hotkeys_to_unstake_from = [
-                (wallet.hotkey_str, wallet.hotkey.ss58_address) for wallet in all_hotkeys
-                    if wallet.hotkey_str not in hotkeys_to_exclude
-            ] # definitely wallets
+                (wallet.hotkey_str, wallet.hotkey.ss58_address)
+                for wallet in all_hotkeys
+                if wallet.hotkey_str not in hotkeys_to_exclude
+            ]  # definitely wallets
 
-        elif cli.config.get('hotkeys'):
+        elif cli.config.get("hotkeys"):
             # Stake to specific hotkeys.
-            for hotkey_ss58_or_hotkey_name in cli.config.get('hotkeys'):
-                if bittensor.utils.is_valid_ss58_address( hotkey_ss58_or_hotkey_name ):
+            for hotkey_ss58_or_hotkey_name in cli.config.get("hotkeys"):
+                if bittensor.utils.is_valid_ss58_address(hotkey_ss58_or_hotkey_name):
                     # If the hotkey is a valid ss58 address, we add it to the list.
-                    hotkeys_to_unstake_from.append( (None, hotkey_ss58_or_hotkey_name ) )
+                    hotkeys_to_unstake_from.append((None, hotkey_ss58_or_hotkey_name))
                 else:
                     # If the hotkey is not a valid ss58 address, we assume it is a hotkey name.
                     #  We then get the hotkey from the wallet and add it to the list.
-                    wallet_ = bittensor.wallet( config = cli.config, hotkey = hotkey_ss58_or_hotkey_name )
-                    hotkeys_to_unstake_from.append( (wallet_.hotkey_str, wallet_.hotkey.ss58_address ) )
-        elif cli.config.wallet.get('hotkey'):
+                    wallet_ = bittensor.wallet(
+                        config=cli.config, hotkey=hotkey_ss58_or_hotkey_name
+                    )
+                    hotkeys_to_unstake_from.append(
+                        (wallet_.hotkey_str, wallet_.hotkey.ss58_address)
+                    )
+        elif cli.config.wallet.get("hotkey"):
             # Only cli.config.wallet.hotkey is specified.
             #  so we stake to that single hotkey.
-            hotkey_ss58_or_name = cli.config.wallet.get('hotkey')
-            if bittensor.utils.is_valid_ss58_address( hotkey_ss58_or_name ):
-                hotkeys_to_unstake_from = [ (None, hotkey_ss58_or_name) ]
+            hotkey_ss58_or_name = cli.config.wallet.get("hotkey")
+            if bittensor.utils.is_valid_ss58_address(hotkey_ss58_or_name):
+                hotkeys_to_unstake_from = [(None, hotkey_ss58_or_name)]
             else:
                 # Hotkey is not a valid ss58 address, so we assume it is a hotkey name.
-                wallet_ = bittensor.wallet( config = cli.config, hotkey = hotkey_ss58_or_name )
-                hotkeys_to_unstake_from = [ (wallet_.hotkey_str, wallet_.hotkey.ss58_address ) ]
+                wallet_ = bittensor.wallet(
+                    config=cli.config, hotkey=hotkey_ss58_or_name
+                )
+                hotkeys_to_unstake_from = [
+                    (wallet_.hotkey_str, wallet_.hotkey.ss58_address)
+                ]
         else:
             # Only cli.config.wallet.hotkey is specified.
             #  so we stake to that single hotkey.
             assert cli.config.wallet.hotkey is not None
-            hotkeys_to_unstake_from = [ (None, bittensor.wallet( config = cli.config ).hotkey.ss58_address) ]
+            hotkeys_to_unstake_from = [
+                (None, bittensor.wallet(config=cli.config).hotkey.ss58_address)
+            ]
 
         final_hotkeys: List[Tuple[str, str]] = []
         final_amounts: List[Union[float, Balance]] = []
         for hotkey in tqdm(hotkeys_to_unstake_from):
-            hotkey: Tuple[Optional[str], str] # (hotkey_name (or None), hotkey_ss58)
-            unstake_amount_tao: float = cli.config.get('amount') # The amount specified to unstake.
-            hotkey_stake: Balance = subtensor.get_stake_for_coldkey_and_hotkey( hotkey_ss58 = hotkey[1], coldkey_ss58 = wallet.coldkeypub.ss58_address )
+            hotkey: Tuple[Optional[str], str]  # (hotkey_name (or None), hotkey_ss58)
+            unstake_amount_tao: float = cli.config.get(
+                "amount"
+            )  # The amount specified to unstake.
+            hotkey_stake: Balance = subtensor.get_stake_for_coldkey_and_hotkey(
+                hotkey_ss58=hotkey[1], coldkey_ss58=wallet.coldkeypub.ss58_address
+            )
             if unstake_amount_tao == None:
                 unstake_amount_tao = hotkey_stake.tao
-            if cli.config.get('max_stake'):
+            if cli.config.get("max_stake"):
                 # Get the current stake of the hotkey from this coldkey.
-                unstake_amount_tao: float = hotkey_stake.tao - cli.config.get('max_stake')
+                unstake_amount_tao: float = hotkey_stake.tao - cli.config.get(
+                    "max_stake"
+                )
                 cli.config.amount = unstake_amount_tao
                 if unstake_amount_tao < 0:
                     # Skip if max_stake is greater than current stake.
                     continue
             else:
                 if unstake_amount_tao is not None:
                     # There is a specified amount to unstake.
                     if unstake_amount_tao > hotkey_stake.tao:
                         # Skip if the specified amount is greater than the current stake.
                         continue
 
             final_amounts.append(unstake_amount_tao)
-            final_hotkeys.append(hotkey) # add both the name and the ss58 address.
+            final_hotkeys.append(hotkey)  # add both the name and the ss58 address.
 
         if len(final_hotkeys) == 0:
             # No hotkeys to unstake from.
-            bittensor.__console__.print("Not enough stake to unstake from any hotkeys or max_stake is more than current stake.")
+            bittensor.__console__.print(
+                "Not enough stake to unstake from any hotkeys or max_stake is more than current stake."
+            )
             return None
 
         # Ask to unstake
         if not cli.config.no_prompt:
-            if not Confirm.ask(f"Do you want to unstake from the following keys to {wallet.name}:\n" + \
-                    "".join([
-                        f"    [bold white]- {hotkey[0] + ':' if hotkey[0] else ''}{hotkey[1]}: {f'{amount} {bittensor.__tao_symbol__}' if amount else 'All'}[/bold white]\n" for hotkey, amount in zip(final_hotkeys, final_amounts)
-                    ])
-                ):
+            if not Confirm.ask(
+                f"Do you want to unstake from the following keys to {wallet.name}:\n"
+                + "".join(
+                    [
+                        f"    [bold white]- {hotkey[0] + ':' if hotkey[0] else ''}{hotkey[1]}: {f'{amount} {bittensor.__tao_symbol__}' if amount else 'All'}[/bold white]\n"
+                        for hotkey, amount in zip(final_hotkeys, final_amounts)
+                    ]
+                )
+            ):
                 return None
 
         if len(final_hotkeys) == 1:
             # do regular unstake
             return subtensor.unstake(
                 wallet=wallet,
-                hotkey_ss58 = final_hotkeys[0][1],
-                amount = None if cli.config.get('unstake_all') else final_amounts[0],
-                wait_for_inclusion = True,
-                prompt = not cli.config.no_prompt
+                hotkey_ss58=final_hotkeys[0][1],
+                amount=None if cli.config.get("unstake_all") else final_amounts[0],
+                wait_for_inclusion=True,
+                prompt=not cli.config.no_prompt,
             )
 
-        subtensor.unstake_multiple( wallet = wallet, hotkey_ss58s=[hotkey_ss58 for _, hotkey_ss58 in final_hotkeys], amounts =  None if cli.config.get('unstake_all') else final_amounts, wait_for_inclusion = True, prompt = False )
-
+        subtensor.unstake_multiple(
+            wallet=wallet,
+            hotkey_ss58s=[hotkey_ss58 for _, hotkey_ss58 in final_hotkeys],
+            amounts=None if cli.config.get("unstake_all") else final_amounts,
+            wait_for_inclusion=True,
+            prompt=False,
+        )
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/utils.py` & `bittensor-5.3.2/bittensor/_cli/commands/utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
@@ -20,146 +19,195 @@
 import os
 import torch
 import bittensor
 from typing import List, Dict, Any, Optional
 from rich.prompt import Confirm, Prompt, PromptBase
 import requests
 from dataclasses import dataclass
+
 console = bittensor.__console__
 
+
 class IntListPrompt(PromptBase):
-    """ Prompt for a list of integers. """
+    """Prompt for a list of integers."""
 
-    def check_choice( self, value: str ) -> bool:
+    def check_choice(self, value: str) -> bool:
         assert self.choices is not None
         # check if value is a valid choice or all the values in a list of ints are valid choices
-        return value == "All" or \
-            value in self.choices or \
-            all( val.strip() in self.choices for val in value.replace(',', ' ').split( ))
+        return (
+            value == "All"
+            or value in self.choices
+            or all(
+                val.strip() in self.choices for val in value.replace(",", " ").split()
+            )
+        )
 
 
-def check_netuid_set( config: 'bittensor.Config', subtensor: 'bittensor.Subtensor', allow_none: bool = False ):
-    if subtensor.network != 'nakamoto':
+def check_netuid_set(
+    config: "bittensor.Config",
+    subtensor: "bittensor.Subtensor",
+    allow_none: bool = False,
+):
+    if subtensor.network != "nakamoto":
         all_netuids = [str(netuid) for netuid in subtensor.get_subnets()]
         if len(all_netuids) == 0:
             console.print(":cross_mark:[red]There are no open networks.[/red]")
             sys.exit()
 
         # Make sure netuid is set.
-        if not config.is_set('netuid'):
+        if not config.is_set("netuid"):
             if not config.no_prompt:
-                netuid = IntListPrompt.ask("Enter netuid", choices=all_netuids, default=str(all_netuids[0]))
+                netuid = IntListPrompt.ask(
+                    "Enter netuid", choices=all_netuids, default=str(all_netuids[0])
+                )
             else:
-                netuid = str(bittensor.defaults.netuid) if not allow_none else 'None'
+                netuid = str(bittensor.defaults.netuid) if not allow_none else "None"
         else:
             netuid = config.netuid
 
-        if isinstance(netuid, str) and netuid.lower() in ['none'] and allow_none:
+        if isinstance(netuid, str) and netuid.lower() in ["none"] and allow_none:
             config.netuid = None
         else:
             try:
                 config.netuid = int(netuid)
             except ValueError:
                 raise ValueError('netuid must be an integer or "None" (if applicable)')
 
 
-def check_for_cuda_reg_config( config: 'bittensor.Config' ) -> None:
+def check_for_cuda_reg_config(config: "bittensor.Config") -> None:
     """Checks, when CUDA is available, if the user would like to register with their CUDA device."""
     if torch.cuda.is_available():
         if not config.no_prompt:
-            if config.subtensor.register.cuda.get('use_cuda') == None: # flag not set
+            if config.subtensor.register.cuda.get("use_cuda") == None:  # flag not set
                 # Ask about cuda registration only if a CUDA device is available.
                 cuda = Confirm.ask("Detected CUDA device, use CUDA for registration?\n")
                 config.subtensor.register.cuda.use_cuda = cuda
 
             # Only ask about which CUDA device if the user has more than one CUDA device.
-            if config.subtensor.register.cuda.use_cuda and config.subtensor.register.cuda.get('dev_id') is None:
+            if (
+                config.subtensor.register.cuda.use_cuda
+                and config.subtensor.register.cuda.get("dev_id") is None
+            ):
                 devices: List[str] = [str(x) for x in range(torch.cuda.device_count())]
-                device_names: List[str] = [torch.cuda.get_device_name(x) for x in range(torch.cuda.device_count())]
+                device_names: List[str] = [
+                    torch.cuda.get_device_name(x)
+                    for x in range(torch.cuda.device_count())
+                ]
                 console.print("Available CUDA devices:")
                 choices_str: str = ""
                 for i, device in enumerate(devices):
-                    choices_str += ("  {}: {}\n".format(device, device_names[i]))
+                    choices_str += "  {}: {}\n".format(device, device_names[i])
                 console.print(choices_str)
-                dev_id = IntListPrompt.ask("Which GPU(s) would you like to use? Please list one, or comma-separated", choices=devices, default='All')
-                if dev_id.lower() == 'all':
+                dev_id = IntListPrompt.ask(
+                    "Which GPU(s) would you like to use? Please list one, or comma-separated",
+                    choices=devices,
+                    default="All",
+                )
+                if dev_id.lower() == "all":
                     dev_id = list(range(torch.cuda.device_count()))
                 else:
                     try:
                         # replace the commas with spaces then split over whitespace.,
                         # then strip the whitespace and convert to ints.
-                        dev_id = [int(dev_id.strip()) for dev_id in dev_id.replace(',', ' ').split()]
+                        dev_id = [
+                            int(dev_id.strip())
+                            for dev_id in dev_id.replace(",", " ").split()
+                        ]
                     except ValueError:
-                        console.log(":cross_mark:[red]Invalid GPU device[/red] [bold white]{}[/bold white]\nAvailable CUDA devices:{}".format(dev_id, choices_str))
+                        console.log(
+                            ":cross_mark:[red]Invalid GPU device[/red] [bold white]{}[/bold white]\nAvailable CUDA devices:{}".format(
+                                dev_id, choices_str
+                            )
+                        )
                         sys.exit(1)
                 config.subtensor.register.cuda.dev_id = dev_id
         else:
             # flag was not set, use default value.
-            if config.subtensor.register.cuda.get('use_cuda') is None:
-                config.subtensor.register.cuda.use_cuda = bittensor.defaults.subtensor.register.cuda.use_cuda
+            if config.subtensor.register.cuda.get("use_cuda") is None:
+                config.subtensor.register.cuda.use_cuda = (
+                    bittensor.defaults.subtensor.register.cuda.use_cuda
+                )
+
 
-def get_hotkey_wallets_for_wallet( wallet ) -> List['bittensor.wallet']:
+def get_hotkey_wallets_for_wallet(wallet) -> List["bittensor.wallet"]:
     hotkey_wallets = []
-    hotkeys_path = wallet.path + '/' + wallet.name + '/hotkeys'
+    hotkeys_path = wallet.path + "/" + wallet.name + "/hotkeys"
     try:
         hotkey_files = next(os.walk(os.path.expanduser(hotkeys_path)))[2]
     except StopIteration:
         hotkey_files = []
     for hotkey_file_name in hotkey_files:
         try:
-            hotkey_for_name = bittensor.wallet( path = wallet.path, name = wallet.name, hotkey = hotkey_file_name )
-            if hotkey_for_name.hotkey_file.exists_on_device() and not hotkey_for_name.hotkey_file.is_encrypted():
-                hotkey_wallets.append( hotkey_for_name )
+            hotkey_for_name = bittensor.wallet(
+                path=wallet.path, name=wallet.name, hotkey=hotkey_file_name
+            )
+            if (
+                hotkey_for_name.hotkey_file.exists_on_device()
+                and not hotkey_for_name.hotkey_file.is_encrypted()
+            ):
+                hotkey_wallets.append(hotkey_for_name)
         except Exception:
             pass
     return hotkey_wallets
 
-def get_coldkey_wallets_for_path( path: str ) -> List['bittensor.wallet']:
+
+def get_coldkey_wallets_for_path(path: str) -> List["bittensor.wallet"]:
     try:
         wallet_names = next(os.walk(os.path.expanduser(path)))[1]
-        return [ bittensor.wallet( path= path, name=name ) for name in wallet_names ]
+        return [bittensor.wallet(path=path, name=name) for name in wallet_names]
     except StopIteration:
         # No wallet files found.
         wallets = []
     return wallets
 
-def get_all_wallets_for_path( path:str ) -> List['bittensor.wallet']:
+
+def get_all_wallets_for_path(path: str) -> List["bittensor.wallet"]:
     all_wallets = []
     cold_wallets = get_coldkey_wallets_for_path(path)
     for cold_wallet in cold_wallets:
-        if cold_wallet.coldkeypub_file.exists_on_device() and not cold_wallet.coldkeypub_file.is_encrypted():
-            all_wallets.extend( get_hotkey_wallets_for_wallet(cold_wallet) )
+        if (
+            cold_wallet.coldkeypub_file.exists_on_device()
+            and not cold_wallet.coldkeypub_file.is_encrypted()
+        ):
+            all_wallets.extend(get_hotkey_wallets_for_wallet(cold_wallet))
     return all_wallets
 
+
 @dataclass
 class DelegatesDetails:
     name: str
     url: str
     description: str
     signature: str
 
     @classmethod
-    def from_json(cls, json: Dict[str, any]) -> 'DelegatesDetails':
+    def from_json(cls, json: Dict[str, any]) -> "DelegatesDetails":
         return cls(
-            name=json['name'],
-            url=json['url'],
-            description=json['description'],
-            signature=json['signature'],
+            name=json["name"],
+            url=json["url"],
+            description=json["description"],
+            signature=json["signature"],
         )
 
-def _get_delegates_details_from_github(requests_get, url: str) -> Dict[str, DelegatesDetails]:
+
+def _get_delegates_details_from_github(
+    requests_get, url: str
+) -> Dict[str, DelegatesDetails]:
     response = requests_get(url)
 
     if response.status_code == 200:
         all_delegates: Dict[str, Any] = response.json()
         all_delegates_details = {}
         for delegate_hotkey, delegates_details in all_delegates.items():
-            all_delegates_details[delegate_hotkey] = DelegatesDetails.from_json(delegates_details)
+            all_delegates_details[delegate_hotkey] = DelegatesDetails.from_json(
+                delegates_details
+            )
         return all_delegates_details
     else:
         return {}
-    
-def get_delegates_details(url: str) -> Optional[Dict[str, DelegatesDetails]]: 
+
+
+def get_delegates_details(url: str) -> Optional[Dict[str, DelegatesDetails]]:
     try:
         return _get_delegates_details_from_github(requests.get, url)
     except Exception:
-        return None # Fail silently
+        return None  # Fail silently
```

### Comparing `bittensor-5.3.1/bittensor/_cli/commands/wallets.py` & `bittensor-5.3.2/bittensor/_cli/commands/wallets.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
@@ -19,381 +18,463 @@
 import argparse
 import bittensor
 import os
 import sys
 from rich.prompt import Prompt
 from typing import Optional
 
+
 class RegenColdkeyCommand:
-    def run ( cli ):
-        r""" Creates a new coldkey under this wallet."""
-        wallet = bittensor.wallet(config = cli.config)
+    def run(cli):
+        r"""Creates a new coldkey under this wallet."""
+        wallet = bittensor.wallet(config=cli.config)
 
         json_str: Optional[str] = None
         json_password: Optional[str] = None
-        if cli.config.get('json'):
-            file_name: str = cli.config.get('json')
+        if cli.config.get("json"):
+            file_name: str = cli.config.get("json")
             if not os.path.exists(file_name) or not os.path.isfile(file_name):
-                raise ValueError('File {} does not exist'.format(file_name))
-            with open(cli.config.get('json'), 'r') as f:
+                raise ValueError("File {} does not exist".format(file_name))
+            with open(cli.config.get("json"), "r") as f:
                 json_str = f.read()
 
             # Password can be "", assume if None
-            json_password = cli.config.get('json_password', "")
+            json_password = cli.config.get("json_password", "")
 
-        wallet.regenerate_coldkey( mnemonic = cli.config.mnemonic, seed = cli.config.seed, json = (json_str, json_password), use_password = cli.config.use_password, overwrite = cli.config.overwrite_coldkey )
+        wallet.regenerate_coldkey(
+            mnemonic=cli.config.mnemonic,
+            seed=cli.config.seed,
+            json=(json_str, json_password),
+            use_password=cli.config.use_password,
+            overwrite=cli.config.overwrite_coldkey,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
-        if config.mnemonic == None and config.get( 'seed', d=None ) == None and config.get( 'json', d=None ) == None:
+        if (
+            config.mnemonic == None
+            and config.get("seed", d=None) == None
+            and config.get("json", d=None) == None
+        ):
             prompt_answer = Prompt.ask("Enter mnemonic, seed, or json file location")
             if prompt_answer.startswith("0x"):
                 config.seed = prompt_answer
             elif len(prompt_answer.split(" ")) > 1:
                 config.mnemonic = prompt_answer
             else:
                 config.json = prompt_answer
 
-        if config.get( 'json', d=None ) and config.get( 'json_password', d=None ) == None:
-            config.json_password = Prompt.ask("Enter json backup password", password=True)
+        if config.get("json", d=None) and config.get("json_password", d=None) == None:
+            config.json_password = Prompt.ask(
+                "Enter json backup password", password=True
+            )
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         regen_coldkey_parser = parser.add_parser(
-            'regen_coldkey',
-            help='''Regenerates a coldkey from a passed value'''
+            "regen_coldkey", help="""Regenerates a coldkey from a passed value"""
+        )
+        regen_coldkey_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
-        regen_coldkey_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
         regen_coldkey_parser.add_argument(
             "--mnemonic",
             required=False,
             nargs="+",
-            help='Mnemonic used to regen your key i.e. horse cart dog ...'
+            help="Mnemonic used to regen your key i.e. horse cart dog ...",
         )
         regen_coldkey_parser.add_argument(
             "--seed",
             required=False,
             default=None,
-            help='Seed hex string used to regen your key i.e. 0x1234...'
+            help="Seed hex string used to regen your key i.e. 0x1234...",
         )
         regen_coldkey_parser.add_argument(
             "--json",
             required=False,
             default=None,
-            help='''Path to a json file containing the encrypted key backup. (e.g. from PolkadotJS)'''
+            help="""Path to a json file containing the encrypted key backup. (e.g. from PolkadotJS)""",
         )
         regen_coldkey_parser.add_argument(
             "--json_password",
             required=False,
             default=None,
-            help='''Password to decrypt the json file.'''
+            help="""Password to decrypt the json file.""",
         )
         regen_coldkey_parser.add_argument(
-            '--use_password',
-            dest='use_password',
-            action='store_true',
-            help='''Set true to protect the generated bittensor key with a password.''',
+            "--use_password",
+            dest="use_password",
+            action="store_true",
+            help="""Set true to protect the generated bittensor key with a password.""",
             default=True,
         )
         regen_coldkey_parser.add_argument(
-            '--no_password',
-            dest='use_password',
-            action='store_false',
-            help='''Set off protects the generated bittensor key with a password.''',
+            "--no_password",
+            dest="use_password",
+            action="store_false",
+            help="""Set off protects the generated bittensor key with a password.""",
         )
         regen_coldkey_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         regen_coldkey_parser.add_argument(
-            '--overwrite_coldkey',
+            "--overwrite_coldkey",
             default=False,
-            action='store_false',
-            help='''Overwrite the old coldkey with the newly generated coldkey'''
+            action="store_false",
+            help="""Overwrite the old coldkey with the newly generated coldkey""",
         )
-        bittensor.wallet.add_args( regen_coldkey_parser )
-        bittensor.subtensor.add_args( regen_coldkey_parser )
+        bittensor.wallet.add_args(regen_coldkey_parser)
+        bittensor.subtensor.add_args(regen_coldkey_parser)
 
 
 class RegenColdkeypubCommand:
-    def run ( cli ):
-        r""" Creates a new coldkeypub under this wallet."""
-        wallet = bittensor.wallet(config = cli.config)
-        wallet.regenerate_coldkeypub( ss58_address=cli.config.get('ss58_address'), public_key=cli.config.get('public_key_hex'), overwrite = cli.config.overwrite_coldkeypub )
+    def run(cli):
+        r"""Creates a new coldkeypub under this wallet."""
+        wallet = bittensor.wallet(config=cli.config)
+        wallet.regenerate_coldkeypub(
+            ss58_address=cli.config.get("ss58_address"),
+            public_key=cli.config.get("public_key_hex"),
+            overwrite=cli.config.overwrite_coldkeypub,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
         if config.ss58_address == None and config.public_key_hex == None:
-            prompt_answer = Prompt.ask("Enter the ss58_address or the public key in hex")
+            prompt_answer = Prompt.ask(
+                "Enter the ss58_address or the public key in hex"
+            )
             if prompt_answer.startswith("0x"):
                 config.public_key_hex = prompt_answer
             else:
                 config.ss58_address = prompt_answer
-        if not bittensor.utils.is_valid_bittensor_address_or_public_key(address = config.ss58_address if config.ss58_address else config.public_key_hex):
+        if not bittensor.utils.is_valid_bittensor_address_or_public_key(
+            address=config.ss58_address
+            if config.ss58_address
+            else config.public_key_hex
+        ):
             sys.exit(1)
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         regen_coldkeypub_parser = parser.add_parser(
-            'regen_coldkeypub',
-            help='''Regenerates a coldkeypub from the public part of the coldkey.'''
+            "regen_coldkeypub",
+            help="""Regenerates a coldkeypub from the public part of the coldkey.""",
+        )
+        regen_coldkeypub_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
-        regen_coldkeypub_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
         regen_coldkeypub_parser.add_argument(
             "--public_key",
             "--pubkey",
             dest="public_key_hex",
             required=False,
             default=None,
             type=str,
-            help='The public key (in hex) of the coldkey to regen e.g. 0x1234 ...'
+            help="The public key (in hex) of the coldkey to regen e.g. 0x1234 ...",
         )
         regen_coldkeypub_parser.add_argument(
             "--ss58_address",
             "--addr",
             "--ss58",
             dest="ss58_address",
             required=False,
             default=None,
             type=str,
-            help='The ss58 address of the coldkey to regen e.g. 5ABCD ...'
+            help="The ss58 address of the coldkey to regen e.g. 5ABCD ...",
         )
         regen_coldkeypub_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         regen_coldkeypub_parser.add_argument(
-            '--overwrite_coldkeypub',
+            "--overwrite_coldkeypub",
             default=False,
-            action='store_true',
-            help='''Overwrite the old coldkeypub file with the newly generated coldkeypub'''
+            action="store_true",
+            help="""Overwrite the old coldkeypub file with the newly generated coldkeypub""",
         )
-        bittensor.wallet.add_args( regen_coldkeypub_parser )
-        bittensor.subtensor.add_args( regen_coldkeypub_parser )
+        bittensor.wallet.add_args(regen_coldkeypub_parser)
+        bittensor.subtensor.add_args(regen_coldkeypub_parser)
 
-class RegenHotkeyCommand:
 
-    def run ( cli ):
-        r""" Creates a new coldkey under this wallet."""
-        wallet = bittensor.wallet(config = cli.config)
+class RegenHotkeyCommand:
+    def run(cli):
+        r"""Creates a new coldkey under this wallet."""
+        wallet = bittensor.wallet(config=cli.config)
 
         json_str: Optional[str] = None
         json_password: Optional[str] = None
-        if cli.config.get('json'):
-            file_name: str = cli.config.get('json')
+        if cli.config.get("json"):
+            file_name: str = cli.config.get("json")
             if not os.path.exists(file_name) or not os.path.isfile(file_name):
-                raise ValueError('File {} does not exist'.format(file_name))
-            with open(cli.config.get('json'), 'r') as f:
+                raise ValueError("File {} does not exist".format(file_name))
+            with open(cli.config.get("json"), "r") as f:
                 json_str = f.read()
 
             # Password can be "", assume if None
-            json_password = cli.config.get('json_password', "")
+            json_password = cli.config.get("json_password", "")
 
-        wallet.regenerate_hotkey( mnemonic = cli.config.mnemonic, seed=cli.config.seed, json = (json_str, json_password), use_password = cli.config.use_password, overwrite = cli.config.overwrite_hotkey)
+        wallet.regenerate_hotkey(
+            mnemonic=cli.config.mnemonic,
+            seed=cli.config.seed,
+            json=(json_str, json_password),
+            use_password=cli.config.use_password,
+            overwrite=cli.config.overwrite_hotkey,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
-        if config.mnemonic == None and config.get( 'seed', d=None ) == None and config.get( 'json', d=None ) == None:
+        if (
+            config.mnemonic == None
+            and config.get("seed", d=None) == None
+            and config.get("json", d=None) == None
+        ):
             prompt_answer = Prompt.ask("Enter mnemonic, seed, or json file location")
             if prompt_answer.startswith("0x"):
                 config.seed = prompt_answer
             elif len(prompt_answer.split(" ")) > 1:
                 config.mnemonic = prompt_answer
             else:
                 config.json = prompt_answer
 
-        if config.get( 'json', d=None ) and config.get( 'json_password', d=None ) == None:
-            config.json_password = Prompt.ask("Enter json backup password", password=True)
+        if config.get("json", d=None) and config.get("json_password", d=None) == None:
+            config.json_password = Prompt.ask(
+                "Enter json backup password", password=True
+            )
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         regen_hotkey_parser = parser.add_parser(
-            'regen_hotkey',
-            help='''Regenerates a hotkey from a passed mnemonic'''
+            "regen_hotkey", help="""Regenerates a hotkey from a passed mnemonic"""
+        )
+        regen_hotkey_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
-        regen_hotkey_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
         regen_hotkey_parser.add_argument(
             "--mnemonic",
             required=False,
             nargs="+",
-            help='Mnemonic used to regen your key i.e. horse cart dog ...'
+            help="Mnemonic used to regen your key i.e. horse cart dog ...",
         )
         regen_hotkey_parser.add_argument(
             "--seed",
             required=False,
             default=None,
-            help='Seed hex string used to regen your key i.e. 0x1234...'
+            help="Seed hex string used to regen your key i.e. 0x1234...",
         )
         regen_hotkey_parser.add_argument(
             "--json",
             required=False,
             default=None,
-            help='''Path to a json file containing the encrypted key backup. (e.g. from PolkadotJS)'''
+            help="""Path to a json file containing the encrypted key backup. (e.g. from PolkadotJS)""",
         )
         regen_hotkey_parser.add_argument(
             "--json_password",
             required=False,
             default=None,
-            help='''Password to decrypt the json file.'''
+            help="""Password to decrypt the json file.""",
         )
         regen_hotkey_parser.add_argument(
-            '--use_password',
-            dest='use_password',
-            action='store_true',
-            help='''Set true to protect the generated bittensor key with a password.''',
-            default=False
+            "--use_password",
+            dest="use_password",
+            action="store_true",
+            help="""Set true to protect the generated bittensor key with a password.""",
+            default=False,
         )
         regen_hotkey_parser.add_argument(
-            '--no_password',
-            dest='use_password',
-            action='store_false',
-            help='''Set off protects the generated bittensor key with a password.'''
+            "--no_password",
+            dest="use_password",
+            action="store_false",
+            help="""Set off protects the generated bittensor key with a password.""",
         )
         regen_hotkey_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         regen_hotkey_parser.add_argument(
-            '--overwrite_hotkey',
-            dest='overwrite_hotkey',
-            action='store_true',
+            "--overwrite_hotkey",
+            dest="overwrite_hotkey",
+            action="store_true",
             default=False,
-            help='''Overwrite the old hotkey with the newly generated hotkey'''
+            help="""Overwrite the old hotkey with the newly generated hotkey""",
         )
-        bittensor.wallet.add_args( regen_hotkey_parser )
-        bittensor.subtensor.add_args( regen_hotkey_parser )
-
+        bittensor.wallet.add_args(regen_hotkey_parser)
+        bittensor.subtensor.add_args(regen_hotkey_parser)
 
 
 class NewHotkeyCommand:
-
-    def run( cli ):
-        """ Creates a new hotke under this wallet."""
-        wallet = bittensor.wallet(config = cli.config)
-        wallet.create_new_hotkey( n_words = cli.config.n_words, use_password = cli.config.use_password, overwrite = cli.config.overwrite_hotkey)
+    def run(cli):
+        """Creates a new hotke under this wallet."""
+        wallet = bittensor.wallet(config=cli.config)
+        wallet.create_new_hotkey(
+            n_words=cli.config.n_words,
+            use_password=cli.config.use_password,
+            overwrite=cli.config.overwrite_hotkey,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
-        if not config.is_set('wallet.hotkey') and not config.no_prompt:
-            hotkey = Prompt.ask("Enter hotkey name", default = bittensor.defaults.wallet.hotkey)
+        if not config.is_set("wallet.hotkey") and not config.no_prompt:
+            hotkey = Prompt.ask(
+                "Enter hotkey name", default=bittensor.defaults.wallet.hotkey
+            )
             config.wallet.hotkey = str(hotkey)
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
-        new_hotkey_parser = parser.add_parser( 'new_hotkey',  help='''Creates a new hotkey (for running a miner) under the specified path.''')
-        new_hotkey_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
-        new_hotkey_parser.add_argument( '--n_words',
+    def add_args(parser: argparse.ArgumentParser):
+        new_hotkey_parser = parser.add_parser(
+            "new_hotkey",
+            help="""Creates a new hotkey (for running a miner) under the specified path.""",
+        )
+        new_hotkey_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
+        )
+        new_hotkey_parser.add_argument(
+            "--n_words",
             type=int,
-            choices=[12,15,18,21,24],
+            choices=[12, 15, 18, 21, 24],
             default=12,
-            help='''The number of words representing the mnemonic. i.e. horse cart dog ... x 24'''
+            help="""The number of words representing the mnemonic. i.e. horse cart dog ... x 24""",
         )
         new_hotkey_parser.add_argument(
-            '--use_password',
-            dest='use_password',
-            action='store_true',
-            help='''Set true to protect the generated bittensor key with a password.''',
-            default=False
+            "--use_password",
+            dest="use_password",
+            action="store_true",
+            help="""Set true to protect the generated bittensor key with a password.""",
+            default=False,
         )
         new_hotkey_parser.add_argument(
-            '--no_password',
-            dest='use_password',
-            action='store_false',
-            help='''Set off protects the generated bittensor key with a password.'''
+            "--no_password",
+            dest="use_password",
+            action="store_false",
+            help="""Set off protects the generated bittensor key with a password.""",
         )
         new_hotkey_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         new_hotkey_parser.add_argument(
-            '--overwrite_hotkey',
-            action='store_false',
+            "--overwrite_hotkey",
+            action="store_false",
             default=False,
-            help='''Overwrite the old hotkey with the newly generated hotkey'''
+            help="""Overwrite the old hotkey with the newly generated hotkey""",
         )
-        bittensor.wallet.add_args( new_hotkey_parser )
-        bittensor.subtensor.add_args( new_hotkey_parser )
+        bittensor.wallet.add_args(new_hotkey_parser)
+        bittensor.subtensor.add_args(new_hotkey_parser)
 
 
 class NewColdkeyCommand:
-    def run ( cli ):
-        r""" Creates a new coldkey under this wallet."""
-        wallet = bittensor.wallet(config = cli.config)
-        wallet.create_new_coldkey( n_words = cli.config.n_words, use_password = cli.config.use_password, overwrite = cli.config.overwrite_coldkey)
+    def run(cli):
+        r"""Creates a new coldkey under this wallet."""
+        wallet = bittensor.wallet(config=cli.config)
+        wallet.create_new_coldkey(
+            n_words=cli.config.n_words,
+            use_password=cli.config.use_password,
+            overwrite=cli.config.overwrite_coldkey,
+        )
 
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
-        if not config.is_set('wallet.name') and not config.no_prompt:
-            wallet_name = Prompt.ask("Enter wallet name", default = bittensor.defaults.wallet.name)
+    def check_config(config: "bittensor.Config"):
+        if not config.is_set("wallet.name") and not config.no_prompt:
+            wallet_name = Prompt.ask(
+                "Enter wallet name", default=bittensor.defaults.wallet.name
+            )
             config.wallet.name = str(wallet_name)
 
     @staticmethod
-    def add_args( parser: argparse.ArgumentParser ):
+    def add_args(parser: argparse.ArgumentParser):
         new_coldkey_parser = parser.add_parser(
-            'new_coldkey',
-            help='''Creates a new coldkey (for containing balance) under the specified path. '''
+            "new_coldkey",
+            help="""Creates a new coldkey (for containing balance) under the specified path. """,
+        )
+        new_coldkey_parser.add_argument(
+            "--no_version_checking",
+            action="store_true",
+            help="""Set false to stop cli version checking""",
+            default=False,
         )
-        new_coldkey_parser.add_argument( '--no_version_checking', action='store_true', help='''Set false to stop cli version checking''', default = False )
         new_coldkey_parser.add_argument(
-            '--n_words',
+            "--n_words",
             type=int,
-            choices=[12,15,18,21,24],
+            choices=[12, 15, 18, 21, 24],
             default=12,
-            help='''The number of words representing the mnemonic. i.e. horse cart dog ... x 24'''
+            help="""The number of words representing the mnemonic. i.e. horse cart dog ... x 24""",
         )
         new_coldkey_parser.add_argument(
-            '--use_password',
-            dest='use_password',
-            action='store_true',
-            help='''Set true to protect the generated bittensor key with a password.''',
+            "--use_password",
+            dest="use_password",
+            action="store_true",
+            help="""Set true to protect the generated bittensor key with a password.""",
             default=True,
         )
         new_coldkey_parser.add_argument(
-            '--no_password',
-            dest='use_password',
-            action='store_false',
-            help='''Set off protects the generated bittensor key with a password.'''
+            "--no_password",
+            dest="use_password",
+            action="store_false",
+            help="""Set off protects the generated bittensor key with a password.""",
         )
         new_coldkey_parser.add_argument(
-            '--no_prompt',
-            dest='no_prompt',
-            action='store_true',
-            help='''Set true to avoid prompting the user.''',
+            "--no_prompt",
+            dest="no_prompt",
+            action="store_true",
+            help="""Set true to avoid prompting the user.""",
             default=False,
         )
         new_coldkey_parser.add_argument(
-            '--overwrite_coldkey',
-            action='store_false',
+            "--overwrite_coldkey",
+            action="store_false",
             default=False,
-            help='''Overwrite the old coldkey with the newly generated coldkey'''
+            help="""Overwrite the old coldkey with the newly generated coldkey""",
         )
-        bittensor.wallet.add_args( new_coldkey_parser )
-        bittensor.subtensor.add_args( new_coldkey_parser )
+        bittensor.wallet.add_args(new_coldkey_parser)
+        bittensor.subtensor.add_args(new_coldkey_parser)
```

### Comparing `bittensor-5.3.1/bittensor/_dataset/__init__.py` & `bittensor-5.3.2/bittensor/_dataset/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -24,165 +24,268 @@
 from typing import Union
 import warnings
 
 import bittensor
 from . import dataset_impl
 from . import dataset_mock
 
+
 class dataset:
-    """ Factory class for the GenesisTextDataset class or the mocked GenesisTextDataset
+    """Factory class for the GenesisTextDataset class or the mocked GenesisTextDataset
     The GenesisTextDataset downloads text data from the bittensor mountain dataset.
     The class makes http requests to bittensor's IPFS backend server which contains the full dataset.
     By default, the GenesisTextDataset class will return a fully functioning pytorch dataloader.
 
     Examples::
             >>> dataset = bittensor.dataset(batch_size = 10, block_size=20)
             >>> # data.shape[batch_size, block_size]
             >>> data = next(dataset)
     """
+
     def __new__(
-            cls,
-            config: 'bittensor.config' = None,
-            block_size: int = None,
-            batch_size: int = None,
-            num_workers: int = None,
-            dataset_names: Union[list, str] = None,
-            save_dataset: bool=None,
-            no_tokenizer: bool=None,
-            num_batches: int = None,
-            _mock:bool=None,
-            dataset_name: list = None, # For backwards compatibility
-        ):
-        r""" Create and init the GenesisTextDataset class, which handles dataloading from ipfs.
-            Args:
-                config (:obj:`bittensor.Config`, `optional`):
-                    bittensor.dataset.config()
-                block_size (:obj:`int`, `optional`):
-                    Number of text items to pull for each example.
-                batch_size (:obj:`int`, `optional`):
-                    Batch size.
-                num_workers (:obj:`int`, `optional`):
-                    Number of workers for data loader.
-                dataset_names (:obj:`list`,`str`, `optional`):
-                    Which datasets to use (ArXiv, BookCorpus2, Books3, DMMathematics, EnronEmails, EuroParl,
-                    Gutenberg_PG, HackerNews, NIHExPorter, OpenSubtitles, PhilPapers, UbuntuIRC, YoutubeSubtitles)).
-                save_dataset (:obj:`bool`, `optional`):
-                    Save the downloaded dataset or not.
-                no_tokenizer (:obj:`bool`, `optional`):
-                    To return non-tokenized text (EXPERIMENTAL, DO NOT USE)
-                num_batches (:obj:`int`, `optional`):
-                    The number of batches of data to prepare for the dataloader.
-                _mock (:obj:`bool`, `optional`):
-                    For testing, if true the dataset if filled with fake text data.
+        cls,
+        config: "bittensor.config" = None,
+        block_size: int = None,
+        batch_size: int = None,
+        num_workers: int = None,
+        dataset_names: Union[list, str] = None,
+        save_dataset: bool = None,
+        no_tokenizer: bool = None,
+        num_batches: int = None,
+        _mock: bool = None,
+        dataset_name: list = None,  # For backwards compatibility
+    ):
+        r"""Create and init the GenesisTextDataset class, which handles dataloading from ipfs.
+        Args:
+            config (:obj:`bittensor.Config`, `optional`):
+                bittensor.dataset.config()
+            block_size (:obj:`int`, `optional`):
+                Number of text items to pull for each example.
+            batch_size (:obj:`int`, `optional`):
+                Batch size.
+            num_workers (:obj:`int`, `optional`):
+                Number of workers for data loader.
+            dataset_names (:obj:`list`,`str`, `optional`):
+                Which datasets to use (ArXiv, BookCorpus2, Books3, DMMathematics, EnronEmails, EuroParl,
+                Gutenberg_PG, HackerNews, NIHExPorter, OpenSubtitles, PhilPapers, UbuntuIRC, YoutubeSubtitles)).
+            save_dataset (:obj:`bool`, `optional`):
+                Save the downloaded dataset or not.
+            no_tokenizer (:obj:`bool`, `optional`):
+                To return non-tokenized text (EXPERIMENTAL, DO NOT USE)
+            num_batches (:obj:`int`, `optional`):
+                The number of batches of data to prepare for the dataloader.
+            _mock (:obj:`bool`, `optional`):
+                For testing, if true the dataset if filled with fake text data.
         """
         if config == None:
             config = dataset.config()
-        config = copy.deepcopy( config )
-        config.dataset.block_size = block_size if block_size != None else config.dataset.block_size
-        config.dataset.batch_size = batch_size if batch_size != None else config.dataset.batch_size
-        config.dataset.num_workers = num_workers if num_workers != None else config.dataset.num_workers
-        config.dataset.dataset_names = dataset_names if dataset_names != None else config.dataset.dataset_names
-        config.dataset.save_dataset = save_dataset if save_dataset != None else config.dataset.save_dataset
-        config.dataset.no_tokenizer = no_tokenizer if no_tokenizer != None else config.dataset.no_tokenizer
-        config.dataset.num_batches = num_batches if num_batches != None else config.dataset.num_batches
+        config = copy.deepcopy(config)
+        config.dataset.block_size = (
+            block_size if block_size != None else config.dataset.block_size
+        )
+        config.dataset.batch_size = (
+            batch_size if batch_size != None else config.dataset.batch_size
+        )
+        config.dataset.num_workers = (
+            num_workers if num_workers != None else config.dataset.num_workers
+        )
+        config.dataset.dataset_names = (
+            dataset_names if dataset_names != None else config.dataset.dataset_names
+        )
+        config.dataset.save_dataset = (
+            save_dataset if save_dataset != None else config.dataset.save_dataset
+        )
+        config.dataset.no_tokenizer = (
+            no_tokenizer if no_tokenizer != None else config.dataset.no_tokenizer
+        )
+        config.dataset.num_batches = (
+            num_batches if num_batches != None else config.dataset.num_batches
+        )
         config.dataset._mock = _mock if _mock != None else config.dataset._mock
-        dataset.check_config( config )
+        dataset.check_config(config)
 
         if dataset_name is not None:
-            warnings.warn("dataset_name as a parameter is deprecated and will be removed in a future release. Use `dataset_names` instead.", DeprecationWarning)
+            warnings.warn(
+                "dataset_name as a parameter is deprecated and will be removed in a future release. Use `dataset_names` instead.",
+                DeprecationWarning,
+            )
             config.dataset.dataset_names = dataset_name
 
         if config.dataset._mock:
             return dataset_mock.MockGenesisTextDataset(
-                block_size = config.dataset.block_size,
-                batch_size = config.dataset.batch_size,
-                num_workers = config.dataset.num_workers,
-                dataset_names = config.dataset.dataset_names,
-                data_dir = config.dataset.data_dir,
-                save_dataset = config.dataset.save_dataset,
-                max_datasets = config.dataset.max_datasets,
-                no_tokenizer = config.dataset.no_tokenizer,
-                num_batches = config.dataset.num_batches,
+                block_size=config.dataset.block_size,
+                batch_size=config.dataset.batch_size,
+                num_workers=config.dataset.num_workers,
+                dataset_names=config.dataset.dataset_names,
+                data_dir=config.dataset.data_dir,
+                save_dataset=config.dataset.save_dataset,
+                max_datasets=config.dataset.max_datasets,
+                no_tokenizer=config.dataset.no_tokenizer,
+                num_batches=config.dataset.num_batches,
             )
         else:
             return dataset_impl.GenesisTextDataset(
-                block_size = config.dataset.block_size,
-                batch_size = config.dataset.batch_size,
-                num_workers = config.dataset.num_workers,
-                dataset_names = config.dataset.dataset_names,
-                data_dir = config.dataset.data_dir,
-                save_dataset = config.dataset.save_dataset,
-                max_datasets = config.dataset.max_datasets,
-                no_tokenizer = config.dataset.no_tokenizer,
-                num_batches = config.dataset.num_batches,
+                block_size=config.dataset.block_size,
+                batch_size=config.dataset.batch_size,
+                num_workers=config.dataset.num_workers,
+                dataset_names=config.dataset.dataset_names,
+                data_dir=config.dataset.data_dir,
+                save_dataset=config.dataset.save_dataset,
+                max_datasets=config.dataset.max_datasets,
+                no_tokenizer=config.dataset.no_tokenizer,
+                num_batches=config.dataset.num_batches,
             )
 
     @classmethod
     def mock(cls):
-        return dataset( _mock = True, dataset_names = ['Books3'])
+        return dataset(_mock=True, dataset_names=["Books3"])
 
     @classmethod
-    def config(cls) -> 'bittensor.Config':
-        """ Get config from the argument parser
-            Return: bittensor.config object
+    def config(cls) -> "bittensor.Config":
+        """Get config from the argument parser
+        Return: bittensor.config object
         """
         parser = argparse.ArgumentParser()
-        dataset.add_args( parser )
-        return bittensor.config( parser )
+        dataset.add_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
-    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None ):
-        """ Accept specific arguments from parser
-        """
-        prefix_str = '' if prefix == None else prefix + '.'
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
+        """Accept specific arguments from parser"""
+        prefix_str = "" if prefix == None else prefix + "."
         if prefix is not None:
             if bittensor.defaults.get(prefix, d=None) == None:
                 setattr(bittensor.defaults, prefix, bittensor.Config())
             getattr(bittensor.defaults, prefix).dataset = bittensor.defaults.dataset
         try:
-            parser.add_argument('--' + prefix_str + 'dataset.batch_size', type=int, help='Batch size.', default = bittensor.defaults.dataset.batch_size)
-            parser.add_argument('--' + prefix_str + 'dataset.block_size', type=int, help='Number of text items to pull for each example..', default = bittensor.defaults.dataset.block_size)
-            parser.add_argument('--' + prefix_str + 'dataset.num_workers',  type=int, help='Number of workers for data loader.', default = bittensor.defaults.dataset.num_workers)
-            parser.add_argument('--' + prefix_str + 'dataset.dataset_names', type=str, required=False, nargs='*', action='store', help='Which datasets to use (ArXiv, BookCorpus2, Books3, DMMathematics, EnronEmails, EuroParl, Gutenberg_PG, HackerNews, NIHExPorter, OpenSubtitles, PhilPapers, UbuntuIRC, YoutubeSubtitles)).',
-                                                                    default = bittensor.defaults.dataset.dataset_names)
-            parser.add_argument('--' + prefix_str + 'dataset.data_dir', type=str, help='Where to save and load the data.', default = bittensor.defaults.dataset.data_dir)
-            parser.add_argument('--' + prefix_str + 'dataset.save_dataset', action='store_true', help='Save the downloaded dataset or not.', default = bittensor.defaults.dataset.save_dataset)
-            parser.add_argument('--' + prefix_str + 'dataset.max_datasets',  type=int, help='Number of datasets to load', default = bittensor.defaults.dataset.max_datasets)
-            parser.add_argument('--' + prefix_str + 'dataset.no_tokenizer', action='store_true', help='To return non-tokenized text (EXPERIMENTAL, DO NOT USE)',default=False)
-            parser.add_argument('--' + prefix_str + 'dataset.num_batches', type=int, help='The number of data to download each time(measured by the number of batches).', default=bittensor.defaults.dataset.num_batches)
-            parser.add_argument('--' + prefix_str + 'dataset._mock', action='store_true', help='To turn on dataset mocking for testing purposes.', default=False)
+            parser.add_argument(
+                "--" + prefix_str + "dataset.batch_size",
+                type=int,
+                help="Batch size.",
+                default=bittensor.defaults.dataset.batch_size,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.block_size",
+                type=int,
+                help="Number of text items to pull for each example..",
+                default=bittensor.defaults.dataset.block_size,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.num_workers",
+                type=int,
+                help="Number of workers for data loader.",
+                default=bittensor.defaults.dataset.num_workers,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.dataset_names",
+                type=str,
+                required=False,
+                nargs="*",
+                action="store",
+                help="Which datasets to use (ArXiv, BookCorpus2, Books3, DMMathematics, EnronEmails, EuroParl, Gutenberg_PG, HackerNews, NIHExPorter, OpenSubtitles, PhilPapers, UbuntuIRC, YoutubeSubtitles)).",
+                default=bittensor.defaults.dataset.dataset_names,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.data_dir",
+                type=str,
+                help="Where to save and load the data.",
+                default=bittensor.defaults.dataset.data_dir,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.save_dataset",
+                action="store_true",
+                help="Save the downloaded dataset or not.",
+                default=bittensor.defaults.dataset.save_dataset,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.max_datasets",
+                type=int,
+                help="Number of datasets to load",
+                default=bittensor.defaults.dataset.max_datasets,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.no_tokenizer",
+                action="store_true",
+                help="To return non-tokenized text (EXPERIMENTAL, DO NOT USE)",
+                default=False,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset.num_batches",
+                type=int,
+                help="The number of data to download each time(measured by the number of batches).",
+                default=bittensor.defaults.dataset.num_batches,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "dataset._mock",
+                action="store_true",
+                help="To turn on dataset mocking for testing purposes.",
+                default=False,
+            )
 
         except argparse.ArgumentError:
             # re-parsing arguments.
             pass
 
     @classmethod
     def help(cls):
-        """ Print help to stdout
-        """
+        """Print help to stdout"""
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        print (cls.__new__.__doc__)
+        cls.add_args(parser)
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
     def add_defaults(cls, defaults):
-        """ Adds parser defaults to object from enviroment variables.
-        """
+        """Adds parser defaults to object from enviroment variables."""
         defaults.dataset = bittensor.Config()
-        defaults.dataset.batch_size = os.getenv('BT_DATASET_BATCH_SIZE') if os.getenv('BT_DATASET_BATCH_SIZE') != None else 10
-        defaults.dataset.block_size = os.getenv('BT_DATASET_BLOCK_SIZE') if os.getenv('BT_DATASET_BLOCK_SIZE') != None else 20
-        defaults.dataset.num_workers = os.getenv('BT_DATASET_NUM_WORKERS') if os.getenv('BT_DATASET_NUM_WORKERS') != None else 0
-        defaults.dataset.dataset_names = os.getenv('BT_DATASET_DATASET_NAME') if os.getenv('BT_DATASET_DATASET_NAME') != None else 'default'
-        defaults.dataset.data_dir = os.getenv('BT_DATASET_DATADIR') if os.getenv('BT_DATASET_DATADIR') != None else '~/.bittensor/data/'
-        defaults.dataset.save_dataset = os.getenv('BT_DATASET_SAVE_DATASET') if os.getenv('BT_DATASET_SAVE_DATASET') != None else False
-        defaults.dataset.max_datasets = os.getenv('BT_DATASET_MAX_DATASETS') if os.getenv('BT_DATASET_MAX_DATASETS') != None else 3
-        defaults.dataset.num_batches = os.getenv('BT_DATASET_NUM_BATCHES') if os.getenv('BT_DATASET_NUM_BATCHES') != None else 100
+        defaults.dataset.batch_size = (
+            os.getenv("BT_DATASET_BATCH_SIZE")
+            if os.getenv("BT_DATASET_BATCH_SIZE") != None
+            else 10
+        )
+        defaults.dataset.block_size = (
+            os.getenv("BT_DATASET_BLOCK_SIZE")
+            if os.getenv("BT_DATASET_BLOCK_SIZE") != None
+            else 20
+        )
+        defaults.dataset.num_workers = (
+            os.getenv("BT_DATASET_NUM_WORKERS")
+            if os.getenv("BT_DATASET_NUM_WORKERS") != None
+            else 0
+        )
+        defaults.dataset.dataset_names = (
+            os.getenv("BT_DATASET_DATASET_NAME")
+            if os.getenv("BT_DATASET_DATASET_NAME") != None
+            else "default"
+        )
+        defaults.dataset.data_dir = (
+            os.getenv("BT_DATASET_DATADIR")
+            if os.getenv("BT_DATASET_DATADIR") != None
+            else "~/.bittensor/data/"
+        )
+        defaults.dataset.save_dataset = (
+            os.getenv("BT_DATASET_SAVE_DATASET")
+            if os.getenv("BT_DATASET_SAVE_DATASET") != None
+            else False
+        )
+        defaults.dataset.max_datasets = (
+            os.getenv("BT_DATASET_MAX_DATASETS")
+            if os.getenv("BT_DATASET_MAX_DATASETS") != None
+            else 3
+        )
+        defaults.dataset.num_batches = (
+            os.getenv("BT_DATASET_NUM_BATCHES")
+            if os.getenv("BT_DATASET_NUM_BATCHES") != None
+            else 100
+        )
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        """ Check config for batch size, block size, corpus size, num_workers and dataset
-        """
-        assert config.dataset.batch_size > 0, 'Batch size must be larger than 0'
-        assert config.dataset.block_size > 0, 'Block size must be larger than 0'
-        assert config.dataset.num_workers >= 0, 'num_workers must be equal to or larger than 0'
-        assert isinstance(config.dataset.save_dataset, bool) , 'save_dataset must be True/False only'
+    def check_config(cls, config: "bittensor.Config"):
+        """Check config for batch size, block size, corpus size, num_workers and dataset"""
+        assert config.dataset.batch_size > 0, "Batch size must be larger than 0"
+        assert config.dataset.block_size > 0, "Block size must be larger than 0"
+        assert (
+            config.dataset.num_workers >= 0
+        ), "num_workers must be equal to or larger than 0"
+        assert isinstance(
+            config.dataset.save_dataset, bool
+        ), "save_dataset must be True/False only"
```

### Comparing `bittensor-5.3.1/bittensor/_dataset/dataset_impl.py` & `bittensor-5.3.2/bittensor/_dataset/dataset_impl.py`

 * *Files 9% similar despite different names*

```diff
@@ -37,34 +37,32 @@
 
 from .thread_queue import ThreadQueue
 
 logger = logger.opt(colors=True)
 
 
 class Dataset:
-    """ Implementation for the dataset class, which handles dataloading from ipfs
-    """
-    def __init__(self):
+    """Implementation for the dataset class, which handles dataloading from ipfs"""
 
+    def __init__(self):
         # Used to retrieve directory contentx
-        self.dataset_dir = 'http://global.ipfs.opentensor.ai/api/v0/cat'
-        self.text_dir = 'http://global.ipfs.opentensor.ai/api/v0/object/get'
-        self.mountain_hash = 'QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX'
+        self.dataset_dir = "http://global.ipfs.opentensor.ai/api/v0/cat"
+        self.text_dir = "http://global.ipfs.opentensor.ai/api/v0/object/get"
+        self.mountain_hash = "QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX"
         # Used when current corpus has been exhausted
         self.refresh_corpus = False
 
-
     @staticmethod
     def requests_retry_session(
-            retries=1,
-            backoff_factor=0.5,
-            status_forcelist=(104, 500, 502, 504),
-            session=None,
-        ):
-        """ Creates a retriable session for request calls. This enables
+        retries=1,
+        backoff_factor=0.5,
+        status_forcelist=(104, 500, 502, 504),
+        session=None,
+    ):
+        """Creates a retriable session for request calls. This enables
         automatic retries and back-off retries should any request calls fail.
 
         Args:
             retries (int, optional): Maximum number of retries. Defaults to 3.
             backoff_factor (float, optional): Factor by which to back off if a retry fails. Defaults to 0.3.
             status_forcelist (tuple, optional): A set of integer HTTP status codes that we should force a retry on. Defaults to (500, 502, 504).
             session ([type], optional): Session for which to set up the retries. Defaults to None.
@@ -77,58 +75,63 @@
             total=retries,
             read=retries,
             connect=retries,
             backoff_factor=backoff_factor,
             status_forcelist=status_forcelist,
         )
         adapter = HTTPAdapter(max_retries=retry)
-        session.mount('http://', adapter)
-        session.mount('https://', adapter)
+        session.mount("http://", adapter)
+        session.mount("https://", adapter)
         return session
 
-    def get_ipfs_directory(self, address: str, file_meta: dict, action: str = 'post', timeout : int = 180):
+    def get_ipfs_directory(
+        self, address: str, file_meta: dict, action: str = "post", timeout: int = 180
+    ):
         r"""Connects to IPFS gateway and retrieves directory.
         Args:
             address: (:type:`str`, required):
                 The target address of the request.
             params: (:type:`tuple`, optional):
                 The arguments of the request. eg. (('arg', dataset_hash),)
             action: (:type:`str`, optional):
                 POST or GET.
             timeout: (:type:`int`, optional):
                 Timeout for getting the server's response.
         Returns:
             dict: A dictionary of the files inside of the genesis_datasets and their hashes.
         """
         session = requests.Session()
-        session.params.update((('arg', file_meta['Hash']), ))
+        session.params.update((("arg", file_meta["Hash"]),))
 
         try:
-            if action == 'get':
-                response = self.requests_retry_session(session=session).get(address, timeout=timeout)
-            elif action == 'post':
-                response = self.requests_retry_session(session=session).post(address, timeout=timeout)
+            if action == "get":
+                response = self.requests_retry_session(session=session).get(
+                    address, timeout=timeout
+                )
+            elif action == "post":
+                response = self.requests_retry_session(session=session).post(
+                    address, timeout=timeout
+                )
 
         except Exception as E:
             logger.error(f"Failed to get from IPFS {file_meta['Name']} {E}")
             return None
 
         return response
 
     def __len__(self):
-        """ Returns length of the dataset that the dataset is processing
-        """
+        """Returns length of the dataset that the dataset is processing"""
 
     def __getitem__(self, idx):
-        """ Returns the next batch from the dataset.
-        """
+        """Returns the next batch from the dataset."""
+
+
+class GenesisTextDataset(Dataset):
+    """One kind of dataset that caters for the data from ipfs"""
 
-class GenesisTextDataset( Dataset ):
-    """ One kind of dataset that caters for the data from ipfs
-    """
     def __init__(
         self,
         block_size,
         batch_size,
         num_workers,
         dataset_names,
         data_dir,
@@ -137,62 +140,64 @@
         no_tokenizer,
         num_batches,
     ):
         super().__init__()
         self.block_size = block_size
         self.batch_size = batch_size
         self.num_workers = num_workers
-        self.tokenizer = bittensor.tokenizer( version = bittensor.__version__ )
+        self.tokenizer = bittensor.tokenizer(version=bittensor.__version__)
         self.dataset_names = dataset_names
         self.data_dir = data_dir
         self.save_dataset = save_dataset
         self.datafile_size_bound = 262158
         self.max_datasets = max_datasets
         self.__infinite_dataset_iterator = None
         self.no_tokenizer = no_tokenizer
         self.IPFS_fails = 0
-        self.backup_dataset_cap_size = 5e7 # set 50MB limit per folder
+        self.backup_dataset_cap_size = 5e7  # set 50MB limit per folder
         self.IPFS_fails_max = 10
         self.num_batches = num_batches
 
         # Ensure dataset_names is formatted correctly
         if isinstance(self.dataset_names, str):
             self.dataset_names = [self.dataset_names]
 
         allowed_datasets = bittensor.__datasets__ + ["default"]
         for dataset_name in self.dataset_names:
             if dataset_name not in allowed_datasets:
                 self.dataset_names.remove(dataset_name)
-                warnings.warn(f"Requested dataset {dataset_name} not in allowed datasets: {allowed_datasets}")
+                warnings.warn(
+                    f"Requested dataset {dataset_name} not in allowed datasets: {allowed_datasets}"
+                )
 
         # Retrieve a random slice of the genesis dataset
         self.data = []
         self.data_reserved = []
 
         # Used to refresh corpus if we've exhausted the whole dataset
         self.refresh_corpus = True
 
         self.build_hash_table()
 
         os.makedirs(os.path.expanduser(data_dir), exist_ok=True)
 
         self.data_queue = ThreadQueue(
-            producer_target = self.reserve_multiple_data,
-            producer_arg = (self.num_batches, ),
-            buffer_size = 1
+            producer_target=self.reserve_multiple_data,
+            producer_arg=(self.num_batches,),
+            buffer_size=1,
         )
 
     def __del__(self):
         self.close()
 
     def close(self):
         self.data_queue.close()
 
     def get_folder_size(self, folder):
-        r""" Get the size (in byte) of a folder inside the data_dir.
+        r"""Get the size (in byte) of a folder inside the data_dir.
         Args:
             folder (str):
                 The name of the folder
 
         Returns:
             total_size (int):
                 The memory size of the folder (in byte).
@@ -205,185 +210,226 @@
                 # skip if it is symbolic link
                 if not os.path.islink(fp):
                     total_size += os.path.getsize(fp)
 
         return total_size
 
     def load_hash(self, file_meta):
-        r""" Load a hash from disk.
+        r"""Load a hash from disk.
         Args:
             file_meta (dict of str: int):
                 Specify the details of the dataset in the format of {'Name': , 'Hash':}.
 
         Returns:
             text (str):
                 The text in the file.
         """
 
-        full_path = os.path.expanduser(os.path.join(self.data_dir, file_meta['Folder'], file_meta['Hash']))
+        full_path = os.path.expanduser(
+            os.path.join(self.data_dir, file_meta["Folder"], file_meta["Hash"])
+        )
         if os.path.exists(full_path):
             try:
-                with open(full_path, mode='r') as f:
+                with open(full_path, mode="r") as f:
                     text = f.read()
 
-                logger.success("Loaded from disk:".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+                logger.success(
+                    "Loaded from disk:".ljust(20)
+                    + "<blue>{}</blue>".format(file_meta["Name"])
+                )
             except Exception:
-                logger.success("Could not load from disk:".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+                logger.success(
+                    "Could not load from disk:".ljust(20)
+                    + "<blue>{}</blue>".format(file_meta["Name"])
+                )
                 pass
 
             return text
 
         return None
 
     def save_hash(self, file_meta, text):
-        r""" Save a hash to disk.
+        r"""Save a hash to disk.
         Args:
             file_meta (dict of str: int):
                 Specify the details of the dataset in the format of {'Name': , 'Hash':}.
             text (str):
                 The string to save to the file.
 
         Returns:
             text (str):
                 The text in the file.
         """
-        folder_path = os.path.expanduser(os.path.join(self.data_dir, file_meta['Folder']))
-        full_path = os.path.expanduser(os.path.join(self.data_dir, file_meta['Folder'], file_meta['Hash']))
+        folder_path = os.path.expanduser(
+            os.path.join(self.data_dir, file_meta["Folder"])
+        )
+        full_path = os.path.expanduser(
+            os.path.join(self.data_dir, file_meta["Folder"], file_meta["Hash"])
+        )
         if not os.path.exists(folder_path):
             os.makedirs(folder_path)
         try:
-            with open(full_path, mode = 'w+') as f:
+            with open(full_path, mode="w+") as f:
                 f.write(text)
-                logger.success("Saved:".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+                logger.success(
+                    "Saved:".ljust(20) + "<blue>{}</blue>".format(file_meta["Name"])
+                )
             return True
 
         except Exception as E:
-            logger.warning("Save failed:".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+            logger.warning(
+                "Save failed:".ljust(20) + "<blue>{}</blue>".format(file_meta["Name"])
+            )
             return False
 
     def get_text(self, file_meta):
-        r""" Either load a file from disk or download it from IPFS
+        r"""Either load a file from disk or download it from IPFS
         Args:
             file_meta (dict of str: int):
                 Specify the details of the file in the format of {'Name': , 'Hash':}.
 
         Return:
             text (str):
                 The text that we get from the file (from disk or IPFS).
         """
         text = None
         response = self.get_ipfs_directory(self.text_dir, file_meta)
         if (response != None) and (response.status_code == 200):
             try:
-                text = json.loads(response.text)['Data']
+                text = json.loads(response.text)["Data"]
             except json.decoder.JSONDecodeError:
                 text = response.text
 
             self.IPFS_fails = 0
 
-            if self.save_dataset and self.dataset_hashes[file_meta['Folder']]['Size'] < self.backup_dataset_cap_size:
-                self.save_hash( file_meta, text )
-                self.dataset_hashes[file_meta['Folder']]['Size'] += file_meta['Size']
+            if (
+                self.save_dataset
+                and self.dataset_hashes[file_meta["Folder"]]["Size"]
+                < self.backup_dataset_cap_size
+            ):
+                self.save_hash(file_meta, text)
+                self.dataset_hashes[file_meta["Folder"]]["Size"] += file_meta["Size"]
 
         else:
-            logger.warning("Failed to get text".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+            logger.warning(
+                "Failed to get text".ljust(20)
+                + "<blue>{}</blue>".format(file_meta["Name"])
+            )
             self.IPFS_fails += 1
 
         return text
 
-    def get_dataset(self , file_meta):
-        r""" Either load a dataset, which is a list of hashes, from disk or download it from IPFS
+    def get_dataset(self, file_meta):
+        r"""Either load a dataset, which is a list of hashes, from disk or download it from IPFS
         Args:
             file_meta (dict of str: int):
                 Specify the details of the dataset in the format of {'Name': , 'Hash':}.
 
         Return:
             hashes (list):
                 The hashes from the dataset downloaded from disk or IPFS.
         """
         # --- Load text from path
-        logger.success( f"Getting dataset: {file_meta['Name']}" )
+        logger.success(f"Getting dataset: {file_meta['Name']}")
 
         hashes = self.load_hash(file_meta)
 
         if hashes != None:
             hashes = json.loads(hashes)
 
         # --- If couldnt load from path, download text.
         else:
             response = self.get_ipfs_directory(self.dataset_dir, file_meta)
             if (response != None) and (response.status_code == 200):
                 self.IPFS_fails = 0
                 hashes = response.json()
 
                 # --- Save text if the save_dataset flag is on.
-                if self.save_dataset :
-                    self.save_hash(file_meta, json.dumps(response.json()) )
+                if self.save_dataset:
+                    self.save_hash(file_meta, json.dumps(response.json()))
 
             else:
                 self.IPFS_fails += 1
-                logger.warning("Failed to get dataset".ljust(20) + "<blue>{}</blue>".format(file_meta['Name']))
+                logger.warning(
+                    "Failed to get dataset".ljust(20)
+                    + "<blue>{}</blue>".format(file_meta["Name"])
+                )
                 return None
 
         if hashes == None:
             return None
         else:
             for h in hashes:
-                h['Folder'] = file_meta['Name']
+                h["Folder"] = file_meta["Name"]
             return hashes
 
     def get_hashes_from_dataset(self):
-        r""" Getting directories .
+        r"""Getting directories .
         Where a directory could be leading to a data file or a directory file.
 
         Returns:
             directories (:type:`list`, `required`)
                 A list of directory.
                     directory: Map{ Name: str, Hash: str, Size: int }:
                         A random directory that lead to a datafile.
         """
+
         def get_hashes(dataset_meta):
             if self.IPFS_fails > self.IPFS_fails_max:
                 sub_directories = json.loads(self.load_hash(dataset_meta))
                 for sub_directory in sub_directories:
-                    sub_directory['Folder'] = dataset_meta['Name']
+                    sub_directory["Folder"] = dataset_meta["Name"]
             else:
                 sub_directories = self.get_dataset(dataset_meta)
 
             if sub_directories != None:
                 return sub_directories
 
             return []
 
         directories = []
         self.IPFS_fails = 0
 
-        if self.dataset_names == ['default']:
+        if self.dataset_names == ["default"]:
             i = 0
             dataset_hashes = list(self.dataset_hashes.values())
             random.shuffle(dataset_hashes)
 
             for dataset_hash in dataset_hashes:
-                dataset_meta = {'Folder': 'mountain', 'Name': dataset_hash['Name'], 'Hash': dataset_hash['Hash']}
+                dataset_meta = {
+                    "Folder": "mountain",
+                    "Name": dataset_hash["Name"],
+                    "Hash": dataset_hash["Hash"],
+                }
                 directories += get_hashes(dataset_meta)
                 i += 1
                 if i >= self.max_datasets:
                     break
 
         else:
             for key in self.dataset_names:
                 if key in self.dataset_hashes.keys():
-                    dataset_meta = {'Folder': 'mountain','Name': key, 'Hash': self.dataset_hashes[key]['Hash'] }
+                    dataset_meta = {
+                        "Folder": "mountain",
+                        "Name": key,
+                        "Hash": self.dataset_hashes[key]["Hash"],
+                    }
                     directories += get_hashes(dataset_meta)
 
                 else:
-                    logger.error('Incorrect dataset name:'.ljust(20) + " <red>{}</red>.".format(key)+' Must be one of the following {}'.format(bittensor.__datasets__))
+                    logger.error(
+                        "Incorrect dataset name:".ljust(20)
+                        + " <red>{}</red>.".format(key)
+                        + " Must be one of the following {}".format(
+                            bittensor.__datasets__
+                        )
+                    )
 
         if len(directories) == 0:
-            logger.error('Could not get any directory from IPFS or local.')
+            logger.error("Could not get any directory from IPFS or local.")
             directories = None
 
         return directories
 
     def get_root_text_hash(self, file_meta):
         r"""
         With recursion, from the given directory, get a directory that leads to a datafile.
@@ -393,60 +439,73 @@
                 The original directory to look up a datafile for.
 
         Returns:
             directory: Map{ Name: str, Hash: str, Size: int }:
                 A random directory that lead to a datafile.
         """
         # --- If the size of directory is small, it is leads to data file, return the data file.
-        if file_meta['Size'] <= self.datafile_size_bound:
+        if file_meta["Size"] <= self.datafile_size_bound:
             return file_meta
 
         # --- Else, the directory leads to more directories, return a random data file within the directories.
         else:
             response = self.get_ipfs_directory(self.text_dir, file_meta)
             # --- Return none if the request failed.
             if (response == None) or (response.status_code != 200):
-                logger.warning("Failed to retrieve directory, ignoring directory:".ljust(20) + "<blue>{}</blue>".format(file_meta))
+                logger.warning(
+                    "Failed to retrieve directory, ignoring directory:".ljust(20)
+                    + "<blue>{}</blue>".format(file_meta)
+                )
                 return None
 
             # --- Pick a random sub_directory, run recursion until we have found a data file
             else:
                 sub_directories = response.json()
-                if sub_directories and 'Links' in sub_directories.keys() and len(sub_directories['Links']) >= 1:
-                    random_sub_directory = random.choice(sub_directories['Links'])
+                if (
+                    sub_directories
+                    and "Links" in sub_directories.keys()
+                    and len(sub_directories["Links"]) >= 1
+                ):
+                    random_sub_directory = random.choice(sub_directories["Links"])
 
                     # --- Fill the name of the random_sub_directory if it is empty.
-                    if random_sub_directory['Name'] == '':
-                        random_sub_directory['Name'] = file_meta['Name']
-                        random_sub_directory['Folder'] = file_meta['Folder']
-
+                    if random_sub_directory["Name"] == "":
+                        random_sub_directory["Name"] = file_meta["Name"]
+                        random_sub_directory["Folder"] = file_meta["Folder"]
 
                     return self.get_root_text_hash(random_sub_directory)
                 else:
-                    logger.warning("Directory seems empty, ignoring directory:".ljust(20) + "<blue>{}</blue>". format(file_meta))
+                    logger.warning(
+                        "Directory seems empty, ignoring directory:".ljust(20)
+                        + "<blue>{}</blue>".format(file_meta)
+                    )
         return None
 
     def get_text_from_local(self, min_data_len):
-
-        folders = os.listdir( os.path.expanduser (self.data_dir))
-        if self.dataset_names == ['default']:
+        folders = os.listdir(os.path.expanduser(self.data_dir))
+        if self.dataset_names == ["default"]:
             folders_avail = folders
             random.shuffle(folders_avail)
-            folders_avail = folders_avail[:self.max_datasets]
+            folders_avail = folders_avail[: self.max_datasets]
         else:
             folders_avail = []
             for dataset_name in self.dataset_names:
                 if dataset_name in folders:
                     folders_avail.append(dataset_name)
             random.shuffle(folders_avail)
 
         files = []
         for folder in folders_avail:
-            file_names = os.listdir(os.path.expanduser(os.path.join(self.data_dir, folder)))
-            sub_files = [{'Name': file_name,'Folder': folder, 'Hash': file_name} for file_name in file_names]
+            file_names = os.listdir(
+                os.path.expanduser(os.path.join(self.data_dir, folder))
+            )
+            sub_files = [
+                {"Name": file_name, "Folder": folder, "Hash": file_name}
+                for file_name in file_names
+            ]
             files += sub_files
 
         random.shuffle(files)
         data_corpus = []
         total_dataset_len = 0
 
         for text_file in files:
@@ -454,21 +513,21 @@
             text = self.load_hash(text_file)
 
             if text != None:
                 text_list = text.split()
                 data_corpus.extend(text_list)
                 total_dataset_len += len(text_list)
 
-            if (total_dataset_len > min_data_len) :
+            if total_dataset_len > min_data_len:
                 break
 
         return data_corpus
 
-    def construct_text_corpus(self, min_data_len = 0):
-        """ Main function for generating the text data.
+    def construct_text_corpus(self, min_data_len=0):
+        """Main function for generating the text data.
         1. Get directories from a random dataset_hash (dataset_hash is the result from calling pin/ls).
         2. Pick a random directory and get the directory that would lead to a datafile.
         3. Get text from the directory.
         4. Repeat 2,3 until we have reached the min data length
 
         Returns:
             text: str:
@@ -487,46 +546,68 @@
             if directories:
                 total_dataset_size = 0
                 total_dataset_len = 0
                 i = 0
 
                 # --- Dont stop until the corpus size and the minimum data_length was reached.
                 n_workers = cpu_count() if self.num_workers == 0 else self.num_workers
-                with concurrent.futures.ThreadPoolExecutor(max_workers=n_workers) as executor:
-                    while (total_dataset_len < min_data_len) and (self.IPFS_fails <= self.IPFS_fails_max):
+                with concurrent.futures.ThreadPoolExecutor(
+                    max_workers=n_workers
+                ) as executor:
+                    while (total_dataset_len < min_data_len) and (
+                        self.IPFS_fails <= self.IPFS_fails_max
+                    ):
                         future_map = {}
                         for idx, call_arg in enumerate(directories[:n_workers]):
                             future = executor.submit(self.get_text, call_arg)
                             future_map[future] = call_arg
 
-                        for i, future in enumerate(concurrent.futures.as_completed(future_map)):
+                        for i, future in enumerate(
+                            concurrent.futures.as_completed(future_map)
+                        ):
                             text = future.result()
                             if text is not None:
                                 text_list = text.split()
                                 data_corpus.extend(text_list)
                                 total_dataset_len += len(text_list)
 
-                        logger.success("Loaded from IPFS".ljust(20) + f"<yellow>{ round(total_dataset_len / min_data_len * 100) }%</yellow>  " + "<blue>{}</blue>".format([file_meta['Name'] for file_meta in directories[:n_workers]]))
+                        logger.success(
+                            "Loaded from IPFS".ljust(20)
+                            + f"<yellow>{ round(total_dataset_len / min_data_len * 100) }%</yellow>  "
+                            + "<blue>{}</blue>".format(
+                                [
+                                    file_meta["Name"]
+                                    for file_meta in directories[:n_workers]
+                                ]
+                            )
+                        )
                         directories = directories[n_workers:]
 
             else:
-                logger.error("It appears the directory is empty... Restart your miner to try again.")
+                logger.error(
+                    "It appears the directory is empty... Restart your miner to try again."
+                )
 
         except Exception as e:
-            logger.error("Ran into exception when trying to retrieve dataset from IPFS: {}".format(e))
-
+            logger.error(
+                "Ran into exception when trying to retrieve dataset from IPFS: {}".format(
+                    e
+                )
+            )
 
         if len(data_corpus) == 0:
-            logger.error("Fail to construct any text from IPFS, getting from local instead.")
+            logger.error(
+                "Fail to construct any text from IPFS, getting from local instead."
+            )
             data_corpus = self.get_text_from_local(min_data_len)
 
         return data_corpus
 
-    def reserve_multiple_data(self, epoch_length = 100, multiples = 2):
-        r""" Make sure the reserved data meet the multiple,
+    def reserve_multiple_data(self, epoch_length=100, multiples=2):
+        r"""Make sure the reserved data meet the multiple,
         If not, then keep constructing text corpus.
         Arg:
             epoch_length (int, optional):
                 A dataloader for a subset of the dataset of epoch_length is returned.
 
             multiples (int, optional):
                 The number of dataloader that the data_reserved should be able to create.
@@ -534,33 +615,33 @@
         Return:
             success (bool):
                 If we have got the data ready.
         """
         logger.success(f"Reserving data with multiples: {multiples}")
         data_size = epoch_length * self.batch_size * self.block_size
 
-        while len(self.data_reserved) < data_size * multiples :
-            self.data_reserved += self.construct_text_corpus(min_data_len = data_size)
+        while len(self.data_reserved) < data_size * multiples:
+            self.data_reserved += self.construct_text_corpus(min_data_len=data_size)
 
         logger.success(f"Dataset download completed, {multiples} copy of data reserved")
         return True
 
     def set_data_size(self, batch_size, block_size):
-        r""" Update the size of data (batch_size, block_size) that we need.
+        r"""Update the size of data (batch_size, block_size) that we need.
 
         Args:
             batch_size(int, required):
                 The batch_size of data that should be produced by dataloader.
 
             block_size(int, required):
                 The block_size of data that should be produced by dataloader.
         """
+
         def check_valid(size):
-            r""" Check if the size is a valid positive intiget, if not, return False.
-            """
+            r"""Check if the size is a valid positive intiget, if not, return False."""
             if size <= 0 or (not isinstance(size, int)):
                 return False
             else:
                 return True
 
         old_batch_size = self.batch_size
         old_block_size = self.block_size
@@ -574,18 +655,20 @@
         # empty the queue
         while not self.data_queue.queue.empty():
             self.data_queue.queue.get()
 
         # empty the dataset_iterator with the old sizing
         self.__infinite_dataset_iterator = iter([])
 
-        logger.success(f"Updated data size: batch_size: {old_batch_size} --> {self.batch_size}, block_size: {old_block_size} --> {self.block_size}")
+        logger.success(
+            f"Updated data size: batch_size: {old_batch_size} --> {self.batch_size}, block_size: {old_block_size} --> {self.block_size}"
+        )
 
-    def dataloader(self, epoch_length = 100):
-        r""" Creates a torch dataloader out of a subclass of this class.
+    def dataloader(self, epoch_length=100):
+        r"""Creates a torch dataloader out of a subclass of this class.
 
         Args:
             epoch_length (int, optional):
                 A dataloader for a subset of the dataset of epoch_length is returned.
 
         Returns:
             torch.utils.data.dataloader.DataLoader: Pytorch dataloader.
@@ -596,39 +679,43 @@
             self.reserve_multiple_data(self.num_batches, 1)
 
         self.data = self.data_reserved[:data_size]
 
         del self.data_reserved[:data_size]
 
         # Datalaoder calls self._getitem_ functions until the self.data uses up, and group the result by batch size
-        return DataLoader(self,
-                    shuffle=True,
-                    batch_size=self.batch_size,
-                    num_workers=self.num_workers,
-                    drop_last=True)
+        return DataLoader(
+            self,
+            shuffle=True,
+            batch_size=self.batch_size,
+            num_workers=self.num_workers,
+            drop_last=True,
+        )
 
     def set_dataset_iterator(self):
-        r""" Get a new dataset that is ready from the queue. The result would be updated to self.__infinite_dataset_iterator__ .
-        """
+        r"""Get a new dataset that is ready from the queue. The result would be updated to self.__infinite_dataset_iterator__ ."""
         success = False
         while not success:
-            if not self.data_queue.queue.empty() :
-                ready = self.data_queue.queue.get() # the queue stores a bool ready signal
+            if not self.data_queue.queue.empty():
+                ready = (
+                    self.data_queue.queue.get()
+                )  # the queue stores a bool ready signal
                 dataset = self.dataloader(self.num_batches)
                 if dataset:
-                    self.__infinite_dataset_iterator = iter([input for input in dataset])
+                    self.__infinite_dataset_iterator = iter(
+                        [input for input in dataset]
+                    )
                     success = True
             else:
                 time.sleep(2)
 
         return
 
     def __next__(self):
-        """Returns the next element from the dataset.
-        """
+        """Returns the next element from the dataset."""
         if self.__infinite_dataset_iterator == None:
             self.set_dataset_iterator()
 
         try:
             return next(self.__infinite_dataset_iterator)
 
         except StopIteration:
@@ -639,52 +726,60 @@
         """Returns number of samples (blocks) of dataset
 
         Returns:
             length: int
         """
         if (self.data == None) or (self.block_size == None) or (self.block_size == 0):
             return 0
-        return round( len(self.data) / self.block_size )
+        return round(len(self.data) / self.block_size)
 
     def __getitem__(self, idx: int) -> Union[str, torch.tensor]:
-        """ Returns a block of sentences from text dataset.
+        """Returns a block of sentences from text dataset.
 
-            Args:
-                idx: index of data input
+        Args:
+            idx: index of data input
 
-            Returns:
-                torch.tensor(dix)
+        Returns:
+            torch.tensor(dix)
         """
         start_idx = (idx * self.block_size) % len(self.data)
         end_idx = start_idx + self.block_size
         text = " ".join(self.data[start_idx:end_idx])
 
         if self.no_tokenizer is True:
             return text
         else:
             tokens = self.tokenizer(text, padding=True, truncation=True)["input_ids"]
-            return torch.tensor(tokens, dtype=torch.long)[:self.block_size]
+            return torch.tensor(tokens, dtype=torch.long)[: self.block_size]
 
     def build_hash_table(self):
         self.IPFS_fails = 0
         self.dataset_hashes = {}
         response = None
 
-        mountain_meta = {'Name': 'mountain', 'Folder': 'meta_data', 'Hash': self.mountain_hash}
+        mountain_meta = {
+            "Name": "mountain",
+            "Folder": "meta_data",
+            "Hash": self.mountain_hash,
+        }
 
         while response == None:
             self.IPFS_fails += 1
             response = self.get_ipfs_directory(self.text_dir, mountain_meta)
 
             if response:
-                dataset_hashes = response.json()['Links']
+                dataset_hashes = response.json()["Links"]
                 if self.save_dataset:
-                    self.save_hash(mountain_meta, json.dumps(dataset_hashes) )
+                    self.save_hash(mountain_meta, json.dumps(dataset_hashes))
 
             if self.IPFS_fails > self.IPFS_fails_max and response == None:
                 dataset_hashes = json.loads(self.load_hash(mountain_meta))
                 break
 
         for i in dataset_hashes:
-            name = i['Name'][:-4]
-            dataset_meta = {'Name': name, 'Hash': i['Hash'], 'Size': self.get_folder_size(name) }
+            name = i["Name"][:-4]
+            dataset_meta = {
+                "Name": name,
+                "Hash": i["Hash"],
+                "Size": self.get_folder_size(name),
+            }
             self.dataset_hashes[name] = dataset_meta
```

### Comparing `bittensor-5.3.1/bittensor/_dataset/dataset_mock.py` & `bittensor-5.3.2/bittensor/_dataset/dataset_mock.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 """ Implementation for the mock dataset which returns dummy tokenized text.
 """
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
@@ -23,15 +22,16 @@
 from loguru import logger
 import bittensor
 from . import dataset_impl
 
 
 logger = logger.opt(colors=True)
 
-class MockGenesisTextDataset( dataset_impl.Dataset ):
+
+class MockGenesisTextDataset(dataset_impl.Dataset):
     def __init__(
         self,
         block_size,
         batch_size,
         num_workers,
         dataset_names,
         data_dir,
@@ -40,15 +40,15 @@
         no_tokenizer,
         num_batches,
     ):
         super().__init__()
         self.block_size = block_size
         self.batch_size = batch_size
         self.num_workers = num_workers
-        self.tokenizer = bittensor.tokenizer( version = bittensor.__version__ )
+        self.tokenizer = bittensor.tokenizer(version=bittensor.__version__)
         self.dataset_names = dataset_names
         self.data_dir = data_dir
         self.save_dataset = save_dataset
         self.datafile_size_bound = 262158
         self.max_datasets = max_datasets
         self.__infinite_dataset_iterator = None
         self.no_tokenizer = no_tokenizer
@@ -59,57 +59,58 @@
 
     def close(self):
         pass
 
     def __del__(self):
         self.close()
 
-    def construct_text_corpus(self, min_data_len = 0):
+    def construct_text_corpus(self, min_data_len=0):
         data_corpus = []
         total_dataset_len = 0
         i = 0
-        while (total_dataset_len < min_data_len):
+        while total_dataset_len < min_data_len:
             text = "lorem ipsum data is not here this is super fake but maybe you could still learn from it?"
             text_list = text.split()
             data_corpus.extend(text_list)
             total_dataset_len += len(text_list)
             i += 1
         return data_corpus
 
-    def _fill_data(self, epoch_length:int = 100):
+    def _fill_data(self, epoch_length: int = 100):
         data_size = epoch_length * self.batch_size * self.block_size
 
         # Make sure the data remained is at least as big as data_size
-        while len(self.data_remained) < (data_size) :
-            self.data_remained += self.construct_text_corpus(min_data_len = data_size)
+        while len(self.data_remained) < (data_size):
+            self.data_remained += self.construct_text_corpus(min_data_len=data_size)
 
         self.data = self.data_remained[:data_size]
         del self.data_remained[:data_size]
 
-    def dataloader(self, epoch_length = 100):
-        """ Creates a torch dataloader out of a subclass of this class.
+    def dataloader(self, epoch_length=100):
+        """Creates a torch dataloader out of a subclass of this class.
 
         Args:
             epoch_length (int, optional): The epoch length of the miner. If this length is not set or if it is larger than the dataset,
             then a dataloader for the entire dataset is returned. Otherwise, a dataloader for a subset of the dataset of epoch_length
             is returned. Defaults to None.
 
         Returns:
             torch.utils.data.dataloader.DataLoader: Pytorch dataloader.
         """
         self._fill_data(epoch_length)
-        return DataLoader(self,
-                    shuffle=True,
-                    batch_size=self.batch_size,
-                    num_workers=self.num_workers,
-                    drop_last=True)
+        return DataLoader(
+            self,
+            shuffle=True,
+            batch_size=self.batch_size,
+            num_workers=self.num_workers,
+            drop_last=True,
+        )
 
     def __next__(self):
-        """Returns the next element from the dataset.
-        """
+        """Returns the next element from the dataset."""
         if self.__infinite_dataset_iterator == None:
             self.__infinite_dataset_iterator = iter(list(self.dataloader()))
         try:
             return next(self.__infinite_dataset_iterator)
         except StopIteration:
             self.__infinite_dataset_iterator = iter(list(self.dataloader()))
             return next(self.__infinite_dataset_iterator)
@@ -118,27 +119,31 @@
         """Returns number of samples (blocks) of dataset
 
         Returns:
             length: int
         """
         if (self.data == None) or (self.block_size == None) or (self.block_size == 0):
             return 0
-        return round( len(self.data) / self.block_size )
+        return round(len(self.data) / self.block_size)
 
     def __getitem__(self, idx):
-        """ Returns a block of sentences from text dataset.
+        """Returns a block of sentences from text dataset.
 
-            Args:
-                idx: index of data input
+        Args:
+            idx: index of data input
 
-            Returns:
-                torch.tensor(dix)
+        Returns:
+            torch.tensor(dix)
         """
         start_idx = (idx * self.block_size) % len(self.data)
         end_idx = start_idx + self.block_size
         if self.no_tokenizer == False:
-            tokenized_text = torch.tensor(self.tokenizer(" ".join(self.data[start_idx:end_idx]), truncation=True)['input_ids'], dtype=torch.long)
+            tokenized_text = torch.tensor(
+                self.tokenizer(" ".join(self.data[start_idx:end_idx]), truncation=True)[
+                    "input_ids"
+                ],
+                dtype=torch.long,
+            )
         elif self.no_tokenizer == True:
             tokenized_text = " ".join(self.data[start_idx:end_idx])
 
-        return tokenized_text[:self.block_size]
-
+        return tokenized_text[: self.block_size]
```

### Comparing `bittensor-5.3.1/bittensor/_dataset/thread_queue.py` & `bittensor-5.3.2/bittensor/_dataset/thread_queue.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,17 +16,18 @@
 # DEALINGS IN THE SOFTWARE.
 
 import threading
 import time
 import queue
 from loguru import logger
 
+
 class ProducerThread(threading.Thread):
-    r""" This producer thread runs in backgraound to fill the queue with the result of the target function.
-    """
+    r"""This producer thread runs in backgraound to fill the queue with the result of the target function."""
+
     def __init__(self, queue, target, arg, name=None):
         r"""Initialization.
         Args:
             queue (:obj:`queue.Queue`, `required`)
                 The queue to be filled.
 
             target (:obj:`function`, `required`)
@@ -34,59 +35,61 @@
 
             arg (:type:`tuple`, `required`)
                 The arguments to be passed to the target function.
 
             name (:type:`str`, `optional`)
                 The name of this threading object.
         """
-        super(ProducerThread,self).__init__()
+        super(ProducerThread, self).__init__()
         self.name = name
         self.target = target
         self.arg = arg
         self.queue = queue
         self._stop_event = threading.Event()
 
     def run(self):
-        r""" Work of the thread. Keep checking if the queue is full, if it is not full, run the target function to fill the queue.
-        """
+        r"""Work of the thread. Keep checking if the queue is full, if it is not full, run the target function to fill the queue."""
         while not self.stopped():
             if not self.queue.full():
-                item = self.target(*self.arg, self.queue.qsize()+1 )
+                item = self.target(*self.arg, self.queue.qsize() + 1)
                 self.queue.put(item)
             time.sleep(2)
         return
 
     def stop(self):
         self._stop_event.set()
 
     def stopped(self):
         return self._stop_event.is_set()
 
-class ThreadQueue():
-    r""" Manages the queue the producer thread that monitor and fills the queue.
-    """
-    def __init__(self, producer_target, producer_arg, buffer_size = 2):
-        """ Setup the queue and start the producer thread.
+
+class ThreadQueue:
+    r"""Manages the queue the producer thread that monitor and fills the queue."""
+
+    def __init__(self, producer_target, producer_arg, buffer_size=2):
+        """Setup the queue and start the producer thread.
 
         Args:
 
             producer_target (:obj:`function`, `required`)
                 The target function to run when the queue is not full.
 
             producer_arg (:type:`tuple`, `required`)
                 The arguments to be passed to the target function.
 
             buffer_size (:type:`int`, `optional`)
                 The size of the queue.
         """
         self.buffer_size = buffer_size
         self.queue = queue.Queue(buffer_size)
-        self.producer = ProducerThread(name='producer', queue = self.queue, target = producer_target, arg = producer_arg)
+        self.producer = ProducerThread(
+            name="producer", queue=self.queue, target=producer_target, arg=producer_arg
+        )
         self.producer.start()
 
     def __del__(self):
         self.close()
 
     def close(self):
         self.producer.stop()
         self.producer.join()
-        logger.success('Dataset Thread Queue Closed')
+        logger.success("Dataset Thread Queue Closed")
```

### Comparing `bittensor-5.3.1/bittensor/_dendrite/dendrite.py` & `bittensor-5.3.2/bittensor/_dendrite/dendrite.py`

 * *Files 15% similar despite different names*

```diff
@@ -23,229 +23,265 @@
 import bittensor
 
 from grpc import _common
 from typing import Union, Optional, Callable, List, Tuple
 from dataclasses import dataclass
 from abc import ABC, abstractmethod
 
+
 @dataclass
-class DendriteCall( ABC ):
-    """ Base class for all dendrite calls."""
+class DendriteCall(ABC):
+    """Base class for all dendrite calls."""
 
     is_forward: bool
     name: str
 
     def __init__(
-            self,
-            dendrite: 'bittensor.Dendrite',
-            timeout: float = bittensor.__blocktime__
-        ):
+        self, dendrite: "bittensor.Dendrite", timeout: float = bittensor.__blocktime__
+    ):
         self.dendrite = dendrite
         self.completed = False
         self.timeout = timeout
         self.start_time = time.time()
         self.elapsed_time = 0.0
         self.src_version = bittensor.__version_as_int__
         self.dest_hotkey = self.dendrite.axon_info.hotkey
         self.dest_version = self.dendrite.axon_info.version
-        self.return_code: bittensor.proto.ReturnCode = bittensor.proto.ReturnCode.Success
-        self.return_message: str = 'Success'
+        self.return_code: bittensor.proto.ReturnCode = (
+            bittensor.proto.ReturnCode.Success
+        )
+        self.return_message: str = "Success"
 
     def __repr__(self) -> str:
         return f"DendriteCall( {bittensor.utils.codes.code_to_string(self.return_code)}, to:{self.dest_hotkey[:4]} + ... + {self.dest_hotkey[-4:]}, msg:{self.return_message})"
 
     def __str__(self) -> str:
         return self.__repr__()
 
     @abstractmethod
-    def get_callable(self) -> Callable: ...
+    def get_callable(self) -> Callable:
+        ...
 
     @abstractmethod
-    def get_inputs_shape(self) -> torch.Size: ...
+    def get_inputs_shape(self) -> torch.Size:
+        ...
 
     @abstractmethod
-    def get_outputs_shape(self) -> torch.Size: ...
+    def get_outputs_shape(self) -> torch.Size:
+        ...
 
     @abstractmethod
-    def get_request_proto(self) -> object: ...
+    def get_request_proto(self) -> object:
+        ...
 
     def _get_request_proto(self) -> object:
         request_proto = self.get_request_proto()
         request_proto.version = self.src_version
         request_proto.timeout = self.timeout
         return request_proto
 
     @abstractmethod
-    def apply_response_proto( self, response_proto: object ): ...
+    def apply_response_proto(self, response_proto: object):
+        ...
 
-    def _apply_response_proto( self, response_proto: object ):
-        self.apply_response_proto( response_proto )
-        try: self.return_message = response_proto.return_message
-        except: pass
-        try: self.return_code = response_proto.return_code
-        except: pass
+    def _apply_response_proto(self, response_proto: object):
+        self.apply_response_proto(response_proto)
+        try:
+            self.return_message = response_proto.return_message
+        except:
+            pass
+        try:
+            self.return_code = response_proto.return_code
+        except:
+            pass
 
     def end(self):
         self.end_time = time.time()
         self.elapsed = self.end_time - self.start_time
         self.completed = True
 
     @property
-    def did_timeout( self ) -> bool: return self.return_code == bittensor.proto.ReturnCode.Timeout
+    def did_timeout(self) -> bool:
+        return self.return_code == bittensor.proto.ReturnCode.Timeout
+
     @property
-    def is_success( self ) -> bool: return self.return_code == bittensor.proto.ReturnCode.Success
+    def is_success(self) -> bool:
+        return self.return_code == bittensor.proto.ReturnCode.Success
+
     @property
-    def did_fail( self ) -> bool: return not self.is_success
+    def did_fail(self) -> bool:
+        return not self.is_success
 
     def log_outbound(self):
         bittensor.logging.rpc_log(
-            axon = False,
-            forward = self.is_forward,
-            is_response = False,
-            code = self.return_code,
-            call_time = 0,
-            pubkey = self.dest_hotkey,
-            uid = self.dendrite.uid,
-            inputs = self.get_inputs_shape(),
-            outputs = self.get_outputs_shape(),
-            message = self.return_message,
-            synapse = self.name,
+            axon=False,
+            forward=self.is_forward,
+            is_response=False,
+            code=self.return_code,
+            call_time=0,
+            pubkey=self.dest_hotkey,
+            uid=self.dendrite.uid,
+            inputs=self.get_inputs_shape(),
+            outputs=self.get_outputs_shape(),
+            message=self.return_message,
+            synapse=self.name,
         )
 
     def log_inbound(self):
         bittensor.logging.rpc_log(
-            axon = False,
-            forward = self.is_forward,
-            is_response = True,
-            code = self.return_code,
-            call_time = self.elapsed,
-            pubkey = self.dest_hotkey,
-            uid = self.dendrite.uid,
-            inputs = self.get_inputs_shape(),
-            outputs = self.get_outputs_shape(),
-            message = self.return_message,
-            synapse = self.name
+            axon=False,
+            forward=self.is_forward,
+            is_response=True,
+            code=self.return_code,
+            call_time=self.elapsed,
+            pubkey=self.dest_hotkey,
+            uid=self.dendrite.uid,
+            inputs=self.get_inputs_shape(),
+            outputs=self.get_outputs_shape(),
+            message=self.return_message,
+            synapse=self.name,
         )
 
-class Dendrite( ABC, torch.nn.Module ):
+
+class Dendrite(ABC, torch.nn.Module):
     def __init__(
-            self,
-            keypair: Union[ 'bittensor.Wallet', 'bittensor.Keypair'],
-            axon: Union[ 'bittensor.axon_info', 'bittensor.axon' ],
-            uid : int = 0,
-            ip: str = None,
-            grpc_options: List[Tuple[str,object]] =
-                    [('grpc.max_send_message_length', -1),
-                     ('grpc.max_receive_message_length', -1),
-                     ('grpc.keepalive_time_ms', 100000) ]
-        ):
-        """ Dendrite abstract class
-            Args:
-                keypair (:obj:`Union[ 'bittensor.Wallet', 'bittensor.Keypair']`, `required`):
-                    bittensor keypair used for signing messages.
-                axon (:obj:Union[`bittensor.axon_info`, 'bittensor.axon'], `required`):
-                    bittensor axon object or its info used to create the connection.
-                grpc_options (:obj:`List[Tuple[str,object]]`, `optional`):
-                    grpc options to pass through to channel.
+        self,
+        keypair: Union["bittensor.Wallet", "bittensor.Keypair"],
+        axon: Union["bittensor.axon_info", "bittensor.axon"],
+        uid: int = 0,
+        ip: str = None,
+        grpc_options: List[Tuple[str, object]] = [
+            ("grpc.max_send_message_length", -1),
+            ("grpc.max_receive_message_length", -1),
+            ("grpc.keepalive_time_ms", 100000),
+        ],
+    ):
+        """Dendrite abstract class
+        Args:
+            keypair (:obj:`Union[ 'bittensor.Wallet', 'bittensor.Keypair']`, `required`):
+                bittensor keypair used for signing messages.
+            axon (:obj:Union[`bittensor.axon_info`, 'bittensor.axon'], `required`):
+                bittensor axon object or its info used to create the connection.
+            grpc_options (:obj:`List[Tuple[str,object]]`, `optional`):
+                grpc options to pass through to channel.
         """
         super(Dendrite, self).__init__()
         self.uuid = str(uuid.uuid1())
         self.uid = uid
         self.ip = ip
-        self.keypair = keypair.hotkey if isinstance( keypair, bittensor.Wallet ) else keypair
-        self.axon_info = axon.info() if isinstance( axon, bittensor.axon ) else axon
+        self.keypair = (
+            keypair.hotkey if isinstance(keypair, bittensor.Wallet) else keypair
+        )
+        self.axon_info = axon.info() if isinstance(axon, bittensor.axon) else axon
         if self.axon_info.ip == self.ip:
             self.endpoint_str = "localhost:" + str(self.axon_info.port)
         else:
-            self.endpoint_str = self.axon_info.ip + ':' + str(self.axon_info.port)
-        self.channel = grpc.aio.insecure_channel( self.endpoint_str, options = grpc_options )
+            self.endpoint_str = self.axon_info.ip + ":" + str(self.axon_info.port)
+        self.channel = grpc.aio.insecure_channel(
+            self.endpoint_str, options=grpc_options
+        )
         self.state_dict = _common.CYGRPC_CONNECTIVITY_STATE_TO_CHANNEL_CONNECTIVITY
         self.loop = asyncio.get_event_loop()
 
-    async def apply( self, dendrite_call: 'DendriteCall' ) -> DendriteCall:
-        """ Applies a dendrite call to the endpoint.
-            Args:
-                dendrite_call (:obj:`DendriteCall`, `required`):
-                    Dendrite call to apply.
-            Returns:
-                DendriteCall: Dendrite call with response.
+    async def apply(self, dendrite_call: "DendriteCall") -> DendriteCall:
+        """Applies a dendrite call to the endpoint.
+        Args:
+            dendrite_call (:obj:`DendriteCall`, `required`):
+                Dendrite call to apply.
+        Returns:
+            DendriteCall: Dendrite call with response.
         """
-        bittensor.logging.trace('Dendrite.apply()')
+        bittensor.logging.trace("Dendrite.apply()")
         try:
             dendrite_call.log_outbound()
             asyncio_future = dendrite_call.get_callable()(
-                request = dendrite_call._get_request_proto(),
-                timeout = dendrite_call.timeout,
-                metadata = (
-                    ('rpc-auth-header','Bittensor'),
-                    ('bittensor-signature', self.sign() ),
-                    ('bittensor-version',str(bittensor.__version_as_int__)),
+                request=dendrite_call._get_request_proto(),
+                timeout=dendrite_call.timeout,
+                metadata=(
+                    ("rpc-auth-header", "Bittensor"),
+                    ("bittensor-signature", self.sign()),
+                    ("bittensor-version", str(bittensor.__version_as_int__)),
+                ),
+            )
+            bittensor.logging.trace(
+                "Dendrite.apply() awaiting response from: {}".format(
+                    self.axon_info.hotkey
+                )
+            )
+            response_proto = await asyncio.wait_for(
+                asyncio_future, timeout=dendrite_call.timeout
+            )
+            dendrite_call._apply_response_proto(response_proto)
+            bittensor.logging.trace(
+                "Dendrite.apply() received response from: {}".format(
+                    self.axon_info.hotkey
                 )
             )
-            bittensor.logging.trace( 'Dendrite.apply() awaiting response from: {}'.format( self.axon_info.hotkey ) )
-            response_proto = await asyncio.wait_for( asyncio_future, timeout = dendrite_call.timeout )
-            dendrite_call._apply_response_proto( response_proto )
-            bittensor.logging.trace( 'Dendrite.apply() received response from: {}'.format( self.axon_info.hotkey ) )
 
         # Request failed with GRPC code.
         except grpc.RpcError as rpc_error_call:
             dendrite_call.return_code = rpc_error_call.code()
-            dendrite_call.return_message = 'GRPC error code: {}, details: {}'.format( rpc_error_call.code(), str(rpc_error_call.details()) )
-            bittensor.logging.trace( 'Dendrite.apply() rpc error: {}'.format( dendrite_call.return_message ) )
+            dendrite_call.return_message = "GRPC error code: {}, details: {}".format(
+                rpc_error_call.code(), str(rpc_error_call.details())
+            )
+            bittensor.logging.trace(
+                "Dendrite.apply() rpc error: {}".format(dendrite_call.return_message)
+            )
 
         # Catch timeout errors.
         except asyncio.TimeoutError:
             dendrite_call.return_code = bittensor.proto.ReturnCode.Timeout
-            dendrite_call.return_message = 'GRPC request timeout after: {}s'.format( dendrite_call.timeout)
-            bittensor.logging.trace( 'Denrite.apply() timeout error: {}'.format( dendrite_call.return_message ) )
+            dendrite_call.return_message = "GRPC request timeout after: {}s".format(
+                dendrite_call.timeout
+            )
+            bittensor.logging.trace(
+                "Denrite.apply() timeout error: {}".format(dendrite_call.return_message)
+            )
 
         except Exception as e:
             # Catch unknown errors.
             dendrite_call.return_code = bittensor.proto.ReturnCode.UnknownException
             dendrite_call.return_message = str(e)
-            bittensor.logging.trace( 'Dendrite.apply() unknown error: {}'.format( dendrite_call.return_message ) )
+            bittensor.logging.trace(
+                "Dendrite.apply() unknown error: {}".format(
+                    dendrite_call.return_message
+                )
+            )
 
         finally:
             dendrite_call.end()
             dendrite_call.log_inbound()
             dendrite_call.elapsed_time = time.time() - dendrite_call.start_time
             return dendrite_call
 
-    def __exit__ ( self ):
+    def __exit__(self):
         self.__del__()
 
-    def close ( self ):
+    def close(self):
         self.__exit__()
 
-    def __del__ ( self ):
+    def __del__(self):
         try:
             result = self.channel._channel.check_connectivity_state(True)
             if self.state_dict[result] != self.state_dict[result].SHUTDOWN:
-                self.loop.run_until_complete ( self.channel.close() )
+                self.loop.run_until_complete(self.channel.close())
         except:
             pass
 
-    def nonce ( self ):
+    def nonce(self):
         return time.monotonic_ns()
 
     def sign(self) -> str:
-        """ Creates a signature for the dendrite and returns it as a string."""
+        """Creates a signature for the dendrite and returns it as a string."""
         nonce = f"{self.nonce()}"
         sender_hotkey = self.keypair.ss58_address
         receiver_hotkey = self.axon_info.hotkey
         message = f"{nonce}.{sender_hotkey}.{receiver_hotkey}.{self.uuid}"
         signature = f"0x{self.keypair.sign(message).hex()}"
         return ".".join([nonce, sender_hotkey, signature, self.uuid])
 
-    def state ( self ):
-        """ Returns the state of the dendrite channel."""
+    def state(self):
+        """Returns the state of the dendrite channel."""
         try:
             return self.state_dict[self.channel._channel.check_connectivity_state(True)]
         except ValueError:
             return "Channel closed"
-
-
-
-
-
-
-
```

### Comparing `bittensor-5.3.1/bittensor/_dendrite/text_prompting/dendrite.py` & `bittensor-5.3.2/bittensor/_dendrite/text_prompting/dendrite.py`

 * *Files 10% similar despite different names*

```diff
@@ -15,180 +15,207 @@
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 import json
 import torch
 import bittensor
 from typing import Callable, List, Union
 
-class DendriteForwardCall( bittensor.DendriteCall ):
 
+class DendriteForwardCall(bittensor.DendriteCall):
     name: str = "text_prompting_forward"
     is_forward: bool = True
-    completion: str = "" # To be filled.
+    completion: str = ""  # To be filled.
 
     def __init__(
         self,
-        dendrite: 'bittensor.TextPromptingDendrite',
+        dendrite: "bittensor.TextPromptingDendrite",
         messages: List[str],
         roles: List[str],
         timeout: float = bittensor.__blocktime__,
     ):
-        super().__init__( dendrite = dendrite, timeout = timeout )
+        super().__init__(dendrite=dendrite, timeout=timeout)
         self.messages = messages
         self.roles = roles
-        self.packed_messages = [json.dumps({"role": role, "content": message}) for role, message in zip(self.roles, self.messages)]
+        self.packed_messages = [
+            json.dumps({"role": role, "content": message})
+            for role, message in zip(self.roles, self.messages)
+        ]
 
     def __repr__(self) -> str:
         return f"DendriteForwardCall( {bittensor.utils.codes.code_to_string(self.return_code)}, to: {self.dest_hotkey[:4]}...{self.dest_hotkey[-4:]}, msg: {self.return_message}, completion: {self.completion.strip()})"
 
-    def __str__(self) -> str: return self.__repr__()
+    def __str__(self) -> str:
+        return self.__repr__()
 
-    def get_callable( self ) -> Callable:
-        return bittensor.grpc.TextPromptingStub( self.dendrite.channel ).Forward
+    def get_callable(self) -> Callable:
+        return bittensor.grpc.TextPromptingStub(self.dendrite.channel).Forward
 
-    def get_request_proto( self ) -> bittensor.proto.ForwardTextPromptingRequest:
-        return bittensor.ForwardTextPromptingRequest( timeout = self.timeout, messages = self.packed_messages )
+    def get_request_proto(self) -> bittensor.proto.ForwardTextPromptingRequest:
+        return bittensor.ForwardTextPromptingRequest(
+            timeout=self.timeout, messages=self.packed_messages
+        )
 
-    def apply_response_proto( self, response_proto: bittensor.ForwardTextPromptingResponse ):
+    def apply_response_proto(
+        self, response_proto: bittensor.ForwardTextPromptingResponse
+    ):
         self.completion = response_proto.response
 
     def get_inputs_shape(self) -> torch.Size:
-        return torch.Size( [len(message) for message in self.packed_messages] )
+        return torch.Size([len(message) for message in self.packed_messages])
 
     def get_outputs_shape(self) -> torch.Size:
-        return torch.Size([ len(self.completion) ] )
+        return torch.Size([len(self.completion)])
 
-    def backward( self, reward: float, timeout: float = None ) -> 'DendriteBackwardCall':
+    def backward(self, reward: float, timeout: float = None) -> "DendriteBackwardCall":
         return self.dendrite.backward(
-            roles = self.roles,
-            messages = self.messages,
-            completion = self.completion,
-            rewards = [ reward ],
-            timeout = self.timeout if timeout is None else bittensor.__blocktime__
+            roles=self.roles,
+            messages=self.messages,
+            completion=self.completion,
+            rewards=[reward],
+            timeout=self.timeout if timeout is None else bittensor.__blocktime__,
         )
 
-    async def async_backward( self, reward: float, timeout: float = None ) -> 'DendriteBackwardCall':
+    async def async_backward(
+        self, reward: float, timeout: float = None
+    ) -> "DendriteBackwardCall":
         return await self.dendrite.async_backward(
-            roles = self.roles,
-            messages = self.messages,
-            completion = self.completion,
-            rewards = [ reward ],
-            timeout = self.timeout if timeout is None else bittensor.__blocktime__
+            roles=self.roles,
+            messages=self.messages,
+            completion=self.completion,
+            rewards=[reward],
+            timeout=self.timeout if timeout is None else bittensor.__blocktime__,
         )
 
 
-class DendriteBackwardCall( bittensor.DendriteCall ):
-
+class DendriteBackwardCall(bittensor.DendriteCall):
     name: str = "text_prompting_backward"
     is_forward: bool = False
 
     def __init__(
         self,
-        dendrite: 'bittensor.TextPromptingDendrite',
+        dendrite: "bittensor.TextPromptingDendrite",
         completion: str,
         messages: List[str],
         roles: List[str],
-        rewards: Union[ List[float], torch.FloatTensor ],
+        rewards: Union[List[float], torch.FloatTensor],
         timeout: float = bittensor.__blocktime__,
     ):
-        super().__init__( dendrite = dendrite, timeout = timeout )
+        super().__init__(dendrite=dendrite, timeout=timeout)
         self.messages = messages
         self.roles = roles
         self.completion = completion
-        self.rewards = rewards if not isinstance( rewards, torch.FloatTensor ) else rewards.tolist()
-        self.packed_messages = [ json.dumps({"role": role, "content": message}) for role, message in zip(self.roles, self.messages)]
+        self.rewards = (
+            rewards if not isinstance(rewards, torch.FloatTensor) else rewards.tolist()
+        )
+        self.packed_messages = [
+            json.dumps({"role": role, "content": message})
+            for role, message in zip(self.roles, self.messages)
+        ]
 
     def __repr__(self) -> str:
         return f"DendriteBackwardCall( {bittensor.utils.codes.code_to_string(self.return_code)}, to: {self.dest_hotkey[:4]}...{self.dest_hotkey[-4:]}, msg: {self.return_message} )"
 
-    def __str__(self) -> str: return self.__repr__()
+    def __str__(self) -> str:
+        return self.__repr__()
 
-    def get_callable( self ) -> Callable:
-        return bittensor.grpc.TextPromptingStub( self.dendrite.channel ).Backward
+    def get_callable(self) -> Callable:
+        return bittensor.grpc.TextPromptingStub(self.dendrite.channel).Backward
 
-    def get_request_proto( self ) -> bittensor.proto.BackwardTextPromptingRequest:
-        return bittensor.BackwardTextPromptingRequest( messages = self.packed_messages, response = self.completion, rewards = self.rewards, timeout = self.timeout )
+    def get_request_proto(self) -> bittensor.proto.BackwardTextPromptingRequest:
+        return bittensor.BackwardTextPromptingRequest(
+            messages=self.packed_messages,
+            response=self.completion,
+            rewards=self.rewards,
+            timeout=self.timeout,
+        )
 
-    def apply_response_proto( self, response_proto: bittensor.ForwardTextPromptingResponse ):
+    def apply_response_proto(
+        self, response_proto: bittensor.ForwardTextPromptingResponse
+    ):
         pass
 
     def get_inputs_shape(self) -> torch.Size:
-        return torch.Size( [len(message) for message in self.packed_messages] )
+        return torch.Size([len(message) for message in self.packed_messages])
 
     def get_outputs_shape(self) -> torch.Size:
-        return torch.Size( [0] )
-
+        return torch.Size([0])
 
-class TextPromptingDendrite( bittensor.Dendrite ):
 
+class TextPromptingDendrite(bittensor.Dendrite):
     def get_stub(self, channel) -> Callable:
         return bittensor.grpc.TextPromptingStub(channel)
 
     def forward(
-            self,
-            roles: List[ str ] ,
-            messages: List[ str ],
-            timeout: float = bittensor.__blocktime__,
-            return_call:bool = True,
-        ) -> Union[ str, DendriteForwardCall ]:
+        self,
+        roles: List[str],
+        messages: List[str],
+        timeout: float = bittensor.__blocktime__,
+        return_call: bool = True,
+    ) -> Union[str, DendriteForwardCall]:
         forward_call = DendriteForwardCall(
-            dendrite = self,
-            messages = messages,
-            roles = roles,
-            timeout = timeout,
-        )
-        response_call = self.loop.run_until_complete( self.apply( dendrite_call = forward_call ) )
-        if return_call: return response_call
-        else: return response_call.completion
+            dendrite=self,
+            messages=messages,
+            roles=roles,
+            timeout=timeout,
+        )
+        response_call = self.loop.run_until_complete(
+            self.apply(dendrite_call=forward_call)
+        )
+        if return_call:
+            return response_call
+        else:
+            return response_call.completion
 
     async def async_forward(
         self,
-        roles: List[ str ],
-        messages: List[ str ],
+        roles: List[str],
+        messages: List[str],
         timeout: float = bittensor.__blocktime__,
         return_call: bool = True,
-    ) -> Union[ str, DendriteForwardCall ]:
+    ) -> Union[str, DendriteForwardCall]:
         forward_call = DendriteForwardCall(
-            dendrite = self,
-            messages = messages,
-            roles = roles,
-            timeout = timeout,
-        )
-        forward_call = await self.apply( dendrite_call = forward_call )
-        if return_call: return forward_call
-        else: return forward_call.completion
+            dendrite=self,
+            messages=messages,
+            roles=roles,
+            timeout=timeout,
+        )
+        forward_call = await self.apply(dendrite_call=forward_call)
+        if return_call:
+            return forward_call
+        else:
+            return forward_call.completion
 
     def backward(
-            self,
-            roles: List[ str ],
-            messages: List[ str ],
-            completion: str,
-            rewards: Union[ List[ float], torch.FloatTensor ],
-            timeout: float = bittensor.__blocktime__,
-        ) -> DendriteBackwardCall:
+        self,
+        roles: List[str],
+        messages: List[str],
+        completion: str,
+        rewards: Union[List[float], torch.FloatTensor],
+        timeout: float = bittensor.__blocktime__,
+    ) -> DendriteBackwardCall:
         backward_call = DendriteBackwardCall(
-            dendrite = self,
-            completion = completion,
-            messages = messages,
-            roles = roles,
-            rewards = rewards,
-            timeout = timeout,
+            dendrite=self,
+            completion=completion,
+            messages=messages,
+            roles=roles,
+            rewards=rewards,
+            timeout=timeout,
         )
-        return self.loop.run_until_complete( self.apply( dendrite_call = backward_call ) )
+        return self.loop.run_until_complete(self.apply(dendrite_call=backward_call))
 
     async def async_backward(
         self,
-        roles: List[ str ],
-        messages: List[ str ],
+        roles: List[str],
+        messages: List[str],
         completion: str,
-        rewards: Union[ List[ float], torch.FloatTensor ],
+        rewards: Union[List[float], torch.FloatTensor],
         timeout: float = bittensor.__blocktime__,
     ) -> DendriteBackwardCall:
         backward_call = DendriteBackwardCall(
-            dendrite = self,
-            completion = completion,
-            messages = messages,
-            roles = roles,
-            rewards = rewards,
-            timeout = timeout,
+            dendrite=self,
+            completion=completion,
+            messages=messages,
+            roles=roles,
+            rewards=rewards,
+            timeout=timeout,
         )
-        return await self.apply( dendrite_call = backward_call )
+        return await self.apply(dendrite_call=backward_call)
```

### Comparing `bittensor-5.3.1/bittensor/_dendrite/text_prompting/dendrite_pool.py` & `bittensor-5.3.2/bittensor/_dendrite/text_prompting/dendrite_pool.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
@@ -18,106 +17,116 @@
 import grpc
 import json
 import torch
 import asyncio
 import bittensor
 from typing import Callable, List, Dict, Union
 
-class TextPromptingDendritePool( torch.nn.Module ):
 
+class TextPromptingDendritePool(torch.nn.Module):
     def __init__(
-            self,
-            keypair: Union[ 'bittensor.Wallet', 'bittensor.Keypair'],
-            metagraph: 'bittensor.metagraph',
-        ):
+        self,
+        keypair: Union["bittensor.Wallet", "bittensor.Keypair"],
+        metagraph: "bittensor.metagraph",
+    ):
         super(TextPromptingDendritePool, self).__init__()
         self.metagraph = metagraph
         self.keypair = keypair
         self.ip = bittensor.utils.networking.get_external_ip()
-        self.dendrites = [ bittensor.text_prompting( axon = axon, keypair = self.keypair, uid = uid, ip = self.ip) for uid, axon in enumerate(self.metagraph.axons) ]
+        self.dendrites = [
+            bittensor.text_prompting(
+                axon=axon, keypair=self.keypair, uid=uid, ip=self.ip
+            )
+            for uid, axon in enumerate(self.metagraph.axons)
+        ]
         self.loop = asyncio.get_event_loop()
-        self.priority_threadpool = bittensor.prioritythreadpool(max_workers = 1)
+        self.priority_threadpool = bittensor.prioritythreadpool(max_workers=1)
 
-    def backward( self,
-            forward_calls: List[ 'DendriteForwardCall' ],
-            rewards: Union[ List[ float ], torch.FloatTensor ],
-            timeout: float = 12.0,
-            priority: int = 1,
-        ):
+    def backward(
+        self,
+        forward_calls: List["DendriteForwardCall"],
+        rewards: Union[List[float], torch.FloatTensor],
+        timeout: float = 12.0,
+        priority: int = 1,
+    ):
         def _backward():
             self.loop.run_until_complete(
-                self.async_backward (
-                    forward_calls = forward_calls,
-                    timeout = timeout,
+                self.async_backward(
+                    forward_calls=forward_calls,
+                    timeout=timeout,
                 )
             )
-        future = self.priority_threadpool.submit(
-            _backward,
-            priority = priority
-        )
+
+        future = self.priority_threadpool.submit(_backward, priority=priority)
         return future.result()
 
-    async def async_backward(self,
-            forward_calls: List[ 'DendriteForwardCall' ],
-            rewards: Union[ List[ float ], torch.FloatTensor ] ,
-            timeout: float = 12.0
-        ):
-        rewards = rewards if not isinstance( rewards, torch.Tensor ) else rewards.tolist()
+    async def async_backward(
+        self,
+        forward_calls: List["DendriteForwardCall"],
+        rewards: Union[List[float], torch.FloatTensor],
+        timeout: float = 12.0,
+    ):
+        rewards = rewards if not isinstance(rewards, torch.Tensor) else rewards.tolist()
+
         async def query():
-            coroutines = [ forward_calls.async_backward( reward ) for call, reward in list(zip( forward_calls, rewards )) ]
-            all_responses = await asyncio.gather( *coroutines )
+            coroutines = [
+                forward_calls.async_backward(reward)
+                for call, reward in list(zip(forward_calls, rewards))
+            ]
+            all_responses = await asyncio.gather(*coroutines)
             return all_responses
+
         await query()
 
     def forward(
-            self,
-            roles: Union[ str, List[str] ],
-            messages: Union[ str, List[str] ],
-            uids: Union[ torch.LongTensor, List[int] ] = None,
-            return_call:bool = True,
-            timeout: float = 12,
-            priority: int = 1,
-        ) -> List['DendriteForwardCall']:
+        self,
+        roles: Union[str, List[str]],
+        messages: Union[str, List[str]],
+        uids: Union[torch.LongTensor, List[int]] = None,
+        return_call: bool = True,
+        timeout: float = 12,
+        priority: int = 1,
+    ) -> List["DendriteForwardCall"]:
         def _forward():
-            bittensor.logging.trace( 'dendrite pool: forward: _forward: start')
+            bittensor.logging.trace("dendrite pool: forward: _forward: start")
             return self.loop.run_until_complete(
-                self.async_forward (
-                    messages = messages,
-                    roles = roles,
-                    uids = uids,
-                    return_call = return_call,
-                    timeout = timeout,
+                self.async_forward(
+                    messages=messages,
+                    roles=roles,
+                    uids=uids,
+                    return_call=return_call,
+                    timeout=timeout,
                 )
             )
-        future = self.priority_threadpool.submit(
-            _forward,
-            priority = priority
-        )
+
+        future = self.priority_threadpool.submit(_forward, priority=priority)
         return future.result()
 
     async def async_forward(
-            self,
-            roles: Union[ str, List[str] ],
-            messages: Union[ str, List[str] ],
-            uids: Union[ torch.LongTensor, List[int] ] = None,
-            return_call:bool = True,
-            timeout: float = 12
-        ) -> List['DendriteForwardCall']:
+        self,
+        roles: Union[str, List[str]],
+        messages: Union[str, List[str]],
+        uids: Union[torch.LongTensor, List[int]] = None,
+        return_call: bool = True,
+        timeout: float = 12,
+    ) -> List["DendriteForwardCall"]:
         # We optionally set the uids to all if uids is None.
-        if uids is None: uids = range( self.metagraph.n.item() )
-        if isinstance( uids, torch.Tensor ): uids = uids.tolist()
+        if uids is None:
+            uids = range(self.metagraph.n.item())
+        if isinstance(uids, torch.Tensor):
+            uids = uids.tolist()
+
         # The following asyncio defintion queries a single endpoint with the message
         # prompt and returns the response.
-        async def call_single_uid( uid: int ) -> str:
+        async def call_single_uid(uid: int) -> str:
             return await self.dendrites[uid].async_forward(
-                roles = roles,
-                messages = messages,
-                return_call = return_call,
-                timeout = timeout
+                roles=roles, messages=messages, return_call=return_call, timeout=timeout
             )
+
         # The following asyncio definition gathers the responses
         # from multiple coroutines for each uid.
         async def query():
-            coroutines = [ call_single_uid( uid ) for uid in uids ]
+            coroutines = [call_single_uid(uid) for uid in uids]
             all_responses = await asyncio.gather(*coroutines)
             return all_responses
-        return await query()
+
+        return await query()
```

### Comparing `bittensor-5.3.1/bittensor/_ipfs/ipfs_impl.py` & `bittensor-5.3.2/bittensor/_ipfs/ipfs_impl.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,38 +1,40 @@
-
 from socket import timeout
 from requests.adapters import HTTPAdapter
 from requests.packages.urllib3.util.retry import Retry
 import requests
 
-class Ipfs():
-    """ Implementation for the dataset class, which handles dataloading from ipfs
-    """
-    def __init__(self):
 
+class Ipfs:
+    """Implementation for the dataset class, which handles dataloading from ipfs"""
+
+    def __init__(self):
         # Used to retrieve directory contentx
-        self.cat = 'http://global.ipfs.opentensor.ai/api/v0/cat'
-        self.node_get = 'http://global.ipfs.opentensor.ai/api/v0/object/get'
-        self.ipns_resolve = 'http://global.ipfs.opentensor.ai/api/v0/name/resolve'
-
-        self.mountain_hash = 'QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX'
-        self.latest_neurons_ipns = "k51qzi5uqu5di1eoe0o91g32tbfsgikva6mvz0jw0414zhxzhiakana67shoh7"
-        self.historical_neurons_ipns = "k51qzi5uqu5dhf5yxm3kqw9hyrv28q492p3t32s23059z911a23l30ai6ziceh"
+        self.cat = "http://global.ipfs.opentensor.ai/api/v0/cat"
+        self.node_get = "http://global.ipfs.opentensor.ai/api/v0/object/get"
+        self.ipns_resolve = "http://global.ipfs.opentensor.ai/api/v0/name/resolve"
+
+        self.mountain_hash = "QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX"
+        self.latest_neurons_ipns = (
+            "k51qzi5uqu5di1eoe0o91g32tbfsgikva6mvz0jw0414zhxzhiakana67shoh7"
+        )
+        self.historical_neurons_ipns = (
+            "k51qzi5uqu5dhf5yxm3kqw9hyrv28q492p3t32s23059z911a23l30ai6ziceh"
+        )
         # Used when current corpus has been exhausted
         self.refresh_corpus = False
 
-
     @staticmethod
     def requests_retry_session(
-            retries=1,
-            backoff_factor=0.5,
-            status_forcelist=(104, 500, 502, 504),
-            session=None,
-        ):
-        """ Creates a retriable session for request calls. This enables
+        retries=1,
+        backoff_factor=0.5,
+        status_forcelist=(104, 500, 502, 504),
+        session=None,
+    ):
+        """Creates a retriable session for request calls. This enables
         automatic retries and back-off retries should any request calls fail.
 
         Args:
             retries (int, optional): Maximum number of retries. Defaults to 3.
             backoff_factor (float, optional): Factor by which to back off if a retry fails. Defaults to 0.3.
             status_forcelist (tuple, optional): A set of integer HTTP status codes that we should force a retry on. Defaults to (500, 502, 504).
             session ([type], optional): Session for which to set up the retries. Defaults to None.
@@ -46,24 +48,30 @@
             total=retries,
             read=retries,
             connect=retries,
             backoff_factor=backoff_factor,
             status_forcelist=status_forcelist,
         )
         adapter = HTTPAdapter(max_retries=retry)
-        session.mount('http://', adapter)
-        session.mount('https://', adapter)
+        session.mount("http://", adapter)
+        session.mount("https://", adapter)
         return session
 
-    def retrieve_directory(self, address: str, params = None, action: str = 'post', timeout: int = 180):
+    def retrieve_directory(
+        self, address: str, params=None, action: str = "post", timeout: int = 180
+    ):
         r"""Connects to Pinata IPFS gateway and retrieves directory.
 
         Returns:
             dict: A dictionary of the files inside of the genesis_datasets and their hashes.
         """
         session = requests.Session()
         session.params.update(params)
-        if action == 'get':
-            response = Ipfs.requests_retry_session(session=session).get(address, timeout=timeout)
-        elif action == 'post':
-            response = Ipfs.requests_retry_session(session=session).post(address, timeout=timeout)
-        return response
+        if action == "get":
+            response = Ipfs.requests_retry_session(session=session).get(
+                address, timeout=timeout
+            )
+        elif action == "post":
+            response = Ipfs.requests_retry_session(session=session).post(
+                address, timeout=timeout
+            )
+        return response
```

### Comparing `bittensor-5.3.1/bittensor/_logging/__init__.py` & `bittensor-5.3.2/bittensor/_logging/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -22,342 +22,384 @@
 import copy
 import torch
 import argparse
 import bittensor
 import bittensor.utils.codes as codes
 
 from loguru import logger
+
 logger = logger.opt(colors=True)
 # Remove default sink.
 try:
-    logger.remove( 0 )
+    logger.remove(0)
 except Exception:
     pass
 
 import re
-def _remove_loguru_ansi_directive( text:str ) -> str:
-    pattern = r'<.*?>'
-    return re.sub(pattern, '', text)
+
+
+def _remove_loguru_ansi_directive(text: str) -> str:
+    pattern = r"<.*?>"
+    return re.sub(pattern, "", text)
+
 
 class logging:
-    """ Standardize logging for bittensor
-    """
-    __has_been_inited__:bool = False
-    __debug_on__:bool = False
-    __trace_on__:bool = False
-    __std_sink__:int = None
-    __file_sink__:int = None
+    """Standardize logging for bittensor"""
+
+    __has_been_inited__: bool = False
+    __debug_on__: bool = False
+    __trace_on__: bool = False
+    __std_sink__: int = None
+    __file_sink__: int = None
 
     def __new__(
-            cls,
-            config: 'bittensor.Config' = None,
-            debug: bool = None,
-            trace: bool = None,
-            record_log: bool = None,
-            logging_dir: str = None,
-        ):
-        r""" Instantiate bittensor logging system backend.
-            Args:
-                config (:obj:`bittensor.Config`, `optional`):
-                    bittensor.logging.config()
-                debug (:obj:`bool`, `optional`):
-                    Turn on debug.
-                trace (:obj:`bool`, `optional`):
-                    Turn on trace.
-                record_log (:obj:`bool`, `optional`):
-                    If true, logs are saved to loggind dir.
-                logging_dir (:obj:`str`, `optional`):
-                    Directory where logs are sunk.
+        cls,
+        config: "bittensor.Config" = None,
+        debug: bool = None,
+        trace: bool = None,
+        record_log: bool = None,
+        logging_dir: str = None,
+    ):
+        r"""Instantiate bittensor logging system backend.
+        Args:
+            config (:obj:`bittensor.Config`, `optional`):
+                bittensor.logging.config()
+            debug (:obj:`bool`, `optional`):
+                Turn on debug.
+            trace (:obj:`bool`, `optional`):
+                Turn on trace.
+            record_log (:obj:`bool`, `optional`):
+                If true, logs are saved to loggind dir.
+            logging_dir (:obj:`str`, `optional`):
+                Directory where logs are sunk.
         """
 
         cls.__has_been_inited__ = True
 
         if config == None:
             config = logging.config()
         config = copy.deepcopy(config)
         config.logging.debug = debug if debug != None else config.logging.debug
         config.logging.trace = trace if trace != None else config.logging.trace
-        config.logging.record_log = record_log if record_log != None else config.logging.record_log
-        config.logging.logging_dir = logging_dir if logging_dir != None else config.logging.logging_dir
+        config.logging.record_log = (
+            record_log if record_log != None else config.logging.record_log
+        )
+        config.logging.logging_dir = (
+            logging_dir if logging_dir != None else config.logging.logging_dir
+        )
 
         # Remove default sink.
         try:
-            logger.remove( 0 )
+            logger.remove(0)
         except Exception:
             pass
 
         # Optionally Remove other sinks.
         if cls.__std_sink__ != None:
-            logger.remove( cls.__std_sink__ )
+            logger.remove(cls.__std_sink__)
         if cls.__file_sink__ != None:
-            logger.remove( cls.__file_sink__ )
+            logger.remove(cls.__file_sink__)
 
         # Add filtered sys.stdout.
-        cls.__std_sink__ = logger.add (
+        cls.__std_sink__ = logger.add(
             sys.stdout,
-            level = 0,
-            filter = cls.log_filter,
-            colorize = True,
-            enqueue = True,
-            backtrace = True,
-            diagnose = True,
-            format = cls.log_formatter
+            level=0,
+            filter=cls.log_filter,
+            colorize=True,
+            enqueue=True,
+            backtrace=True,
+            diagnose=True,
+            format=cls.log_formatter,
         )
 
         cls.set_debug(config.logging.debug)
         cls.set_trace(config.logging.trace)
 
         # ---- Setup logging to root ----
         if config.logging.record_log:
             filepath = config.logging.logging_dir + "/logs.log"
-            cls.__file_sink__ = logger.add (
+            cls.__file_sink__ = logger.add(
                 filepath,
-                filter = cls.log_save_filter,
-                enqueue = True,
-                backtrace = True,
-                diagnose = True,
-                format = cls.log_save_formatter,
+                filter=cls.log_save_filter,
+                enqueue=True,
+                backtrace=True,
+                diagnose=True,
+                format=cls.log_save_formatter,
                 rotation="25 MB",
-                retention="10 days"
+                retention="10 days",
             )
 
     @classmethod
     def config(cls):
-        """ Get config from the argument parser
-            Return: bittensor.config object
+        """Get config from the argument parser
+        Return: bittensor.config object
         """
         parser = argparse.ArgumentParser()
-        logging.add_args( parser )
-        return bittensor.config( parser )
+        logging.add_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
     def help(cls):
-        """ Print help to stdout
-        """
+        """Print help to stdout"""
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        print (cls.__new__.__doc__)
+        cls.add_args(parser)
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None ):
-        """ Accept specific arguments fro parser
-        """
-        prefix_str = '' if prefix == None else prefix + '.'
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
+        """Accept specific arguments fro parser"""
+        prefix_str = "" if prefix == None else prefix + "."
         if prefix is not None:
             if bittensor.defaults.get(prefix, d=None) == None:
                 setattr(bittensor.defaults, prefix, bittensor.Config())
             getattr(bittensor.defaults, prefix).logging = bittensor.defaults.logging
         try:
-            parser.add_argument('--' + prefix_str + 'logging.debug', action='store_true', help='''Turn on bittensor debugging information''', default = bittensor.defaults.logging.debug )
-            parser.add_argument('--' + prefix_str + 'logging.trace', action='store_true', help='''Turn on bittensor trace level information''', default = bittensor.defaults.logging.trace )
-            parser.add_argument('--' + prefix_str + 'logging.record_log', action='store_true', help='''Turns on logging to file.''', default = bittensor.defaults.logging.record_log )
-            parser.add_argument('--' + prefix_str + 'logging.logging_dir', type=str, help='Logging default root directory.', default = bittensor.defaults.logging.logging_dir )
+            parser.add_argument(
+                "--" + prefix_str + "logging.debug",
+                action="store_true",
+                help="""Turn on bittensor debugging information""",
+                default=bittensor.defaults.logging.debug,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "logging.trace",
+                action="store_true",
+                help="""Turn on bittensor trace level information""",
+                default=bittensor.defaults.logging.trace,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "logging.record_log",
+                action="store_true",
+                help="""Turns on logging to file.""",
+                default=bittensor.defaults.logging.record_log,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "logging.logging_dir",
+                type=str,
+                help="Logging default root directory.",
+                default=bittensor.defaults.logging.logging_dir,
+            )
         except argparse.ArgumentError:
             # re-parsing arguments.
             pass
 
     @classmethod
     def add_defaults(cls, defaults):
-        """ Adds parser defaults to object from enviroment variables.
-        """
+        """Adds parser defaults to object from enviroment variables."""
         defaults.logging = bittensor.Config()
-        defaults.logging.debug = os.getenv('BT_LOGGING_DEBUG') if os.getenv('BT_LOGGING_DEBUG') != None else False
-        defaults.logging.trace = os.getenv('BT_LOGGING_TRACE') if os.getenv('BT_LOGGING_DEBUG') != None else False
-        defaults.logging.record_log = os.getenv('BT_LOGGING_RECORD_LOG') if os.getenv('BT_LOGGING_RECORD_LOG') != None else False
-        defaults.logging.logging_dir = os.getenv('BT_LOGGING_LOGGING_DIR') if os.getenv('BT_LOGGING_LOGGING_DIR') != None else '~/.bittensor/miners'
+        defaults.logging.debug = (
+            os.getenv("BT_LOGGING_DEBUG")
+            if os.getenv("BT_LOGGING_DEBUG") != None
+            else False
+        )
+        defaults.logging.trace = (
+            os.getenv("BT_LOGGING_TRACE")
+            if os.getenv("BT_LOGGING_DEBUG") != None
+            else False
+        )
+        defaults.logging.record_log = (
+            os.getenv("BT_LOGGING_RECORD_LOG")
+            if os.getenv("BT_LOGGING_RECORD_LOG") != None
+            else False
+        )
+        defaults.logging.logging_dir = (
+            os.getenv("BT_LOGGING_LOGGING_DIR")
+            if os.getenv("BT_LOGGING_LOGGING_DIR") != None
+            else "~/.bittensor/miners"
+        )
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
-        """ Check config
-        """
+    def check_config(cls, config: "bittensor.Config"):
+        """Check config"""
         assert config.logging
 
     @classmethod
-    def set_debug(cls, debug_on: bool = True ):
-        """ Set debug for the specific cls class
-        """
+    def set_debug(cls, debug_on: bool = True):
+        """Set debug for the specific cls class"""
         if not cls.__has_been_inited__:
             cls()
         cls.__debug_on__ = debug_on
 
     @classmethod
     def set_trace(cls, trace_on: bool = True):
-        """ Set trace back for the specific cls class
-        """
+        """Set trace back for the specific cls class"""
         if not cls.__has_been_inited__:
             cls()
         cls.__trace_on__ = trace_on
 
     @classmethod
-    def get_level( cls ) -> int:
+    def get_level(cls) -> int:
         return 5 if cls.__trace_on__ else 10 if cls.__debug_on__ else 20
 
     @classmethod
-    def log_filter(cls, record ):
-        """ Filter out debug log if debug is not on
-        """
+    def log_filter(cls, record):
+        """Filter out debug log if debug is not on"""
         if cls.get_level() <= record["level"].no:
             return True
         else:
             return False
 
     @classmethod
-    def log_save_filter(cls, record ):
+    def log_save_filter(cls, record):
         if cls.get_level() < record["level"].no:
             return True
         else:
             return False
 
     @classmethod
     def log_formatter(cls, record):
-        """ Log with different format according to record['extra']
-        """
-        extra = record['extra']
-        if 'rpc' in extra:
-            return "<blue>{time:YYYY-MM-DD HH:mm:ss.SSS}</blue> | " + extra['code_str'] + " | {extra[prefix]} | {extra[direction]} | {extra[arrow]} | {extra[uid_str]} | {extra[inputs]} | {extra[call_time]} | {extra[key_str]} | {extra[rpc_message]} | {extra[synapse]} \n"
+        """Log with different format according to record['extra']"""
+        extra = record["extra"]
+        if "rpc" in extra:
+            return (
+                "<blue>{time:YYYY-MM-DD HH:mm:ss.SSS}</blue> | "
+                + extra["code_str"]
+                + " | {extra[prefix]} | {extra[direction]} | {extra[arrow]} | {extra[uid_str]} | {extra[inputs]} | {extra[call_time]} | {extra[key_str]} | {extra[rpc_message]} | {extra[synapse]} \n"
+            )
         else:
             return "<blue>{time:YYYY-MM-DD HH:mm:ss.SSS}</blue> | <level>{level: ^16}</level> | {message}\n"
 
     @classmethod
     def log_save_formatter(cls, record):
-        extra = record['extra']
-        if 'rpc' in extra:
-            return "{time:YYYY-MM-DD HH:mm:ss.SSS} | " + extra['code_str'] + " | {extra[prefix]} | {extra[direction]} | {extra[arrow]} | {extra[uid_str]} | {extra[inputs]} | {extra[call_time]} | {extra[key_str]} | {extra[rpc_message]} \n"
+        extra = record["extra"]
+        if "rpc" in extra:
+            return (
+                "{time:YYYY-MM-DD HH:mm:ss.SSS} | "
+                + extra["code_str"]
+                + " | {extra[prefix]} | {extra[direction]} | {extra[arrow]} | {extra[uid_str]} | {extra[inputs]} | {extra[call_time]} | {extra[key_str]} | {extra[rpc_message]} \n"
+            )
         else:
             if cls.__trace_on__:
                 return "{time:YYYY-MM-DD HH:mm:ss.SSS} | <level>{level: ^16}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | {message}\n"
             else:
                 return "{time:YYYY-MM-DD HH:mm:ss.SSS} | <level>{level: ^16}</level> | {message}\n"
 
-
     @classmethod
     def rpc_log(
-                 cls,
-                 axon: bool,
-                 forward: bool,
-                 is_response: bool,
-                 code:int,
-                 call_time: float,
-                 pubkey: str,
-                 uid: int = None,
-                 inputs:list = None,
-                 outputs:list = None,
-                 message:str = '',
-                 synapse:'bittensor.Synapse' = None
-        ):
-        """ Debug logging for the communication between endpoints with axon/dendrite
-        """
+        cls,
+        axon: bool,
+        forward: bool,
+        is_response: bool,
+        code: int,
+        call_time: float,
+        pubkey: str,
+        uid: int = None,
+        inputs: list = None,
+        outputs: list = None,
+        message: str = "",
+        synapse: "bittensor.Synapse" = None,
+    ):
+        """Debug logging for the communication between endpoints with axon/dendrite"""
 
         if axon:
             prefix = "Synapse"
         else:
             prefix = "Dendrite"
-        prefix = prefix.center(len('Dendrite'))
+        prefix = prefix.center(len("Dendrite"))
 
         if forward:
             direction = "Forward"
         else:
             direction = "Backward"
-        direction = direction.center(len('Backward'))
+        direction = direction.center(len("Backward"))
 
         if is_response:
             arrow = "<---"
         else:
             arrow = "--->"
 
-        key_str = "{}".format( pubkey )
+        key_str = "{}".format(pubkey)
         call_time_str = "{:.2f}s".format(call_time).center(6)
 
         if uid != None:
             uid_str = str(uid).center(5)
         else:
             uid_str = "-".center(5)
 
-        code_color = codes.code_to_loguru_color( code )
-        code_string = codes.code_to_string( code )
+        code_color = codes.code_to_loguru_color(code)
+        code_string = codes.code_to_string(code)
         code_string = code_string.center(16)
         code_str = "<" + code_color + ">" + code_string + "</" + code_color + ">"
 
         if is_response:
-            inputs = str(list(outputs)) if outputs != None else '[x]'
+            inputs = str(list(outputs)) if outputs != None else "[x]"
         else:
-            inputs = str(list(inputs)) if inputs != None else '[x]'
+            inputs = str(list(inputs)) if inputs != None else "[x]"
         inputs = inputs.center(15)
 
         if synapse != None:
             synapse = codes.code_to_synapse(synapse)
 
-        rpc_message = message if message != None else 'None'
+        rpc_message = message if message != None else "None"
         logger.debug(
-                    'rpc',
-                    rpc=True,
-                    prefix=prefix,
-                    direction=direction,
-                    arrow=arrow,
-                    call_time = call_time_str,
-                    uid_str=uid_str,
-                    key_str=key_str,
-                    code_str=code_str,
-                    inputs = inputs,
-                    rpc_message = rpc_message,
-                    synapse = synapse
+            "rpc",
+            rpc=True,
+            prefix=prefix,
+            direction=direction,
+            arrow=arrow,
+            call_time=call_time_str,
+            uid_str=uid_str,
+            key_str=key_str,
+            code_str=code_str,
+            inputs=inputs,
+            rpc_message=rpc_message,
+            synapse=synapse,
         )
 
     @classmethod
-    def _format( cls, prefix:object, sufix:object = None ):
-        """ Format logging message
-        """
-        if isinstance( prefix, torch.Tensor ):
+    def _format(cls, prefix: object, sufix: object = None):
+        """Format logging message"""
+        if isinstance(prefix, torch.Tensor):
             prefix = prefix.detach()
         if sufix != None:
-            if isinstance( sufix, torch.Tensor ):
-                sufix = 'shape: {}'.format( str(sufix.shape) ) + " data: {}".format( str( sufix.detach() ) )
+            if isinstance(sufix, torch.Tensor):
+                sufix = "shape: {}".format(str(sufix.shape)) + " data: {}".format(
+                    str(sufix.detach())
+                )
             else:
-                sufix = "{}".format( str( sufix ) )
+                sufix = "{}".format(str(sufix))
         else:
             sufix = ""
-        log_msg = str( prefix ).ljust(30) + str( sufix )
-        return _remove_loguru_ansi_directive( log_msg )
+        log_msg = str(prefix).ljust(30) + str(sufix)
+        return _remove_loguru_ansi_directive(log_msg)
 
     @classmethod
-    def success( cls, prefix:object, sufix:object = None ):
-        """ Success logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.success( cls._format( prefix, sufix ) )
+    def success(cls, prefix: object, sufix: object = None):
+        """Success logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.success(cls._format(prefix, sufix))
 
     @classmethod
-    def warning( cls, prefix:object, sufix:object = None ):
-        """ Warning logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.warning( cls._format( prefix, sufix ) )
+    def warning(cls, prefix: object, sufix: object = None):
+        """Warning logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.warning(cls._format(prefix, sufix))
 
     @classmethod
-    def error( cls, prefix:object, sufix:object= None  ):
-        """ Error logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.error( cls._format( prefix, sufix ) )
+    def error(cls, prefix: object, sufix: object = None):
+        """Error logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.error(cls._format(prefix, sufix))
 
     @classmethod
-    def info( cls, prefix:object, sufix:object = None ):
-        """ Info logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.info( cls._format( prefix, sufix ) )
-
+    def info(cls, prefix: object, sufix: object = None):
+        """Info logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.info(cls._format(prefix, sufix))
 
     @classmethod
-    def debug( cls, prefix:object, sufix:object = None ):
-        """ Info logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.debug( cls._format( prefix, sufix ) )
+    def debug(cls, prefix: object, sufix: object = None):
+        """Info logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.debug(cls._format(prefix, sufix))
 
     @classmethod
-    def trace( cls, prefix:object, sufix:object = None ):
-        """ Info logging
-        """
-        if not cls.__has_been_inited__: cls()
-        logger.trace( cls._format( prefix, sufix ) )
+    def trace(cls, prefix: object, sufix: object = None):
+        """Info logging"""
+        if not cls.__has_been_inited__:
+            cls()
+        logger.trace(cls._format(prefix, sufix))
```

### Comparing `bittensor-5.3.1/bittensor/_metagraph/__init__.py` & `bittensor-5.3.2/bittensor/_metagraph/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -23,180 +23,364 @@
 
 from os import listdir
 from os.path import join
 from typing import List, Optional
 
 
 # Return directory path from network and netuid
-def get_save_dir(  network: str, netuid: int ) -> str:
-    return os.path.expanduser(f"~/.bittensor/metagraphs/network-{str(network)}/netuid-{str(netuid)}/")
+def get_save_dir(network: str, netuid: int) -> str:
+    return os.path.expanduser(
+        f"~/.bittensor/metagraphs/network-{str(network)}/netuid-{str(netuid)}/"
+    )
 
-def latest_block_path( dir_path: str ) -> int:
-        latest_block = -1
-        latest_file_full_path = None
-        for filename in listdir(dir_path):
-            full_path_filename = os.path.expanduser(join(dir_path, filename))
-            try:
-                block_number = int(filename.split('-')[1].split('.')[0])
-                if block_number > latest_block:
-                    latest_block = block_number
-                    latest_file_full_path = full_path_filename
-            except Exception as e:
-                pass
-        if not latest_file_full_path:
-            raise ValueError( f"Metagraph not found at: {dir_path}" )
-        else:
-            return latest_file_full_path
 
-class metagraph( torch.nn.Module ):
+def latest_block_path(dir_path: str) -> int:
+    latest_block = -1
+    latest_file_full_path = None
+    for filename in listdir(dir_path):
+        full_path_filename = os.path.expanduser(join(dir_path, filename))
+        try:
+            block_number = int(filename.split("-")[1].split(".")[0])
+            if block_number > latest_block:
+                latest_block = block_number
+                latest_file_full_path = full_path_filename
+        except Exception as e:
+            pass
+    if not latest_file_full_path:
+        raise ValueError(f"Metagraph not found at: {dir_path}")
+    else:
+        return latest_file_full_path
+
 
+class metagraph(torch.nn.Module):
     @property
-    def S(self) -> torch.FloatTensor: return self.total_stake
+    def S(self) -> torch.FloatTensor:
+        return self.total_stake
+
     @property
-    def R(self) -> torch.FloatTensor: return self.ranks
+    def R(self) -> torch.FloatTensor:
+        return self.ranks
+
     @property
-    def I(self) -> torch.FloatTensor: return self.incentive
+    def I(self) -> torch.FloatTensor:
+        return self.incentive
+
     @property
-    def E(self) -> torch.FloatTensor: return self.emission
+    def E(self) -> torch.FloatTensor:
+        return self.emission
+
     @property
-    def C(self) -> torch.FloatTensor: return self.consensus
+    def C(self) -> torch.FloatTensor:
+        return self.consensus
+
     @property
-    def T(self) -> torch.FloatTensor: return self.trust
+    def T(self) -> torch.FloatTensor:
+        return self.trust
+
     @property
-    def Tv(self) -> torch.FloatTensor: return self.validator_trust
+    def Tv(self) -> torch.FloatTensor:
+        return self.validator_trust
+
     @property
-    def D(self) -> torch.FloatTensor: return self.dividends
+    def D(self) -> torch.FloatTensor:
+        return self.dividends
+
     @property
-    def B(self) -> torch.FloatTensor: return self.bonds
+    def B(self) -> torch.FloatTensor:
+        return self.bonds
+
     @property
-    def W(self) -> torch.FloatTensor: return self.weights
+    def W(self) -> torch.FloatTensor:
+        return self.weights
+
     @property
-    def hotkeys( self ) -> List[str]: return [ axon.hotkey for axon in self.axons ]
+    def hotkeys(self) -> List[str]:
+        return [axon.hotkey for axon in self.axons]
+
     @property
-    def coldkeys( self ) -> List[str]: return [ axon.coldkey for axon in self.axons ]
+    def coldkeys(self) -> List[str]:
+        return [axon.coldkey for axon in self.axons]
+
     @property
-    def addresses( self ) -> List[str]: return [ axon.ip_str() for axon in self.axons ]
+    def addresses(self) -> List[str]:
+        return [axon.ip_str() for axon in self.axons]
 
-    def __str__(self): return "Metagraph(netuid:{}, n:{}, block:{}, network:{})".format(self.netuid, self.n.item(), self.block.item(), self.network)
+    def __str__(self):
+        return "Metagraph(netuid:{}, n:{}, block:{}, network:{})".format(
+            self.netuid, self.n.item(), self.block.item(), self.network
+        )
 
-    def __repr__(self): return self.__str__()
+    def __repr__(self):
+        return self.__str__()
 
-    def metadata(self) -> dict: return {"netuid": self.netuid, "n": self.n.item(), "block": self.block.item(), "network": self.network, "version": bittensor.__version__ }
+    def metadata(self) -> dict:
+        return {
+            "netuid": self.netuid,
+            "n": self.n.item(),
+            "block": self.block.item(),
+            "network": self.network,
+            "version": bittensor.__version__,
+        }
 
-    def __init__(self, netuid: int, network: str = 'finney', lite: bool = True, sync: bool = True ) -> 'metagraph':
+    def __init__(
+        self, netuid: int, network: str = "finney", lite: bool = True, sync: bool = True
+    ) -> "metagraph":
         super(metagraph, self).__init__()
         self.netuid = netuid
         self.network = network
-        self.version = torch.nn.Parameter( torch.tensor( [ bittensor.__version_as_int__ ], dtype=torch.int64), requires_grad=False )
-        self.n = torch.nn.Parameter( torch.tensor( [0], dtype=torch.int64), requires_grad = False )
-        self.block = torch.nn.Parameter( torch.tensor( [0], dtype=torch.int64), requires_grad = False )
-        self.stake = torch.nn.Parameter( torch.tensor( [], dtype=torch.float32 ), requires_grad=False )
-        self.total_stake = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.ranks = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.trust = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.consensus = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.validator_trust = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.incentive = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.emission = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.dividends = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.active = torch.nn.Parameter(  torch.tensor( [], dtype=torch.int64), requires_grad=False )
-        self.last_update = torch.nn.Parameter(  torch.tensor( [], dtype=torch.int64), requires_grad=False )
-        self.validator_permit = torch.nn.Parameter(  torch.tensor( [], dtype=torch.bool), requires_grad=False )
-        self.weights = torch.nn.Parameter(  torch.tensor( [], dtype=torch.float32), requires_grad=False )
-        self.bonds = torch.nn.Parameter(  torch.tensor( [], dtype=torch.int64), requires_grad=False )
-        self.uids = torch.nn.Parameter( torch.tensor([], dtype = torch.int64),requires_grad=False )
+        self.version = torch.nn.Parameter(
+            torch.tensor([bittensor.__version_as_int__], dtype=torch.int64),
+            requires_grad=False,
+        )
+        self.n = torch.nn.Parameter(
+            torch.tensor([0], dtype=torch.int64), requires_grad=False
+        )
+        self.block = torch.nn.Parameter(
+            torch.tensor([0], dtype=torch.int64), requires_grad=False
+        )
+        self.stake = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.total_stake = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.ranks = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.trust = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.consensus = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.validator_trust = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.incentive = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.emission = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.dividends = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.active = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.int64), requires_grad=False
+        )
+        self.last_update = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.int64), requires_grad=False
+        )
+        self.validator_permit = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.bool), requires_grad=False
+        )
+        self.weights = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.float32), requires_grad=False
+        )
+        self.bonds = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.int64), requires_grad=False
+        )
+        self.uids = torch.nn.Parameter(
+            torch.tensor([], dtype=torch.int64), requires_grad=False
+        )
         self.axons = []
         if sync:
-            self.sync( block = None, lite = lite )
+            self.sync(block=None, lite=lite)
 
-    def sync ( self, block: Optional[int] = None, lite: bool = True, subtensor: Optional['bittensor.Subtensor'] = None ) -> 'metagraph':
+    def sync(
+        self,
+        block: Optional[int] = None,
+        lite: bool = True,
+        subtensor: Optional["bittensor.Subtensor"] = None,
+    ) -> "metagraph":
         if not subtensor:
-            subtensor = bittensor.subtensor( network = self.network )
+            subtensor = bittensor.subtensor(network=self.network)
         if lite:
-            self.neurons = subtensor.neurons_lite( block = block, netuid = self.netuid )
+            self.neurons = subtensor.neurons_lite(block=block, netuid=self.netuid)
         else:
-            self.neurons = subtensor.neurons( block = block, netuid = self.netuid )
+            self.neurons = subtensor.neurons(block=block, netuid=self.netuid)
 
         self.lite = lite
-        self.n = torch.nn.Parameter( torch.tensor( len(self.neurons), dtype=torch.int64 ), requires_grad=False )
-        self.version = torch.nn.Parameter( torch.tensor( [bittensor.__version_as_int__], dtype=torch.int64 ), requires_grad=False )
-        self.block = torch.nn.Parameter( torch.tensor( block if block else subtensor.block, dtype=torch.int64 ), requires_grad=False )
-        self.uids = torch.nn.Parameter( torch.tensor( [ neuron.uid for neuron in self.neurons ], dtype=torch.int64 ), requires_grad=False )
-        self.trust = torch.nn.Parameter( torch.tensor( [ neuron.trust for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.consensus = torch.nn.Parameter( torch.tensor( [ neuron.consensus for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.incentive = torch.nn.Parameter( torch.tensor( [ neuron.incentive for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.dividends = torch.nn.Parameter( torch.tensor( [ neuron.dividends for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.ranks = torch.nn.Parameter( torch.tensor( [ neuron.rank for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.emission = torch.nn.Parameter( torch.tensor( [ neuron.emission for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.active = torch.nn.Parameter( torch.tensor( [ neuron.active for neuron in self.neurons ], dtype=torch.int64 ), requires_grad=False )
-        self.last_update = torch.nn.Parameter( torch.tensor( [ neuron.last_update for neuron in self.neurons ], dtype=torch.int64 ), requires_grad=False )
-        self.validator_permit = torch.nn.Parameter( torch.tensor( [ neuron.validator_permit for neuron in self.neurons ], dtype=torch.bool ), requires_grad=False )
-        self.validator_trust = torch.nn.Parameter( torch.tensor( [ neuron.validator_trust for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.total_stake = torch.nn.Parameter( torch.tensor( [ neuron.total_stake.tao for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.stake = torch.nn.Parameter( torch.tensor( [ neuron.stake for neuron in self.neurons ], dtype=torch.float32 ), requires_grad=False )
-        self.axons = [ n.axon_info for n in self.neurons ]
+        self.n = torch.nn.Parameter(
+            torch.tensor(len(self.neurons), dtype=torch.int64), requires_grad=False
+        )
+        self.version = torch.nn.Parameter(
+            torch.tensor([bittensor.__version_as_int__], dtype=torch.int64),
+            requires_grad=False,
+        )
+        self.block = torch.nn.Parameter(
+            torch.tensor(block if block else subtensor.block, dtype=torch.int64),
+            requires_grad=False,
+        )
+        self.uids = torch.nn.Parameter(
+            torch.tensor([neuron.uid for neuron in self.neurons], dtype=torch.int64),
+            requires_grad=False,
+        )
+        self.trust = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.trust for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.consensus = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.consensus for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.incentive = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.incentive for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.dividends = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.dividends for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.ranks = torch.nn.Parameter(
+            torch.tensor([neuron.rank for neuron in self.neurons], dtype=torch.float32),
+            requires_grad=False,
+        )
+        self.emission = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.emission for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.active = torch.nn.Parameter(
+            torch.tensor([neuron.active for neuron in self.neurons], dtype=torch.int64),
+            requires_grad=False,
+        )
+        self.last_update = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.last_update for neuron in self.neurons], dtype=torch.int64
+            ),
+            requires_grad=False,
+        )
+        self.validator_permit = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.validator_permit for neuron in self.neurons], dtype=torch.bool
+            ),
+            requires_grad=False,
+        )
+        self.validator_trust = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.validator_trust for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.total_stake = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.total_stake.tao for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.stake = torch.nn.Parameter(
+            torch.tensor(
+                [neuron.stake for neuron in self.neurons], dtype=torch.float32
+            ),
+            requires_grad=False,
+        )
+        self.axons = [n.axon_info for n in self.neurons]
         if not lite:
             weights_array = []
             for n in self.neurons:
                 if len(n.weights) == 0:
-                    weights_array.append( torch.zeros( len( self.neurons ) ) )
+                    weights_array.append(torch.zeros(len(self.neurons)))
                 else:
                     w_uids, w_weights = zip(*n.weights)
-                    weights_array.append( bittensor.utils.weight_utils.convert_weight_uids_and_vals_to_tensor( len(self.neurons), w_uids, w_weights ) )
-            self.weights = torch.nn.Parameter( torch.stack( weights_array ), requires_grad=False ) if len( weights_array ) else torch.nn.Parameter()
+                    weights_array.append(
+                        bittensor.utils.weight_utils.convert_weight_uids_and_vals_to_tensor(
+                            len(self.neurons), w_uids, w_weights
+                        )
+                    )
+            self.weights = (
+                torch.nn.Parameter(torch.stack(weights_array), requires_grad=False)
+                if len(weights_array)
+                else torch.nn.Parameter()
+            )
             if len(weights_array) == 0:
-                bittensor.logging.warning("Empty weights_array on metagraph.sync(). The 'weights' tensor is empty.")
+                bittensor.logging.warning(
+                    "Empty weights_array on metagraph.sync(). The 'weights' tensor is empty."
+                )
         if not lite:
             bonds_array = []
             for n in self.neurons:
                 if len(n.bonds) == 0:
-                    bonds_array.append( torch.zeros( len( self.neurons ) ) )
+                    bonds_array.append(torch.zeros(len(self.neurons)))
                 else:
                     b_uids, b_bonds = zip(*n.bonds)
-                    bonds_array.append( bittensor.utils.weight_utils.convert_bond_uids_and_vals_to_tensor( len(self.neurons), b_uids, b_bonds ) )
-            self.bonds = torch.nn.Parameter( torch.stack( bonds_array ), requires_grad=False ) if len( bonds_array ) else torch.nn.Parameter()
+                    bonds_array.append(
+                        bittensor.utils.weight_utils.convert_bond_uids_and_vals_to_tensor(
+                            len(self.neurons), b_uids, b_bonds
+                        )
+                    )
+            self.bonds = (
+                torch.nn.Parameter(torch.stack(bonds_array), requires_grad=False)
+                if len(bonds_array)
+                else torch.nn.Parameter()
+            )
             if len(bonds_array) == 0:
-                bittensor.logging.warning("Empty bonds_array on metagraph.sync(). The 'bonds' tensor is empty.")
-
-    def save( self ) -> 'metagraph':
-        r""" Saves this metagraph object's state_dict under bittensor root dir."""
-        save_directory = get_save_dir( self.network, self.netuid  )
-        os.makedirs( save_directory, exist_ok=True )
-        graph_file = save_directory + f'/block-{self.block.item()}.pt'
+                bittensor.logging.warning(
+                    "Empty bonds_array on metagraph.sync(). The 'bonds' tensor is empty."
+                )
+
+    def save(self) -> "metagraph":
+        r"""Saves this metagraph object's state_dict under bittensor root dir."""
+        save_directory = get_save_dir(self.network, self.netuid)
+        os.makedirs(save_directory, exist_ok=True)
+        graph_file = save_directory + f"/block-{self.block.item()}.pt"
         state_dict = self.state_dict()
-        state_dict['axons'] = self.axons
+        state_dict["axons"] = self.axons
         torch.save(state_dict, graph_file)
-        state_dict = torch.load( graph_file )
+        state_dict = torch.load(graph_file)
         return self
 
-    def load( self ) -> 'metagraph':
-        r""" Loads this metagraph object's state_dict from bittensor root dir. """
-        self.load_from_path( get_save_dir( self.network, self.netuid ) )
-
-    def load_from_path( self, dir_path:str ) -> 'metagraph':
-        r""" Loads this metagraph object with state_dict under the specified path."""
-        graph_file = latest_block_path( dir_path )
-        state_dict = torch.load( graph_file )
-        self.n = torch.nn.Parameter( state_dict['n'], requires_grad=False )
-        self.block = torch.nn.Parameter( state_dict['block'], requires_grad=False )
-        self.uids = torch.nn.Parameter( state_dict['uids'], requires_grad=False )
-        self.stake = torch.nn.Parameter( state_dict['stake'], requires_grad=False )
-        self.total_stake = torch.nn.Parameter( state_dict['total_stake'], requires_grad=False )
-        self.ranks = torch.nn.Parameter( state_dict['ranks'], requires_grad=False )
-        self.trust = torch.nn.Parameter( state_dict['trust'], requires_grad=False )
-        self.consensus = torch.nn.Parameter( state_dict['consensus'], requires_grad=False )
-        self.validator_trust = torch.nn.Parameter( state_dict['validator_trust'], requires_grad=False )
-        self.incentive = torch.nn.Parameter( state_dict['incentive'], requires_grad=False )
-        self.emission = torch.nn.Parameter( state_dict['emission'], requires_grad=False )
-        self.dividends = torch.nn.Parameter( state_dict['dividends'], requires_grad=False )
-        self.active = torch.nn.Parameter( state_dict['active'], requires_grad=False )
-        self.last_update = torch.nn.Parameter( state_dict['last_update'], requires_grad=False )
-        self.validator_permit = torch.nn.Parameter( state_dict['validator_permit'], requires_grad=False )
-        self.uids = torch.nn.Parameter( state_dict['uids'], requires_grad=False )
-        self.axons = state_dict['axons']
-        if 'weights' in state_dict:
-            self.weights = torch.nn.Parameter( state_dict['weights'], requires_grad=False )
-        if 'bonds' in state_dict:
-            self.bonds = torch.nn.Parameter( state_dict['bonds'], requires_grad=False )
+    def load(self) -> "metagraph":
+        r"""Loads this metagraph object's state_dict from bittensor root dir."""
+        self.load_from_path(get_save_dir(self.network, self.netuid))
+
+    def load_from_path(self, dir_path: str) -> "metagraph":
+        r"""Loads this metagraph object with state_dict under the specified path."""
+        graph_file = latest_block_path(dir_path)
+        state_dict = torch.load(graph_file)
+        self.n = torch.nn.Parameter(state_dict["n"], requires_grad=False)
+        self.block = torch.nn.Parameter(state_dict["block"], requires_grad=False)
+        self.uids = torch.nn.Parameter(state_dict["uids"], requires_grad=False)
+        self.stake = torch.nn.Parameter(state_dict["stake"], requires_grad=False)
+        self.total_stake = torch.nn.Parameter(
+            state_dict["total_stake"], requires_grad=False
+        )
+        self.ranks = torch.nn.Parameter(state_dict["ranks"], requires_grad=False)
+        self.trust = torch.nn.Parameter(state_dict["trust"], requires_grad=False)
+        self.consensus = torch.nn.Parameter(
+            state_dict["consensus"], requires_grad=False
+        )
+        self.validator_trust = torch.nn.Parameter(
+            state_dict["validator_trust"], requires_grad=False
+        )
+        self.incentive = torch.nn.Parameter(
+            state_dict["incentive"], requires_grad=False
+        )
+        self.emission = torch.nn.Parameter(state_dict["emission"], requires_grad=False)
+        self.dividends = torch.nn.Parameter(
+            state_dict["dividends"], requires_grad=False
+        )
+        self.active = torch.nn.Parameter(state_dict["active"], requires_grad=False)
+        self.last_update = torch.nn.Parameter(
+            state_dict["last_update"], requires_grad=False
+        )
+        self.validator_permit = torch.nn.Parameter(
+            state_dict["validator_permit"], requires_grad=False
+        )
+        self.uids = torch.nn.Parameter(state_dict["uids"], requires_grad=False)
+        self.axons = state_dict["axons"]
+        if "weights" in state_dict:
+            self.weights = torch.nn.Parameter(
+                state_dict["weights"], requires_grad=False
+            )
+        if "bonds" in state_dict:
+            self.bonds = torch.nn.Parameter(state_dict["bonds"], requires_grad=False)
         return self
-
-
```

### Comparing `bittensor-5.3.1/bittensor/_neuron/base_huggingface_miner.py` & `bittensor-5.3.2/bittensor/_neuron/base_huggingface_miner.py`

 * *Files 27% similar despite different names*

```diff
@@ -16,80 +16,168 @@
 # DEALINGS IN THE SOFTWARE.
 
 import bittensor
 import argparse
 from typing import List, Dict
 from abc import ABC, abstractmethod
 
-class HuggingFaceMiner( bittensor.BasePromptingMiner, ABC ):
+
+class HuggingFaceMiner(bittensor.BasePromptingMiner, ABC):
     arg_prefix: str
     assistant_label: str
     user_label: str
     system_label: str
 
     @classmethod
-    def check_config( cls, config: 'bittensor.Config' ):
+    def check_config(cls, config: "bittensor.Config"):
         pass
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
-        parser.add_argument( f'--{cls.arg_prefix}.model_name', type=str, default=None, help='Name or path of model to load' )
-        parser.add_argument( f'--{cls.arg_prefix}.api_key', type=str, help='huggingface api key', default=None )
-        parser.add_argument( f'--{cls.arg_prefix}.device', type=str, help='Device to load model', default="cuda" )
-        parser.add_argument( f'--{cls.arg_prefix}.max_new_tokens', type=int, help='Max tokens for model output.', default=256 )
-        parser.add_argument( f'--{cls.arg_prefix}.temperature', type=float, help='Sampling temperature of model', default=0.5 )
-        parser.add_argument( f'--{cls.arg_prefix}.do_sample', action='store_true', default=False, help='Whether to use multinomial sampling.' )
-        parser.add_argument( f'--{cls.arg_prefix}.repetition_penalty', type=float, help='Repetition penalty for model', default=1.3 )
-        parser.add_argument( f'--{cls.arg_prefix}.do_prompt_injection', action='store_true', default=False, help='Whether to use a custom "system" prompt instead of the one sent by bittensor.' )
-        parser.add_argument( f'--{cls.arg_prefix}.system_prompt', type=str, help='What prompt to replace the system prompt with', default= "BEGINNING OF CONVERSATION: " )
-        parser.add_argument( f'--{cls.arg_prefix}.repetition-penalty', type=float, default=1.1, help='Repetition penalty for greedy decoding. Between 1.0 and infinity. 1.0 means no penalty. Default: 1.0' )
-        parser.add_argument( f'--{cls.arg_prefix}.top_p', type=float, default=0.9, help='Top-p (nucleus) sampling. Defaults to 1.0 (top-k sampling). Must be between 0.0 and 1.0.' )
-        parser.add_argument( f'--{cls.arg_prefix}.top_k', type=int, default=0, help='Top-k sampling. Defaults to 0 (no top-k sampling). Must be between 0 and 1000.' )
-        parser.add_argument( f'--{cls.arg_prefix}.load_in_8bit', type=bool, default=False, help='Load model in 8 bit precision')
-        parser.add_argument( f'--{cls.arg_prefix}.device_map', type=str, default=None, help='Device map for model parallelism.')
-        parser.add_argument( f'--{cls.arg_prefix}.pad_tokens', type=int, default=[], nargs='+', help='A list of integers separated by spaces for the pad_tokens.')
+    def add_args(cls, parser: argparse.ArgumentParser):
+        parser.add_argument(
+            f"--{cls.arg_prefix}.model_name",
+            type=str,
+            default=None,
+            help="Name or path of model to load",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.api_key",
+            type=str,
+            help="huggingface api key",
+            default=None,
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.device",
+            type=str,
+            help="Device to load model",
+            default="cuda",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.max_new_tokens",
+            type=int,
+            help="Max tokens for model output.",
+            default=256,
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.temperature",
+            type=float,
+            help="Sampling temperature of model",
+            default=0.5,
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.do_sample",
+            action="store_true",
+            default=False,
+            help="Whether to use multinomial sampling.",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.repetition_penalty",
+            type=float,
+            help="Repetition penalty for model",
+            default=1.3,
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.do_prompt_injection",
+            action="store_true",
+            default=False,
+            help='Whether to use a custom "system" prompt instead of the one sent by bittensor.',
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.system_prompt",
+            type=str,
+            help="What prompt to replace the system prompt with",
+            default="BEGINNING OF CONVERSATION: ",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.repetition-penalty",
+            type=float,
+            default=1.1,
+            help="Repetition penalty for greedy decoding. Between 1.0 and infinity. 1.0 means no penalty. Default: 1.0",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.top_p",
+            type=float,
+            default=0.9,
+            help="Top-p (nucleus) sampling. Defaults to 1.0 (top-k sampling). Must be between 0.0 and 1.0.",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.top_k",
+            type=int,
+            default=0,
+            help="Top-k sampling. Defaults to 0 (no top-k sampling). Must be between 0 and 1000.",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.load_in_8bit",
+            type=bool,
+            default=False,
+            help="Load model in 8 bit precision",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.device_map",
+            type=str,
+            default=None,
+            help="Device map for model parallelism.",
+        )
+        parser.add_argument(
+            f"--{cls.arg_prefix}.pad_tokens",
+            type=int,
+            default=[],
+            nargs="+",
+            help="A list of integers separated by spaces for the pad_tokens.",
+        )
 
     def __init__(self):
-        super( HuggingFaceMiner, self ).__init__()
+        super(HuggingFaceMiner, self).__init__()
 
         # Set model name if unset.
-        if getattr( self.config, self.arg_prefix ).model_name == None:
-            getattr( self.config, self.arg_prefix ).model_name = self.arg_prefix
+        if getattr(self.config, self.arg_prefix).model_name == None:
+            getattr(self.config, self.arg_prefix).model_name = self.arg_prefix
 
-        bittensor.logging.info( 'Loading ' + str( getattr( self.config, self.arg_prefix ).model_name ) )
+        bittensor.logging.info(
+            "Loading " + str(getattr(self.config, self.arg_prefix).model_name)
+        )
         self.tokenizer = self.load_tokenizer()
         self.model = self.load_model()
-        bittensor.logging.info( 'Model loaded!' )
+        bittensor.logging.info("Model loaded!")
 
         # Device already configured if using pipieline or device_map is set. (i.e. Pipelines have no `.to()` method)
-        if getattr( self.config, self.arg_prefix ).device != "cpu" \
-            and 'pipeline' not in self.model.__class__.__name__.lower() \
-            and  getattr( self.config, self.arg_prefix ).device_map == None:
-            self.model = self.model.to( getattr( self.config, self.arg_prefix ).device )
+        if (
+            getattr(self.config, self.arg_prefix).device != "cpu"
+            and "pipeline" not in self.model.__class__.__name__.lower()
+            and getattr(self.config, self.arg_prefix).device_map == None
+        ):
+            self.model = self.model.to(getattr(self.config, self.arg_prefix).device)
 
     @abstractmethod
     def load_model(self):
         ...
 
     @abstractmethod
     def load_tokenizer(self):
         ...
 
     @abstractmethod
     def forward(self, messages: List[Dict[str, str]], **kwargs) -> str:
         ...
 
-    def process_history( self, history: List[Dict[str, str]] ) -> str:
-        processed_history = ''
+    def process_history(self, history: List[Dict[str, str]]) -> str:
+        processed_history = ""
 
         if getattr(self.config, self.arg_prefix).do_prompt_injection:
             processed_history += getattr(self.config, self.arg_prefix).system_prompt
 
         for message in history:
-            if message['role'] == 'system':
-                if not getattr(self.config, self.arg_prefix).do_prompt_injection or message != history[0]:
-                    processed_history += self.system_label + message['content'].strip() + ' '
-            if message['role'] == 'assistant':
-                processed_history += self.assistant_label + message['content'].strip() + '</s>'
-            if message['role'] == 'user':
-                processed_history += self.user_label + message['content'].strip() + ' '
+            if message["role"] == "system":
+                if (
+                    not getattr(self.config, self.arg_prefix).do_prompt_injection
+                    or message != history[0]
+                ):
+                    processed_history += (
+                        self.system_label + message["content"].strip() + " "
+                    )
+            if message["role"] == "assistant":
+                processed_history += (
+                    self.assistant_label + message["content"].strip() + "</s>"
+                )
+            if message["role"] == "user":
+                processed_history += self.user_label + message["content"].strip() + " "
         return processed_history
```

### Comparing `bittensor-5.3.1/bittensor/_neuron/base_miner_neuron.py` & `bittensor-5.3.2/bittensor/_neuron/base_miner_neuron.py`

 * *Files 15% similar despite different names*

```diff
@@ -22,201 +22,224 @@
 import argparse
 import bittensor
 
 from rich import print
 from typing import Union, Tuple
 from datetime import datetime
 
+
 class BaseMinerNeuron:
+    def priority(self, forward_call: "bittensor.SynapseCall") -> float:
+        return self.prioritizer.priority(forward_call, metagraph=self.metagraph)
 
-    def priority( self, forward_call: "bittensor.SynapseCall" ) -> float:
-        return self.prioritizer.priority( forward_call, metagraph = self.metagraph )
+    def blacklist(
+        self, forward_call: "bittensor.SynapseCall"
+    ) -> Union[Tuple[bool, str], bool]:
+        return self.blacklister.blacklist(forward_call, metagraph=self.metagraph)
 
-    def blacklist( self, forward_call: "bittensor.SynapseCall" ) -> Union[ Tuple[bool, str], bool ]:
-        return self.blacklister.blacklist( forward_call, metagraph = self.metagraph )
-    
     @classmethod
-    def config( cls ) -> "bittensor.Config":
+    def config(cls) -> "bittensor.Config":
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        return bittensor.config( parser )
+        cls.add_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
-    def help( cls ):
+    def help(cls):
         parser = argparse.ArgumentParser()
         cls.add_args(parser)
-        print( cls.__new__.__doc__ )
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def check_config( cls, config: "bittensor.Config" ):
-        bittensor.axon.check_config( config )
-        bittensor.wallet.check_config( config )
-        bittensor.logging.check_config( config )
-        bittensor.subtensor.check_config( config )
+    def check_config(cls, config: "bittensor.Config"):
+        bittensor.axon.check_config(config)
+        bittensor.wallet.check_config(config)
+        bittensor.logging.check_config(config)
+        bittensor.subtensor.check_config(config)
         full_path = os.path.expanduser(
-            '{}/{}/{}/{}'.format( config.logging.logging_dir, config.wallet.get('name', bittensor.defaults.wallet.name),
-                                  config.wallet.get('hotkey', bittensor.defaults.wallet.hotkey), config.neuron.name ) )
-        config.neuron.full_path = os.path.expanduser( full_path )
-        if not os.path.exists( config.neuron.full_path ):
-            os.makedirs( config.neuron.full_path )
+            "{}/{}/{}/{}".format(
+                config.logging.logging_dir,
+                config.wallet.get("name", bittensor.defaults.wallet.name),
+                config.wallet.get("hotkey", bittensor.defaults.wallet.hotkey),
+                config.neuron.name,
+            )
+        )
+        config.neuron.full_path = os.path.expanduser(full_path)
+        if not os.path.exists(config.neuron.full_path):
+            os.makedirs(config.neuron.full_path)
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser, prefix: str = None ):
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
         prefix_str = "" if prefix is None else prefix + "."
         parser.add_argument(
-            '--' + prefix_str + 'netuid', 
-            type = int, 
-            help = 'Subnet netuid', 
-            default = 1
+            "--" + prefix_str + "netuid", type=int, help="Subnet netuid", default=1
         )
         parser.add_argument(
-            '--' + prefix_str + 'neuron.name', 
-            type = str,
-            help = 'Trials for this miner go in miner.root / (wallet_cold - wallet_hot) / miner.name ',
-            default = 'openai_prompting_miner'
+            "--" + prefix_str + "neuron.name",
+            type=str,
+            help="Trials for this miner go in miner.root / (wallet_cold - wallet_hot) / miner.name ",
+            default="openai_prompting_miner",
         )
         parser.add_argument(
-            '--' + prefix_str + 'neuron.blocks_per_epoch', 
-            type = str, 
-            help = 'Blocks until the miner sets weights on chain',
-            default = 100
+            "--" + prefix_str + "neuron.blocks_per_epoch",
+            type=str,
+            help="Blocks until the miner sets weights on chain",
+            default=100,
         )
         parser.add_argument(
-            '--' + prefix_str + 'neuron.no_set_weights', 
-            action = 'store_true', 
-            help = 'If True, the model does not set weights.',
-            default = False
+            "--" + prefix_str + "neuron.no_set_weights",
+            action="store_true",
+            help="If True, the model does not set weights.",
+            default=False,
         )
         parser.add_argument(
-            '--' + prefix_str + 'neuron.reregister',
-            action = 'store_true',
-            help = 'If True, the miner will reregister on chain.',
-            default = False
-        )
-        bittensor.wallet.add_args( parser, prefix = prefix )
-        bittensor.axon.add_args( parser, prefix = prefix )
-        bittensor.subtensor.add_args( parser, prefix = prefix )
-        bittensor.logging.add_args( parser, prefix = prefix )
-        bittensor.blacklist.add_args( parser, prefix = prefix_str + 'neuron' )
-        bittensor.priority.add_args( parser, prefix = prefix_str + 'neuron' )
-
-    def __init__(self, netuid: int = None, config: "bittensor.Config" = None ):
-        super_config = config if config != None else BaseMinerNeuron.config() # Grab super (BaseMinerNeuron) config
-        child_config = self.config() # grab child (<subclass>Miner) class configs.
+            "--" + prefix_str + "neuron.reregister",
+            action="store_true",
+            help="If True, the miner will reregister on chain.",
+            default=False,
+        )
+        bittensor.wallet.add_args(parser, prefix=prefix)
+        bittensor.axon.add_args(parser, prefix=prefix)
+        bittensor.subtensor.add_args(parser, prefix=prefix)
+        bittensor.logging.add_args(parser, prefix=prefix)
+        bittensor.blacklist.add_args(parser, prefix=prefix_str + "neuron")
+        bittensor.priority.add_args(parser, prefix=prefix_str + "neuron")
+
+    def __init__(self, netuid: int = None, config: "bittensor.Config" = None):
+        super_config = (
+            config if config != None else BaseMinerNeuron.config()
+        )  # Grab super (BaseMinerNeuron) config
+        child_config = self.config()  # grab child (<subclass>Miner) class configs.
         self.config = child_config
-        self.config.merge( super_config ) # Merge the two configs. Child configs override super configs.
+        self.config.merge(
+            super_config
+        )  # Merge the two configs. Child configs override super configs.
         self.config.netuid = netuid or self.config.netuid
-        BaseMinerNeuron.check_config( self.config )
+        BaseMinerNeuron.check_config(self.config)
 
         # Build objects.
-        bittensor.logging( config = self.config, logging_dir = self.config.neuron.full_path )
-        self.subtensor = bittensor.subtensor( self.config )
-        self.wallet = bittensor.wallet( self.config )
-        self.metagraph = self.subtensor.metagraph( netuid = self.config.netuid )
-        self.metagraph.sync( lite = True, subtensor=self.subtensor )
-
-        self.axon = bittensor.axon( wallet = self.wallet, config = self.config )
-        self.blacklister = bittensor.blacklist( config = self.config.neuron )
-        self.prioritizer = bittensor.priority( config = self.config.neuron )
+        bittensor.logging(config=self.config, logging_dir=self.config.neuron.full_path)
+        self.subtensor = bittensor.subtensor(self.config)
+        self.wallet = bittensor.wallet(self.config)
+        self.metagraph = self.subtensor.metagraph(netuid=self.config.netuid)
+        self.metagraph.sync(lite=True, subtensor=self.subtensor)
+
+        self.axon = bittensor.axon(wallet=self.wallet, config=self.config)
+        self.blacklister = bittensor.blacklist(config=self.config.neuron)
+        self.prioritizer = bittensor.priority(config=self.config.neuron)
 
         # Used for backgounr process.
         self.is_running = False
-        self.should_exit = False 
+        self.should_exit = False
         self.background_thread = None
 
-    def attach( self, synapse: "bittensor.Synapse" ):
+    def attach(self, synapse: "bittensor.Synapse"):
         # pass through attach function.
-        self.axon.attach( synapse )
+        self.axon.attach(synapse)
 
     def __enter__(self):
-        bittensor.logging.trace( 'BaseMinerNeuron.__enter__()' )
+        bittensor.logging.trace("BaseMinerNeuron.__enter__()")
         self.start_in_background()
         return self
-    
+
     def __exit__(self, exc_type, exc_value, traceback):
-        bittensor.logging.trace( 'BaseMinerNeuron.__exit__()' )
+        bittensor.logging.trace("BaseMinerNeuron.__exit__()")
         self.stop()
 
     def start_in_background(self):
         if self.is_running:
-            bittensor.logging.warning( 'The base miner neuron is already running.')
+            bittensor.logging.warning("The base miner neuron is already running.")
         else:
             self.should_exit = False
-            self.background_thread = threading.Thread( target = self.run, daemon = True )
+            self.background_thread = threading.Thread(target=self.run, daemon=True)
             self.background_thread.start()
             self.is_running = True
-            bittensor.logging.trace( 'Starting the base miner neuron in the background.')
+            bittensor.logging.trace("Starting the base miner neuron in the background.")
 
     def stop(self):
         if self.is_running:
             self.should_exit = True
         else:
-            bittensor.logging.warning( 'The base miner neuron is not running.')
+            bittensor.logging.warning("The base miner neuron is not running.")
 
-    def run( self ):
-        bittensor.logging.debug( 'BaseMinerNeuron.run()' )
+    def run(self):
+        bittensor.logging.debug("BaseMinerNeuron.run()")
 
         # --- Start the miner.
         self.is_running = True
-        bittensor.utils.reregister( wallet = self.wallet, subtensor = self.subtensor, netuid = self.config.netuid, reregister = self.config.neuron.reregister )
+        bittensor.utils.reregister(
+            wallet=self.wallet,
+            subtensor=self.subtensor,
+            netuid=self.config.netuid,
+            reregister=self.config.neuron.reregister,
+        )
         self.axon.start()
-        self.subtensor.serve_axon( netuid = self.config.netuid, axon = self.axon, wait_for_finalization = False, wait_for_inclusion = False ) #TODO: fix finalization & inclusion
+        self.subtensor.serve_axon(
+            netuid=self.config.netuid,
+            axon=self.axon,
+            wait_for_finalization=False,
+            wait_for_inclusion=False,
+        )  # TODO: fix finalization & inclusion
 
         # --- Run Forever.
         last_update = self.subtensor.get_current_block()
         retries = 0
         while not self.should_exit:
-
             # --- Wait until next epoch.
             current_block = self.subtensor.get_current_block()
             while (current_block - last_update) < self.config.neuron.blocks_per_epoch:
-                if self.should_exit: continue
-                time.sleep( 0.1 ) #bittensor.__blocktime__
+                if self.should_exit:
+                    continue
+                time.sleep(0.1)  # bittensor.__blocktime__
                 current_block = self.subtensor.get_current_block()
             last_update = self.subtensor.get_current_block()
 
             # --- Update the metagraph with the latest network state.
             try:
-                self.metagraph.sync( lite = True, subtensor=self.subtensor )
-                uid = self.metagraph.hotkeys.index( self.wallet.hotkey.ss58_address )
+                self.metagraph.sync(lite=True, subtensor=self.subtensor)
+                uid = self.metagraph.hotkeys.index(self.wallet.hotkey.ss58_address)
             except:
                 # --- If we fail to sync the metagraph, wait and try again.
-                if(retries > 8):
-                    bittensor.logging.error( f'Failed to sync metagraph, exiting.')
+                if retries > 8:
+                    bittensor.logging.error(f"Failed to sync metagraph, exiting.")
                     self.stop()
-                    break 
-                seconds_to_sleep = 5 * 1.5**(retries)
-                bittensor.logging.error( f'Failed to sync metagraph, retrying in {seconds_to_sleep} seconds.')
-                time.sleep( seconds_to_sleep )
+                    break
+                seconds_to_sleep = 5 * 1.5 ** (retries)
+                bittensor.logging.error(
+                    f"Failed to sync metagraph, retrying in {seconds_to_sleep} seconds."
+                )
+                time.sleep(seconds_to_sleep)
                 retries += 1
                 continue
 
-            if(retries > 0):
+            if retries > 0:
                 retries = 0
 
             # --- Log performance.
             print(
                 f"[white not bold]{datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
                 f"{f'UID [bright_cyan]{uid}[/bright_cyan]'.center(16 + len('[bright_cyan][/bright_cyan]'))} | "
-                f'[dim white not bold] [green]{str(self.metagraph.S[uid].item()):.4}[/green] Stake [/dim white not bold]'
-                f'[dim white not bold]| [yellow]{str(self.metagraph.trust[uid].item()) :.3}[/yellow] Trust [/dim white not bold]'
-                f'[dim white not bold]| [green]{str(self.metagraph.incentive[uid].item()):.3}[/green] Incentive [/dim white not bold]')
+                f"[dim white not bold] [green]{str(self.metagraph.S[uid].item()):.4}[/green] Stake [/dim white not bold]"
+                f"[dim white not bold]| [yellow]{str(self.metagraph.trust[uid].item()) :.3}[/yellow] Trust [/dim white not bold]"
+                f"[dim white not bold]| [green]{str(self.metagraph.incentive[uid].item()):.3}[/green] Incentive [/dim white not bold]"
+            )
 
             # --- Set weights.
             if not self.config.neuron.no_set_weights:
                 try:
                     # --- query the chain for the most current number of peers on the network
-                    chain_weights = torch.zeros( self.subtensor.subnetwork_n( netuid = self.config.netuid ))
+                    chain_weights = torch.zeros(
+                        self.subtensor.subnetwork_n(netuid=self.config.netuid)
+                    )
                     chain_weights[uid] = 1
                     did_set = self.subtensor.set_weights(
-                        uids = torch.arange(0, len(chain_weights)),
-                        netuid = self.config.netuid,
-                        weights = chain_weights,
-                        wait_for_inclusion = False,
-                        walle = self.wallet,
-                        version_key = 1
+                        uids=torch.arange(0, len(chain_weights)),
+                        netuid=self.config.netuid,
+                        weights=chain_weights,
+                        wait_for_inclusion=False,
+                        walle=self.wallet,
+                        version_key=1,
                     )
                 except:
                     pass
 
-        self.axon.stop()
+        self.axon.stop()
```

### Comparing `bittensor-5.3.1/bittensor/_neuron/base_prompting_miner.py` & `bittensor-5.3.2/bittensor/_neuron/base_prompting_miner.py`

 * *Files 26% similar despite different names*

```diff
@@ -19,59 +19,72 @@
 import argparse
 import bittensor
 
 from rich import print
 from typing import List, Dict, Union, Tuple
 from abc import ABC, abstractmethod
 
-class BasePromptingMiner( bittensor.BaseMinerNeuron, ABC ):
 
+class BasePromptingMiner(bittensor.BaseMinerNeuron, ABC):
     @classmethod
     @abstractmethod
-    def add_args( cls, parser: argparse.ArgumentParser ):
+    def add_args(cls, parser: argparse.ArgumentParser):
         ...
 
     @abstractmethod
-    def forward( self, messages: List[Dict[str, str]] ) -> str:
+    def forward(self, messages: List[Dict[str, str]]) -> str:
         ...
 
     @classmethod
     @abstractmethod
-    def check_config( cls, config: 'bittensor.Config' ):
+    def check_config(cls, config: "bittensor.Config"):
         ...
 
     @classmethod
-    def config( cls ) -> "bittensor.Config":
+    def config(cls) -> "bittensor.Config":
         parser = argparse.ArgumentParser()
-        cls.add_super_args( parser )
-        return bittensor.config( parser )
+        cls.add_super_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
-    def add_super_args( cls, parser: argparse.ArgumentParser ):
-        """ Add arguments specific to BasePromptingMiner to parser.
-        """
+    def add_super_args(cls, parser: argparse.ArgumentParser):
+        """Add arguments specific to BasePromptingMiner to parser."""
         cls.add_args(parser)
         parser.add_argument(
-            '--neuron.max_batch_size', 
-            type = int, 
-            help = 'The maximum batch size for forward requests.',
-            default = -1
+            "--neuron.max_batch_size",
+            type=int,
+            help="The maximum batch size for forward requests.",
+            default=-1,
         )
         parser.add_argument(
-            '--neuron.max_sequence_len', 
-            type = int, 
-            help = 'The maximum sequence length for forward requests.',
-            default = -1
+            "--neuron.max_sequence_len",
+            type=int,
+            help="The maximum sequence length for forward requests.",
+            default=-1,
         )
 
-    def __init__( self, config: "bittensor.Config" = None ):
-        super( BasePromptingMiner, self ).__init__()
+    def __init__(self, config: "bittensor.Config" = None):
+        super(BasePromptingMiner, self).__init__()
 
-        class Synapse( bittensor.TextPromptingSynapse ):
-            def priority( _, forward_call: "bittensor.TextPromptingForwardCall" ) -> float:
-                return self.priority( forward_call )
-            def blacklist( _, forward_call: "bittensor.TextPromptingForwardCall" ) -> Union[ Tuple[bool, str], bool ]:
-                return self.blacklist( forward_call )
-            def backward( self, messages: List[Dict[str, str]], response: str, rewards: torch.FloatTensor ) -> str: pass
-            def forward( _, messages: List[Dict[str, str]] ) -> str:
-                return self.forward( messages )
-        self.synapse = Synapse( axon = self.axon )
+        class Synapse(bittensor.TextPromptingSynapse):
+            def priority(
+                _, forward_call: "bittensor.TextPromptingForwardCall"
+            ) -> float:
+                return self.priority(forward_call)
+
+            def blacklist(
+                _, forward_call: "bittensor.TextPromptingForwardCall"
+            ) -> Union[Tuple[bool, str], bool]:
+                return self.blacklist(forward_call)
+
+            def backward(
+                self,
+                messages: List[Dict[str, str]],
+                response: str,
+                rewards: torch.FloatTensor,
+            ) -> str:
+                pass
+
+            def forward(_, messages: List[Dict[str, str]]) -> str:
+                return self.forward(messages)
+
+        self.synapse = Synapse(axon=self.axon)
```

### Comparing `bittensor-5.3.1/bittensor/_priority/__init__.py` & `bittensor-5.3.2/bittensor/_priority/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,73 +15,74 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 import math
 import argparse
 import bittensor
 
-class priority:
 
-    def __init__( self, config: "bittensor.Config" = None ):
+class priority:
+    def __init__(self, config: "bittensor.Config" = None):
         self.config = config or priority.config()
 
     @classmethod
-    def config( cls ) -> "bittensor.Config":
+    def config(cls) -> "bittensor.Config":
         parser = argparse.ArgumentParser()
         priority.add_args(parser)
-        return bittensor.config( parser )
+        return bittensor.config(parser)
 
     @classmethod
     def help(cls):
         parser = argparse.ArgumentParser()
         cls.add_args(parser)
-        print( cls.__new__.__doc__ )
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def add_args( cls, parser: argparse.ArgumentParser, prefix: str = None ):
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
         prefix_str = "" if prefix is None else prefix + "."
         parser.add_argument(
-            '--' + prefix_str + 'priority.default_priority',
-            type = float,
-            help = 'Default call priority in queue.',
-            default = 0.0
+            "--" + prefix_str + "priority.default_priority",
+            type=float,
+            help="Default call priority in queue.",
+            default=0.0,
         )
         parser.add_argument(
-            '--' + prefix_str + 'priority.blacklisted_keys', 
-            type = str, 
-            required = False, 
-            nargs = '*', 
-            action = 'store',
-            help = 'List of ss58 addresses which are always given -math.inf priority', default=[]
+            "--" + prefix_str + "priority.blacklisted_keys",
+            type=str,
+            required=False,
+            nargs="*",
+            action="store",
+            help="List of ss58 addresses which are always given -math.inf priority",
+            default=[],
         )
         parser.add_argument(
-            '--' + prefix_str + 'priority.whitelisted_keys', 
-            type = str, 
-            required = False, 
-            nargs = '*', 
-            action = 'store',
-            help = 'List of ss58 addresses which are always given math.inf priority', default=[]
+            "--" + prefix_str + "priority.whitelisted_keys",
+            type=str,
+            required=False,
+            nargs="*",
+            action="store",
+            help="List of ss58 addresses which are always given math.inf priority",
+            default=[],
         )
 
-    def priority( 
-            self, 
-            forward_call: "bittensor.SynapseCall",
-            metagraph: "bittensor.Metagraph" = None,
-        ) -> float:
-
+    def priority(
+        self,
+        forward_call: "bittensor.SynapseCall",
+        metagraph: "bittensor.Metagraph" = None,
+    ) -> float:
         # Check for blacklisted keys which take priority over all other checks.
         src_hotkey = forward_call.src_hotkey
         if src_hotkey in self.config.priority.blacklisted_keys:
             return -math.inf
-        
+
         # Check for whitelisted keys which take priority over all remaining checks.
         if src_hotkey in self.config.priority.whitelisted_keys:
-            return math.inf 
+            return math.inf
 
         # Otherwise priority of requests is based on stake.
         if metagraph is not None:
-            uid = metagraph.hotkeys.index( forward_call.src_hotkey )
-            return metagraph.S[ uid ].item()
-        
+            uid = metagraph.hotkeys.index(forward_call.src_hotkey)
+            return metagraph.S[uid].item()
+
         # Default priority.
         return self.config.priority.default_priority
```

### Comparing `bittensor-5.3.1/bittensor/_prometheus/__init__.py` & `bittensor-5.3.2/bittensor/_prometheus/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,165 +22,198 @@
 import argparse
 import bittensor
 from typing import List, Callable, Union
 from prometheus_client import start_http_server
 from enum import Enum
 
 from loguru import logger
+
 logger = logger.opt(colors=True)
 
 
 class prometheus:
-    """ Namespace for prometheus tooling.
-    """
+    """Namespace for prometheus tooling."""
 
     # Prometheus global logging levels.
-    class level ( Enum ):
+    class level(Enum):
         OFF = "OFF"
         INFO = "INFO"
         DEBUG = "DEBUG"
+
         def __str__(self):
             return self.value
 
     # Prometheus Global state.
     port: int = None
     started: bool = False
 
     def __new__(
         cls,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         netuid: int,
-        config: 'bittensor.config' = None,
+        config: "bittensor.config" = None,
         port: int = None,
         level: Union[str, "prometheus.level"] = None,
         network: str = None,
         chain_endpoint: str = None,
-        subtensor: 'bittensor.subtensor' = None,
+        subtensor: "bittensor.subtensor" = None,
     ):
-        """ Instantiates a global prometheus DB which can be accessed by other processes.
-            Each prometheus DB is designated by a port.
-            Args:
-                wallet (:obj: `bittensor.wallet`, `required`):
-                    bittensor wallet object.
-                netuid (:obj: `int`, `required`):
-                    network uid to serve on.
-                config (:obj:`bittensor.Config`, `optional`, defaults to bittensor.prometheus.config()):
-                    A config namespace object created by calling bittensor.prometheus.config()
-                port (:obj:`int`, `optional`, defaults to bittensor.defaults.prometheus.port ):
-                    The port to run the prometheus DB on, this uniquely identifies the prometheus DB.
-                level (:obj:`prometheus.level`, `optional`, defaults to bittensor.defaults.prometheus.level ):
-                    Prometheus logging level. If OFF, the prometheus DB is not initialized.
-                subtensor (:obj:`bittensor.Subtensor`, `optional`):
-                    Chain connection through which to serve.
-                network (default='local', type=str)
-                    If subtensor is not set, uses this network flag to create the subtensor connection.
-                chain_endpoint (default=None, type=str)
-                    Overrides the network argument if not set.
+        """Instantiates a global prometheus DB which can be accessed by other processes.
+        Each prometheus DB is designated by a port.
+        Args:
+            wallet (:obj: `bittensor.wallet`, `required`):
+                bittensor wallet object.
+            netuid (:obj: `int`, `required`):
+                network uid to serve on.
+            config (:obj:`bittensor.Config`, `optional`, defaults to bittensor.prometheus.config()):
+                A config namespace object created by calling bittensor.prometheus.config()
+            port (:obj:`int`, `optional`, defaults to bittensor.defaults.prometheus.port ):
+                The port to run the prometheus DB on, this uniquely identifies the prometheus DB.
+            level (:obj:`prometheus.level`, `optional`, defaults to bittensor.defaults.prometheus.level ):
+                Prometheus logging level. If OFF, the prometheus DB is not initialized.
+            subtensor (:obj:`bittensor.Subtensor`, `optional`):
+                Chain connection through which to serve.
+            network (default='local', type=str)
+                If subtensor is not set, uses this network flag to create the subtensor connection.
+            chain_endpoint (default=None, type=str)
+                Overrides the network argument if not set.
         """
         if config == None:
             config = prometheus.config()
 
         if isinstance(level, prometheus.level):
-            level = level.name # Convert ENUM to str.
+            level = level.name  # Convert ENUM to str.
 
-        if subtensor == None: subtensor = bittensor.subtensor( network = network, chain_endpoint = chain_endpoint)
+        if subtensor == None:
+            subtensor = bittensor.subtensor(
+                network=network, chain_endpoint=chain_endpoint
+            )
 
         config.prometheus.port = port if port != None else config.prometheus.port
         config.prometheus.level = level if level != None else config.prometheus.level
 
         if isinstance(config.prometheus.level, str):
-            config.prometheus.level = config.prometheus.level.upper() # Convert str to upper case.
+            config.prometheus.level = (
+                config.prometheus.level.upper()
+            )  # Convert str to upper case.
 
-        cls.check_config( config )
+        cls.check_config(config)
 
         return cls.serve(
             cls,
-            wallet = wallet,
-            netuid = netuid,
-            subtensor = subtensor,
-            port = config.prometheus.port,
-            level = config.prometheus.level,
+            wallet=wallet,
+            netuid=netuid,
+            subtensor=subtensor,
+            port=config.prometheus.port,
+            level=config.prometheus.level,
         )
 
     def serve(cls, wallet, subtensor, netuid, port, level) -> bool:
-        if level == prometheus.level.OFF.name: # If prometheus is off, return true.
-            logger.success('Prometheus:'.ljust(20) + '<red>OFF</red>')
+        if level == prometheus.level.OFF.name:  # If prometheus is off, return true.
+            logger.success("Prometheus:".ljust(20) + "<red>OFF</red>")
             return True
         else:
             # Serve prometheus. Not OFF
             serve_success = subtensor.serve_prometheus(
-                wallet = wallet,
-                port = port,
-                netuid = netuid,
+                wallet=wallet,
+                port=port,
+                netuid=netuid,
             )
             if serve_success:
                 try:
-                    start_http_server( port )
+                    start_http_server(port)
                 except OSError:
                     # The singleton process is likely already running.
-                    logger.error( "Prometheus:".ljust(20) + "<blue>{}</blue>  <red>already in use</red> ".format( port ) )
+                    logger.error(
+                        "Prometheus:".ljust(20)
+                        + "<blue>{}</blue>  <red>already in use</red> ".format(port)
+                    )
                 prometheus.started = True
                 prometheus.port = port
-                logger.success( "Prometheus:".ljust(20) + "<green>ON</green>".ljust(20) + "using: <blue>[::]:{}</blue>".format( port ))
+                logger.success(
+                    "Prometheus:".ljust(20)
+                    + "<green>ON</green>".ljust(20)
+                    + "using: <blue>[::]:{}</blue>".format(port)
+                )
                 return True
             else:
-                logger.error('Prometheus:'.ljust(20) + '<red>OFF</red>')
-                raise RuntimeError('Failed to serve neuron.')
+                logger.error("Prometheus:".ljust(20) + "<red>OFF</red>")
+                raise RuntimeError("Failed to serve neuron.")
 
     @classmethod
-    def config(cls) -> 'bittensor.Config':
-        """ Get config from the argument parser
+    def config(cls) -> "bittensor.Config":
+        """Get config from the argument parser
         Return: bittensor.config object
         """
         parser = argparse.ArgumentParser()
         cls.add_args(parser=parser)
-        return bittensor.config( parser )
+        return bittensor.config(parser)
 
     @classmethod
     def help(cls):
-        """ Print help to stdout
-        """
+        """Print help to stdout"""
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        print (cls.__new__.__doc__)
+        cls.add_args(parser)
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None ):
-        """ Accept specific arguments from parser
-        """
-        prefix_str = '' if prefix == None else prefix + '.'
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
+        """Accept specific arguments from parser"""
+        prefix_str = "" if prefix == None else prefix + "."
         if prefix is not None:
             if bittensor.defaults.get(prefix, d=None) == None:
                 setattr(bittensor.defaults, prefix, bittensor.Config())
-            getattr(bittensor.defaults, prefix).prometheus = bittensor.defaults.prometheus
+            getattr(
+                bittensor.defaults, prefix
+            ).prometheus = bittensor.defaults.prometheus
         try:
-            parser.add_argument('--' + prefix_str + 'prometheus.port',  type=int, required=False, default = bittensor.defaults.prometheus.port,
-                help='''Prometheus serving port.''')
             parser.add_argument(
-                '--' + prefix_str + 'prometheus.level',
-                required = False,
-                type = str,
-                choices = [l.name for l in list(prometheus.level)],
-                default = bittensor.defaults.prometheus.level,
-                help = '''Prometheus logging level. <OFF | INFO | DEBUG>''')
+                "--" + prefix_str + "prometheus.port",
+                type=int,
+                required=False,
+                default=bittensor.defaults.prometheus.port,
+                help="""Prometheus serving port.""",
+            )
+            parser.add_argument(
+                "--" + prefix_str + "prometheus.level",
+                required=False,
+                type=str,
+                choices=[l.name for l in list(prometheus.level)],
+                default=bittensor.defaults.prometheus.level,
+                help="""Prometheus logging level. <OFF | INFO | DEBUG>""",
+            )
         except argparse.ArgumentError as e:
             pass
 
     @classmethod
     def add_defaults(cls, defaults):
-        """ Adds parser defaults to object from enviroment variables.
-        """
+        """Adds parser defaults to object from enviroment variables."""
         defaults.prometheus = bittensor.Config()
         # Default the prometheus port to axon.port - 1000
-        defaults.prometheus.port = os.getenv('BT_PROMETHEUS_PORT') if os.getenv('BT_PROMETHEUS_PORT') != None else 7091
-        defaults.prometheus.level = os.getenv('BT_PROMETHEUS_LEVEL') if os.getenv('BT_PROMETHEUS_LEVEL') != None else bittensor.prometheus.level.INFO.value
+        defaults.prometheus.port = (
+            os.getenv("BT_PROMETHEUS_PORT")
+            if os.getenv("BT_PROMETHEUS_PORT") != None
+            else 7091
+        )
+        defaults.prometheus.level = (
+            os.getenv("BT_PROMETHEUS_LEVEL")
+            if os.getenv("BT_PROMETHEUS_LEVEL") != None
+            else bittensor.prometheus.level.INFO.value
+        )
 
     @classmethod
-    def check_config(cls, config: 'bittensor.Config' ):
-        """ Check config for wallet name/hotkey/path/hotkeys/sort_by
-        """
-        assert 'prometheus' in config
-        assert config.prometheus.level in [l.name for l in list(prometheus.level)], "config.prometheus.level must be in: {}".format([l.name for l in list(prometheus.level)])
-        assert config.prometheus.port > 1024 and config.prometheus.port < 65535, 'config.prometheus.port must be in range [1024, 65535]'
+    def check_config(cls, config: "bittensor.Config"):
+        """Check config for wallet name/hotkey/path/hotkeys/sort_by"""
+        assert "prometheus" in config
+        assert config.prometheus.level in [
+            l.name for l in list(prometheus.level)
+        ], "config.prometheus.level must be in: {}".format(
+            [l.name for l in list(prometheus.level)]
+        )
+        assert (
+            config.prometheus.port > 1024 and config.prometheus.port < 65535
+        ), "config.prometheus.port must be in range [1024, 65535]"
         if "axon" in config and "port" in config.axon:
-            assert config.prometheus.port != config.axon.port, 'config.prometheus.port != config.axon.port'
+            assert (
+                config.prometheus.port != config.axon.port
+            ), "config.prometheus.port != config.axon.port"
```

### Comparing `bittensor-5.3.1/bittensor/_proto/bittensor_pb2.py` & `bittensor-5.3.2/bittensor/_proto/bittensor_pb2.py`

 * *Files 22% similar despite different names*

```diff
@@ -3,285 +3,401 @@
 # source: bittensor/_proto/bittensor.proto
 """Generated protocol buffer code."""
 from google.protobuf.internal import enum_type_wrapper
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import message as _message
 from google.protobuf import reflection as _reflection
 from google.protobuf import symbol_database as _symbol_database
+
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
-
-
 DESCRIPTOR = _descriptor.FileDescriptor(
-  name='bittensor/_proto/bittensor.proto',
-  package='',
-  syntax='proto3',
-  serialized_options=None,
-  create_key=_descriptor._internal_create_key,
-  serialized_pb=b'\n bittensor/_proto/bittensor.proto\"Q\n\x1b\x46orwardTextPromptingRequest\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x10\n\x08messages\x18\x03 \x03(\t\x12\x0f\n\x07timeout\x18\x04 \x01(\x02\"{\n\x1c\x46orwardTextPromptingResponse\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x10\n\x08response\x18\x03 \x01(\t\x12\x16\n\x0ereturn_message\x18\x04 \x01(\t\x12 \n\x0breturn_code\x18\x05 \x01(\x0e\x32\x0b.ReturnCode\"u\n\x1c\x42\x61\x63kwardTextPromptingRequest\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x0f\n\x07rewards\x18\x03 \x03(\x02\x12\x10\n\x08messages\x18\x04 \x03(\t\x12\x10\n\x08response\x18\x05 \x01(\t\x12\x0f\n\x07timeout\x18\x06 \x01(\x02\"j\n\x1d\x42\x61\x63kwardTextPromptingResponse\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x16\n\x0ereturn_message\x18\x04 \x01(\t\x12 \n\x0breturn_code\x18\x05 \x01(\x0e\x32\x0b.ReturnCode\"\xac\x01\n\x06Tensor\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x0e\n\x06\x62uffer\x18\x02 \x01(\x0c\x12\r\n\x05shape\x18\x03 \x03(\x03\x12\x1f\n\nserializer\x18\x04 \x01(\x0e\x32\x0b.Serializer\x12 \n\x0btensor_type\x18\x05 \x01(\x0e\x32\x0b.TensorType\x12\x18\n\x05\x64type\x18\x06 \x01(\x0e\x32\t.DataType\x12\x15\n\rrequires_grad\x18\x08 \x01(\x08*\xda\x04\n\nReturnCode\x12\x0c\n\x08NoReturn\x10\x00\x12\x0b\n\x07Success\x10\x01\x12\x0b\n\x07Timeout\x10\x02\x12\x0b\n\x07\x42\x61\x63koff\x10\x03\x12\x0f\n\x0bUnavailable\x10\x04\x12\x12\n\x0eNotImplemented\x10\x05\x12\x10\n\x0c\x45mptyRequest\x10\x06\x12\x11\n\rEmptyResponse\x10\x07\x12\x13\n\x0fInvalidResponse\x10\x08\x12\x12\n\x0eInvalidRequest\x10\t\x12\x19\n\x15RequestShapeException\x10\n\x12\x1a\n\x16ResponseShapeException\x10\x0b\x12!\n\x1dRequestSerializationException\x10\x0c\x12\"\n\x1eResponseSerializationException\x10\r\x12#\n\x1fRequestDeserializationException\x10\x0e\x12$\n ResponseDeserializationException\x10\x0f\x12\x15\n\x11NotServingNucleus\x10\x10\x12\x12\n\x0eNucleusTimeout\x10\x11\x12\x0f\n\x0bNucleusFull\x10\x12\x12\x1e\n\x1aRequestIncompatibleVersion\x10\x13\x12\x1f\n\x1bResponseIncompatibleVersion\x10\x14\x12\x11\n\rSenderUnknown\x10\x15\x12\x14\n\x10UnknownException\x10\x16\x12\x13\n\x0fUnauthenticated\x10\x17\x12\x0f\n\x0b\x42\x61\x64\x45ndpoint\x10\x18\x12\x0f\n\x0b\x42lacklisted\x10\x19*&\n\nSerializer\x12\x0b\n\x07MSGPACK\x10\x00\x12\x0b\n\x07\x43MPPACK\x10\x01*2\n\nTensorType\x12\t\n\x05TORCH\x10\x00\x12\x0e\n\nTENSORFLOW\x10\x01\x12\t\n\x05NUMPY\x10\x02*h\n\x08\x44\x61taType\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07\x46LOAT32\x10\x01\x12\x0b\n\x07\x46LOAT64\x10\x02\x12\t\n\x05INT32\x10\x03\x12\t\n\x05INT64\x10\x04\x12\x08\n\x04UTF8\x10\x05\x12\x0b\n\x07\x46LOAT16\x10\x06\x12\x08\n\x04\x42OOL\x10\x07\x32\xa6\x01\n\rTextPrompting\x12H\n\x07\x46orward\x12\x1c.ForwardTextPromptingRequest\x1a\x1d.ForwardTextPromptingResponse\"\x00\x12K\n\x08\x42\x61\x63kward\x12\x1d.BackwardTextPromptingRequest\x1a\x1e.BackwardTextPromptingResponse\"\x00\x62\x06proto3'
+    name="bittensor/_proto/bittensor.proto",
+    package="",
+    syntax="proto3",
+    serialized_options=None,
+    create_key=_descriptor._internal_create_key,
+    serialized_pb=b'\n bittensor/_proto/bittensor.proto"Q\n\x1b\x46orwardTextPromptingRequest\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x10\n\x08messages\x18\x03 \x03(\t\x12\x0f\n\x07timeout\x18\x04 \x01(\x02"{\n\x1c\x46orwardTextPromptingResponse\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x10\n\x08response\x18\x03 \x01(\t\x12\x16\n\x0ereturn_message\x18\x04 \x01(\t\x12 \n\x0breturn_code\x18\x05 \x01(\x0e\x32\x0b.ReturnCode"u\n\x1c\x42\x61\x63kwardTextPromptingRequest\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x0f\n\x07rewards\x18\x03 \x03(\x02\x12\x10\n\x08messages\x18\x04 \x03(\t\x12\x10\n\x08response\x18\x05 \x01(\t\x12\x0f\n\x07timeout\x18\x06 \x01(\x02"j\n\x1d\x42\x61\x63kwardTextPromptingResponse\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x16\n\x0ereturn_message\x18\x04 \x01(\t\x12 \n\x0breturn_code\x18\x05 \x01(\x0e\x32\x0b.ReturnCode"\xac\x01\n\x06Tensor\x12\x0f\n\x07version\x18\x01 \x01(\x05\x12\x0e\n\x06\x62uffer\x18\x02 \x01(\x0c\x12\r\n\x05shape\x18\x03 \x03(\x03\x12\x1f\n\nserializer\x18\x04 \x01(\x0e\x32\x0b.Serializer\x12 \n\x0btensor_type\x18\x05 \x01(\x0e\x32\x0b.TensorType\x12\x18\n\x05\x64type\x18\x06 \x01(\x0e\x32\t.DataType\x12\x15\n\rrequires_grad\x18\x08 \x01(\x08*\xda\x04\n\nReturnCode\x12\x0c\n\x08NoReturn\x10\x00\x12\x0b\n\x07Success\x10\x01\x12\x0b\n\x07Timeout\x10\x02\x12\x0b\n\x07\x42\x61\x63koff\x10\x03\x12\x0f\n\x0bUnavailable\x10\x04\x12\x12\n\x0eNotImplemented\x10\x05\x12\x10\n\x0c\x45mptyRequest\x10\x06\x12\x11\n\rEmptyResponse\x10\x07\x12\x13\n\x0fInvalidResponse\x10\x08\x12\x12\n\x0eInvalidRequest\x10\t\x12\x19\n\x15RequestShapeException\x10\n\x12\x1a\n\x16ResponseShapeException\x10\x0b\x12!\n\x1dRequestSerializationException\x10\x0c\x12"\n\x1eResponseSerializationException\x10\r\x12#\n\x1fRequestDeserializationException\x10\x0e\x12$\n ResponseDeserializationException\x10\x0f\x12\x15\n\x11NotServingNucleus\x10\x10\x12\x12\n\x0eNucleusTimeout\x10\x11\x12\x0f\n\x0bNucleusFull\x10\x12\x12\x1e\n\x1aRequestIncompatibleVersion\x10\x13\x12\x1f\n\x1bResponseIncompatibleVersion\x10\x14\x12\x11\n\rSenderUnknown\x10\x15\x12\x14\n\x10UnknownException\x10\x16\x12\x13\n\x0fUnauthenticated\x10\x17\x12\x0f\n\x0b\x42\x61\x64\x45ndpoint\x10\x18\x12\x0f\n\x0b\x42lacklisted\x10\x19*&\n\nSerializer\x12\x0b\n\x07MSGPACK\x10\x00\x12\x0b\n\x07\x43MPPACK\x10\x01*2\n\nTensorType\x12\t\n\x05TORCH\x10\x00\x12\x0e\n\nTENSORFLOW\x10\x01\x12\t\n\x05NUMPY\x10\x02*h\n\x08\x44\x61taType\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07\x46LOAT32\x10\x01\x12\x0b\n\x07\x46LOAT64\x10\x02\x12\t\n\x05INT32\x10\x03\x12\t\n\x05INT64\x10\x04\x12\x08\n\x04UTF8\x10\x05\x12\x0b\n\x07\x46LOAT16\x10\x06\x12\x08\n\x04\x42OOL\x10\x07\x32\xa6\x01\n\rTextPrompting\x12H\n\x07\x46orward\x12\x1c.ForwardTextPromptingRequest\x1a\x1d.ForwardTextPromptingResponse"\x00\x12K\n\x08\x42\x61\x63kward\x12\x1d.BackwardTextPromptingRequest\x1a\x1e.BackwardTextPromptingResponse"\x00\x62\x06proto3',
 )
 
 _RETURNCODE = _descriptor.EnumDescriptor(
-  name='ReturnCode',
-  full_name='ReturnCode',
-  filename=None,
-  file=DESCRIPTOR,
-  create_key=_descriptor._internal_create_key,
-  values=[
-    _descriptor.EnumValueDescriptor(
-      name='NoReturn', index=0, number=0,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Success', index=1, number=1,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Timeout', index=2, number=2,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Backoff', index=3, number=3,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Unavailable', index=4, number=4,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='NotImplemented', index=5, number=5,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='EmptyRequest', index=6, number=6,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='EmptyResponse', index=7, number=7,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='InvalidResponse', index=8, number=8,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='InvalidRequest', index=9, number=9,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='RequestShapeException', index=10, number=10,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='ResponseShapeException', index=11, number=11,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='RequestSerializationException', index=12, number=12,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='ResponseSerializationException', index=13, number=13,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='RequestDeserializationException', index=14, number=14,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='ResponseDeserializationException', index=15, number=15,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='NotServingNucleus', index=16, number=16,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='NucleusTimeout', index=17, number=17,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='NucleusFull', index=18, number=18,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='RequestIncompatibleVersion', index=19, number=19,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='ResponseIncompatibleVersion', index=20, number=20,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='SenderUnknown', index=21, number=21,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='UnknownException', index=22, number=22,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Unauthenticated', index=23, number=23,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='BadEndpoint', index=24, number=24,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='Blacklisted', index=25, number=25,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-  ],
-  containing_type=None,
-  serialized_options=None,
-  serialized_start=647,
-  serialized_end=1249,
+    name="ReturnCode",
+    full_name="ReturnCode",
+    filename=None,
+    file=DESCRIPTOR,
+    create_key=_descriptor._internal_create_key,
+    values=[
+        _descriptor.EnumValueDescriptor(
+            name="NoReturn",
+            index=0,
+            number=0,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Success",
+            index=1,
+            number=1,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Timeout",
+            index=2,
+            number=2,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Backoff",
+            index=3,
+            number=3,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Unavailable",
+            index=4,
+            number=4,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="NotImplemented",
+            index=5,
+            number=5,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="EmptyRequest",
+            index=6,
+            number=6,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="EmptyResponse",
+            index=7,
+            number=7,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="InvalidResponse",
+            index=8,
+            number=8,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="InvalidRequest",
+            index=9,
+            number=9,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="RequestShapeException",
+            index=10,
+            number=10,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="ResponseShapeException",
+            index=11,
+            number=11,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="RequestSerializationException",
+            index=12,
+            number=12,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="ResponseSerializationException",
+            index=13,
+            number=13,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="RequestDeserializationException",
+            index=14,
+            number=14,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="ResponseDeserializationException",
+            index=15,
+            number=15,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="NotServingNucleus",
+            index=16,
+            number=16,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="NucleusTimeout",
+            index=17,
+            number=17,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="NucleusFull",
+            index=18,
+            number=18,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="RequestIncompatibleVersion",
+            index=19,
+            number=19,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="ResponseIncompatibleVersion",
+            index=20,
+            number=20,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="SenderUnknown",
+            index=21,
+            number=21,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="UnknownException",
+            index=22,
+            number=22,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Unauthenticated",
+            index=23,
+            number=23,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="BadEndpoint",
+            index=24,
+            number=24,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="Blacklisted",
+            index=25,
+            number=25,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    containing_type=None,
+    serialized_options=None,
+    serialized_start=647,
+    serialized_end=1249,
 )
 _sym_db.RegisterEnumDescriptor(_RETURNCODE)
 
 ReturnCode = enum_type_wrapper.EnumTypeWrapper(_RETURNCODE)
 _SERIALIZER = _descriptor.EnumDescriptor(
-  name='Serializer',
-  full_name='Serializer',
-  filename=None,
-  file=DESCRIPTOR,
-  create_key=_descriptor._internal_create_key,
-  values=[
-    _descriptor.EnumValueDescriptor(
-      name='MSGPACK', index=0, number=0,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='CMPPACK', index=1, number=1,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-  ],
-  containing_type=None,
-  serialized_options=None,
-  serialized_start=1251,
-  serialized_end=1289,
+    name="Serializer",
+    full_name="Serializer",
+    filename=None,
+    file=DESCRIPTOR,
+    create_key=_descriptor._internal_create_key,
+    values=[
+        _descriptor.EnumValueDescriptor(
+            name="MSGPACK",
+            index=0,
+            number=0,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="CMPPACK",
+            index=1,
+            number=1,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    containing_type=None,
+    serialized_options=None,
+    serialized_start=1251,
+    serialized_end=1289,
 )
 _sym_db.RegisterEnumDescriptor(_SERIALIZER)
 
 Serializer = enum_type_wrapper.EnumTypeWrapper(_SERIALIZER)
 _TENSORTYPE = _descriptor.EnumDescriptor(
-  name='TensorType',
-  full_name='TensorType',
-  filename=None,
-  file=DESCRIPTOR,
-  create_key=_descriptor._internal_create_key,
-  values=[
-    _descriptor.EnumValueDescriptor(
-      name='TORCH', index=0, number=0,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='TENSORFLOW', index=1, number=1,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='NUMPY', index=2, number=2,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-  ],
-  containing_type=None,
-  serialized_options=None,
-  serialized_start=1291,
-  serialized_end=1341,
+    name="TensorType",
+    full_name="TensorType",
+    filename=None,
+    file=DESCRIPTOR,
+    create_key=_descriptor._internal_create_key,
+    values=[
+        _descriptor.EnumValueDescriptor(
+            name="TORCH",
+            index=0,
+            number=0,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="TENSORFLOW",
+            index=1,
+            number=1,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="NUMPY",
+            index=2,
+            number=2,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    containing_type=None,
+    serialized_options=None,
+    serialized_start=1291,
+    serialized_end=1341,
 )
 _sym_db.RegisterEnumDescriptor(_TENSORTYPE)
 
 TensorType = enum_type_wrapper.EnumTypeWrapper(_TENSORTYPE)
 _DATATYPE = _descriptor.EnumDescriptor(
-  name='DataType',
-  full_name='DataType',
-  filename=None,
-  file=DESCRIPTOR,
-  create_key=_descriptor._internal_create_key,
-  values=[
-    _descriptor.EnumValueDescriptor(
-      name='UNKNOWN', index=0, number=0,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='FLOAT32', index=1, number=1,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='FLOAT64', index=2, number=2,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='INT32', index=3, number=3,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='INT64', index=4, number=4,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='UTF8', index=5, number=5,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='FLOAT16', index=6, number=6,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-    _descriptor.EnumValueDescriptor(
-      name='BOOL', index=7, number=7,
-      serialized_options=None,
-      type=None,
-      create_key=_descriptor._internal_create_key),
-  ],
-  containing_type=None,
-  serialized_options=None,
-  serialized_start=1343,
-  serialized_end=1447,
+    name="DataType",
+    full_name="DataType",
+    filename=None,
+    file=DESCRIPTOR,
+    create_key=_descriptor._internal_create_key,
+    values=[
+        _descriptor.EnumValueDescriptor(
+            name="UNKNOWN",
+            index=0,
+            number=0,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="FLOAT32",
+            index=1,
+            number=1,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="FLOAT64",
+            index=2,
+            number=2,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="INT32",
+            index=3,
+            number=3,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="INT64",
+            index=4,
+            number=4,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="UTF8",
+            index=5,
+            number=5,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="FLOAT16",
+            index=6,
+            number=6,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.EnumValueDescriptor(
+            name="BOOL",
+            index=7,
+            number=7,
+            serialized_options=None,
+            type=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    containing_type=None,
+    serialized_options=None,
+    serialized_start=1343,
+    serialized_end=1447,
 )
 _sym_db.RegisterEnumDescriptor(_DATATYPE)
 
 DataType = enum_type_wrapper.EnumTypeWrapper(_DATATYPE)
 NoReturn = 0
 Success = 1
 Timeout = 2
@@ -319,375 +435,651 @@
 INT32 = 3
 INT64 = 4
 UTF8 = 5
 FLOAT16 = 6
 BOOL = 7
 
 
-
 _FORWARDTEXTPROMPTINGREQUEST = _descriptor.Descriptor(
-  name='ForwardTextPromptingRequest',
-  full_name='ForwardTextPromptingRequest',
-  filename=None,
-  file=DESCRIPTOR,
-  containing_type=None,
-  create_key=_descriptor._internal_create_key,
-  fields=[
-    _descriptor.FieldDescriptor(
-      name='version', full_name='ForwardTextPromptingRequest.version', index=0,
-      number=1, type=5, cpp_type=1, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='messages', full_name='ForwardTextPromptingRequest.messages', index=1,
-      number=3, type=9, cpp_type=9, label=3,
-      has_default_value=False, default_value=[],
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='timeout', full_name='ForwardTextPromptingRequest.timeout', index=2,
-      number=4, type=2, cpp_type=6, label=1,
-      has_default_value=False, default_value=float(0),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-  ],
-  extensions=[
-  ],
-  nested_types=[],
-  enum_types=[
-  ],
-  serialized_options=None,
-  is_extendable=False,
-  syntax='proto3',
-  extension_ranges=[],
-  oneofs=[
-  ],
-  serialized_start=36,
-  serialized_end=117,
+    name="ForwardTextPromptingRequest",
+    full_name="ForwardTextPromptingRequest",
+    filename=None,
+    file=DESCRIPTOR,
+    containing_type=None,
+    create_key=_descriptor._internal_create_key,
+    fields=[
+        _descriptor.FieldDescriptor(
+            name="version",
+            full_name="ForwardTextPromptingRequest.version",
+            index=0,
+            number=1,
+            type=5,
+            cpp_type=1,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="messages",
+            full_name="ForwardTextPromptingRequest.messages",
+            index=1,
+            number=3,
+            type=9,
+            cpp_type=9,
+            label=3,
+            has_default_value=False,
+            default_value=[],
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="timeout",
+            full_name="ForwardTextPromptingRequest.timeout",
+            index=2,
+            number=4,
+            type=2,
+            cpp_type=6,
+            label=1,
+            has_default_value=False,
+            default_value=float(0),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    extensions=[],
+    nested_types=[],
+    enum_types=[],
+    serialized_options=None,
+    is_extendable=False,
+    syntax="proto3",
+    extension_ranges=[],
+    oneofs=[],
+    serialized_start=36,
+    serialized_end=117,
 )
 
 
 _FORWARDTEXTPROMPTINGRESPONSE = _descriptor.Descriptor(
-  name='ForwardTextPromptingResponse',
-  full_name='ForwardTextPromptingResponse',
-  filename=None,
-  file=DESCRIPTOR,
-  containing_type=None,
-  create_key=_descriptor._internal_create_key,
-  fields=[
-    _descriptor.FieldDescriptor(
-      name='version', full_name='ForwardTextPromptingResponse.version', index=0,
-      number=1, type=5, cpp_type=1, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='response', full_name='ForwardTextPromptingResponse.response', index=1,
-      number=3, type=9, cpp_type=9, label=1,
-      has_default_value=False, default_value=b"".decode('utf-8'),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='return_message', full_name='ForwardTextPromptingResponse.return_message', index=2,
-      number=4, type=9, cpp_type=9, label=1,
-      has_default_value=False, default_value=b"".decode('utf-8'),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='return_code', full_name='ForwardTextPromptingResponse.return_code', index=3,
-      number=5, type=14, cpp_type=8, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-  ],
-  extensions=[
-  ],
-  nested_types=[],
-  enum_types=[
-  ],
-  serialized_options=None,
-  is_extendable=False,
-  syntax='proto3',
-  extension_ranges=[],
-  oneofs=[
-  ],
-  serialized_start=119,
-  serialized_end=242,
+    name="ForwardTextPromptingResponse",
+    full_name="ForwardTextPromptingResponse",
+    filename=None,
+    file=DESCRIPTOR,
+    containing_type=None,
+    create_key=_descriptor._internal_create_key,
+    fields=[
+        _descriptor.FieldDescriptor(
+            name="version",
+            full_name="ForwardTextPromptingResponse.version",
+            index=0,
+            number=1,
+            type=5,
+            cpp_type=1,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="response",
+            full_name="ForwardTextPromptingResponse.response",
+            index=1,
+            number=3,
+            type=9,
+            cpp_type=9,
+            label=1,
+            has_default_value=False,
+            default_value=b"".decode("utf-8"),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="return_message",
+            full_name="ForwardTextPromptingResponse.return_message",
+            index=2,
+            number=4,
+            type=9,
+            cpp_type=9,
+            label=1,
+            has_default_value=False,
+            default_value=b"".decode("utf-8"),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="return_code",
+            full_name="ForwardTextPromptingResponse.return_code",
+            index=3,
+            number=5,
+            type=14,
+            cpp_type=8,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    extensions=[],
+    nested_types=[],
+    enum_types=[],
+    serialized_options=None,
+    is_extendable=False,
+    syntax="proto3",
+    extension_ranges=[],
+    oneofs=[],
+    serialized_start=119,
+    serialized_end=242,
 )
 
 
 _BACKWARDTEXTPROMPTINGREQUEST = _descriptor.Descriptor(
-  name='BackwardTextPromptingRequest',
-  full_name='BackwardTextPromptingRequest',
-  filename=None,
-  file=DESCRIPTOR,
-  containing_type=None,
-  create_key=_descriptor._internal_create_key,
-  fields=[
-    _descriptor.FieldDescriptor(
-      name='version', full_name='BackwardTextPromptingRequest.version', index=0,
-      number=1, type=5, cpp_type=1, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='rewards', full_name='BackwardTextPromptingRequest.rewards', index=1,
-      number=3, type=2, cpp_type=6, label=3,
-      has_default_value=False, default_value=[],
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='messages', full_name='BackwardTextPromptingRequest.messages', index=2,
-      number=4, type=9, cpp_type=9, label=3,
-      has_default_value=False, default_value=[],
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='response', full_name='BackwardTextPromptingRequest.response', index=3,
-      number=5, type=9, cpp_type=9, label=1,
-      has_default_value=False, default_value=b"".decode('utf-8'),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='timeout', full_name='BackwardTextPromptingRequest.timeout', index=4,
-      number=6, type=2, cpp_type=6, label=1,
-      has_default_value=False, default_value=float(0),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-  ],
-  extensions=[
-  ],
-  nested_types=[],
-  enum_types=[
-  ],
-  serialized_options=None,
-  is_extendable=False,
-  syntax='proto3',
-  extension_ranges=[],
-  oneofs=[
-  ],
-  serialized_start=244,
-  serialized_end=361,
+    name="BackwardTextPromptingRequest",
+    full_name="BackwardTextPromptingRequest",
+    filename=None,
+    file=DESCRIPTOR,
+    containing_type=None,
+    create_key=_descriptor._internal_create_key,
+    fields=[
+        _descriptor.FieldDescriptor(
+            name="version",
+            full_name="BackwardTextPromptingRequest.version",
+            index=0,
+            number=1,
+            type=5,
+            cpp_type=1,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="rewards",
+            full_name="BackwardTextPromptingRequest.rewards",
+            index=1,
+            number=3,
+            type=2,
+            cpp_type=6,
+            label=3,
+            has_default_value=False,
+            default_value=[],
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="messages",
+            full_name="BackwardTextPromptingRequest.messages",
+            index=2,
+            number=4,
+            type=9,
+            cpp_type=9,
+            label=3,
+            has_default_value=False,
+            default_value=[],
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="response",
+            full_name="BackwardTextPromptingRequest.response",
+            index=3,
+            number=5,
+            type=9,
+            cpp_type=9,
+            label=1,
+            has_default_value=False,
+            default_value=b"".decode("utf-8"),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="timeout",
+            full_name="BackwardTextPromptingRequest.timeout",
+            index=4,
+            number=6,
+            type=2,
+            cpp_type=6,
+            label=1,
+            has_default_value=False,
+            default_value=float(0),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    extensions=[],
+    nested_types=[],
+    enum_types=[],
+    serialized_options=None,
+    is_extendable=False,
+    syntax="proto3",
+    extension_ranges=[],
+    oneofs=[],
+    serialized_start=244,
+    serialized_end=361,
 )
 
 
 _BACKWARDTEXTPROMPTINGRESPONSE = _descriptor.Descriptor(
-  name='BackwardTextPromptingResponse',
-  full_name='BackwardTextPromptingResponse',
-  filename=None,
-  file=DESCRIPTOR,
-  containing_type=None,
-  create_key=_descriptor._internal_create_key,
-  fields=[
-    _descriptor.FieldDescriptor(
-      name='version', full_name='BackwardTextPromptingResponse.version', index=0,
-      number=1, type=5, cpp_type=1, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='return_message', full_name='BackwardTextPromptingResponse.return_message', index=1,
-      number=4, type=9, cpp_type=9, label=1,
-      has_default_value=False, default_value=b"".decode('utf-8'),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='return_code', full_name='BackwardTextPromptingResponse.return_code', index=2,
-      number=5, type=14, cpp_type=8, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-  ],
-  extensions=[
-  ],
-  nested_types=[],
-  enum_types=[
-  ],
-  serialized_options=None,
-  is_extendable=False,
-  syntax='proto3',
-  extension_ranges=[],
-  oneofs=[
-  ],
-  serialized_start=363,
-  serialized_end=469,
+    name="BackwardTextPromptingResponse",
+    full_name="BackwardTextPromptingResponse",
+    filename=None,
+    file=DESCRIPTOR,
+    containing_type=None,
+    create_key=_descriptor._internal_create_key,
+    fields=[
+        _descriptor.FieldDescriptor(
+            name="version",
+            full_name="BackwardTextPromptingResponse.version",
+            index=0,
+            number=1,
+            type=5,
+            cpp_type=1,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="return_message",
+            full_name="BackwardTextPromptingResponse.return_message",
+            index=1,
+            number=4,
+            type=9,
+            cpp_type=9,
+            label=1,
+            has_default_value=False,
+            default_value=b"".decode("utf-8"),
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="return_code",
+            full_name="BackwardTextPromptingResponse.return_code",
+            index=2,
+            number=5,
+            type=14,
+            cpp_type=8,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    extensions=[],
+    nested_types=[],
+    enum_types=[],
+    serialized_options=None,
+    is_extendable=False,
+    syntax="proto3",
+    extension_ranges=[],
+    oneofs=[],
+    serialized_start=363,
+    serialized_end=469,
 )
 
 
 _TENSOR = _descriptor.Descriptor(
-  name='Tensor',
-  full_name='Tensor',
-  filename=None,
-  file=DESCRIPTOR,
-  containing_type=None,
-  create_key=_descriptor._internal_create_key,
-  fields=[
-    _descriptor.FieldDescriptor(
-      name='version', full_name='Tensor.version', index=0,
-      number=1, type=5, cpp_type=1, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='buffer', full_name='Tensor.buffer', index=1,
-      number=2, type=12, cpp_type=9, label=1,
-      has_default_value=False, default_value=b"",
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='shape', full_name='Tensor.shape', index=2,
-      number=3, type=3, cpp_type=2, label=3,
-      has_default_value=False, default_value=[],
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='serializer', full_name='Tensor.serializer', index=3,
-      number=4, type=14, cpp_type=8, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='tensor_type', full_name='Tensor.tensor_type', index=4,
-      number=5, type=14, cpp_type=8, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='dtype', full_name='Tensor.dtype', index=5,
-      number=6, type=14, cpp_type=8, label=1,
-      has_default_value=False, default_value=0,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-    _descriptor.FieldDescriptor(
-      name='requires_grad', full_name='Tensor.requires_grad', index=6,
-      number=8, type=8, cpp_type=7, label=1,
-      has_default_value=False, default_value=False,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      serialized_options=None, file=DESCRIPTOR,  create_key=_descriptor._internal_create_key),
-  ],
-  extensions=[
-  ],
-  nested_types=[],
-  enum_types=[
-  ],
-  serialized_options=None,
-  is_extendable=False,
-  syntax='proto3',
-  extension_ranges=[],
-  oneofs=[
-  ],
-  serialized_start=472,
-  serialized_end=644,
-)
-
-_FORWARDTEXTPROMPTINGRESPONSE.fields_by_name['return_code'].enum_type = _RETURNCODE
-_BACKWARDTEXTPROMPTINGRESPONSE.fields_by_name['return_code'].enum_type = _RETURNCODE
-_TENSOR.fields_by_name['serializer'].enum_type = _SERIALIZER
-_TENSOR.fields_by_name['tensor_type'].enum_type = _TENSORTYPE
-_TENSOR.fields_by_name['dtype'].enum_type = _DATATYPE
-DESCRIPTOR.message_types_by_name['ForwardTextPromptingRequest'] = _FORWARDTEXTPROMPTINGREQUEST
-DESCRIPTOR.message_types_by_name['ForwardTextPromptingResponse'] = _FORWARDTEXTPROMPTINGRESPONSE
-DESCRIPTOR.message_types_by_name['BackwardTextPromptingRequest'] = _BACKWARDTEXTPROMPTINGREQUEST
-DESCRIPTOR.message_types_by_name['BackwardTextPromptingResponse'] = _BACKWARDTEXTPROMPTINGRESPONSE
-DESCRIPTOR.message_types_by_name['Tensor'] = _TENSOR
-DESCRIPTOR.enum_types_by_name['ReturnCode'] = _RETURNCODE
-DESCRIPTOR.enum_types_by_name['Serializer'] = _SERIALIZER
-DESCRIPTOR.enum_types_by_name['TensorType'] = _TENSORTYPE
-DESCRIPTOR.enum_types_by_name['DataType'] = _DATATYPE
+    name="Tensor",
+    full_name="Tensor",
+    filename=None,
+    file=DESCRIPTOR,
+    containing_type=None,
+    create_key=_descriptor._internal_create_key,
+    fields=[
+        _descriptor.FieldDescriptor(
+            name="version",
+            full_name="Tensor.version",
+            index=0,
+            number=1,
+            type=5,
+            cpp_type=1,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="buffer",
+            full_name="Tensor.buffer",
+            index=1,
+            number=2,
+            type=12,
+            cpp_type=9,
+            label=1,
+            has_default_value=False,
+            default_value=b"",
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="shape",
+            full_name="Tensor.shape",
+            index=2,
+            number=3,
+            type=3,
+            cpp_type=2,
+            label=3,
+            has_default_value=False,
+            default_value=[],
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="serializer",
+            full_name="Tensor.serializer",
+            index=3,
+            number=4,
+            type=14,
+            cpp_type=8,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="tensor_type",
+            full_name="Tensor.tensor_type",
+            index=4,
+            number=5,
+            type=14,
+            cpp_type=8,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="dtype",
+            full_name="Tensor.dtype",
+            index=5,
+            number=6,
+            type=14,
+            cpp_type=8,
+            label=1,
+            has_default_value=False,
+            default_value=0,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.FieldDescriptor(
+            name="requires_grad",
+            full_name="Tensor.requires_grad",
+            index=6,
+            number=8,
+            type=8,
+            cpp_type=7,
+            label=1,
+            has_default_value=False,
+            default_value=False,
+            message_type=None,
+            enum_type=None,
+            containing_type=None,
+            is_extension=False,
+            extension_scope=None,
+            serialized_options=None,
+            file=DESCRIPTOR,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+    extensions=[],
+    nested_types=[],
+    enum_types=[],
+    serialized_options=None,
+    is_extendable=False,
+    syntax="proto3",
+    extension_ranges=[],
+    oneofs=[],
+    serialized_start=472,
+    serialized_end=644,
+)
+
+_FORWARDTEXTPROMPTINGRESPONSE.fields_by_name["return_code"].enum_type = _RETURNCODE
+_BACKWARDTEXTPROMPTINGRESPONSE.fields_by_name["return_code"].enum_type = _RETURNCODE
+_TENSOR.fields_by_name["serializer"].enum_type = _SERIALIZER
+_TENSOR.fields_by_name["tensor_type"].enum_type = _TENSORTYPE
+_TENSOR.fields_by_name["dtype"].enum_type = _DATATYPE
+DESCRIPTOR.message_types_by_name[
+    "ForwardTextPromptingRequest"
+] = _FORWARDTEXTPROMPTINGREQUEST
+DESCRIPTOR.message_types_by_name[
+    "ForwardTextPromptingResponse"
+] = _FORWARDTEXTPROMPTINGRESPONSE
+DESCRIPTOR.message_types_by_name[
+    "BackwardTextPromptingRequest"
+] = _BACKWARDTEXTPROMPTINGREQUEST
+DESCRIPTOR.message_types_by_name[
+    "BackwardTextPromptingResponse"
+] = _BACKWARDTEXTPROMPTINGRESPONSE
+DESCRIPTOR.message_types_by_name["Tensor"] = _TENSOR
+DESCRIPTOR.enum_types_by_name["ReturnCode"] = _RETURNCODE
+DESCRIPTOR.enum_types_by_name["Serializer"] = _SERIALIZER
+DESCRIPTOR.enum_types_by_name["TensorType"] = _TENSORTYPE
+DESCRIPTOR.enum_types_by_name["DataType"] = _DATATYPE
 _sym_db.RegisterFileDescriptor(DESCRIPTOR)
 
-ForwardTextPromptingRequest = _reflection.GeneratedProtocolMessageType('ForwardTextPromptingRequest', (_message.Message,), {
-  'DESCRIPTOR' : _FORWARDTEXTPROMPTINGREQUEST,
-  '__module__' : 'bittensor._proto.bittensor_pb2'
-  # @@protoc_insertion_point(class_scope:ForwardTextPromptingRequest)
-  })
+ForwardTextPromptingRequest = _reflection.GeneratedProtocolMessageType(
+    "ForwardTextPromptingRequest",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _FORWARDTEXTPROMPTINGREQUEST,
+        "__module__": "bittensor._proto.bittensor_pb2"
+        # @@protoc_insertion_point(class_scope:ForwardTextPromptingRequest)
+    },
+)
 _sym_db.RegisterMessage(ForwardTextPromptingRequest)
 
-ForwardTextPromptingResponse = _reflection.GeneratedProtocolMessageType('ForwardTextPromptingResponse', (_message.Message,), {
-  'DESCRIPTOR' : _FORWARDTEXTPROMPTINGRESPONSE,
-  '__module__' : 'bittensor._proto.bittensor_pb2'
-  # @@protoc_insertion_point(class_scope:ForwardTextPromptingResponse)
-  })
+ForwardTextPromptingResponse = _reflection.GeneratedProtocolMessageType(
+    "ForwardTextPromptingResponse",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _FORWARDTEXTPROMPTINGRESPONSE,
+        "__module__": "bittensor._proto.bittensor_pb2"
+        # @@protoc_insertion_point(class_scope:ForwardTextPromptingResponse)
+    },
+)
 _sym_db.RegisterMessage(ForwardTextPromptingResponse)
 
-BackwardTextPromptingRequest = _reflection.GeneratedProtocolMessageType('BackwardTextPromptingRequest', (_message.Message,), {
-  'DESCRIPTOR' : _BACKWARDTEXTPROMPTINGREQUEST,
-  '__module__' : 'bittensor._proto.bittensor_pb2'
-  # @@protoc_insertion_point(class_scope:BackwardTextPromptingRequest)
-  })
+BackwardTextPromptingRequest = _reflection.GeneratedProtocolMessageType(
+    "BackwardTextPromptingRequest",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _BACKWARDTEXTPROMPTINGREQUEST,
+        "__module__": "bittensor._proto.bittensor_pb2"
+        # @@protoc_insertion_point(class_scope:BackwardTextPromptingRequest)
+    },
+)
 _sym_db.RegisterMessage(BackwardTextPromptingRequest)
 
-BackwardTextPromptingResponse = _reflection.GeneratedProtocolMessageType('BackwardTextPromptingResponse', (_message.Message,), {
-  'DESCRIPTOR' : _BACKWARDTEXTPROMPTINGRESPONSE,
-  '__module__' : 'bittensor._proto.bittensor_pb2'
-  # @@protoc_insertion_point(class_scope:BackwardTextPromptingResponse)
-  })
+BackwardTextPromptingResponse = _reflection.GeneratedProtocolMessageType(
+    "BackwardTextPromptingResponse",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _BACKWARDTEXTPROMPTINGRESPONSE,
+        "__module__": "bittensor._proto.bittensor_pb2"
+        # @@protoc_insertion_point(class_scope:BackwardTextPromptingResponse)
+    },
+)
 _sym_db.RegisterMessage(BackwardTextPromptingResponse)
 
-Tensor = _reflection.GeneratedProtocolMessageType('Tensor', (_message.Message,), {
-  'DESCRIPTOR' : _TENSOR,
-  '__module__' : 'bittensor._proto.bittensor_pb2'
-  # @@protoc_insertion_point(class_scope:Tensor)
-  })
+Tensor = _reflection.GeneratedProtocolMessageType(
+    "Tensor",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _TENSOR,
+        "__module__": "bittensor._proto.bittensor_pb2"
+        # @@protoc_insertion_point(class_scope:Tensor)
+    },
+)
 _sym_db.RegisterMessage(Tensor)
 
 
-
 _TEXTPROMPTING = _descriptor.ServiceDescriptor(
-  name='TextPrompting',
-  full_name='TextPrompting',
-  file=DESCRIPTOR,
-  index=0,
-  serialized_options=None,
-  create_key=_descriptor._internal_create_key,
-  serialized_start=1450,
-  serialized_end=1616,
-  methods=[
-  _descriptor.MethodDescriptor(
-    name='Forward',
-    full_name='TextPrompting.Forward',
+    name="TextPrompting",
+    full_name="TextPrompting",
+    file=DESCRIPTOR,
     index=0,
-    containing_service=None,
-    input_type=_FORWARDTEXTPROMPTINGREQUEST,
-    output_type=_FORWARDTEXTPROMPTINGRESPONSE,
-    serialized_options=None,
-    create_key=_descriptor._internal_create_key,
-  ),
-  _descriptor.MethodDescriptor(
-    name='Backward',
-    full_name='TextPrompting.Backward',
-    index=1,
-    containing_service=None,
-    input_type=_BACKWARDTEXTPROMPTINGREQUEST,
-    output_type=_BACKWARDTEXTPROMPTINGRESPONSE,
     serialized_options=None,
     create_key=_descriptor._internal_create_key,
-  ),
-])
+    serialized_start=1450,
+    serialized_end=1616,
+    methods=[
+        _descriptor.MethodDescriptor(
+            name="Forward",
+            full_name="TextPrompting.Forward",
+            index=0,
+            containing_service=None,
+            input_type=_FORWARDTEXTPROMPTINGREQUEST,
+            output_type=_FORWARDTEXTPROMPTINGRESPONSE,
+            serialized_options=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+        _descriptor.MethodDescriptor(
+            name="Backward",
+            full_name="TextPrompting.Backward",
+            index=1,
+            containing_service=None,
+            input_type=_BACKWARDTEXTPROMPTINGREQUEST,
+            output_type=_BACKWARDTEXTPROMPTINGRESPONSE,
+            serialized_options=None,
+            create_key=_descriptor._internal_create_key,
+        ),
+    ],
+)
 _sym_db.RegisterServiceDescriptor(_TEXTPROMPTING)
 
-DESCRIPTOR.services_by_name['TextPrompting'] = _TEXTPROMPTING
+DESCRIPTOR.services_by_name["TextPrompting"] = _TEXTPROMPTING
 
 # @@protoc_insertion_point(module_scope)
```

### Comparing `bittensor-5.3.1/bittensor/_serializer/__init__.py` & `bittensor-5.3.2/bittensor/_serializer/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -20,63 +20,69 @@
 import torch
 import numpy as np
 import bittensor
 from typing import Tuple, List, Union, Optional
 
 from . import serializer_impl
 
+
 class serializer:
-    """ An interface for serializing and deserializing bittensor tensors"""
+    """An interface for serializing and deserializing bittensor tensors"""
 
-    class SerializationException (Exception):
-        """ Raised during serialization """
+    class SerializationException(Exception):
+        """Raised during serialization"""
 
-    class DeserializationException (Exception):
-        """ Raised during deserialization """
+    class DeserializationException(Exception):
+        """Raised during deserialization"""
 
-    class NoSerializerForEnum (Exception):
-        """ Raised if there is no serializer for the passed type """
+    class NoSerializerForEnum(Exception):
+        """Raised if there is no serializer for the passed type"""
 
-    class SerializationTypeNotImplementedException (Exception):
-        """ Raised if serialization/deserialization is not implemented for the passed object type """
+    class SerializationTypeNotImplementedException(Exception):
+        """Raised if serialization/deserialization is not implemented for the passed object type"""
 
-    def __new__(cls, serializer_type: bittensor.proto.Serializer = bittensor.proto.Serializer.MSGPACK ) -> 'bittensor.Serializer':
+    def __new__(
+        cls,
+        serializer_type: bittensor.proto.Serializer = bittensor.proto.Serializer.MSGPACK,
+    ) -> "bittensor.Serializer":
         r"""Returns the correct serializer object for the passed Serializer enum.
 
-            Args:
-                serializer_type (:obj:`bittensor.proto.Serializer`, `required`):
-                    The serializer_type ENUM from bittensor.proto.
-
-            Returns:
-                Serializer: (obj: `bittensor.Serializer`, `required`):
-                    The bittensor serializer/deserialzer for the passed type.
-
-            Raises:
-                NoSerializerForEnum: (Exception):
-                    Raised if the passed there is no serialzier for the passed type.
+        Args:
+            serializer_type (:obj:`bittensor.proto.Serializer`, `required`):
+                The serializer_type ENUM from bittensor.proto.
+
+        Returns:
+            Serializer: (obj: `bittensor.Serializer`, `required`):
+                The bittensor serializer/deserialzer for the passed type.
+
+        Raises:
+            NoSerializerForEnum: (Exception):
+                Raised if the passed there is no serialzier for the passed type.
         """
         # WARNING: the pickle serializer is not safe. Should be removed in future verions.
         # if serializer_type == bittensor.proto.Serializer.PICKLE:
         #     return PyTorchPickleSerializer()
         if serializer_type == bittensor.proto.Serializer.MSGPACK:
             return serializer_impl.MSGPackSerializer()
         elif serializer_type == bittensor.proto.Serializer.CMPPACK:
             return serializer_impl.CMPPackSerializer()
         else:
-            raise bittensor.serializer.NoSerializerForEnum("No known serialzier for proto type {}".format(serializer_type))
+            raise bittensor.serializer.NoSerializerForEnum(
+                "No known serialzier for proto type {}".format(serializer_type)
+            )
 
     @staticmethod
     def torch_dtype_to_bittensor_dtype(tdtype):
-        """ Translates between torch.dtypes and bittensor.dtypes.
+        """Translates between torch.dtypes and bittensor.dtypes.
 
-            Args:
-                tdtype (torch.dtype): torch.dtype to translate.
+        Args:
+            tdtype (torch.dtype): torch.dtype to translate.
 
-            Returns:
-                dtype: (bittensor.dtype): translated bittensor.dtype.
+        Returns:
+            dtype: (bittensor.dtype): translated bittensor.dtype.
         """
         if tdtype == torch.float32:
             dtype = bittensor.proto.DataType.FLOAT32
         elif tdtype == torch.float64:
             dtype = bittensor.proto.DataType.FLOAT64
         elif tdtype == torch.int32:
             dtype = bittensor.proto.DataType.INT32
@@ -88,57 +94,60 @@
             dtype = bittensor.proto.DataType.BOOL
         else:
             dtype = bittensor.proto.DataType.UNKNOWN
         return dtype
 
     @staticmethod
     def bittensor_dtype_to_torch_dtype(bdtype):
-        """ Translates between bittensor.dtype and torch.dtypes.
+        """Translates between bittensor.dtype and torch.dtypes.
 
-            Args:
-                bdtype (bittensor.dtype): bittensor.dtype to translate.
+        Args:
+            bdtype (bittensor.dtype): bittensor.dtype to translate.
 
-            Returns:
-                dtype: (torch.dtype): translated torch.dtype.
+        Returns:
+            dtype: (torch.dtype): translated torch.dtype.
         """
         if bdtype == bittensor.proto.DataType.FLOAT32:
-            dtype=torch.float32
+            dtype = torch.float32
         elif bdtype == bittensor.proto.DataType.FLOAT64:
             dtype = torch.float64
         elif bdtype == bittensor.proto.DataType.INT32:
             dtype = torch.int32
         elif bdtype == bittensor.proto.DataType.INT64:
-            dtype=torch.int64
+            dtype = torch.int64
         elif bdtype == bittensor.proto.DataType.FLOAT16:
-            dtype=torch.float16
+            dtype = torch.float16
         elif bdtype == bittensor.proto.DataType.BOOL:
-            dtype=torch.bool
+            dtype = torch.bool
         else:
             raise bittensor.serializer.DeserializationException(
-                'Unknown bittensor.Dtype or no equivalent torch.dtype for bittensor.dtype = {}'
-                .format(bdtype))
+                "Unknown bittensor.Dtype or no equivalent torch.dtype for bittensor.dtype = {}".format(
+                    bdtype
+                )
+            )
         return dtype
 
     @staticmethod
     def bittensor_dtype_np_dtype(bdtype):
-        """ Translates between bittensor.dtype and np.dtypes.
+        """Translates between bittensor.dtype and np.dtypes.
 
-            Args:
-                bdtype (bittensor.dtype): bittensor.dtype to translate.
+        Args:
+            bdtype (bittensor.dtype): bittensor.dtype to translate.
 
-            Returns:
-                dtype: (numpy.dtype): translated np.dtype.
+        Returns:
+            dtype: (numpy.dtype): translated np.dtype.
         """
         if bdtype == bittensor.proto.DataType.FLOAT32:
             dtype = np.float32
         elif bdtype == bittensor.proto.DataType.FLOAT64:
             dtype = np.float64
         elif bdtype == bittensor.proto.DataType.INT32:
             dtype = np.int32
         elif bdtype == bittensor.proto.DataType.INT64:
             dtype = np.int64
         else:
             raise bittensor.serializer.SerializationException(
-                'Unknown bittensor.dtype or no equivalent numpy.dtype for bittensor.dtype = {}'
-                .format(bdtype))
+                "Unknown bittensor.dtype or no equivalent numpy.dtype for bittensor.dtype = {}".format(
+                    bdtype
+                )
+            )
         return dtype
-
```

### Comparing `bittensor-5.3.1/bittensor/_serializer/serializer_impl.py` & `bittensor-5.3.2/bittensor/_serializer/serializer_impl.py`

 * *Files 6% similar despite different names*

```diff
@@ -21,26 +21,29 @@
 import msgpack
 import msgpack_numpy
 from typing import Tuple, List, Union, Optional
 
 
 import bittensor
 
+
 class Serializer(object):
-    r""" Bittensor base serialization object for converting between bittensor.proto.Tensor and their
+    r"""Bittensor base serialization object for converting between bittensor.proto.Tensor and their
     various python tensor equivalents. i.e. torch.Tensor or tensorflow.Tensor
     """
 
     @staticmethod
     def empty():
         """Returns an empty bittensor.proto.Tensor message with the version"""
-        torch_proto = bittensor.proto.Tensor(version= bittensor.__version_as_int__)
+        torch_proto = bittensor.proto.Tensor(version=bittensor.__version_as_int__)
         return torch_proto
 
-    def serialize (self, tensor_obj: object, from_type: int = bittensor.proto.TensorType.TORCH ) -> bittensor.proto.Tensor:
+    def serialize(
+        self, tensor_obj: object, from_type: int = bittensor.proto.TensorType.TORCH
+    ) -> bittensor.proto.Tensor:
         """Serializes a torch object to bittensor.proto.Tensor wire format.
 
         Args:
             tensor_obj (:obj:`object`, `required`):
                 general tensor object i.e. torch.Tensor or tensorflow.Tensor
 
             from_type (`obj`: bittensor.proto.TensorType, `Optional`):
@@ -55,28 +58,34 @@
                 Raised if the serializer does not implement the conversion between the passed type and a bittensor.proto.Tensor
 
             SerializationException: (Exception):
                 Raised when the subclass serialization throws an error for the passed object.
         """
         # TODO (const): add deserialization types for torch -> tensorflow
         if from_type == bittensor.proto.TensorType.TORCH:
-            return self.serialize_from_torch( torch_tensor = tensor_obj )
+            return self.serialize_from_torch(torch_tensor=tensor_obj)
 
         elif from_type == bittensor.proto.TensorType.NUMPY:
-            return self.serialize_from_numpy( numpy_tensor = tensor_obj )
+            return self.serialize_from_numpy(numpy_tensor=tensor_obj)
 
         elif from_type == bittensor.proto.TensorType.TENSORFLOW:
-            return self.serialize_from_tensorflow( tensorflow_tensor = tensor_obj )
+            return self.serialize_from_tensorflow(tensorflow_tensor=tensor_obj)
 
         else:
-            raise bittensor.serializer.SerializationTypeNotImplementedException("Serialization from type {} not implemented.".format(from_type))
+            raise bittensor.serializer.SerializationTypeNotImplementedException(
+                "Serialization from type {} not implemented.".format(from_type)
+            )
 
         raise NotImplementedError
 
-    def deserialize (self, tensor_pb2: bittensor.proto.Tensor, to_type: int = bittensor.proto.TensorType.TORCH ) -> object:
+    def deserialize(
+        self,
+        tensor_pb2: bittensor.proto.Tensor,
+        to_type: int = bittensor.proto.TensorType.TORCH,
+    ) -> object:
         """Serializes a torch object to bittensor.proto.Tensor wire format.
 
         Args:
             tensor_pb2 (`obj`: bittensor.proto.Tensor, `required`):
                 Serialized tensor as bittensor.proto.proto.
 
             to_type (`obj`: bittensor.proto.TensorType, `required`):
@@ -91,76 +100,86 @@
                 Raised if the serializer does not implement the conversion between the pb2 and the passed type.
 
             DeserializationException: (Exception):
                 Raised when the subclass deserializer throws an error for the passed object.
         """
         # TODO (const): add deserialization types for torch -> tensorflow
         if to_type == bittensor.proto.TensorType.TORCH:
-            return self.deserialize_to_torch( tensor_pb2 )
+            return self.deserialize_to_torch(tensor_pb2)
 
         elif to_type == bittensor.proto.TensorType.NUMPY:
-            return self.deserialize_to_numpy( tensor_pb2 )
+            return self.deserialize_to_numpy(tensor_pb2)
 
         elif to_type == bittensor.proto.TensorType.TENSORFLOW:
-            return self.deserialize_to_tensorflow( tensor_pb2 )
+            return self.deserialize_to_tensorflow(tensor_pb2)
 
         else:
-            raise bittensor.serializer.SerializationTypeNotImplementedException("Deserialization to type {} not implemented.".format(to_type))
+            raise bittensor.serializer.SerializationTypeNotImplementedException(
+                "Deserialization to type {} not implemented.".format(to_type)
+            )
 
-    def serialize_from_tensorflow( self, tensorflow_tensor: torch.Tensor ) -> bittensor.proto.Tensor:
-        """ tensorflow -> bittensor.proto.Tensor """
+    def serialize_from_tensorflow(
+        self, tensorflow_tensor: torch.Tensor
+    ) -> bittensor.proto.Tensor:
+        """tensorflow -> bittensor.proto.Tensor"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
-    def serialize_from_torch( self, torch_tensor: torch.Tensor ) -> bittensor.proto.Tensor:
-        """ torch -> bittensor.proto.Tensor """
+    def serialize_from_torch(
+        self, torch_tensor: torch.Tensor
+    ) -> bittensor.proto.Tensor:
+        """torch -> bittensor.proto.Tensor"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
-    def serialize_from_numpy( self, numpy_tensor: torch.Tensor ) -> bittensor.proto.Tensor:
-        """ numpy -> bittensor.proto.Tensor """
+    def serialize_from_numpy(
+        self, numpy_tensor: torch.Tensor
+    ) -> bittensor.proto.Tensor:
+        """numpy -> bittensor.proto.Tensor"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
-    def deserialize_to_torch( self, tensor_pb2: bittensor.proto.Tensor ) -> torch.Tensor:
-        """ bittensor.proto.Tensor -> torch """
+    def deserialize_to_torch(self, tensor_pb2: bittensor.proto.Tensor) -> torch.Tensor:
+        """bittensor.proto.Tensor -> torch"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
-    def deserialize_to_tensorflow( self, tensor_pb2: bittensor.proto.Tensor ) -> object:
-        """ bittensor.proto.Tensor -> tensorflow """
+    def deserialize_to_tensorflow(self, tensor_pb2: bittensor.proto.Tensor) -> object:
+        """bittensor.proto.Tensor -> tensorflow"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
-    def deserialize_to_numpy( self, tensor_pb2: bittensor.proto.Tensor ) -> object:
-        """ bittensor.proto.Tensor -> numpy """
+    def deserialize_to_numpy(self, tensor_pb2: bittensor.proto.Tensor) -> object:
+        """bittensor.proto.Tensor -> numpy"""
         raise bittensor.serializer.SerializationTypeNotImplementedException
 
 
-class MSGPackSerializer( Serializer ):
-    """ Make conversion between torch and bittensor.proto.torch
-    """
-    def serialize_from_torch( self, torch_tensor: torch.Tensor ) -> bittensor.proto.Tensor:
-        """ Serializes a torch.Tensor to an bittensor Tensor proto.
+class MSGPackSerializer(Serializer):
+    """Make conversion between torch and bittensor.proto.torch"""
+
+    def serialize_from_torch(
+        self, torch_tensor: torch.Tensor
+    ) -> bittensor.proto.Tensor:
+        """Serializes a torch.Tensor to an bittensor Tensor proto.
 
         Args:
             torch_tensor (torch.Tensor):
                 Torch tensor to serialize.
         Returns:
             bittensor.proto.Tensor:
                 The serialized torch tensor as bittensor.proto.proto.
         """
         dtype = bittensor.serializer.torch_dtype_to_bittensor_dtype(torch_tensor.dtype)
         shape = list(torch_tensor.shape)
         torch_numpy = torch_tensor.cpu().detach().numpy().copy()
         data_buffer = msgpack.packb(torch_numpy, default=msgpack_numpy.encode)
-        torch_proto = bittensor.proto.Tensor (
-                                    version = bittensor.__version_as_int__,
-                                    buffer = data_buffer,
-                                    shape = shape,
-                                    dtype = dtype,
-                                    serializer = bittensor.proto.Serializer.MSGPACK,
-                                    tensor_type = bittensor.proto.TensorType.TORCH,
-                                    requires_grad = torch_tensor.requires_grad
-                                )
+        torch_proto = bittensor.proto.Tensor(
+            version=bittensor.__version_as_int__,
+            buffer=data_buffer,
+            shape=shape,
+            dtype=dtype,
+            serializer=bittensor.proto.Serializer.MSGPACK,
+            tensor_type=bittensor.proto.TensorType.TORCH,
+            requires_grad=torch_tensor.requires_grad,
+        )
         return torch_proto
 
     def deserialize_to_torch(self, torch_proto: bittensor.proto.Tensor) -> torch.Tensor:
         """Deserializes an bittensor.proto.Tensor to a torch.Tensor object.
 
         Args:
             torch_proto (bittensor.proto.Tensor):
@@ -168,45 +187,53 @@
 
         Returns:
             torch.Tensor:
                 Deserialized torch tensor.
         """
         dtype = bittensor.serializer.bittensor_dtype_to_torch_dtype(torch_proto.dtype)
         shape = tuple(torch_proto.shape)
-        numpy_object = msgpack.unpackb(torch_proto.buffer, object_hook=msgpack_numpy.decode).copy()
-        torch_object = torch.as_tensor(numpy_object).view(shape).requires_grad_(torch_proto.requires_grad)
+        numpy_object = msgpack.unpackb(
+            torch_proto.buffer, object_hook=msgpack_numpy.decode
+        ).copy()
+        torch_object = (
+            torch.as_tensor(numpy_object)
+            .view(shape)
+            .requires_grad_(torch_proto.requires_grad)
+        )
         return torch_object.type(dtype)
 
 
-class CMPPackSerializer( Serializer ):
-    """ Make conversion between torch and bittensor.proto.torch in float16
-    """
-    def serialize_from_torch(self, torch_tensor: torch.Tensor ) -> bittensor.proto.Tensor:
-        """ Serializes a torch.Tensor to an bittensor Tensor proto in float16
+class CMPPackSerializer(Serializer):
+    """Make conversion between torch and bittensor.proto.torch in float16"""
+
+    def serialize_from_torch(
+        self, torch_tensor: torch.Tensor
+    ) -> bittensor.proto.Tensor:
+        """Serializes a torch.Tensor to an bittensor Tensor proto in float16
 
         Args:
             torch_tensor (torch.Tensor):
                 Torch tensor to serialize.
         Returns:
             bittensor.proto.Tensor:
                 The serialized torch tensor as bittensor.proto.proto.
         """
         dtype = bittensor.serializer.torch_dtype_to_bittensor_dtype(torch_tensor.dtype)
         shape = list(torch_tensor.shape)
         torch_numpy = torch_tensor.cpu().detach().half().numpy().copy()
         data_buffer = msgpack.packb(torch_numpy, default=msgpack_numpy.encode)
-        torch_proto = bittensor.proto.Tensor (
-                                    version = bittensor.__version_as_int__,
-                                    buffer = data_buffer,
-                                    shape = shape,
-                                    dtype = dtype,
-                                    serializer = bittensor.proto.Serializer.CMPPACK,
-                                    tensor_type = bittensor.proto.TensorType.TORCH,
-                                    requires_grad = torch_tensor.requires_grad
-                                )
+        torch_proto = bittensor.proto.Tensor(
+            version=bittensor.__version_as_int__,
+            buffer=data_buffer,
+            shape=shape,
+            dtype=dtype,
+            serializer=bittensor.proto.Serializer.CMPPACK,
+            tensor_type=bittensor.proto.TensorType.TORCH,
+            requires_grad=torch_tensor.requires_grad,
+        )
         return torch_proto
 
     def deserialize_to_torch(self, torch_proto: bittensor.proto.Tensor) -> torch.Tensor:
         """Deserializes an bittensor.proto.Tensor to a torch.Tensor object.
 
         Args:
             torch_proto (bittensor.proto.Tensor):
@@ -214,11 +241,16 @@
 
         Returns:
             torch.Tensor:
                 Deserialized torch tensor.
         """
         dtype = bittensor.serializer.bittensor_dtype_to_torch_dtype(torch_proto.dtype)
         shape = tuple(torch_proto.shape)
-        numpy_object = msgpack.unpackb(torch_proto.buffer, object_hook=msgpack_numpy.decode).copy()
-        torch_object = torch.as_tensor(numpy_object).view(shape).requires_grad_(torch_proto.requires_grad)
+        numpy_object = msgpack.unpackb(
+            torch_proto.buffer, object_hook=msgpack_numpy.decode
+        ).copy()
+        torch_object = (
+            torch.as_tensor(numpy_object)
+            .view(shape)
+            .requires_grad_(torch_proto.requires_grad)
+        )
         return torch_object.type(dtype)
-
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/__init__.py` & `bittensor-5.3.2/bittensor/_subtensor/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -25,198 +25,322 @@
 from loguru import logger
 from substrateinterface import SubstrateInterface
 from torch.cuda import is_available as is_cuda_available
 from . import subtensor_impl, subtensor_mock
 
 logger = logger.opt(colors=True)
 
-GLOBAL_SUBTENSOR_MOCK_PROCESS_NAME = 'node-subtensor'
+GLOBAL_SUBTENSOR_MOCK_PROCESS_NAME = "node-subtensor"
+
 
 class subtensor:
     """Factory Class for both bittensor.Subtensor and Mock_Subtensor Classes
 
     The Subtensor class handles interactions with the substrate subtensor chain.
     By default, the Subtensor class connects to the Finney which serves as the main bittensor network.
     """
 
     def __new__(
-            cls,
-            config: 'bittensor.config' = None,
-            network: str = None,
-            chain_endpoint: str = None,
-            _mock: bool = None,
-        ) -> 'bittensor.Subtensor':
-        r""" Initializes a subtensor chain interface.
-            Args:
-                config (:obj:`bittensor.Config`, `optional`):
-                    bittensor.subtensor.config()
-                network (default='local', type=str)
-                    The subtensor network flag. The likely choices are:
-                            -- local (local running network)
-                            -- finney (main network)
-                            -- mock (mock network for testing.)
-                    If this option is set it overloads subtensor.chain_endpoint with
-                    an entry point node from that network.
-                chain_endpoint (default=None, type=str)
-                    The subtensor endpoint flag. If set, overrides the network argument.
-                _mock (bool, `optional`):
-                    Returned object is mocks the underlying chain connection.
+        cls,
+        config: "bittensor.config" = None,
+        network: str = None,
+        chain_endpoint: str = None,
+        _mock: bool = None,
+    ) -> "bittensor.Subtensor":
+        r"""Initializes a subtensor chain interface.
+        Args:
+            config (:obj:`bittensor.Config`, `optional`):
+                bittensor.subtensor.config()
+            network (default='local', type=str)
+                The subtensor network flag. The likely choices are:
+                        -- local (local running network)
+                        -- finney (main network)
+                        -- mock (mock network for testing.)
+                If this option is set it overloads subtensor.chain_endpoint with
+                an entry point node from that network.
+            chain_endpoint (default=None, type=str)
+                The subtensor endpoint flag. If set, overrides the network argument.
+            _mock (bool, `optional`):
+                Returned object is mocks the underlying chain connection.
         """
-        if config == None: config = subtensor.config()
-        config = copy.deepcopy( config )
+        if config == None:
+            config = subtensor.config()
+        config = copy.deepcopy(config)
 
         # Returns a mocked connection with a background chain connection.
         config.subtensor._mock = _mock if _mock != None else config.subtensor._mock
-        if config.subtensor._mock == True or network == 'mock' or config.subtensor.get('network', bittensor.defaults.subtensor.network) == 'mock':
+        if (
+            config.subtensor._mock == True
+            or network == "mock"
+            or config.subtensor.get("network", bittensor.defaults.subtensor.network)
+            == "mock"
+        ):
             config.subtensor._mock = True
             return subtensor_mock.MockSubtensor()
 
         # Determine config.subtensor.chain_endpoint and config.subtensor.network config.
         # If chain_endpoint is set, we override the network flag, otherwise, the chain_endpoint is assigned by the network.
         # Argument importance: chain_endpoint > network > config.subtensor.chain_endpoint > config.subtensor.network
 
         # Select using chain_endpoint arg.
         if chain_endpoint != None:
             config.subtensor.chain_endpoint = chain_endpoint
             if network != None:
                 config.subtensor.network = network
             else:
-                config.subtensor.network = config.subtensor.get('network', bittensor.defaults.subtensor.network)
+                config.subtensor.network = config.subtensor.get(
+                    "network", bittensor.defaults.subtensor.network
+                )
 
         # Select using network arg.
         elif network != None:
-            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint( network )
+            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint(
+                network
+            )
             config.subtensor.network = network
 
         # Select using config.subtensor.chain_endpoint
         elif config.subtensor.chain_endpoint != None:
             config.subtensor.chain_endpoint = config.subtensor.chain_endpoint
-            config.subtensor.network = config.subtensor.get('network', bittensor.defaults.subtensor.network)
+            config.subtensor.network = config.subtensor.get(
+                "network", bittensor.defaults.subtensor.network
+            )
 
         # Select using config.subtensor.network
-        elif config.subtensor.get('network', bittensor.defaults.subtensor.network) != None:
-            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint( config.subtensor.get('network', bittensor.defaults.subtensor.network) )
-            config.subtensor.network = config.subtensor.get('network', bittensor.defaults.subtensor.network)
+        elif (
+            config.subtensor.get("network", bittensor.defaults.subtensor.network)
+            != None
+        ):
+            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint(
+                config.subtensor.get("network", bittensor.defaults.subtensor.network)
+            )
+            config.subtensor.network = config.subtensor.get(
+                "network", bittensor.defaults.subtensor.network
+            )
 
         # Fallback to defaults.
         else:
-            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint( bittensor.defaults.subtensor.network )
+            config.subtensor.chain_endpoint = subtensor.determine_chain_endpoint(
+                bittensor.defaults.subtensor.network
+            )
             config.subtensor.network = bittensor.defaults.subtensor.network
 
         # make sure it's wss:// or ws://
         # If it's bellagene (parachain testnet) then it has to be wss
         endpoint_url: str = config.subtensor.chain_endpoint
 
         # make sure formatting is good
-        endpoint_url = bittensor.utils.networking.get_formatted_ws_endpoint_url(endpoint_url)
+        endpoint_url = bittensor.utils.networking.get_formatted_ws_endpoint_url(
+            endpoint_url
+        )
 
-        subtensor.check_config( config )
-        network = config.subtensor.get('network', bittensor.defaults.subtensor.network)
+        subtensor.check_config(config)
+        network = config.subtensor.get("network", bittensor.defaults.subtensor.network)
         substrate = SubstrateInterface(
-            ss58_format = bittensor.__ss58_format__,
+            ss58_format=bittensor.__ss58_format__,
             use_remote_preset=True,
-            url = endpoint_url,
-            type_registry=bittensor.__type_registry__
+            url=endpoint_url,
+            type_registry=bittensor.__type_registry__,
         )
         return subtensor_impl.Subtensor(
-            substrate = substrate,
-            network = config.subtensor.get('network', bittensor.defaults.subtensor.network),
-            chain_endpoint = config.subtensor.chain_endpoint,
+            substrate=substrate,
+            network=config.subtensor.get(
+                "network", bittensor.defaults.subtensor.network
+            ),
+            chain_endpoint=config.subtensor.chain_endpoint,
         )
 
     @staticmethod
-    def config() -> 'bittensor.Config':
+    def config() -> "bittensor.Config":
         parser = argparse.ArgumentParser()
-        subtensor.add_args( parser )
-        return bittensor.config( parser )
+        subtensor.add_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
     def help(cls):
-        """ Print help to stdout
-        """
+        """Print help to stdout"""
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        print (cls.__new__.__doc__)
+        cls.add_args(parser)
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
-    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None ):
-        prefix_str = '' if prefix == None else prefix + '.'
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
+        prefix_str = "" if prefix == None else prefix + "."
         if prefix is not None:
             if bittensor.defaults.get(prefix, d=None) == None:
                 setattr(bittensor.defaults, prefix, bittensor.Config())
             getattr(bittensor.defaults, prefix).subtensor = bittensor.defaults.subtensor
         try:
-            parser.add_argument('--' + prefix_str + 'subtensor.network', default = bittensor.defaults.subtensor.network, type=str,
-                                help='''The subtensor network flag. The likely choices are:
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.network",
+                default=bittensor.defaults.subtensor.network,
+                type=str,
+                help="""The subtensor network flag. The likely choices are:
                                         -- finney (main network)
                                         -- local (local running network)
                                         -- mock (creates a mock connection (for testing))
                                     If this option is set it overloads subtensor.chain_endpoint with
                                     an entry point node from that network.
-                                    ''')
-            parser.add_argument('--' + prefix_str + 'subtensor.chain_endpoint', default = bittensor.defaults.subtensor.chain_endpoint, type=str,
-                                help='''The subtensor endpoint flag. If set, overrides the --network flag.
-                                    ''')
-            parser.add_argument('--' + prefix_str + 'subtensor._mock', action='store_true', help='To turn on subtensor mocking for testing purposes.', default=bittensor.defaults.subtensor._mock)
+                                    """,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.chain_endpoint",
+                default=bittensor.defaults.subtensor.chain_endpoint,
+                type=str,
+                help="""The subtensor endpoint flag. If set, overrides the --network flag.
+                                    """,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor._mock",
+                action="store_true",
+                help="To turn on subtensor mocking for testing purposes.",
+                default=bittensor.defaults.subtensor._mock,
+            )
             # registration args. Used for register and re-register and anything that calls register.
-            parser.add_argument('--' + prefix_str + 'subtensor.register.num_processes', '-n', dest=prefix_str + 'subtensor.register.num_processes', help="Number of processors to use for registration", type=int, default=bittensor.defaults.subtensor.register.num_processes)
-            parser.add_argument('--' + prefix_str + 'subtensor.register.update_interval', '--' + prefix_str + 'subtensor.register.cuda.update_interval', '--' + prefix_str + 'cuda.update_interval', '-u', help="The number of nonces to process before checking for next block during registration", type=int, default=bittensor.defaults.subtensor.register.update_interval)
-            parser.add_argument('--' + prefix_str + 'subtensor.register.no_output_in_place', '--' + prefix_str + 'no_output_in_place', dest="subtensor.register.output_in_place", help="Whether to not ouput the registration statistics in-place. Set flag to disable output in-place.", action='store_false', required=False, default=bittensor.defaults.subtensor.register.output_in_place)
-            parser.add_argument('--' + prefix_str + 'subtensor.register.verbose', help="Whether to ouput the registration statistics verbosely.", action='store_true', required=False, default=bittensor.defaults.subtensor.register.verbose)
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.num_processes",
+                "-n",
+                dest=prefix_str + "subtensor.register.num_processes",
+                help="Number of processors to use for registration",
+                type=int,
+                default=bittensor.defaults.subtensor.register.num_processes,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.update_interval",
+                "--" + prefix_str + "subtensor.register.cuda.update_interval",
+                "--" + prefix_str + "cuda.update_interval",
+                "-u",
+                help="The number of nonces to process before checking for next block during registration",
+                type=int,
+                default=bittensor.defaults.subtensor.register.update_interval,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.no_output_in_place",
+                "--" + prefix_str + "no_output_in_place",
+                dest="subtensor.register.output_in_place",
+                help="Whether to not ouput the registration statistics in-place. Set flag to disable output in-place.",
+                action="store_false",
+                required=False,
+                default=bittensor.defaults.subtensor.register.output_in_place,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.verbose",
+                help="Whether to ouput the registration statistics verbosely.",
+                action="store_true",
+                required=False,
+                default=bittensor.defaults.subtensor.register.verbose,
+            )
 
             ## Registration args for CUDA registration.
-            parser.add_argument( '--' + prefix_str + 'subtensor.register.cuda.use_cuda', '--' + prefix_str + 'cuda', '--' + prefix_str + 'cuda.use_cuda', default=bittensor.defaults.subtensor.register.cuda.use_cuda, help='''Set flag to use CUDA to register.''', action="store_true", required=False )
-            parser.add_argument( '--' + prefix_str + 'subtensor.register.cuda.no_cuda', '--' + prefix_str + 'no_cuda', '--' + prefix_str + 'cuda.no_cuda', dest=prefix_str + 'subtensor.register.cuda.use_cuda', default=not bittensor.defaults.subtensor.register.cuda.use_cuda, help='''Set flag to not use CUDA for registration''', action="store_false", required=False )
-
-            parser.add_argument( '--' + prefix_str + 'subtensor.register.cuda.dev_id', '--' + prefix_str + 'cuda.dev_id',  type=int, nargs='+', default=bittensor.defaults.subtensor.register.cuda.dev_id, help='''Set the CUDA device id(s). Goes by the order of speed. (i.e. 0 is the fastest).''', required=False )
-            parser.add_argument( '--' + prefix_str + 'subtensor.register.cuda.TPB', '--' + prefix_str + 'cuda.TPB', type=int, default=bittensor.defaults.subtensor.register.cuda.TPB, help='''Set the number of Threads Per Block for CUDA.''', required=False )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.cuda.use_cuda",
+                "--" + prefix_str + "cuda",
+                "--" + prefix_str + "cuda.use_cuda",
+                default=bittensor.defaults.subtensor.register.cuda.use_cuda,
+                help="""Set flag to use CUDA to register.""",
+                action="store_true",
+                required=False,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.cuda.no_cuda",
+                "--" + prefix_str + "no_cuda",
+                "--" + prefix_str + "cuda.no_cuda",
+                dest=prefix_str + "subtensor.register.cuda.use_cuda",
+                default=not bittensor.defaults.subtensor.register.cuda.use_cuda,
+                help="""Set flag to not use CUDA for registration""",
+                action="store_false",
+                required=False,
+            )
+
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.cuda.dev_id",
+                "--" + prefix_str + "cuda.dev_id",
+                type=int,
+                nargs="+",
+                default=bittensor.defaults.subtensor.register.cuda.dev_id,
+                help="""Set the CUDA device id(s). Goes by the order of speed. (i.e. 0 is the fastest).""",
+                required=False,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "subtensor.register.cuda.TPB",
+                "--" + prefix_str + "cuda.TPB",
+                type=int,
+                default=bittensor.defaults.subtensor.register.cuda.TPB,
+                help="""Set the number of Threads Per Block for CUDA.""",
+                required=False,
+            )
 
         except argparse.ArgumentError:
             # re-parsing arguments.
             pass
 
     @classmethod
-    def add_defaults(cls, defaults ):
-        """ Adds parser defaults to object from enviroment variables.
-        """
+    def add_defaults(cls, defaults):
+        """Adds parser defaults to object from enviroment variables."""
         defaults.subtensor = bittensor.Config()
-        defaults.subtensor.network = os.getenv('BT_SUBTENSOR_NETWORK') if os.getenv('BT_SUBTENSOR_NETWORK') != None else 'finney'
-        defaults.subtensor.chain_endpoint = os.getenv('BT_SUBTENSOR_CHAIN_ENDPOINT') if os.getenv('BT_SUBTENSOR_CHAIN_ENDPOINT') != None else None
-        defaults.subtensor._mock = os.getenv('BT_SUBTENSOR_MOCK') if os.getenv('BT_SUBTENSOR_MOCK') != None else False
+        defaults.subtensor.network = (
+            os.getenv("BT_SUBTENSOR_NETWORK")
+            if os.getenv("BT_SUBTENSOR_NETWORK") != None
+            else "finney"
+        )
+        defaults.subtensor.chain_endpoint = (
+            os.getenv("BT_SUBTENSOR_CHAIN_ENDPOINT")
+            if os.getenv("BT_SUBTENSOR_CHAIN_ENDPOINT") != None
+            else None
+        )
+        defaults.subtensor._mock = (
+            os.getenv("BT_SUBTENSOR_MOCK")
+            if os.getenv("BT_SUBTENSOR_MOCK") != None
+            else False
+        )
 
         defaults.subtensor.register = bittensor.Config()
-        defaults.subtensor.register.num_processes = os.getenv('BT_SUBTENSOR_REGISTER_NUM_PROCESSES') if os.getenv('BT_SUBTENSOR_REGISTER_NUM_PROCESSES') != None else None # uses processor count by default within the function
-        defaults.subtensor.register.update_interval = os.getenv('BT_SUBTENSOR_REGISTER_UPDATE_INTERVAL') if os.getenv('BT_SUBTENSOR_REGISTER_UPDATE_INTERVAL') != None else 50_000
+        defaults.subtensor.register.num_processes = (
+            os.getenv("BT_SUBTENSOR_REGISTER_NUM_PROCESSES")
+            if os.getenv("BT_SUBTENSOR_REGISTER_NUM_PROCESSES") != None
+            else None
+        )  # uses processor count by default within the function
+        defaults.subtensor.register.update_interval = (
+            os.getenv("BT_SUBTENSOR_REGISTER_UPDATE_INTERVAL")
+            if os.getenv("BT_SUBTENSOR_REGISTER_UPDATE_INTERVAL") != None
+            else 50_000
+        )
         defaults.subtensor.register.output_in_place = True
         defaults.subtensor.register.verbose = False
 
         defaults.subtensor.register.cuda = bittensor.Config()
         defaults.subtensor.register.cuda.dev_id = [0]
         defaults.subtensor.register.cuda.use_cuda = False
         defaults.subtensor.register.cuda.TPB = 256
 
-
-
     @staticmethod
-    def check_config( config: 'bittensor.Config' ):
+    def check_config(config: "bittensor.Config"):
         assert config.subtensor
-        #assert config.subtensor.network != None
-        if config.subtensor.get('register') and config.subtensor.register.get('cuda'):
-            assert all((isinstance(x, int) or isinstance(x, str) and x.isnumeric() ) for x in config.subtensor.register.cuda.get('dev_id', []))
-
-            if config.subtensor.register.cuda.get('use_cuda', bittensor.defaults.subtensor.register.cuda.use_cuda):
+        # assert config.subtensor.network != None
+        if config.subtensor.get("register") and config.subtensor.register.get("cuda"):
+            assert all(
+                (isinstance(x, int) or isinstance(x, str) and x.isnumeric())
+                for x in config.subtensor.register.cuda.get("dev_id", [])
+            )
+
+            if config.subtensor.register.cuda.get(
+                "use_cuda", bittensor.defaults.subtensor.register.cuda.use_cuda
+            ):
                 try:
                     import cubit
                 except ImportError:
-                    raise ImportError('CUDA registration is enabled but cubit is not installed. Please install cubit.')
+                    raise ImportError(
+                        "CUDA registration is enabled but cubit is not installed. Please install cubit."
+                    )
 
                 if not is_cuda_available():
-                    raise RuntimeError('CUDA registration is enabled but no CUDA devices are detected.')
-
+                    raise RuntimeError(
+                        "CUDA registration is enabled but no CUDA devices are detected."
+                    )
 
     @staticmethod
     def determine_chain_endpoint(network: str):
         if network == "finney":
             # Kiru Finney stagin network.
             return bittensor.__finney_entrypoint__
         elif network == "nobunaga":
@@ -224,13 +348,13 @@
             return bittensor.__nobunaga_entrypoint__
         elif network == "bellagene":
             # Parachain test net
             return bittensor.__bellagene_entrypoint__
         elif network == "local":
             # Local chain.
             return bittensor.__local_entrypoint__
-        elif network == 'mock':
+        elif network == "mock":
             return bittensor.__mock_entrypoint__
-        elif network == 'test':
+        elif network == "test":
             return bittensor.__finney_test_entrypoint__
         else:
             return bittensor.__local_entrypoint__
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/chain_data.py` & `bittensor-5.3.2/bittensor/_subtensor/chain_data.py`

 * *Files 21% similar despite different names*

```diff
@@ -49,15 +49,15 @@
                 ["max_allowed_uids", "Compact<u16>"],
                 ["blocks_since_last_step", "Compact<u64>"],
                 ["tempo", "Compact<u16>"],
                 ["network_modality", "Compact<u16>"],
                 ["network_connect", "Vec<[u16; 2]>"],
                 ["emission_values", "Compact<u64>"],
                 ["burn", "Compact<u64>"],
-            ]
+            ],
         },
         "DelegateInfo": {
             "type": "struct",
             "type_mapping": [
                 ["delegate_ss58", "AccountId"],
                 ["take", "Compact<u16>"],
                 ["nominators", "Vec<(AccountId, Compact<u64>)>"],
@@ -86,15 +86,15 @@
                 ["trust", "Compact<u16>"],
                 ["validator_trust", "Compact<u16>"],
                 ["dividends", "Compact<u16>"],
                 ["last_update", "Compact<u64>"],
                 ["validator_permit", "bool"],
                 ["weights", "Vec<(Compact<u16>, Compact<u16>)>"],
                 ["bonds", "Vec<(Compact<u16>, Compact<u16>)>"],
-                ["pruning_score", "Compact<u16>"]
+                ["pruning_score", "Compact<u16>"],
             ],
         },
         "NeuronInfoLite": {
             "type": "struct",
             "type_mapping": [
                 ["hotkey", "AccountId"],
                 ["coldkey", "AccountId"],
@@ -109,15 +109,15 @@
                 ["incentive", "Compact<u16>"],
                 ["consensus", "Compact<u16>"],
                 ["trust", "Compact<u16>"],
                 ["validator_trust", "Compact<u16>"],
                 ["dividends", "Compact<u16>"],
                 ["last_update", "Compact<u64>"],
                 ["validator_permit", "bool"],
-                ["pruning_score", "Compact<u16>"]
+                ["pruning_score", "Compact<u16>"],
             ],
         },
         "axon_info": {
             "type": "struct",
             "type_mapping": [
                 ["block", "u64"],
                 ["version", "u32"],
@@ -138,49 +138,55 @@
                 ["port", "u16"],
                 ["ip_type", "u8"],
             ],
         },
     }
 }
 
+
 class ChainDataType(Enum):
     NeuronInfo = 1
     SubnetInfo = 2
     DelegateInfo = 3
     NeuronInfoLite = 4
     DelegatedInfo = 5
 
+
 # Constants
 RAOPERTAO = 1e9
 U16_MAX = 65535
 U64_MAX = 18446744073709551615
 
-def from_scale_encoding( vec_u8: List[int], type_name: ChainDataType, is_vec: bool = False, is_option: bool = False ) -> Optional[Dict]:
+
+def from_scale_encoding(
+    vec_u8: List[int],
+    type_name: ChainDataType,
+    is_vec: bool = False,
+    is_option: bool = False,
+) -> Optional[Dict]:
     as_bytes = bytes(vec_u8)
     as_scale_bytes = ScaleBytes(as_bytes)
     rpc_runtime_config = RuntimeConfiguration()
     rpc_runtime_config.update_type_registry(load_type_registry_preset("legacy"))
     rpc_runtime_config.update_type_registry(custom_rpc_type_registry)
 
     type_string = type_name.name
     if type_name == ChainDataType.DelegatedInfo:
         # DelegatedInfo is a tuple of (DelegateInfo, Compact<u64>)
-        type_string = f'({ChainDataType.DelegateInfo.name}, Compact<u64>)'
+        type_string = f"({ChainDataType.DelegateInfo.name}, Compact<u64>)"
     if is_option:
-        type_string = f'Option<{type_string}>'
+        type_string = f"Option<{type_string}>"
     if is_vec:
-        type_string = f'Vec<{type_string}>'
+        type_string = f"Vec<{type_string}>"
 
-    obj = rpc_runtime_config.create_scale_object(
-        type_string,
-        data=as_scale_bytes
-    )
+    obj = rpc_runtime_config.create_scale_object(type_string, data=as_scale_bytes)
 
     return obj.decode()
 
+
 # Dataclasses for chain data.
 @dataclass
 class NeuronInfo:
     r"""
     Dataclass for neuron metadata.
     """
     hotkey: str
@@ -199,128 +205,166 @@
     trust: float
     validator_trust: float
     dividends: float
     last_update: int
     validator_permit: bool
     weights: List[List[int]]
     bonds: List[List[int]]
-    prometheus_info: 'PrometheusInfo'
-    axon_info: 'axon_info'
+    prometheus_info: "PrometheusInfo"
+    axon_info: "axon_info"
     pruning_score: int
     is_null: bool = False
 
     @classmethod
-    def fix_decoded_values(cls, neuron_info_decoded: Any) -> 'NeuronInfo':
-        r""" Fixes the values of the NeuronInfo object.
-        """
-        neuron_info_decoded['hotkey'] = ss58_encode(neuron_info_decoded['hotkey'], bittensor.__ss58_format__)
-        neuron_info_decoded['coldkey'] = ss58_encode(neuron_info_decoded['coldkey'], bittensor.__ss58_format__)
-        stake_dict =  { ss58_encode( coldkey, bittensor.__ss58_format__): bittensor.Balance.from_rao(int(stake)) for coldkey, stake in neuron_info_decoded['stake'] }
-        neuron_info_decoded['stake_dict'] = stake_dict
-        neuron_info_decoded['stake'] = sum(stake_dict.values())
-        neuron_info_decoded['total_stake'] = neuron_info_decoded['stake']
-        neuron_info_decoded['weights'] = [[int(weight[0]), int(weight[1])] for weight in neuron_info_decoded['weights']]
-        neuron_info_decoded['bonds'] = [[int(bond[0]), int(bond[1])] for bond in neuron_info_decoded['bonds']]
-        neuron_info_decoded['rank'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['rank'])
-        neuron_info_decoded['emission'] = neuron_info_decoded['emission'] / RAOPERTAO
-        neuron_info_decoded['incentive'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['incentive'])
-        neuron_info_decoded['consensus'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['consensus'])
-        neuron_info_decoded['trust'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['trust'])
-        neuron_info_decoded['validator_trust'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['validator_trust'])
-        neuron_info_decoded['dividends'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['dividends'])
-        neuron_info_decoded['prometheus_info'] = PrometheusInfo.fix_decoded_values(neuron_info_decoded['prometheus_info'])
-        neuron_info_decoded['axon_info'] = bittensor.axon_info.from_neuron_info( neuron_info_decoded )
+    def fix_decoded_values(cls, neuron_info_decoded: Any) -> "NeuronInfo":
+        r"""Fixes the values of the NeuronInfo object."""
+        neuron_info_decoded["hotkey"] = ss58_encode(
+            neuron_info_decoded["hotkey"], bittensor.__ss58_format__
+        )
+        neuron_info_decoded["coldkey"] = ss58_encode(
+            neuron_info_decoded["coldkey"], bittensor.__ss58_format__
+        )
+        stake_dict = {
+            ss58_encode(coldkey, bittensor.__ss58_format__): bittensor.Balance.from_rao(
+                int(stake)
+            )
+            for coldkey, stake in neuron_info_decoded["stake"]
+        }
+        neuron_info_decoded["stake_dict"] = stake_dict
+        neuron_info_decoded["stake"] = sum(stake_dict.values())
+        neuron_info_decoded["total_stake"] = neuron_info_decoded["stake"]
+        neuron_info_decoded["weights"] = [
+            [int(weight[0]), int(weight[1])]
+            for weight in neuron_info_decoded["weights"]
+        ]
+        neuron_info_decoded["bonds"] = [
+            [int(bond[0]), int(bond[1])] for bond in neuron_info_decoded["bonds"]
+        ]
+        neuron_info_decoded["rank"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["rank"]
+        )
+        neuron_info_decoded["emission"] = neuron_info_decoded["emission"] / RAOPERTAO
+        neuron_info_decoded["incentive"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["incentive"]
+        )
+        neuron_info_decoded["consensus"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["consensus"]
+        )
+        neuron_info_decoded["trust"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["trust"]
+        )
+        neuron_info_decoded["validator_trust"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["validator_trust"]
+        )
+        neuron_info_decoded["dividends"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["dividends"]
+        )
+        neuron_info_decoded["prometheus_info"] = PrometheusInfo.fix_decoded_values(
+            neuron_info_decoded["prometheus_info"]
+        )
+        neuron_info_decoded["axon_info"] = bittensor.axon_info.from_neuron_info(
+            neuron_info_decoded
+        )
 
         return cls(**neuron_info_decoded)
 
     @classmethod
-    def from_vec_u8(cls, vec_u8: List[int]) -> 'NeuronInfo':
-        r""" Returns a NeuronInfo object from a vec_u8.
-        """
+    def from_vec_u8(cls, vec_u8: List[int]) -> "NeuronInfo":
+        r"""Returns a NeuronInfo object from a vec_u8."""
         if len(vec_u8) == 0:
             return NeuronInfo._null_neuron()
 
         decoded = from_scale_encoding(vec_u8, ChainDataType.NeuronInfo)
         if decoded is None:
             return NeuronInfo._null_neuron()
 
         decoded = NeuronInfo.fix_decoded_values(decoded)
 
         return decoded
 
     @classmethod
-    def list_from_vec_u8(cls, vec_u8: List[int]) -> List['NeuronInfo']:
-        r""" Returns a list of NeuronInfo objects from a vec_u8.
-        """
+    def list_from_vec_u8(cls, vec_u8: List[int]) -> List["NeuronInfo"]:
+        r"""Returns a list of NeuronInfo objects from a vec_u8."""
 
-        decoded_list = from_scale_encoding(vec_u8, ChainDataType.NeuronInfo, is_vec=True)
+        decoded_list = from_scale_encoding(
+            vec_u8, ChainDataType.NeuronInfo, is_vec=True
+        )
         if decoded_list is None:
             return []
 
-        decoded_list = [NeuronInfo.fix_decoded_values(decoded) for decoded in decoded_list]
+        decoded_list = [
+            NeuronInfo.fix_decoded_values(decoded) for decoded in decoded_list
+        ]
         return decoded_list
 
-
     @staticmethod
-    def _null_neuron() -> 'NeuronInfo':
+    def _null_neuron() -> "NeuronInfo":
         neuron = NeuronInfo(
-            uid = 0,
-            netuid = 0,
-            active =  0,
-            stake = Balance.from_rao(0),
-            stake_dict = {},
-            total_stake = Balance.from_rao(0),
-            rank = 0,
-            emission = 0,
-            incentive = 0,
-            consensus = 0,
-            trust = 0,
-            validator_trust = 0,
-            dividends = 0,
-            last_update = 0,
-            validator_permit = False,
-            weights = [],
-            bonds = [],
-            prometheus_info = None,
-            axon_info = None,
-            is_null = True,
-            coldkey = "000000000000000000000000000000000000000000000000",
-            hotkey = "000000000000000000000000000000000000000000000000",
-            pruning_score = 0,
+            uid=0,
+            netuid=0,
+            active=0,
+            stake=Balance.from_rao(0),
+            stake_dict={},
+            total_stake=Balance.from_rao(0),
+            rank=0,
+            emission=0,
+            incentive=0,
+            consensus=0,
+            trust=0,
+            validator_trust=0,
+            dividends=0,
+            last_update=0,
+            validator_permit=False,
+            weights=[],
+            bonds=[],
+            prometheus_info=None,
+            axon_info=None,
+            is_null=True,
+            coldkey="000000000000000000000000000000000000000000000000",
+            hotkey="000000000000000000000000000000000000000000000000",
+            pruning_score=0,
         )
         return neuron
-    
+
     @classmethod
-    def from_weights_bonds_and_neuron_lite( cls, neuron_lite: 'NeuronInfoLite', weights_as_dict: Dict[int, List[Tuple[int, int]]], bonds_as_dict: Dict[int, List[Tuple[int, int]]] ) -> 'NeuronInfo':
+    def from_weights_bonds_and_neuron_lite(
+        cls,
+        neuron_lite: "NeuronInfoLite",
+        weights_as_dict: Dict[int, List[Tuple[int, int]]],
+        bonds_as_dict: Dict[int, List[Tuple[int, int]]],
+    ) -> "NeuronInfo":
         n_dict = neuron_lite.__dict__
-        n_dict['weights'] = weights_as_dict.get(neuron_lite.uid, [])
-        n_dict['bonds'] = bonds_as_dict.get(neuron_lite.uid, [])
-        
-        return cls( **n_dict )
+        n_dict["weights"] = weights_as_dict.get(neuron_lite.uid, [])
+        n_dict["bonds"] = bonds_as_dict.get(neuron_lite.uid, [])
+
+        return cls(**n_dict)
 
     @staticmethod
-    def _neuron_dict_to_namespace(neuron_dict) -> 'NeuronInfo':
+    def _neuron_dict_to_namespace(neuron_dict) -> "NeuronInfo":
         # TODO: Legacy: remove?
-        if neuron_dict['hotkey'] == '5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM':
+        if neuron_dict["hotkey"] == "5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM":
             return NeuronInfo._null_neuron()
         else:
-            neuron = NeuronInfo( **neuron_dict )
-            neuron.stake_dict = { hk: Balance.from_rao(stake) for hk, stake in neuron.stake.items() }
+            neuron = NeuronInfo(**neuron_dict)
+            neuron.stake_dict = {
+                hk: Balance.from_rao(stake) for hk, stake in neuron.stake.items()
+            }
             neuron.stake = Balance.from_rao(neuron.total_stake)
             neuron.total_stake = neuron.stake
             neuron.rank = neuron.rank / U16_MAX
             neuron.trust = neuron.trust / U16_MAX
             neuron.consensus = neuron.consensus / U16_MAX
             neuron.validator_trust = neuron.validator_trust / U16_MAX
             neuron.incentive = neuron.incentive / U16_MAX
             neuron.dividends = neuron.dividends / U16_MAX
             neuron.emission = neuron.emission / RAOPERTAO
 
             return neuron
 
+
 @dataclass
 class NeuronInfoLite:
     r"""
     Dataclass for neuron metadata, but without the weights and bonds.
     """
     hotkey: str
     coldkey: str
@@ -336,218 +380,265 @@
     incentive: float
     consensus: float
     trust: float
     validator_trust: float
     dividends: float
     last_update: int
     validator_permit: bool
-    #weights: List[List[int]]
-    #bonds: List[List[int]] No weights or bonds in lite version
-    prometheus_info: 'PrometheusInfo'
-    axon_info: 'axon_info'
+    # weights: List[List[int]]
+    # bonds: List[List[int]] No weights or bonds in lite version
+    prometheus_info: "PrometheusInfo"
+    axon_info: "axon_info"
     pruning_score: int
     is_null: bool = False
 
     @classmethod
-    def fix_decoded_values(cls, neuron_info_decoded: Any) -> 'NeuronInfoLite':
-        r""" Fixes the values of the NeuronInfoLite object.
-        """
-        neuron_info_decoded['hotkey'] = ss58_encode(neuron_info_decoded['hotkey'], bittensor.__ss58_format__)
-        neuron_info_decoded['coldkey'] = ss58_encode(neuron_info_decoded['coldkey'], bittensor.__ss58_format__)
-        stake_dict =  { ss58_encode( coldkey, bittensor.__ss58_format__): bittensor.Balance.from_rao(int(stake)) for coldkey, stake in neuron_info_decoded['stake'] }
-        neuron_info_decoded['stake_dict'] = stake_dict
-        neuron_info_decoded['stake'] = sum(stake_dict.values())
-        neuron_info_decoded['total_stake'] = neuron_info_decoded['stake']
+    def fix_decoded_values(cls, neuron_info_decoded: Any) -> "NeuronInfoLite":
+        r"""Fixes the values of the NeuronInfoLite object."""
+        neuron_info_decoded["hotkey"] = ss58_encode(
+            neuron_info_decoded["hotkey"], bittensor.__ss58_format__
+        )
+        neuron_info_decoded["coldkey"] = ss58_encode(
+            neuron_info_decoded["coldkey"], bittensor.__ss58_format__
+        )
+        stake_dict = {
+            ss58_encode(coldkey, bittensor.__ss58_format__): bittensor.Balance.from_rao(
+                int(stake)
+            )
+            for coldkey, stake in neuron_info_decoded["stake"]
+        }
+        neuron_info_decoded["stake_dict"] = stake_dict
+        neuron_info_decoded["stake"] = sum(stake_dict.values())
+        neuron_info_decoded["total_stake"] = neuron_info_decoded["stake"]
         # Don't need weights and bonds in lite version
-        #neuron_info_decoded['weights'] = [[int(weight[0]), int(weight[1])] for weight in neuron_info_decoded['weights']]
-        #neuron_info_decoded['bonds'] = [[int(bond[0]), int(bond[1])] for bond in neuron_info_decoded['bonds']]
-        neuron_info_decoded['rank'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['rank'])
-        neuron_info_decoded['emission'] = neuron_info_decoded['emission'] / RAOPERTAO
-        neuron_info_decoded['incentive'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['incentive'])
-        neuron_info_decoded['consensus'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['consensus'])
-        neuron_info_decoded['trust'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['trust'])
-        neuron_info_decoded['validator_trust'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['validator_trust'])
-        neuron_info_decoded['dividends'] = bittensor.utils.U16_NORMALIZED_FLOAT(neuron_info_decoded['dividends'])
-        neuron_info_decoded['prometheus_info'] = PrometheusInfo.fix_decoded_values(neuron_info_decoded['prometheus_info'])
-        neuron_info_decoded['axon_info'] = axon_info.from_neuron_info(neuron_info_decoded)
+        # neuron_info_decoded['weights'] = [[int(weight[0]), int(weight[1])] for weight in neuron_info_decoded['weights']]
+        # neuron_info_decoded['bonds'] = [[int(bond[0]), int(bond[1])] for bond in neuron_info_decoded['bonds']]
+        neuron_info_decoded["rank"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["rank"]
+        )
+        neuron_info_decoded["emission"] = neuron_info_decoded["emission"] / RAOPERTAO
+        neuron_info_decoded["incentive"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["incentive"]
+        )
+        neuron_info_decoded["consensus"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["consensus"]
+        )
+        neuron_info_decoded["trust"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["trust"]
+        )
+        neuron_info_decoded["validator_trust"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["validator_trust"]
+        )
+        neuron_info_decoded["dividends"] = bittensor.utils.U16_NORMALIZED_FLOAT(
+            neuron_info_decoded["dividends"]
+        )
+        neuron_info_decoded["prometheus_info"] = PrometheusInfo.fix_decoded_values(
+            neuron_info_decoded["prometheus_info"]
+        )
+        neuron_info_decoded["axon_info"] = axon_info.from_neuron_info(
+            neuron_info_decoded
+        )
         return cls(**neuron_info_decoded)
 
     @classmethod
-    def from_vec_u8(cls, vec_u8: List[int]) -> 'NeuronInfoLite':
-        r""" Returns a NeuronInfoLite object from a vec_u8.
-        """
+    def from_vec_u8(cls, vec_u8: List[int]) -> "NeuronInfoLite":
+        r"""Returns a NeuronInfoLite object from a vec_u8."""
         if len(vec_u8) == 0:
             return NeuronInfoLite._null_neuron()
 
         decoded = from_scale_encoding(vec_u8, ChainDataType.NeuronInfoLite)
         if decoded is None:
             return NeuronInfoLite._null_neuron()
 
         decoded = NeuronInfoLite.fix_decoded_values(decoded)
 
         return decoded
 
     @classmethod
-    def list_from_vec_u8(cls, vec_u8: List[int]) -> List['NeuronInfoLite']:
-        r""" Returns a list of NeuronInfoLite objects from a vec_u8.
-        """
+    def list_from_vec_u8(cls, vec_u8: List[int]) -> List["NeuronInfoLite"]:
+        r"""Returns a list of NeuronInfoLite objects from a vec_u8."""
 
-        decoded_list = from_scale_encoding(vec_u8, ChainDataType.NeuronInfoLite, is_vec=True)
+        decoded_list = from_scale_encoding(
+            vec_u8, ChainDataType.NeuronInfoLite, is_vec=True
+        )
         if decoded_list is None:
             return []
 
-        decoded_list = [NeuronInfoLite.fix_decoded_values(decoded) for decoded in decoded_list]
+        decoded_list = [
+            NeuronInfoLite.fix_decoded_values(decoded) for decoded in decoded_list
+        ]
         return decoded_list
 
-
     @staticmethod
-    def _null_neuron() -> 'NeuronInfoLite':
+    def _null_neuron() -> "NeuronInfoLite":
         neuron = NeuronInfoLite(
-            uid = 0,
-            netuid = 0,
-            active =  0,
-            stake = Balance.from_rao(0),
-            stake_dict = {},
-            total_stake = Balance.from_rao(0),
-            rank = 0,
-            emission = 0,
-            incentive = 0,
-            consensus = 0,
-            trust = 0,
-            validator_trust = 0,
-            dividends = 0,
-            last_update = 0,
-            validator_permit = False,
-            #weights = [], // No weights or bonds in lite version
-            #bonds = [],
-            prometheus_info = None,
-            axon_info = None,
-            is_null = True,
-            coldkey = "000000000000000000000000000000000000000000000000",
-            hotkey = "000000000000000000000000000000000000000000000000",
-            pruning_score = 0,
+            uid=0,
+            netuid=0,
+            active=0,
+            stake=Balance.from_rao(0),
+            stake_dict={},
+            total_stake=Balance.from_rao(0),
+            rank=0,
+            emission=0,
+            incentive=0,
+            consensus=0,
+            trust=0,
+            validator_trust=0,
+            dividends=0,
+            last_update=0,
+            validator_permit=False,
+            # weights = [], // No weights or bonds in lite version
+            # bonds = [],
+            prometheus_info=None,
+            axon_info=None,
+            is_null=True,
+            coldkey="000000000000000000000000000000000000000000000000",
+            hotkey="000000000000000000000000000000000000000000000000",
+            pruning_score=0,
         )
         return neuron
 
     @staticmethod
-    def _neuron_dict_to_namespace(neuron_dict) -> 'NeuronInfoLite':
+    def _neuron_dict_to_namespace(neuron_dict) -> "NeuronInfoLite":
         # TODO: Legacy: remove?
-        if neuron_dict['hotkey'] == '5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM':
+        if neuron_dict["hotkey"] == "5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM":
             return NeuronInfoLite._null_neuron()
         else:
-            neuron = NeuronInfoLite( **neuron_dict )
+            neuron = NeuronInfoLite(**neuron_dict)
             neuron.stake = Balance.from_rao(neuron.total_stake)
-            neuron.stake_dict = { hk: Balance.from_rao(stake) for hk, stake in neuron.stake.items() }
+            neuron.stake_dict = {
+                hk: Balance.from_rao(stake) for hk, stake in neuron.stake.items()
+            }
             neuron.total_stake = neuron.stake
             neuron.rank = neuron.rank / U16_MAX
             neuron.trust = neuron.trust / U16_MAX
             neuron.consensus = neuron.consensus / U16_MAX
             neuron.validator_trust = neuron.validator_trust / U16_MAX
             neuron.incentive = neuron.incentive / U16_MAX
             neuron.dividends = neuron.dividends / U16_MAX
             neuron.emission = neuron.emission / RAOPERTAO
 
             return neuron
 
+
 @dataclass
 class PrometheusInfo:
     r"""
     Dataclass for prometheus info.
     """
     block: int
     version: int
     ip: str
     port: int
     ip_type: int
 
     @classmethod
-    def fix_decoded_values(cls, prometheus_info_decoded: Dict) -> 'PrometheusInfo':
-        r""" Returns a PrometheusInfo object from a prometheus_info_decoded dictionary.
-        """
-        prometheus_info_decoded['ip'] = bittensor.utils.networking.int_to_ip(int(prometheus_info_decoded['ip']))
+    def fix_decoded_values(cls, prometheus_info_decoded: Dict) -> "PrometheusInfo":
+        r"""Returns a PrometheusInfo object from a prometheus_info_decoded dictionary."""
+        prometheus_info_decoded["ip"] = bittensor.utils.networking.int_to_ip(
+            int(prometheus_info_decoded["ip"])
+        )
 
         return cls(**prometheus_info_decoded)
+
+
 @dataclass
 class DelegateInfo:
     r"""
     Dataclass for delegate info.
     """
-    hotkey_ss58: str # Hotkey of delegate
-    total_stake: Balance # Total stake of the delegate
-    nominators: List[Tuple[str, Balance]] # List of nominators of the delegate and their stake
-    owner_ss58: str # Coldkey of owner
-    take: float # Take of the delegate as a percentage
-    validator_permits: List[int] # List of subnets that the delegate is allowed to validate on
-    registrations: List[int] # List of subnets that the delegate is registered on
-    return_per_1000: bittensor.Balance # Return per 1000 tao of the delegate over a day
-    total_daily_return: bittensor.Balance # Total daily return of the delegate
+    hotkey_ss58: str  # Hotkey of delegate
+    total_stake: Balance  # Total stake of the delegate
+    nominators: List[
+        Tuple[str, Balance]
+    ]  # List of nominators of the delegate and their stake
+    owner_ss58: str  # Coldkey of owner
+    take: float  # Take of the delegate as a percentage
+    validator_permits: List[
+        int
+    ]  # List of subnets that the delegate is allowed to validate on
+    registrations: List[int]  # List of subnets that the delegate is registered on
+    return_per_1000: bittensor.Balance  # Return per 1000 tao of the delegate over a day
+    total_daily_return: bittensor.Balance  # Total daily return of the delegate
 
     @classmethod
-    def fix_decoded_values(cls, decoded: Any) -> 'DelegateInfo':
-        r""" Fixes the decoded values.
-        """
+    def fix_decoded_values(cls, decoded: Any) -> "DelegateInfo":
+        r"""Fixes the decoded values."""
 
         return cls(
-            hotkey_ss58 = ss58_encode(decoded['delegate_ss58'], bittensor.__ss58_format__),
-            owner_ss58 = ss58_encode(decoded['owner_ss58'], bittensor.__ss58_format__),
-            take = bittensor.utils.U16_NORMALIZED_FLOAT(decoded['take']),
-            nominators = [
-                (ss58_encode(nom[0], bittensor.__ss58_format__), Balance.from_rao(nom[1]))
-                for nom in decoded['nominators']
+            hotkey_ss58=ss58_encode(
+                decoded["delegate_ss58"], bittensor.__ss58_format__
+            ),
+            owner_ss58=ss58_encode(decoded["owner_ss58"], bittensor.__ss58_format__),
+            take=bittensor.utils.U16_NORMALIZED_FLOAT(decoded["take"]),
+            nominators=[
+                (
+                    ss58_encode(nom[0], bittensor.__ss58_format__),
+                    Balance.from_rao(nom[1]),
+                )
+                for nom in decoded["nominators"]
             ],
-            total_stake = Balance.from_rao(sum([nom[1] for nom in decoded['nominators']])),
-            validator_permits = decoded['validator_permits'],
-            registrations = decoded['registrations'],
-            return_per_1000 = bittensor.Balance.from_rao(decoded['return_per_1000']),
-            total_daily_return = bittensor.Balance.from_rao(decoded['total_daily_return']),
+            total_stake=Balance.from_rao(
+                sum([nom[1] for nom in decoded["nominators"]])
+            ),
+            validator_permits=decoded["validator_permits"],
+            registrations=decoded["registrations"],
+            return_per_1000=bittensor.Balance.from_rao(decoded["return_per_1000"]),
+            total_daily_return=bittensor.Balance.from_rao(
+                decoded["total_daily_return"]
+            ),
         )
 
     @classmethod
-    def from_vec_u8(cls, vec_u8: List[int]) -> Optional['DelegateInfo']:
-        r""" Returns a DelegateInfo object from a vec_u8.
-        """
+    def from_vec_u8(cls, vec_u8: List[int]) -> Optional["DelegateInfo"]:
+        r"""Returns a DelegateInfo object from a vec_u8."""
         if len(vec_u8) == 0:
             return None
 
         decoded = from_scale_encoding(vec_u8, ChainDataType.DelegateInfo)
 
         if decoded is None:
             return None
 
         decoded = DelegateInfo.fix_decoded_values(decoded)
 
         return decoded
 
     @classmethod
-    def list_from_vec_u8(cls, vec_u8: List[int]) -> List['DelegateInfo']:
-        r""" Returns a list of DelegateInfo objects from a vec_u8.
-        """
+    def list_from_vec_u8(cls, vec_u8: List[int]) -> List["DelegateInfo"]:
+        r"""Returns a list of DelegateInfo objects from a vec_u8."""
         decoded = from_scale_encoding(vec_u8, ChainDataType.DelegateInfo, is_vec=True)
 
         if decoded is None:
             return []
 
         decoded = [DelegateInfo.fix_decoded_values(d) for d in decoded]
 
         return decoded
 
     @classmethod
-    def delegated_list_from_vec_u8(cls, vec_u8: List[int]) -> List[Tuple['DelegateInfo', Balance]]:
-        r""" Returns a list of Tuples of DelegateInfo objects, and Balance, from a vec_u8.
+    def delegated_list_from_vec_u8(
+        cls, vec_u8: List[int]
+    ) -> List[Tuple["DelegateInfo", Balance]]:
+        r"""Returns a list of Tuples of DelegateInfo objects, and Balance, from a vec_u8.
         This is the list of delegates that the user has delegated to, and the amount of stake delegated.
         """
         decoded = from_scale_encoding(vec_u8, ChainDataType.DelegatedInfo, is_vec=True)
 
         if decoded is None:
             return []
 
-        decoded = [(DelegateInfo.fix_decoded_values(d), Balance.from_rao(s)) for d, s in decoded]
+        decoded = [
+            (DelegateInfo.fix_decoded_values(d), Balance.from_rao(s))
+            for d, s in decoded
+        ]
 
         return decoded
 
+
 @dataclass
 class SubnetInfo:
     r"""
     Dataclass for subnet info.
     """
     netuid: int
     rho: int
@@ -570,88 +661,88 @@
     modality: int
     # netuid -> topk percentile prunning score requirement (u16:MAX normalized.)
     connection_requirements: Dict[str, float]
     emission_value: float
     burn: Balance
 
     @classmethod
-    def from_vec_u8(cls, vec_u8: List[int]) -> Optional['SubnetInfo']:
-        r""" Returns a SubnetInfo object from a vec_u8.
-        """
+    def from_vec_u8(cls, vec_u8: List[int]) -> Optional["SubnetInfo"]:
+        r"""Returns a SubnetInfo object from a vec_u8."""
         if len(vec_u8) == 0:
             return None
 
         decoded = from_scale_encoding(vec_u8, ChainDataType.SubnetInfo)
 
         if decoded is None:
             return None
 
         return SubnetInfo.fix_decoded_values(decoded)
 
     @classmethod
-    def list_from_vec_u8(cls, vec_u8: List[int]) -> List['SubnetInfo']:
-        r""" Returns a list of SubnetInfo objects from a vec_u8.
-        """
-        decoded = from_scale_encoding(vec_u8, ChainDataType.SubnetInfo, is_vec=True, is_option=True)
+    def list_from_vec_u8(cls, vec_u8: List[int]) -> List["SubnetInfo"]:
+        r"""Returns a list of SubnetInfo objects from a vec_u8."""
+        decoded = from_scale_encoding(
+            vec_u8, ChainDataType.SubnetInfo, is_vec=True, is_option=True
+        )
 
         if decoded is None:
             return []
 
         decoded = [SubnetInfo.fix_decoded_values(d) for d in decoded]
 
         return decoded
 
     @classmethod
-    def fix_decoded_values(cls, decoded: Dict) -> 'SubnetInfo':
-        r""" Returns a SubnetInfo object from a decoded SubnetInfo dictionary.
-        """
+    def fix_decoded_values(cls, decoded: Dict) -> "SubnetInfo":
+        r"""Returns a SubnetInfo object from a decoded SubnetInfo dictionary."""
         return SubnetInfo(
-            netuid = decoded['netuid'],
-            rho = decoded['rho'],
-            kappa = decoded['kappa'],
-            difficulty = decoded['difficulty'],
-            immunity_period = decoded['immunity_period'],
-            validator_batch_size = decoded['validator_batch_size'],
-            validator_sequence_length = decoded['validator_sequence_length'],
-            validator_epochs_per_reset = decoded['validator_epochs_per_reset'],
-            validator_epoch_length = decoded['validator_epoch_length'],
-            max_allowed_validators = decoded['max_allowed_validators'],
-            min_allowed_weights = decoded['min_allowed_weights'],
-            max_weight_limit = decoded['max_weights_limit'],
-            scaling_law_power = decoded['scaling_law_power'],
-            synergy_scaling_law_power= decoded['synergy_scaling_law_power'],
-            subnetwork_n = decoded['subnetwork_n'],
-            max_n = decoded['max_allowed_uids'],
-            blocks_since_epoch = decoded['blocks_since_last_step'],
-            tempo = decoded['tempo'],
-            modality = decoded['network_modality'],
-            connection_requirements = {
-                str(int(netuid)): bittensor.utils.U16_NORMALIZED_FLOAT(int(req)) for netuid, req in decoded['network_connect']
+            netuid=decoded["netuid"],
+            rho=decoded["rho"],
+            kappa=decoded["kappa"],
+            difficulty=decoded["difficulty"],
+            immunity_period=decoded["immunity_period"],
+            validator_batch_size=decoded["validator_batch_size"],
+            validator_sequence_length=decoded["validator_sequence_length"],
+            validator_epochs_per_reset=decoded["validator_epochs_per_reset"],
+            validator_epoch_length=decoded["validator_epoch_length"],
+            max_allowed_validators=decoded["max_allowed_validators"],
+            min_allowed_weights=decoded["min_allowed_weights"],
+            max_weight_limit=decoded["max_weights_limit"],
+            scaling_law_power=decoded["scaling_law_power"],
+            synergy_scaling_law_power=decoded["synergy_scaling_law_power"],
+            subnetwork_n=decoded["subnetwork_n"],
+            max_n=decoded["max_allowed_uids"],
+            blocks_since_epoch=decoded["blocks_since_last_step"],
+            tempo=decoded["tempo"],
+            modality=decoded["network_modality"],
+            connection_requirements={
+                str(int(netuid)): bittensor.utils.U16_NORMALIZED_FLOAT(int(req))
+                for netuid, req in decoded["network_connect"]
             },
-            emission_value= decoded['emission_values'],
-            burn = Balance.from_rao(decoded['burn'])
+            emission_value=decoded["emission_values"],
+            burn=Balance.from_rao(decoded["burn"]),
         )
 
-    def to_parameter_dict( self ) -> 'torch.nn.ParameterDict':
-        r""" Returns a torch tensor of the subnet info.
-        """
-        return torch.nn.ParameterDict(
-            self.__dict__
-        )
+    def to_parameter_dict(self) -> "torch.nn.ParameterDict":
+        r"""Returns a torch tensor of the subnet info."""
+        return torch.nn.ParameterDict(self.__dict__)
 
     @classmethod
-    def from_parameter_dict( cls, parameter_dict: 'torch.nn.ParameterDict' ) -> 'SubnetInfo':
-        r""" Returns a SubnetInfo object from a torch parameter_dict.
-        """
-        return cls( **dict(parameter_dict) )
+    def from_parameter_dict(
+        cls, parameter_dict: "torch.nn.ParameterDict"
+    ) -> "SubnetInfo":
+        r"""Returns a SubnetInfo object from a torch parameter_dict."""
+        return cls(**dict(parameter_dict))
 
 
 # Senate / Proposal data
 
+
 class ProposalVoteData(TypedDict):
     index: int
     threshold: int
     ayes: List[str]
     nays: List[str]
     end: int
 
+
 ProposalCallData = GenericCall
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/errors.py` & `bittensor-5.3.2/bittensor/_subtensor/errors.py`

 * *Files 17% similar despite different names*

```diff
@@ -11,70 +11,61 @@
 
 # THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
+
 class ChainError(BaseException):
-    r""" Base error for any chain related errors.
-    """
+    r"""Base error for any chain related errors."""
     pass
 
 
 class ChainConnectionError(ChainError):
-    r""" Error for any chain connection related errors.
-    """
+    r"""Error for any chain connection related errors."""
     pass
 
 
 class ChainTransactionError(ChainError):
-    r""" Error for any chain transaction related errors.
-    """
+    r"""Error for any chain transaction related errors."""
     pass
 
 
 class ChainQueryError(ChainError):
-    r""" Error for any chain query related errors.
-    """
+    r"""Error for any chain query related errors."""
     pass
 
 
 class StakeError(ChainTransactionError):
-    r""" Error raised when a stake transaction fails.
-    """
+    r"""Error raised when a stake transaction fails."""
     pass
 
 
 class UnstakeError(ChainTransactionError):
-    r""" Error raised when an unstake transaction fails.
-    """
+    r"""Error raised when an unstake transaction fails."""
     pass
 
+
 class NominationError(ChainTransactionError):
-    r""" Error raised when a nomination transaction fails.
-    """
+    r"""Error raised when a nomination transaction fails."""
     pass
 
 
 class TransferError(ChainTransactionError):
-    r""" Error raised when a transfer transaction fails.
-    """
+    r"""Error raised when a transfer transaction fails."""
     pass
 
 
 class RegistrationError(ChainTransactionError):
-    r""" Error raised when a neuron registration transaction fails.
-    """
+    r"""Error raised when a neuron registration transaction fails."""
     pass
 
 
 class NotRegisteredError(ChainTransactionError):
-    r""" Error raised when a neuron is not registered, and the transaction requires it to be.
-    """
+    r"""Error raised when a neuron is not registered, and the transaction requires it to be."""
     pass
 
 
 class NotDelegateError(StakeError):
-    r""" Error raised when a hotkey you are trying to stake to is not a delegate.
-    """
-    pass
+    r"""Error raised when a hotkey you are trying to stake to is not a delegate."""
+    pass
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/__init__.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/__init__.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -9,8 +9,8 @@
 # The above copyright notice and this permission notice shall be included in all copies or substantial portions of
 # the Software.
 
 # THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
-# DEALINGS IN THE SOFTWARE.
+# DEALINGS IN THE SOFTWARE.
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/delegation.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/delegation.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 # Copyright © 2023 Opentensor Foundation
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
@@ -22,74 +20,95 @@
 from ..errors import *
 from rich.prompt import Confirm
 from typing import List, Dict, Union, Optional
 from bittensor.utils.balance import Balance
 from .staking import __do_add_stake_single
 
 from loguru import logger
+
 logger = logger.opt(colors=True)
 
+
 def nominate_extrinsic(
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     wait_for_finalization: bool = False,
-    wait_for_inclusion: bool = True
+    wait_for_inclusion: bool = True,
 ) -> bool:
-    r""" Becomes a delegate for the hotkey.
+    r"""Becomes a delegate for the hotkey.
     Args:
         wallet ( bittensor.Wallet ):
             The wallet to become a delegate for.
     Returns:
         success (bool):
             True if the transaction was successful.
     """
     # Unlock the coldkey.
     wallet.coldkey
     wallet.hotkey
 
     # Check if the hotkey is already a delegate.
-    if subtensor.is_hotkey_delegate( wallet.hotkey.ss58_address ):
-        logger.error('Hotkey {} is already a delegate.'.format(wallet.hotkey.ss58_address))
+    if subtensor.is_hotkey_delegate(wallet.hotkey.ss58_address):
+        logger.error(
+            "Hotkey {} is already a delegate.".format(wallet.hotkey.ss58_address)
+        )
         return False
 
-    with bittensor.__console__.status(":satellite: Sending nominate call on [white]{}[/white] ...".format(subtensor.network)):
+    with bittensor.__console__.status(
+        ":satellite: Sending nominate call on [white]{}[/white] ...".format(
+            subtensor.network
+        )
+    ):
         try:
             success = subtensor._do_nominate(
-                wallet = wallet,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization
+                wallet=wallet,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            
+
             if success == True:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-                bittensor.logging.success(  prefix = 'Become Delegate', sufix = '<green>Finalized: </green>' + str(success) )
-            
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Finalized[/green]"
+                )
+                bittensor.logging.success(
+                    prefix="Become Delegate",
+                    sufix="<green>Finalized: </green>" + str(success),
+                )
+
             # Raises NominationError if False
             return success
 
         except Exception as e:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(e))
-            bittensor.logging.warning(  prefix = 'Set weights', sufix = '<red>Failed: </red>' + str(e) )
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: error:{}".format(e)
+            )
+            bittensor.logging.warning(
+                prefix="Set weights", sufix="<red>Failed: </red>" + str(e)
+            )
         except NominationError as e:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(e))
-            bittensor.logging.warning(  prefix = 'Set weights', sufix = '<red>Failed: </red>' + str(e) )
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: error:{}".format(e)
+            )
+            bittensor.logging.warning(
+                prefix="Set weights", sufix="<red>Failed: </red>" + str(e)
+            )
 
     return False
 
 
 def delegate_extrinsic(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        delegate_ss58: Optional[str] = None,
-        amount: Union[Balance, float] = None,
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Delegates the specified amount of stake to the passed delegate.
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    delegate_ss58: Optional[str] = None,
+    amount: Union[Balance, float] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Delegates the specified amount of stake to the passed delegate.
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object.
         delegate_ss58 (Optional[str]):
             ss58 address of the delegate.
         amount (Union[Balance, float]):
             Amount to stake as bittensor balance, or float interpreted as Tao.
@@ -110,98 +129,135 @@
         NotRegisteredError:
             If the wallet is not registered on the chain.
         NotDelegateError:
             If the hotkey is not a delegate on the chain.
     """
     # Decrypt keys,
     wallet.coldkey
-    if not subtensor.is_hotkey_delegate( delegate_ss58 ):
-        raise NotDelegateError("Hotkey: {} is not a delegate.".format( delegate_ss58 ))
+    if not subtensor.is_hotkey_delegate(delegate_ss58):
+        raise NotDelegateError("Hotkey: {} is not a delegate.".format(delegate_ss58))
 
     # Get state.
-    my_prev_coldkey_balance = subtensor.get_balance( wallet.coldkey.ss58_address )
-    delegate_take = subtensor.get_delegate_take( delegate_ss58 )
-    delegate_owner = subtensor.get_hotkey_owner( delegate_ss58 )
-    my_prev_delegated_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = delegate_ss58 )
+    my_prev_coldkey_balance = subtensor.get_balance(wallet.coldkey.ss58_address)
+    delegate_take = subtensor.get_delegate_take(delegate_ss58)
+    delegate_owner = subtensor.get_hotkey_owner(delegate_ss58)
+    my_prev_delegated_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+        coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=delegate_ss58
+    )
 
     # Convert to bittensor.Balance
     if amount == None:
         # Stake it all.
-        staking_balance = bittensor.Balance.from_tao( my_prev_coldkey_balance.tao )
-    elif not isinstance(amount, bittensor.Balance ):
-        staking_balance = bittensor.Balance.from_tao( amount )
+        staking_balance = bittensor.Balance.from_tao(my_prev_coldkey_balance.tao)
+    elif not isinstance(amount, bittensor.Balance):
+        staking_balance = bittensor.Balance.from_tao(amount)
     else:
         staking_balance = amount
 
     # Remove existential balance to keep key alive.
-    if staking_balance > bittensor.Balance.from_rao( 1000 ):
-        staking_balance = staking_balance - bittensor.Balance.from_rao( 1000 )
+    if staking_balance > bittensor.Balance.from_rao(1000):
+        staking_balance = staking_balance - bittensor.Balance.from_rao(1000)
     else:
         staking_balance = staking_balance
 
     # Check enough balance to stake.
     if staking_balance > my_prev_coldkey_balance:
-        bittensor.__console__.print(":cross_mark: [red]Not enough balance[/red]:[bold white]\n  balance:{}\n  amount: {}\n  coldkey: {}[/bold white]".format(my_prev_coldkey_balance, staking_balance, wallet.name))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Not enough balance[/red]:[bold white]\n  balance:{}\n  amount: {}\n  coldkey: {}[/bold white]".format(
+                my_prev_coldkey_balance, staking_balance, wallet.name
+            )
+        )
         return False
 
     # Ask before moving on.
     if prompt:
-        if not Confirm.ask("Do you want to delegate:[bold white]\n  amount: {}\n  to: {}\n owner: {}[/bold white]".format( staking_balance, delegate_ss58, delegate_owner) ):
+        if not Confirm.ask(
+            "Do you want to delegate:[bold white]\n  amount: {}\n  to: {}\n owner: {}[/bold white]".format(
+                staking_balance, delegate_ss58, delegate_owner
+            )
+        ):
             return False
 
     try:
-        with bittensor.__console__.status(":satellite: Staking to: [bold white]{}[/bold white] ...".format(subtensor.network)):
+        with bittensor.__console__.status(
+            ":satellite: Staking to: [bold white]{}[/bold white] ...".format(
+                subtensor.network
+            )
+        ):
             staking_response: bool = subtensor._do_delegation(
-                wallet = wallet,
-                delegate_ss58 = delegate_ss58,
-                amount = staking_balance,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization,
+                wallet=wallet,
+                delegate_ss58=delegate_ss58,
+                amount=staking_balance,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
 
-        if staking_response == True: # If we successfully staked.
+        if staking_response == True:  # If we successfully staked.
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-            with bittensor.__console__.status(":satellite: Checking Balance on: [white]{}[/white] ...".format(subtensor.network)):
-                new_balance = subtensor.get_balance( address = wallet.coldkey.ss58_address )
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Finalized[/green]"
+            )
+            with bittensor.__console__.status(
+                ":satellite: Checking Balance on: [white]{}[/white] ...".format(
+                    subtensor.network
+                )
+            ):
+                new_balance = subtensor.get_balance(address=wallet.coldkey.ss58_address)
                 block = subtensor.get_current_block()
                 new_delegate_stake = subtensor.get_stake_for_coldkey_and_hotkey(
-                    coldkey_ss58 = wallet.coldkeypub.ss58_address,
-                    hotkey_ss58 = delegate_ss58,
-                    block=block
-                ) # Get current stake
-
-                bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( my_prev_coldkey_balance, new_balance ))
-                bittensor.__console__.print("Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( my_prev_delegated_stake, new_delegate_stake ))
+                    coldkey_ss58=wallet.coldkeypub.ss58_address,
+                    hotkey_ss58=delegate_ss58,
+                    block=block,
+                )  # Get current stake
+
+                bittensor.__console__.print(
+                    "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        my_prev_coldkey_balance, new_balance
+                    )
+                )
+                bittensor.__console__.print(
+                    "Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        my_prev_delegated_stake, new_delegate_stake
+                    )
+                )
                 return True
         else:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: Error unknown."
+            )
             return False
 
     except NotRegisteredError as e:
-        bittensor.__console__.print(":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(wallet.hotkey_str))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(
+                wallet.hotkey_str
+            )
+        )
         return False
     except StakeError as e:
         bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
         return False
 
+
 def undelegate_extrinsic(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        delegate_ss58: Optional[str] = None,
-        amount: Union[Balance, float] = None,
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Un-delegates stake from the passed delegate.
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    delegate_ss58: Optional[str] = None,
+    amount: Union[Balance, float] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Un-delegates stake from the passed delegate.
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object.
         delegate_ss58 (Optional[str]):
             ss58 address of the delegate.
         amount (Union[Balance, float]):
             Amount to unstake as bittensor balance, or float interpreted as Tao.
@@ -222,76 +278,112 @@
         NotRegisteredError:
             If the wallet is not registered on the chain.
         NotDelegateError:
             If the hotkey is not a delegate on the chain.
     """
     # Decrypt keys,
     wallet.coldkey
-    if not subtensor.is_hotkey_delegate( delegate_ss58 ):
-        raise NotDelegateError("Hotkey: {} is not a delegate.".format( delegate_ss58 ))
+    if not subtensor.is_hotkey_delegate(delegate_ss58):
+        raise NotDelegateError("Hotkey: {} is not a delegate.".format(delegate_ss58))
 
     # Get state.
-    my_prev_coldkey_balance = subtensor.get_balance( wallet.coldkey.ss58_address )
-    delegate_take = subtensor.get_delegate_take( delegate_ss58 )
-    delegate_owner = subtensor.get_hotkey_owner( delegate_ss58 )
-    my_prev_delegated_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = delegate_ss58 )
+    my_prev_coldkey_balance = subtensor.get_balance(wallet.coldkey.ss58_address)
+    delegate_take = subtensor.get_delegate_take(delegate_ss58)
+    delegate_owner = subtensor.get_hotkey_owner(delegate_ss58)
+    my_prev_delegated_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+        coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=delegate_ss58
+    )
 
     # Convert to bittensor.Balance
     if amount == None:
         # Stake it all.
-        unstaking_balance = bittensor.Balance.from_tao( my_prev_delegated_stake.tao )
+        unstaking_balance = bittensor.Balance.from_tao(my_prev_delegated_stake.tao)
 
-    elif not isinstance(amount, bittensor.Balance ):
-        unstaking_balance = bittensor.Balance.from_tao( amount )
+    elif not isinstance(amount, bittensor.Balance):
+        unstaking_balance = bittensor.Balance.from_tao(amount)
 
     else:
         unstaking_balance = amount
 
     # Check enough stake to unstake.
     if unstaking_balance > my_prev_delegated_stake:
-        bittensor.__console__.print(":cross_mark: [red]Not enough delegated stake[/red]:[bold white]\n  stake:{}\n  amount: {}\n coldkey: {}[/bold white]".format(my_prev_delegated_stake, unstaking_balance, wallet.name))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Not enough delegated stake[/red]:[bold white]\n  stake:{}\n  amount: {}\n coldkey: {}[/bold white]".format(
+                my_prev_delegated_stake, unstaking_balance, wallet.name
+            )
+        )
         return False
 
     # Ask before moving on.
     if prompt:
-        if not Confirm.ask("Do you want to un-delegate:[bold white]\n  amount: {}\n  from: {}\n  owner: {}[/bold white]".format( unstaking_balance, delegate_ss58, delegate_owner) ):
+        if not Confirm.ask(
+            "Do you want to un-delegate:[bold white]\n  amount: {}\n  from: {}\n  owner: {}[/bold white]".format(
+                unstaking_balance, delegate_ss58, delegate_owner
+            )
+        ):
             return False
 
     try:
-        with bittensor.__console__.status(":satellite: Unstaking from: [bold white]{}[/bold white] ...".format(subtensor.network)):
+        with bittensor.__console__.status(
+            ":satellite: Unstaking from: [bold white]{}[/bold white] ...".format(
+                subtensor.network
+            )
+        ):
             staking_response: bool = subtensor._do_undelegation(
-                wallet = wallet,
-                delegate_ss58 = delegate_ss58,
-                amount = unstaking_balance,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization,
+                wallet=wallet,
+                delegate_ss58=delegate_ss58,
+                amount=unstaking_balance,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
 
-        if staking_response == True: # If we successfully staked.
+        if staking_response == True:  # If we successfully staked.
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-            with bittensor.__console__.status(":satellite: Checking Balance on: [white]{}[/white] ...".format(subtensor.network)):
-                new_balance = subtensor.get_balance( address = wallet.coldkey.ss58_address )
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Finalized[/green]"
+            )
+            with bittensor.__console__.status(
+                ":satellite: Checking Balance on: [white]{}[/white] ...".format(
+                    subtensor.network
+                )
+            ):
+                new_balance = subtensor.get_balance(address=wallet.coldkey.ss58_address)
                 block = subtensor.get_current_block()
                 new_delegate_stake = subtensor.get_stake_for_coldkey_and_hotkey(
-                    coldkey_ss58 = wallet.coldkeypub.ss58_address,
-                    hotkey_ss58 = delegate_ss58,
-                    block=block
-                ) # Get current stake
-
-                bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( my_prev_coldkey_balance, new_balance ))
-                bittensor.__console__.print("Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( my_prev_delegated_stake, new_delegate_stake ))
+                    coldkey_ss58=wallet.coldkeypub.ss58_address,
+                    hotkey_ss58=delegate_ss58,
+                    block=block,
+                )  # Get current stake
+
+                bittensor.__console__.print(
+                    "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        my_prev_coldkey_balance, new_balance
+                    )
+                )
+                bittensor.__console__.print(
+                    "Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        my_prev_delegated_stake, new_delegate_stake
+                    )
+                )
                 return True
         else:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: Error unknown."
+            )
             return False
 
     except NotRegisteredError as e:
-        bittensor.__console__.print(":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(wallet.hotkey_str))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(
+                wallet.hotkey_str
+            )
+        )
         return False
     except StakeError as e:
         bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
-        return False
+        return False
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/log_utilities.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/log_utilities.py`

 * *Files 14% similar despite different names*

```diff
@@ -6,73 +6,230 @@
 from rich.errors import MarkupError
 from rich.style import Style
 from typing import List, Tuple, Callable, Dict, Any, Union, Set
 import datetime
 from prometheus_client import Counter, Gauge, Histogram, Summary, Info
 import bittensor
 
+
 class ValidatorLogger:
     r"""
     Logger object for handling all logging function specific to validator.
     Including console log styling, console table print and prometheus.
 
     Args:
             config (:obj:`bittensor.Config`, `optional`):
                 bittensor.server.config()
     """
-    def __init__(self, config = None):
+
+    def __init__(self, config=None):
         # Neuron stats recorded by validator neuron/nucleus
         #   [Column_name, key_name, format_string, rich_style]  # description
         self.config = config
         self.neuron_stats_columns = [
-            ['UID', 'uid', '{:.0f}', 'cyan'],  # neuron UID
-            ['Upd!', 'updates!', '{}', 'bright_yellow'],  # number of exponential moving average updates with zeroing on
-            ['nUpd', 'updates_shapley_values_nxt', '{}', 'bright_yellow'],  # number of exponential moving average updates to nShap
-            ['mUpd', 'updates_shapley_values_min', '{}', 'bright_yellow'],  # number of exponential moving average updates to mShap
-            ['nTime', 'response_time_nxt', '{:.2f}', 'yellow'],  # response time to TextCausalLMNext forward requests [TextCausalLMNext]
-            ['sTime', 'response_time', '{:.2f}', 'yellow'],  # response time to TextCausalLM forward requests
-            ['Route', 'routing_score', '{:.3f}', 'grey30'],  # validator routing score (higher preferred)
-            ['Weight', 'weight', '{:.5f}', 'green'],  # weight set on substrate (each epoch)
-            ['nShap!', 'shapley_values_nxt!', '{:.0f}', 'magenta'],  # Shapley value (=vBase+vSyn) for phrase validation (zeroing) [TextCausalLMNext]
-            ['nShap', 'shapley_values_nxt', '{:.0f}', 'magenta'],  # Shapley value (=vBase+vSyn) for phrase validation [TextCausalLMNext]
-            ['mShap!', 'shapley_values_min!', '{:.0f}', 'bright_magenta'],  # min(Shap, vShap) of sequence and validation Shapley (zeroing)
-            ['mShap', 'shapley_values_min', '{:.0f}', 'bright_magenta'],  # min(Shap, vShap) of sequence and validation Shapley
-            ['sLoss', 'loss', '{:.2f}', 'bright_cyan'],  # next token prediction loss average over sequence
-            ['vLoss', 'loss_val', '{:.2f}', 'bright_cyan'],  # next token prediction loss for validation task
-            ['nvLoss', 'loss_val_nxt', '{:.2f}', 'bright_cyan'],  # next token prediction loss for validation task [TextCausalLMNext]
-            ['nLoss', 'loss_nxt', '{:.2f}', 'bright_cyan'],  # next token phrase prediction loss for phrase validation task [TextCausalLMNext]
-            ['RLoss', 'routing_loss', '{:.3f}', 'grey30'],  # MSE between routing_score and conditioned loss
-            ['nRLoss', 'routing_loss_nxt', '{:.3f}', 'grey30'],  # MSE between routing_score_nxt and conditioned loss [TextCausalLMNext]
-            ['sShap', 'shapley_values', '{:.0f}', 'magenta'],  # Shapley value (=Base+Syn) over sequence
-            ['vShap', 'shapley_values_val', '{:.0f}', 'magenta'],  # Shapley value (=vBase+vSyn) for validation
-            ['sBase', 'base_params', '{:.0f}', ''],  # parameter count estimate via adjusted scaling law
-            ['vBase', 'base_params_val', '{:.0f}', ''],  # square root parameter count estimate for validation task
-            ['nBase', 'base_params_nxt', '{:.0f}', ''],  # square root parameter count estimate for phrase validation task [TextCausalLMNext]
-            ['nParam~', 'est_params_nxt', '{:.2g}', 'magenta'],  # parameter count estimate for phrase validation task [TextCausalLMNext]
-            ['nDiv', 'logits_divergence_nxt', '{:.2g}', ''],  # logits divergence avg compared to network prob dist [TextCausalLMNext]
-            ['nExc', 'logits_excess_nxt', '{:.2f}', ''],  # logits divergence excess avg above network avg + std [TextCausalLMNext]
-            ['sSyn', 'synergy', '{:.0f}', 'white'],  # Shapley pairwise synergy over sequence loss (parameter count estimate)
-            ['vSyn', 'synergy_val', '{:.0f}', 'white'],  # Shapley pairwise synergy over validation loss (count estimate)
-            ['nSyn', 'synergy_nxt', '{:.0f}', 'white'],  # Shapley pairwise synergy over phrase validation loss (count estimate) [TextCausalLMNext]
-            ['sSynD', 'synergy_loss_diff', '{:.2f}', 'bright_blue'],  # Shapley pairwise synergy over sequence loss (loss difference)
-            ['vSynD', 'synergy_loss_diff_val', '{:.2f}', 'bright_blue'],  # Shapley pairwise synergy over validation loss (loss difference)
-            ['nSynD', 'synergy_loss_diff_nxt', '{:.2f}', 'bright_blue'],  # Shapley pairwise synergy over phrase validation loss (loss difference) [TextCausalLMNext]
+            ["UID", "uid", "{:.0f}", "cyan"],  # neuron UID
+            [
+                "Upd!",
+                "updates!",
+                "{}",
+                "bright_yellow",
+            ],  # number of exponential moving average updates with zeroing on
+            [
+                "nUpd",
+                "updates_shapley_values_nxt",
+                "{}",
+                "bright_yellow",
+            ],  # number of exponential moving average updates to nShap
+            [
+                "mUpd",
+                "updates_shapley_values_min",
+                "{}",
+                "bright_yellow",
+            ],  # number of exponential moving average updates to mShap
+            [
+                "nTime",
+                "response_time_nxt",
+                "{:.2f}",
+                "yellow",
+            ],  # response time to TextCausalLMNext forward requests [TextCausalLMNext]
+            [
+                "sTime",
+                "response_time",
+                "{:.2f}",
+                "yellow",
+            ],  # response time to TextCausalLM forward requests
+            [
+                "Route",
+                "routing_score",
+                "{:.3f}",
+                "grey30",
+            ],  # validator routing score (higher preferred)
+            [
+                "Weight",
+                "weight",
+                "{:.5f}",
+                "green",
+            ],  # weight set on substrate (each epoch)
+            [
+                "nShap!",
+                "shapley_values_nxt!",
+                "{:.0f}",
+                "magenta",
+            ],  # Shapley value (=vBase+vSyn) for phrase validation (zeroing) [TextCausalLMNext]
+            [
+                "nShap",
+                "shapley_values_nxt",
+                "{:.0f}",
+                "magenta",
+            ],  # Shapley value (=vBase+vSyn) for phrase validation [TextCausalLMNext]
+            [
+                "mShap!",
+                "shapley_values_min!",
+                "{:.0f}",
+                "bright_magenta",
+            ],  # min(Shap, vShap) of sequence and validation Shapley (zeroing)
+            [
+                "mShap",
+                "shapley_values_min",
+                "{:.0f}",
+                "bright_magenta",
+            ],  # min(Shap, vShap) of sequence and validation Shapley
+            [
+                "sLoss",
+                "loss",
+                "{:.2f}",
+                "bright_cyan",
+            ],  # next token prediction loss average over sequence
+            [
+                "vLoss",
+                "loss_val",
+                "{:.2f}",
+                "bright_cyan",
+            ],  # next token prediction loss for validation task
+            [
+                "nvLoss",
+                "loss_val_nxt",
+                "{:.2f}",
+                "bright_cyan",
+            ],  # next token prediction loss for validation task [TextCausalLMNext]
+            [
+                "nLoss",
+                "loss_nxt",
+                "{:.2f}",
+                "bright_cyan",
+            ],  # next token phrase prediction loss for phrase validation task [TextCausalLMNext]
+            [
+                "RLoss",
+                "routing_loss",
+                "{:.3f}",
+                "grey30",
+            ],  # MSE between routing_score and conditioned loss
+            [
+                "nRLoss",
+                "routing_loss_nxt",
+                "{:.3f}",
+                "grey30",
+            ],  # MSE between routing_score_nxt and conditioned loss [TextCausalLMNext]
+            [
+                "sShap",
+                "shapley_values",
+                "{:.0f}",
+                "magenta",
+            ],  # Shapley value (=Base+Syn) over sequence
+            [
+                "vShap",
+                "shapley_values_val",
+                "{:.0f}",
+                "magenta",
+            ],  # Shapley value (=vBase+vSyn) for validation
+            [
+                "sBase",
+                "base_params",
+                "{:.0f}",
+                "",
+            ],  # parameter count estimate via adjusted scaling law
+            [
+                "vBase",
+                "base_params_val",
+                "{:.0f}",
+                "",
+            ],  # square root parameter count estimate for validation task
+            [
+                "nBase",
+                "base_params_nxt",
+                "{:.0f}",
+                "",
+            ],  # square root parameter count estimate for phrase validation task [TextCausalLMNext]
+            [
+                "nParam~",
+                "est_params_nxt",
+                "{:.2g}",
+                "magenta",
+            ],  # parameter count estimate for phrase validation task [TextCausalLMNext]
+            [
+                "nDiv",
+                "logits_divergence_nxt",
+                "{:.2g}",
+                "",
+            ],  # logits divergence avg compared to network prob dist [TextCausalLMNext]
+            [
+                "nExc",
+                "logits_excess_nxt",
+                "{:.2f}",
+                "",
+            ],  # logits divergence excess avg above network avg + std [TextCausalLMNext]
+            [
+                "sSyn",
+                "synergy",
+                "{:.0f}",
+                "white",
+            ],  # Shapley pairwise synergy over sequence loss (parameter count estimate)
+            [
+                "vSyn",
+                "synergy_val",
+                "{:.0f}",
+                "white",
+            ],  # Shapley pairwise synergy over validation loss (count estimate)
+            [
+                "nSyn",
+                "synergy_nxt",
+                "{:.0f}",
+                "white",
+            ],  # Shapley pairwise synergy over phrase validation loss (count estimate) [TextCausalLMNext]
+            [
+                "sSynD",
+                "synergy_loss_diff",
+                "{:.2f}",
+                "bright_blue",
+            ],  # Shapley pairwise synergy over sequence loss (loss difference)
+            [
+                "vSynD",
+                "synergy_loss_diff_val",
+                "{:.2f}",
+                "bright_blue",
+            ],  # Shapley pairwise synergy over validation loss (loss difference)
+            [
+                "nSynD",
+                "synergy_loss_diff_nxt",
+                "{:.2f}",
+                "bright_blue",
+            ],  # Shapley pairwise synergy over phrase validation loss (loss difference) [TextCausalLMNext]
         ]
         # console_width (:obj:`int`, `required`):
         #     Config console width for table print.
-        self.console_width = self.config.get('width', None) if self.config else None
+        self.console_width = self.config.get("width", None) if self.config else None
         self.prometheus = ValidatorPrometheus(config)
 
     def print_response_table(
         self,
         batch_predictions: List,
         stats: Dict,
         sort_col: str,
         task_repeat: int = 4,
-        tasks_per_server: int = 3
+        tasks_per_server: int = 3,
     ):
         r"""
         Prints the query response table: top prediction probabilities and texts for batch tasks.
 
             Args:
                 batch_predictions (:obj:`List[Union[str, Dict{torch.Tensor, str}]]`, `required`):
                     Predictions in string per task per uid. In the format of [(task, {uid, "prob: phrase" })] of length batch size.
@@ -85,55 +242,77 @@
                 tasks_per_server (:type:`int`, `required`):
                     How many tasks to show for each server.
         """
         # === Batch permutation ===
         batch_size = len(batch_predictions)
         if batch_size == 0:
             return
-        batch_perm = torch.randperm(batch_size)  # avoid restricting observation to predictable subsets
+        batch_perm = torch.randperm(
+            batch_size
+        )  # avoid restricting observation to predictable subsets
 
         # === Column selection ===
-        columns = [c[:] for c in self.neuron_stats_columns if c[1] in ['uid', sort_col, 'loss_nxt', 'synergy_nxt', 'logits_excess_nxt']]
+        columns = [
+            c[:]
+            for c in self.neuron_stats_columns
+            if c[1] in ["uid", sort_col, "loss_nxt", "synergy_nxt", "logits_excess_nxt"]
+        ]
         col_keys = [c[1] for c in columns]
 
         # === Sort rows ===
-        sort = sorted([(uid, s[sort_col]) for uid, s in stats.items() if sort_col in s],
-                    reverse='loss' not in sort_col, key=lambda _row: _row[1])
+        sort = sorted(
+            [(uid, s[sort_col]) for uid, s in stats.items() if sort_col in s],
+            reverse="loss" not in sort_col,
+            key=lambda _row: _row[1],
+        )
         if sort_col in col_keys:
             sort_idx = col_keys.index(sort_col)  # sort column with key of sort_col
-            columns[sort_idx][0] += '\u2193'  # ↓ downwards arrow (sort)
+            columns[sort_idx][0] += "\u2193"  # ↓ downwards arrow (sort)
 
         for i, (uid, val) in enumerate(sort):
             # === New table section ===
             if i % task_repeat == 0:
                 table = Table(width=self.console_width, box=None)
                 if i == 0:
-                    table.title = f"[white bold] Query responses [/white bold] | " \
-                                f"[white]context[/white][bold]continuation[/bold] | .prob: 'prediction'"
+                    table.title = (
+                        f"[white bold] Query responses [/white bold] | "
+                        f"[white]context[/white][bold]continuation[/bold] | .prob: 'prediction'"
+                    )
 
-                for col, _, _, stl in columns:  # [Column_name, key_name, format_string, rich_style]
-                    table.add_column(col, style=stl, justify='right')
+                for (
+                    col,
+                    _,
+                    _,
+                    stl,
+                ) in columns:  # [Column_name, key_name, format_string, rich_style]
+                    table.add_column(col, style=stl, justify="right")
 
             # === Last table section ===
             if i == len(sort) - 1:
-                table.caption = f'[bold]{len(sort)}[/bold]/{len(stats)} (respond/topk) | ' \
-                                f'[bold]{tasks_per_server}[/bold] tasks per server | ' \
-                                f'repeat tasks over [bold]{task_repeat}[/bold] servers ' \
-                                f'[white]\[{math.ceil(1. * len(sort) / task_repeat) * tasks_per_server}/' \
-                                f'{batch_size} batch tasks][/white]'
+                table.caption = (
+                    f"[bold]{len(sort)}[/bold]/{len(stats)} (respond/topk) | "
+                    f"[bold]{tasks_per_server}[/bold] tasks per server | "
+                    f"repeat tasks over [bold]{task_repeat}[/bold] servers "
+                    f"[white]\[{math.ceil(1. * len(sort) / task_repeat) * tasks_per_server}/"
+                    f"{batch_size} batch tasks][/white]"
+                )
 
             # === Row addition ===
             row = [txt.format(stats[uid][key]) for _, key, txt, _ in columns]
             for j in range(tasks_per_server):
-                batch_item = ((i // task_repeat) * tasks_per_server + j) % batch_size  # repeat task over servers, do not exceed batch_size
+                batch_item = (
+                    (i // task_repeat) * tasks_per_server + j
+                ) % batch_size  # repeat task over servers, do not exceed batch_size
                 task, predictions = batch_predictions[batch_perm[batch_item]]
                 row += [predictions[uid]]
 
                 if i % task_repeat == 0:
-                    table.add_column(task, header_style='not bold', style='', justify='left')
+                    table.add_column(
+                        task, header_style="not bold", style="", justify="left"
+                    )
 
             table.add_row(*row)
 
             # === Table print ===
             if (i == len(sort) - 1) or (i % task_repeat == task_repeat - 1):
                 try:
                     rich_print(table)
@@ -142,58 +321,75 @@
                 else:
                     if i == len(sort) - 1:
                         print()
 
     def print_synergy_table(
         self,
         stats: Dict,
-        syn_loss_diff: Dict ,
+        syn_loss_diff: Dict,
         sort_col: str,
     ):
         r"""
         Prints the synergy loss diff matrix with pairwise loss reduction due to synergy (original loss on diagonal).
 
             Args:
                 stats (:obj:`Dict{Dict}`, `required`):
                     Statistics per endpoint for this batch. In the format of {uid, {statistics}}.
                 syn_loss_diff (:obj:`Dict`, `required`):
                     Dictionary table of pairwise synergies as loss reductions, with direct loss on diagonal.
                 sort_col (:type:`str`, `required`):
                     Column name used for sorting. Options from self.neuron_stats_columns[:, 1].
         """
-        sort = sorted([(uid, s[sort_col]) for uid, s in stats.items() if sort_col in s],
-                    reverse='loss' not in sort_col, key=lambda _row: _row[1])
-        uid_col = self.neuron_stats_columns[0]  # [Column_name, key_name, format_string, rich_style]
-        columns = [uid_col] + [[f'{s[0]}', '', '{:.2f}', ''] for s in sort]
-        rows = [[uid_col[2].format(s[0])] +
-                [('[bright_cyan]{:.2f}[/bright_cyan]' if t == s else
-                '[magenta]{:.3f}[/magenta]' if syn_loss_diff[s[0]][t[0]] > 0 else
-                '[dim]{:.0f}[/dim]').format(syn_loss_diff[s[0]][t[0]]).replace('0.', '.') for t in sort] for s in sort]
+        sort = sorted(
+            [(uid, s[sort_col]) for uid, s in stats.items() if sort_col in s],
+            reverse="loss" not in sort_col,
+            key=lambda _row: _row[1],
+        )
+        uid_col = self.neuron_stats_columns[
+            0
+        ]  # [Column_name, key_name, format_string, rich_style]
+        columns = [uid_col] + [[f"{s[0]}", "", "{:.2f}", ""] for s in sort]
+        rows = [
+            [uid_col[2].format(s[0])]
+            + [
+                (
+                    "[bright_cyan]{:.2f}[/bright_cyan]"
+                    if t == s
+                    else "[magenta]{:.3f}[/magenta]"
+                    if syn_loss_diff[s[0]][t[0]] > 0
+                    else "[dim]{:.0f}[/dim]"
+                )
+                .format(syn_loss_diff[s[0]][t[0]])
+                .replace("0.", ".")
+                for t in sort
+            ]
+            for s in sort
+        ]
 
         # === Synergy table ===
         table = Table(width=self.console_width, box=None)
-        table.title = f'[white] Synergy table [/white] | Pairwise synergy'
-        table.caption = f'loss decrease'
+        table.title = f"[white] Synergy table [/white] | Pairwise synergy"
+        table.caption = f"loss decrease"
 
-        for col, _, _, stl in columns:  # [Column_name, key_name, format_string, rich_style]
-            table.add_column(col, style=stl, justify='right')
+        for (
+            col,
+            _,
+            _,
+            stl,
+        ) in columns:  # [Column_name, key_name, format_string, rich_style]
+            table.add_column(col, style=stl, justify="right")
         for row in rows:
             table.add_row(*row)
 
         if len(rows):
             rich_print(table)
             print()
 
     def print_stats_table(
-        self,
-        stats: Dict,
-        sort_col: str,
-        title: str,
-        caption: str,
-        mark_uids=None
+        self, stats: Dict, sort_col: str, title: str, caption: str, mark_uids=None
     ):
         r"""
         Gathers data and constructs neuron statistics table and prints it.
 
             Args:
                 stats (:obj:`Dict{Dict}`, `required`):
                     Statistics per endpoint for this batch. In the format of {uid, {statistics}}.
@@ -203,56 +399,74 @@
                     Title of the table.
                 caption (:type:`str`, `required`):
                     Caption shown at the end of table.
         """
         # === Gather columns and rows ===
         if mark_uids is None:
             mark_uids = list()
-        stats_keys = [set(k for k in stat)
-                    for stat in stats.values() if sort_col in stat]  # all available stats keys with sort_col
+        stats_keys = [
+            set(k for k in stat) for stat in stats.values() if sort_col in stat
+        ]  # all available stats keys with sort_col
 
         if len(stats_keys) == 0:
             return  # nothing to print
 
         stats_keys = set.union(*stats_keys)
-        columns = [c[:] for c in self.neuron_stats_columns if c[1] in stats_keys]  # available columns intersecting with stats_keys
-        rows = [[('', 0) if key not in stat
-                else (('* ' if key == 'uid' and mark_uids and uid in mark_uids else '') + txt.format(stat[key]), stat[key])
-                for _, key, txt, _ in columns]
-                for uid, stat in stats.items() if sort_col in stat]  # only keep rows with at least one non-empty cell
+        columns = [
+            c[:] for c in self.neuron_stats_columns if c[1] in stats_keys
+        ]  # available columns intersecting with stats_keys
+        rows = [
+            [
+                ("", 0)
+                if key not in stat
+                else (
+                    ("* " if key == "uid" and mark_uids and uid in mark_uids else "")
+                    + txt.format(stat[key]),
+                    stat[key],
+                )
+                for _, key, txt, _ in columns
+            ]
+            for uid, stat in stats.items()
+            if sort_col in stat
+        ]  # only keep rows with at least one non-empty cell
 
         if len(columns) == 0 or len(rows) == 0:
             return  # nothing to print
 
         # === Sort rows ===
         col_keys = [c[1] for c in columns]
         if sort_col in col_keys:
             sort_idx = col_keys.index(sort_col)  # sort column with key of sort_col
-            columns[sort_idx][0] += '\u2193'  # ↓ downwards arrow (sort)
-            rows = sorted(rows, reverse='loss' not in sort_col, key=lambda _row: _row[sort_idx][1])  # sort according to sortcol
+            columns[sort_idx][0] += "\u2193"  # ↓ downwards arrow (sort)
+            rows = sorted(
+                rows, reverse="loss" not in sort_col, key=lambda _row: _row[sort_idx][1]
+            )  # sort according to sortcol
 
         # === Instantiate stats table ===
-        table = Table(width=self.console_width, box=None, row_styles=[Style(bgcolor='grey15'), ""])
+        table = Table(
+            width=self.console_width, box=None, row_styles=[Style(bgcolor="grey15"), ""]
+        )
         table.title = title
         table.caption = caption
 
-        for col, _, _, stl in columns:  # [Column_name, key_name, format_string, rich_style]
-            table.add_column(col, style=stl, justify='right')
+        for (
+            col,
+            _,
+            _,
+            stl,
+        ) in columns:  # [Column_name, key_name, format_string, rich_style]
+            table.add_column(col, style=stl, justify="right")
         for row in rows:
             table.add_row(*[txt for txt, val in row])
 
         # === Print table ===
         rich_print(table)
 
     def print_synapse_table(
-        self,
-        name: str,
-        stats: Dict,
-        sort_col: str,
-        start_time: time.time
+        self, name: str, stats: Dict, sort_col: str, start_time: time.time
     ):
         r"""
         Prints the evaluation of the neuron responses to the validator request
 
             Args:
                 stats (:obj:`Dict{Dict}`, `required`):
                     Statistics per endpoint for this batch. In the format of {uid, {statistics}}.
@@ -260,33 +474,35 @@
                     Column name used for sorting. Options from self.neuron_stats_columns[:, 1].
                 name (:obj:`str`, `required`):
                     Name of synapse for the title of the table.
                 start_time (:obj:`time.time`, `required`):
                     Starting time for shapley calculation.
 
         """
-        self.print_stats_table(stats, sort_col,
-                    f'[white] \[{name}] responses [/white] | Validator forward',  # title
-                    f'[bold]{len([s for s in stats.values() if len(s) and sort_col in s])}[/bold]/'
-                    f'{len(stats)} (respond/topk) | '
-                    f'[bold]Synapse[/bold] | [white]\[{time.time() - start_time:.3g}s][/white]'  # caption
-                    )
+        self.print_stats_table(
+            stats,
+            sort_col,
+            f"[white] \[{name}] responses [/white] | Validator forward",  # title
+            f"[bold]{len([s for s in stats.values() if len(s) and sort_col in s])}[/bold]/"
+            f"{len(stats)} (respond/topk) | "
+            f"[bold]Synapse[/bold] | [white]\[{time.time() - start_time:.3g}s][/white]",  # caption
+        )
 
     def print_weights_table(
-            self,
-            min_allowed_weights: int,
-            max_weight_limit: int,
-            neuron_stats: Dict,
-            title: str,
-            metagraph_n: int,
-            sample_uids: torch.Tensor,
-            sample_weights: torch.Tensor,
-            include_uids: List = None,
-            num_rows: int = None
-        ):
+        self,
+        min_allowed_weights: int,
+        max_weight_limit: int,
+        neuron_stats: Dict,
+        title: str,
+        metagraph_n: int,
+        sample_uids: torch.Tensor,
+        sample_weights: torch.Tensor,
+        include_uids: List = None,
+        num_rows: int = None,
+    ):
         r"""
         Prints weights table given sample_uids and sample_weights.
 
             Args:
                 min_allowed_weights (:type:`int`, `required`):
                     subtensor minimum allowed weight to set.
                 max_weight_limit (:type:`int`, `required`):
@@ -314,215 +530,247 @@
 
         if len(sample_weights) == 0:
             return
 
         for uid, weight in zip(sample_uids.tolist(), sample_weights.tolist()):
             if uid in neuron_stats:
                 _neuron_stats[uid] = {k: v for k, v in neuron_stats[uid].items()}
-                _neuron_stats[uid]['weight'] = weight
+                _neuron_stats[uid]["weight"] = weight
                 uid_weights += [(uid, weight)]
             else:
                 unvalidated += [uid]
 
         if include_uids is not None and num_rows is not None:
             sorted_uids = sorted(uid_weights, key=lambda tup: tup[1])
             top_bottom_uids = [_uid for _uid, _ in sorted_uids[:5] + sorted_uids[-10:]]
             _include_uids = set(include_uids) | set(top_bottom_uids)
-            avail_include_uids = list(set(_neuron_stats.keys()) & _include_uids)  # exclude include_uids with no stats
-            if len(_neuron_stats) > num_rows:  # limit table to included_uids and remaining sample up to num_rows
-                remaining_uids = set(_neuron_stats.keys()) - _include_uids  # find sample remaining, loses sample ordering
-                remaining_uids = [uid for uid in _neuron_stats if uid in remaining_uids]  # recover sample ordering
-                limited_uids = avail_include_uids + remaining_uids[:num_rows - len(_include_uids)]
-                _neuron_stats = {uid: stats for uid, stats in _neuron_stats.items() if uid in limited_uids}
+            avail_include_uids = list(
+                set(_neuron_stats.keys()) & _include_uids
+            )  # exclude include_uids with no stats
+            if (
+                len(_neuron_stats) > num_rows
+            ):  # limit table to included_uids and remaining sample up to num_rows
+                remaining_uids = (
+                    set(_neuron_stats.keys()) - _include_uids
+                )  # find sample remaining, loses sample ordering
+                remaining_uids = [
+                    uid for uid in _neuron_stats if uid in remaining_uids
+                ]  # recover sample ordering
+                limited_uids = (
+                    avail_include_uids + remaining_uids[: num_rows - len(_include_uids)]
+                )
+                _neuron_stats = {
+                    uid: stats
+                    for uid, stats in _neuron_stats.items()
+                    if uid in limited_uids
+                }
 
         print()
-        self.print_stats_table(_neuron_stats, 'weight',
-                    f'[white] Neuron weights [/white] | ' + title,  # title
-                    f'Validated {min_allowed_weights}/'
-                    f'[bold]{len(neuron_stats)}[/bold]/{metagraph_n} (min/[bold]valid[/bold]/total) | '
-                    f'sum:{sample_weights.sum().item():.2g} '
-                    f'[white] max:[bold]{sample_weights.max().item():.4g}[/bold] / '
-                    f'min:[bold]{sample_weights.min().item():.4g}[/bold] [/white] '
-                    f'\[{max_weight_limit:.4g} allowed]',  # caption
-                    mark_uids=include_uids)
+        self.print_stats_table(
+            _neuron_stats,
+            "weight",
+            f"[white] Neuron weights [/white] | " + title,  # title
+            f"Validated {min_allowed_weights}/"
+            f"[bold]{len(neuron_stats)}[/bold]/{metagraph_n} (min/[bold]valid[/bold]/total) | "
+            f"sum:{sample_weights.sum().item():.2g} "
+            f"[white] max:[bold]{sample_weights.max().item():.4g}[/bold] / "
+            f"min:[bold]{sample_weights.min().item():.4g}[/bold] [/white] "
+            f"\[{max_weight_limit:.4g} allowed]",  # caption
+            mark_uids=include_uids,
+        )
 
     def print_console_validator_identifier(
         self,
         uid: int,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         external_ip: str,
     ):
-        r""" Console print for validator identifier.
-        """
+        r"""Console print for validator identifier."""
 
         # validator identifier status console message (every 25 validation steps)
-        rich_print(f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
-        f"{f'[bright_white]core_validator[/bright_white]'.center(16 + len('[bright_white][/bright_white]'))} | "
-        f"UID [cyan]{uid}[/cyan] "
-        f"[dim white not bold][{external_ip}][/dim white not bold] "
-        f"[white not bold]cold:[bold]{wallet.name}[/bold]:"
-        f"[bright_white not bold]{wallet.coldkeypub.ss58_address}[/bright_white not bold] "
-        f"[dim white]/[/dim white] "
-        f"hot:[bold]{wallet.hotkey_str}[/bold]:"
-        f"[bright_white not bold]{wallet.hotkey.ss58_address}[/bright_white not bold][/white not bold]")
+        rich_print(
+            f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
+            f"{f'[bright_white]core_validator[/bright_white]'.center(16 + len('[bright_white][/bright_white]'))} | "
+            f"UID [cyan]{uid}[/cyan] "
+            f"[dim white not bold][{external_ip}][/dim white not bold] "
+            f"[white not bold]cold:[bold]{wallet.name}[/bold]:"
+            f"[bright_white not bold]{wallet.coldkeypub.ss58_address}[/bright_white not bold] "
+            f"[dim white]/[/dim white] "
+            f"hot:[bold]{wallet.hotkey_str}[/bold]:"
+            f"[bright_white not bold]{wallet.hotkey.ss58_address}[/bright_white not bold][/white not bold]"
+        )
 
     def print_console_metagraph_status(
         self,
         uid: int,
-        metagraph: 'bittensor.Metagraph',
+        metagraph: "bittensor.Metagraph",
         current_block: int,
         start_block: int,
         network: str,
-        netuid: int
+        netuid: int,
     ):
-        r""" Console print for current validator's metagraph status.
-        """
+        r"""Console print for current validator's metagraph status."""
         # validator update status console message
-        rich_print(f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
-        f"{f'UID [bright_cyan]{uid}[/bright_cyan]'.center(16 + len('[bright_cyan][/bright_cyan]'))} | "
-        f'Updated [yellow]{current_block - metagraph.last_update[uid]}[/yellow] [dim]blocks ago[/dim] | '
-        f'Dividends [green not bold]{metagraph.dividends[uid]:.5f}[/green not bold] | '
-        f'Stake \u03C4[magenta not bold]{metagraph.total_stake[uid]:.5f}[/magenta not bold] '
-        f'[dim](retrieved [yellow]{current_block - start_block}[/yellow] blocks ago from {network})[/dim]')
+        rich_print(
+            f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
+            f"{f'UID [bright_cyan]{uid}[/bright_cyan]'.center(16 + len('[bright_cyan][/bright_cyan]'))} | "
+            f"Updated [yellow]{current_block - metagraph.last_update[uid]}[/yellow] [dim]blocks ago[/dim] | "
+            f"Dividends [green not bold]{metagraph.dividends[uid]:.5f}[/green not bold] | "
+            f"Stake \u03C4[magenta not bold]{metagraph.total_stake[uid]:.5f}[/magenta not bold] "
+            f"[dim](retrieved [yellow]{current_block - start_block}[/yellow] blocks ago from {network})[/dim]"
+        )
 
     def print_console_query_summary(
         self,
         current_block: int,
         start_block: int,
         blocks_per_epoch: int,
         epoch_steps: int,
         epoch: int,
         responsive_uids: List,
         queried_uids: List,
         step_time: float,
         epoch_responsive_uids: Set,
-        epoch_queried_uids: Set
+        epoch_queried_uids: Set,
     ):
-        r""" Console print for query summary.
-        """
-        rich_print(f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
-        f"{f'[magenta dim not bold]#{current_block}[/magenta dim not bold]'.center(16 + len('[magenta dim not bold][/magenta dim not bold]'))} | "
-        f'[green not bold]{current_block - start_block}[/green not bold]/'
-        f'[white not bold]{blocks_per_epoch}[/white not bold] [dim]blocks/epoch[/dim] | '
-        f'[white not bold]Step {epoch_steps}[white not bold] '
-        f'[dim] Epoch {epoch}[/dim] | '
-        f'[bright_green not bold]{len(responsive_uids)}[/bright_green not bold]/'
-        f'[white]{len(queried_uids)}[/white] '
-        f'[[yellow]{step_time:.3g}[/yellow]s] '
-        f'[dim white not bold][green]{len(epoch_responsive_uids)}[/green]/'
-        f'{len(epoch_queried_uids)}[/dim white not bold]')
+        r"""Console print for query summary."""
+        rich_print(
+            f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
+            f"{f'[magenta dim not bold]#{current_block}[/magenta dim not bold]'.center(16 + len('[magenta dim not bold][/magenta dim not bold]'))} | "
+            f"[green not bold]{current_block - start_block}[/green not bold]/"
+            f"[white not bold]{blocks_per_epoch}[/white not bold] [dim]blocks/epoch[/dim] | "
+            f"[white not bold]Step {epoch_steps}[white not bold] "
+            f"[dim] Epoch {epoch}[/dim] | "
+            f"[bright_green not bold]{len(responsive_uids)}[/bright_green not bold]/"
+            f"[white]{len(queried_uids)}[/white] "
+            f"[[yellow]{step_time:.3g}[/yellow]s] "
+            f"[dim white not bold][green]{len(epoch_responsive_uids)}[/green]/"
+            f"{len(epoch_queried_uids)}[/dim white not bold]"
+        )
 
     def print_console_subtensor_weight(
         self,
         sample_weights: torch.Tensor,
         epoch_responsive_uids: Set,
         epoch_queried_uids: Set,
         max_weight_limit: float,
         epoch_start_time: time.time,
     ):
-        r""" Console print for weight setting to subtensor.
-        """
+        r"""Console print for weight setting to subtensor."""
+
+        rich_print(
+            f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
+            f"{f'[bright_white]Set weights[/bright_white]'.center(16 + len('[bright_white][/bright_white]'))} | "
+            f"[bright_green not bold]{len(sample_weights)}[/bright_green not bold] [dim]weights set[/dim] | "
+            f"[bright_green not bold]{len(epoch_responsive_uids)}[/bright_green not bold]/"
+            f"[white]{len(epoch_queried_uids)}[/white] "
+            f"[dim white not bold][green]responsive[/green]/queried[/dim white not bold] "
+            f"[[yellow]{time.time() - epoch_start_time:.0f}[/yellow]s] | "
+            f"[dim]weights[/dim] sum:{sample_weights.sum().item():.2g} "
+            f"[white] max:[bold]{sample_weights.max().item():.4g}[/bold] / "
+            f"min:[bold]{sample_weights.min().item():.4g}[/bold] [/white] "
+            f"\[{max_weight_limit:.4g} allowed]"
+        )
 
-        rich_print(f"[white not bold]{datetime.datetime.now():%Y-%m-%d %H:%M:%S}[/white not bold]{' ' * 4} | "
-        f"{f'[bright_white]Set weights[/bright_white]'.center(16 + len('[bright_white][/bright_white]'))} | "
-        f'[bright_green not bold]{len(sample_weights)}[/bright_green not bold] [dim]weights set[/dim] | '
-        f'[bright_green not bold]{len(epoch_responsive_uids)}[/bright_green not bold]/'
-        f'[white]{len(epoch_queried_uids)}[/white] '
-        f'[dim white not bold][green]responsive[/green]/queried[/dim white not bold] '
-        f'[[yellow]{time.time() - epoch_start_time:.0f}[/yellow]s] | '
-        f'[dim]weights[/dim] sum:{sample_weights.sum().item():.2g} '
-        f'[white] max:[bold]{sample_weights.max().item():.4g}[/bold] / '
-        f'min:[bold]{sample_weights.min().item():.4g}[/bold] [/white] '
-        f'\[{max_weight_limit:.4g} allowed]')
 
 class ValidatorPrometheus:
     r"""
     Prometheis logging object for validator.
         Args:
             config (:obj:`bittensor.Config`, `optional`):
                 bittensor.server.config()
     """
+
     def __init__(self, config):
         self.config = config
         self.info = Info("neuron_info", "Info sumamries for the running server-miner.")
-        self.gauges = Gauge('validator_gauges', 'Gauges for the running validator.', ['validator_gauges_name'])
-        self.counters = Counter('validator_counters', 'Counters for the running validator.', ['validator_counters_name'])
-        self.step_time = Histogram('validator_step_time', 'Validator step time histogram.', buckets=list(range(0, 2 * bittensor.__blocktime__, 1)))
+        self.gauges = Gauge(
+            "validator_gauges",
+            "Gauges for the running validator.",
+            ["validator_gauges_name"],
+        )
+        self.counters = Counter(
+            "validator_counters",
+            "Counters for the running validator.",
+            ["validator_counters_name"],
+        )
+        self.step_time = Histogram(
+            "validator_step_time",
+            "Validator step time histogram.",
+            buckets=list(range(0, 2 * bittensor.__blocktime__, 1)),
+        )
 
     def log_run_info(
         self,
         parameters: torch.nn.parameter.Parameter,
         uid: int,
         network: str,
-        wallet: 'bittensor.Wallet'
+        wallet: "bittensor.Wallet",
     ):
-        r""" Set up prometheus running info.
-        """
+        r"""Set up prometheus running info."""
 
-        self.gauges.labels( "model_size_params" ).set( sum(p.numel() for p in parameters) )
-        self.gauges.labels( "model_size_bytes" ).set( sum(p.element_size() * p.nelement() for p in parameters) )
-        self.info.info({
-            'type': "core_validator",
-            'uid': str(uid),
-            'network': network,
-            'coldkey': str(wallet.coldkeypub.ss58_address),
-            'hotkey': str(wallet.hotkey.ss58_address),
-        })
+        self.gauges.labels("model_size_params").set(sum(p.numel() for p in parameters))
+        self.gauges.labels("model_size_bytes").set(
+            sum(p.element_size() * p.nelement() for p in parameters)
+        )
+        self.info.info(
+            {
+                "type": "core_validator",
+                "uid": str(uid),
+                "network": network,
+                "coldkey": str(wallet.coldkeypub.ss58_address),
+                "hotkey": str(wallet.hotkey.ss58_address),
+            }
+        )
 
     def log_epoch_start(
         self,
         current_block: int,
         batch_size: int,
         sequence_length: int,
         validation_len: int,
         min_allowed_weights: int,
         blocks_per_epoch: int,
-        epochs_until_reset: int
+        epochs_until_reset: int,
     ):
-        r""" All prometheus logging at the start of epoch.
-        """
-        self.gauges.labels("current_block").set( current_block )
-        self.gauges.labels("batch_size").set( batch_size )
-        self.gauges.labels("sequence_length").set( sequence_length )
-        self.gauges.labels("validation_len").set( validation_len )
-        self.gauges.labels("min_allowed_weights").set( min_allowed_weights )
-        self.gauges.labels("blocks_per_epoch").set( blocks_per_epoch )
-        self.gauges.labels("epochs_until_reset").set( epochs_until_reset )
-        self.gauges.labels("scaling_law_power").set( self.config.nucleus.scaling_law_power )
-        self.gauges.labels("synergy_scaling_law_power").set( self.config.nucleus.synergy_scaling_law_power )
+        r"""All prometheus logging at the start of epoch."""
+        self.gauges.labels("current_block").set(current_block)
+        self.gauges.labels("batch_size").set(batch_size)
+        self.gauges.labels("sequence_length").set(sequence_length)
+        self.gauges.labels("validation_len").set(validation_len)
+        self.gauges.labels("min_allowed_weights").set(min_allowed_weights)
+        self.gauges.labels("blocks_per_epoch").set(blocks_per_epoch)
+        self.gauges.labels("epochs_until_reset").set(epochs_until_reset)
+        self.gauges.labels("scaling_law_power").set(
+            self.config.nucleus.scaling_law_power
+        )
+        self.gauges.labels("synergy_scaling_law_power").set(
+            self.config.nucleus.synergy_scaling_law_power
+        )
         self.gauges.labels("epoch_steps").set(0)
 
-    def log_step(
-        self,
-        current_block: int,
-        last_update: int,
-        step_time: int,
-        loss: int
-    ):
-        r""" All prometheus logging at the each validation step.
-        """
+    def log_step(self, current_block: int, last_update: int, step_time: int, loss: int):
+        r"""All prometheus logging at the each validation step."""
         self.gauges.labels("global_step").inc()
         self.gauges.labels("epoch_steps").inc()
         self.gauges.labels("current_block").set(current_block)
-        self.gauges.labels("last_updated").set( current_block - last_update )
-        self.step_time.observe( step_time )
-        self.gauges.labels('step_time').set( step_time )
-        self.gauges.labels("loss").set( loss )
+        self.gauges.labels("last_updated").set(current_block - last_update)
+        self.step_time.observe(step_time)
+        self.gauges.labels("step_time").set(step_time)
+        self.gauges.labels("loss").set(loss)
 
     def log_epoch_end(
         self,
         uid: int,
-        metagraph: 'bittensor.Metagraph',
+        metagraph: "bittensor.Metagraph",
         current_block: int,
     ):
-        r""" All prometheus logging at the end of epoch.
-        """
+        r"""All prometheus logging at the end of epoch."""
         self.gauges.labels("epoch").inc()
         self.gauges.labels("set_weights").inc()
-        self.gauges.labels('set_weights_block').set(current_block)
-        self.gauges.labels("stake").set( metagraph.total_stake[uid] )
-        self.gauges.labels("rank").set( metagraph.ranks[uid] )
-        self.gauges.labels("trust").set( metagraph.trust[uid] )
-        self.gauges.labels("incentive").set( metagraph.incentive[uid] )
-        self.gauges.labels("dividends").set( metagraph.dividends[uid] )
-        self.gauges.labels("emission").set( metagraph.emission[uid] )
-
+        self.gauges.labels("set_weights_block").set(current_block)
+        self.gauges.labels("stake").set(metagraph.total_stake[uid])
+        self.gauges.labels("rank").set(metagraph.ranks[uid])
+        self.gauges.labels("trust").set(metagraph.trust[uid])
+        self.gauges.labels("incentive").set(metagraph.incentive[uid])
+        self.gauges.labels("dividends").set(metagraph.dividends[uid])
+        self.gauges.labels("emission").set(metagraph.emission[uid])
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/prometheus.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/prometheus.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,24 +19,25 @@
 
 import json
 from rich.prompt import Confirm
 import bittensor.utils.networking as net
 from ..errors import *
 from ..types import PrometheusServeCallParams
 
+
 def prometheus_extrinsic(
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.wallet',
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
     port: int,
     netuid: int,
     ip: int = None,
     wait_for_inclusion: bool = False,
-    wait_for_finalization = True,
+    wait_for_finalization=True,
 ) -> bool:
-    r""" Subscribes an bittensor endpoint to the substensor chain.
+    r"""Subscribes an bittensor endpoint to the substensor chain.
     Args:
         subtensor (bittensor.subtensor):
             bittensor subtensor object.
         wallet (bittensor.wallet):
             bittensor wallet object.
         ip (str):
             endpoint host port i.e. 192.122.31.4
@@ -56,66 +57,91 @@
             If we did not wait for finalization / inclusion, the response is true.
     """
 
     # ---- Get external ip ----
     if ip == None:
         try:
             external_ip = net.get_external_ip()
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Found external ip: {}[/green]".format( external_ip ))
-            bittensor.logging.success(prefix = 'External IP', sufix = '<blue>{}</blue>'.format( external_ip ))
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Found external ip: {}[/green]".format(
+                    external_ip
+                )
+            )
+            bittensor.logging.success(
+                prefix="External IP", sufix="<blue>{}</blue>".format(external_ip)
+            )
         except Exception as E:
-            raise RuntimeError('Unable to attain your external ip. Check your internet connection. error: {}'.format(E)) from E
+            raise RuntimeError(
+                "Unable to attain your external ip. Check your internet connection. error: {}".format(
+                    E
+                )
+            ) from E
     else:
         external_ip = ip
 
-    call_params: 'PrometheusServeCallParams' = {
-        'version': bittensor.__version_as_int__,
-        'ip': net.ip_to_int(external_ip),
-        'port': port,
-        'ip_type': net.ip_version(external_ip),
+    call_params: "PrometheusServeCallParams" = {
+        "version": bittensor.__version_as_int__,
+        "ip": net.ip_to_int(external_ip),
+        "port": port,
+        "ip_type": net.ip_version(external_ip),
     }
 
     with bittensor.__console__.status(":satellite: Checking Prometheus..."):
-        neuron = subtensor.get_neuron_for_pubkey_and_subnet( wallet.hotkey.ss58_address, netuid = netuid )
+        neuron = subtensor.get_neuron_for_pubkey_and_subnet(
+            wallet.hotkey.ss58_address, netuid=netuid
+        )
         neuron_up_to_date = not neuron.is_null and call_params == {
-            'version': neuron.prometheus_info.version,
-            'ip': net.ip_to_int(neuron.prometheus_info.ip),
-            'port': neuron.prometheus_info.port,
-            'ip_type': neuron.prometheus_info.ip_type,
+            "version": neuron.prometheus_info.version,
+            "ip": net.ip_to_int(neuron.prometheus_info.ip),
+            "port": neuron.prometheus_info.port,
+            "ip_type": neuron.prometheus_info.ip_type,
         }
 
     if neuron_up_to_date:
         bittensor.__console__.print(
             f":white_heavy_check_mark: [green]Prometheus already Served[/green]\n"
             f"[green not bold]- Status: [/green not bold] |"
             f"[green not bold] ip: [/green not bold][white not bold]{net.int_to_ip(neuron.prometheus_info.ip)}[/white not bold] |"
             f"[green not bold] ip_type: [/green not bold][white not bold]{neuron.prometheus_info.ip_type}[/white not bold] |"
             f"[green not bold] port: [/green not bold][white not bold]{neuron.prometheus_info.port}[/white not bold] | "
             f"[green not bold] version: [/green not bold][white not bold]{neuron.prometheus_info.version}[/white not bold] |"
         )
 
-
-        bittensor.__console__.print(":white_heavy_check_mark: [white]Prometheus already served.[/white]".format( external_ip ))
+        bittensor.__console__.print(
+            ":white_heavy_check_mark: [white]Prometheus already served.[/white]".format(
+                external_ip
+            )
+        )
         return True
 
     # Add netuid, not in prometheus_info
-    call_params['netuid'] = netuid
+    call_params["netuid"] = netuid
 
-    with bittensor.__console__.status(":satellite: Serving prometheus on: [white]{}:{}[/white] ...".format(subtensor.network, netuid)):
+    with bittensor.__console__.status(
+        ":satellite: Serving prometheus on: [white]{}:{}[/white] ...".format(
+            subtensor.network, netuid
+        )
+    ):
         success, err = subtensor._do_serve_prometheus(
             wallet=wallet,
-            call_params = call_params,
+            call_params=call_params,
             wait_for_finalization=wait_for_finalization,
-            wait_for_inclusion=wait_for_inclusion
+            wait_for_inclusion=wait_for_inclusion,
         )
 
         if wait_for_inclusion or wait_for_finalization:
             if success == True:
-                bittensor.__console__.print(':white_heavy_check_mark: [green]Served prometheus[/green]\n  [bold white]{}[/bold white]'.format(
-                    json.dumps(call_params, indent=4, sort_keys=True)
-                ))
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Served prometheus[/green]\n  [bold white]{}[/bold white]".format(
+                        json.dumps(call_params, indent=4, sort_keys=True)
+                    )
+                )
                 return True
             else:
-                bittensor.__console__.print(':cross_mark: [green]Failed to serve prometheus[/green] error: {}'.format(err))
+                bittensor.__console__.print(
+                    ":cross_mark: [green]Failed to serve prometheus[/green] error: {}".format(
+                        err
+                    )
+                )
                 return False
         else:
             return True
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/registration.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/registration.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 # Copyright © 2023 Opentensor Foundation
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
@@ -23,31 +22,32 @@
 import time
 from rich.prompt import Confirm
 from typing import List, Dict, Union, Optional, Tuple
 import bittensor.utils.networking as net
 from bittensor.utils.registration import POWSolution, create_pow
 from ..errors import *
 
-def register_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+
+def register_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     netuid: int,
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
     prompt: bool = False,
     max_allowed_attempts: int = 3,
     output_in_place: bool = True,
     cuda: bool = False,
     dev_id: Union[List[int], int] = 0,
     TPB: int = 256,
     num_processes: Optional[int] = None,
     update_interval: Optional[int] = None,
     log_verbose: bool = False,
 ) -> bool:
-    r""" Registers the wallet to chain.
+    r"""Registers the wallet to chain.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         netuid (int):
             The netuid of the subnet to register on.
         wait_for_inclusion (bool):
             If set, waits for the extrinsic to enter a block before returning true,
@@ -72,121 +72,172 @@
         log_verbose (bool):
             If true, the registration process will log more information.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    if not subtensor.subnet_exists( netuid ):
-        bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error: [bold white]subnet:{}[/bold white] does not exist.".format(netuid))
+    if not subtensor.subnet_exists(netuid):
+        bittensor.__console__.print(
+            ":cross_mark: [red]Failed[/red]: error: [bold white]subnet:{}[/bold white] does not exist.".format(
+                netuid
+            )
+        )
         return False
 
-    with bittensor.__console__.status(f":satellite: Checking Account on [bold]subnet:{netuid}[/bold]..."):
-        neuron = subtensor.get_neuron_for_pubkey_and_subnet( wallet.hotkey.ss58_address, netuid = netuid )
+    with bittensor.__console__.status(
+        f":satellite: Checking Account on [bold]subnet:{netuid}[/bold]..."
+    ):
+        neuron = subtensor.get_neuron_for_pubkey_and_subnet(
+            wallet.hotkey.ss58_address, netuid=netuid
+        )
         if not neuron.is_null:
             bittensor.__console__.print(
-            ':white_heavy_check_mark: [green]Already Registered[/green]:\n'\
-            'uid: [bold white]{}[/bold white]\n' \
-            'netuid: [bold white]{}[/bold white]\n' \
-            'hotkey: [bold white]{}[/bold white]\n' \
-            'coldkey: [bold white]{}[/bold white]'
-            .format(neuron.uid, neuron.netuid, neuron.hotkey, neuron.coldkey))
+                ":white_heavy_check_mark: [green]Already Registered[/green]:\n"
+                "uid: [bold white]{}[/bold white]\n"
+                "netuid: [bold white]{}[/bold white]\n"
+                "hotkey: [bold white]{}[/bold white]\n"
+                "coldkey: [bold white]{}[/bold white]".format(
+                    neuron.uid, neuron.netuid, neuron.hotkey, neuron.coldkey
+                )
+            )
             return True
 
     if prompt:
-        if not Confirm.ask("Continue Registration?\n  hotkey:     [bold white]{}[/bold white]\n  coldkey:    [bold white]{}[/bold white]\n  network:    [bold white]{}[/bold white]".format( wallet.hotkey.ss58_address, wallet.coldkeypub.ss58_address, subtensor.network ) ):
+        if not Confirm.ask(
+            "Continue Registration?\n  hotkey:     [bold white]{}[/bold white]\n  coldkey:    [bold white]{}[/bold white]\n  network:    [bold white]{}[/bold white]".format(
+                wallet.hotkey.ss58_address,
+                wallet.coldkeypub.ss58_address,
+                subtensor.network,
+            )
+        ):
             return False
 
     # Attempt rolling registration.
     attempts = 1
     while True:
-        bittensor.__console__.print(":satellite: Registering...({}/{})".format(attempts, max_allowed_attempts))
+        bittensor.__console__.print(
+            ":satellite: Registering...({}/{})".format(attempts, max_allowed_attempts)
+        )
         # Solve latest POW.
         if cuda:
             if not torch.cuda.is_available():
                 if prompt:
-                    bittensor.__console__.error('CUDA is not available.')
+                    bittensor.__console__.error("CUDA is not available.")
                 return False
-            pow_result: Optional[POWSolution] = create_pow( subtensor, wallet, netuid, output_in_place, cuda, dev_id, TPB, num_processes=num_processes, update_interval=update_interval, log_verbose=log_verbose )
+            pow_result: Optional[POWSolution] = create_pow(
+                subtensor,
+                wallet,
+                netuid,
+                output_in_place,
+                cuda,
+                dev_id,
+                TPB,
+                num_processes=num_processes,
+                update_interval=update_interval,
+                log_verbose=log_verbose,
+            )
         else:
-            pow_result: Optional[POWSolution] = create_pow( subtensor, wallet, netuid, output_in_place, num_processes=num_processes, update_interval=update_interval, log_verbose=log_verbose )
+            pow_result: Optional[POWSolution] = create_pow(
+                subtensor,
+                wallet,
+                netuid,
+                output_in_place,
+                num_processes=num_processes,
+                update_interval=update_interval,
+                log_verbose=log_verbose,
+            )
 
         # pow failed
         if not pow_result:
             # might be registered already on this subnet
             is_registered = subtensor.is_hotkey_registered(
-                netuid = netuid,
-                hotkey_ss58 = wallet.hotkey.ss58_address,
+                netuid=netuid,
+                hotkey_ss58=wallet.hotkey.ss58_address,
             )
             if is_registered:
-                bittensor.__console__.print(f":white_heavy_check_mark: [green]Already registered on netuid:{netuid}[/green]")
+                bittensor.__console__.print(
+                    f":white_heavy_check_mark: [green]Already registered on netuid:{netuid}[/green]"
+                )
                 return True
 
         # pow successful, proceed to submit pow to chain for registration
         else:
             with bittensor.__console__.status(":satellite: Submitting POW..."):
                 # check if pow result is still valid
                 while not pow_result.is_stale(subtensor=subtensor):
                     result: Tuple[bool, Optional[str]] = subtensor._do_pow_register(
-                        netuid = netuid,
-                        wallet = wallet,
-                        pow_result = pow_result,
-                        wait_for_inclusion = wait_for_inclusion,
-                        wait_for_finalization = wait_for_finalization,
+                        netuid=netuid,
+                        wallet=wallet,
+                        pow_result=pow_result,
+                        wait_for_inclusion=wait_for_inclusion,
+                        wait_for_finalization=wait_for_finalization,
                     )
                     success, err_msg = result
 
                     if success != True or success == False:
-                        if 'key is already registered' in err_msg:
+                        if "key is already registered" in err_msg:
                             # Error meant that the key is already registered.
-                            bittensor.__console__.print(f":white_heavy_check_mark: [green]Already Registered on [bold]subnet:{netuid}[/bold][/green]")
+                            bittensor.__console__.print(
+                                f":white_heavy_check_mark: [green]Already Registered on [bold]subnet:{netuid}[/bold][/green]"
+                            )
                             return True
 
-                        bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(err_msg))
+                        bittensor.__console__.print(
+                            ":cross_mark: [red]Failed[/red]: error:{}".format(err_msg)
+                        )
                         time.sleep(0.5)
 
                     # Successful registration, final check for neuron and pubkey
                     else:
                         bittensor.__console__.print(":satellite: Checking Balance...")
                         is_registered = subtensor.is_hotkey_registered(
-                            netuid = netuid,
-                            hotkey_ss58 = wallet.hotkey.ss58_address,
+                            netuid=netuid,
+                            hotkey_ss58=wallet.hotkey.ss58_address,
                         )
                         if is_registered:
-                            bittensor.__console__.print(":white_heavy_check_mark: [green]Registered[/green]")
+                            bittensor.__console__.print(
+                                ":white_heavy_check_mark: [green]Registered[/green]"
+                            )
                             return True
                         else:
                             # neuron not found, try again
-                            bittensor.__console__.print(":cross_mark: [red]Unknown error. Neuron not found.[/red]")
+                            bittensor.__console__.print(
+                                ":cross_mark: [red]Unknown error. Neuron not found.[/red]"
+                            )
                             continue
                 else:
                     # Exited loop because pow is no longer valid.
-                    bittensor.__console__.print( "[red]POW is stale.[/red]" )
+                    bittensor.__console__.print("[red]POW is stale.[/red]")
                     # Try again.
                     continue
 
         if attempts < max_allowed_attempts:
-            #Failed registration, retry pow
+            # Failed registration, retry pow
             attempts += 1
-            bittensor.__console__.print( ":satellite: Failed registration, retrying pow ...({}/{})".format(attempts, max_allowed_attempts))
+            bittensor.__console__.print(
+                ":satellite: Failed registration, retrying pow ...({}/{})".format(
+                    attempts, max_allowed_attempts
+                )
+            )
         else:
             # Failed to register after max attempts.
-            bittensor.__console__.print( "[red]No more attempts.[/red]" )
+            bittensor.__console__.print("[red]No more attempts.[/red]")
             return False
 
 
-def burned_register_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+def burned_register_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     netuid: int,
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
-    prompt: bool = False
+    prompt: bool = False,
 ) -> bool:
-    r""" Registers the wallet to chain by recycling TAO.
+    r"""Registers the wallet to chain by recycling TAO.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         netuid (int):
             The netuid of the subnet to register on.
         wait_for_inclusion (bool):
             If set, waits for the extrinsic to enter a block before returning true,
@@ -197,62 +248,84 @@
         prompt (bool):
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    if not subtensor.subnet_exists( netuid ):
-        bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error: [bold white]subnet:{}[/bold white] does not exist.".format(netuid))
+    if not subtensor.subnet_exists(netuid):
+        bittensor.__console__.print(
+            ":cross_mark: [red]Failed[/red]: error: [bold white]subnet:{}[/bold white] does not exist.".format(
+                netuid
+            )
+        )
         return False
 
-    wallet.coldkey # unlock coldkey
-    with bittensor.__console__.status(f":satellite: Checking Account on [bold]subnet:{netuid}[/bold]..."):
-        neuron = subtensor.get_neuron_for_pubkey_and_subnet( wallet.hotkey.ss58_address, netuid = netuid )
+    wallet.coldkey  # unlock coldkey
+    with bittensor.__console__.status(
+        f":satellite: Checking Account on [bold]subnet:{netuid}[/bold]..."
+    ):
+        neuron = subtensor.get_neuron_for_pubkey_and_subnet(
+            wallet.hotkey.ss58_address, netuid=netuid
+        )
 
-        old_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
+        old_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
 
-        burn_amount = subtensor.burn( netuid = netuid )
+        burn_amount = subtensor.burn(netuid=netuid)
         if not neuron.is_null:
             bittensor.__console__.print(
-            ':white_heavy_check_mark: [green]Already Registered[/green]:\n'\
-            'uid: [bold white]{}[/bold white]\n' \
-            'netuid: [bold white]{}[/bold white]\n' \
-            'hotkey: [bold white]{}[/bold white]\n' \
-            'coldkey: [bold white]{}[/bold white]'
-            .format(neuron.uid, neuron.netuid, neuron.hotkey, neuron.coldkey))
+                ":white_heavy_check_mark: [green]Already Registered[/green]:\n"
+                "uid: [bold white]{}[/bold white]\n"
+                "netuid: [bold white]{}[/bold white]\n"
+                "hotkey: [bold white]{}[/bold white]\n"
+                "coldkey: [bold white]{}[/bold white]".format(
+                    neuron.uid, neuron.netuid, neuron.hotkey, neuron.coldkey
+                )
+            )
             return True
 
     if prompt:
         # Prompt user for confirmation.
-        if not Confirm.ask( f"Recycle {burn_amount} to register on subnet:{netuid}?" ):
+        if not Confirm.ask(f"Recycle {burn_amount} to register on subnet:{netuid}?"):
             return False
 
     with bittensor.__console__.status(":satellite: Recycling TAO for Registration..."):
         success, err_msg = subtensor._do_burned_register(
-            netuid = netuid,
-            wallet = wallet,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
+            netuid=netuid,
+            wallet=wallet,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
         )
-       
+
         if success != True or success == False:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(err_msg))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: error:{}".format(err_msg)
+            )
             time.sleep(0.5)
 
         # Successful registration, final check for neuron and pubkey
         else:
             bittensor.__console__.print(":satellite: Checking Balance...")
             block = subtensor.get_current_block()
-            new_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address, block = block )
+            new_balance = subtensor.get_balance(
+                wallet.coldkeypub.ss58_address, block=block
+            )
 
-            bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_balance, new_balance ))
+            bittensor.__console__.print(
+                "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                    old_balance, new_balance
+                )
+            )
             is_registered = subtensor.is_hotkey_registered(
-                netuid = netuid,
-                hotkey_ss58 = wallet.hotkey.ss58_address,
+                netuid=netuid,
+                hotkey_ss58=wallet.hotkey.ss58_address,
             )
             if is_registered:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Registered[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Registered[/green]"
+                )
                 return True
             else:
                 # neuron not found, try again
-                bittensor.__console__.print(":cross_mark: [red]Unknown error. Neuron not found.[/red]")
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Unknown error. Neuron not found.[/red]"
+                )
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/senate.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/senate.py`

 * *Files 9% similar despite different names*

```diff
@@ -19,22 +19,23 @@
 # Imports
 import bittensor
 
 import time
 from rich.prompt import Confirm
 from ..errors import *
 
-def register_senate_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+
+def register_senate_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
-    prompt: bool = False
+    prompt: bool = False,
 ) -> bool:
-    r""" Registers the wallet to chain for senate voting.
+    r"""Registers the wallet to chain for senate voting.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         wait_for_inclusion (bool):
             If set, waits for the extrinsic to enter a block before returning true,
             or returns false if the extrinsic fails to enter the block within the timeout.
         wait_for_finalization (bool):
@@ -43,65 +44,80 @@
         prompt (bool):
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or included in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    wallet.coldkey # unlock coldkey
-    wallet.hotkey # unlock hotkey
+    wallet.coldkey  # unlock coldkey
+    wallet.hotkey  # unlock hotkey
 
     if prompt:
         # Prompt user for confirmation.
-        if not Confirm.ask( f"Register delegate hotkey to senate?" ):
+        if not Confirm.ask(f"Register delegate hotkey to senate?"):
             return False
 
     with bittensor.__console__.status(":satellite: Registering with senate..."):
-       with subtensor.substrate as substrate:
+        with subtensor.substrate as substrate:
             # create extrinsic call
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='join_senate',
-                call_params={
-                    "hotkey": wallet.hotkey.ss58_address
-                }
+                call_module="SubtensorModule",
+                call_function="join_senate",
+                call_params={"hotkey": wallet.hotkey.ss58_address},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion=wait_for_inclusion, wait_for_finalization=wait_for_finalization )
 
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
             # process if registration successful
             response.process_events()
             if not response.is_success:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(response.error_message))
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: error:{}".format(
+                        response.error_message
+                    )
+                )
                 time.sleep(0.5)
 
             # Successful registration, final check for membership
             else:
                 is_registered = wallet.is_senate_member(subtensor)
 
                 if is_registered:
-                    bittensor.__console__.print(":white_heavy_check_mark: [green]Registered[/green]")
+                    bittensor.__console__.print(
+                        ":white_heavy_check_mark: [green]Registered[/green]"
+                    )
                     return True
                 else:
                     # neuron not found, try again
-                    bittensor.__console__.print(":cross_mark: [red]Unknown error. Senate membership not found.[/red]")
+                    bittensor.__console__.print(
+                        ":cross_mark: [red]Unknown error. Senate membership not found.[/red]"
+                    )
+
 
-def leave_senate_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+def leave_senate_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
-    prompt: bool = False
+    prompt: bool = False,
 ) -> bool:
-    r""" Removes the wallet from chain for senate voting.
+    r"""Removes the wallet from chain for senate voting.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         wait_for_inclusion (bool):
             If set, waits for the extrinsic to enter a block before returning true,
             or returns false if the extrinsic fails to enter the block within the timeout.
         wait_for_finalization (bool):
@@ -110,68 +126,83 @@
         prompt (bool):
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or included in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    wallet.coldkey # unlock coldkey
-    wallet.hotkey # unlock hotkey
+    wallet.coldkey  # unlock coldkey
+    wallet.hotkey  # unlock hotkey
 
     if prompt:
         # Prompt user for confirmation.
-        if not Confirm.ask( f"Remove delegate hotkey from senate?" ):
+        if not Confirm.ask(f"Remove delegate hotkey from senate?"):
             return False
 
     with bittensor.__console__.status(":satellite: Leaving senate..."):
-       with subtensor.substrate as substrate:
+        with subtensor.substrate as substrate:
             # create extrinsic call
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='leave_senate',
-                call_params={
-                    "hotkey": wallet.hotkey.ss58_address
-                }
+                call_module="SubtensorModule",
+                call_function="leave_senate",
+                call_params={"hotkey": wallet.hotkey.ss58_address},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion=wait_for_inclusion, wait_for_finalization=wait_for_finalization )
 
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
             # process if registration successful
             response.process_events()
             if not response.is_success:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(response.error_message))
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: error:{}".format(
+                        response.error_message
+                    )
+                )
                 time.sleep(0.5)
 
             # Successful registration, final check for membership
             else:
                 is_registered = wallet.is_senate_member(subtensor)
 
                 if not is_registered:
-                    bittensor.__console__.print(":white_heavy_check_mark: [green]Left senate[/green]")
+                    bittensor.__console__.print(
+                        ":white_heavy_check_mark: [green]Left senate[/green]"
+                    )
                     return True
                 else:
                     # neuron not found, try again
-                    bittensor.__console__.print(":cross_mark: [red]Unknown error. Senate membership still found.[/red]")
+                    bittensor.__console__.print(
+                        ":cross_mark: [red]Unknown error. Senate membership still found.[/red]"
+                    )
+
 
-def vote_senate_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.Wallet',
+def vote_senate_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
     proposal_hash: str,
     proposal_idx: int,
     vote: bool,
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
-    prompt: bool = False
+    prompt: bool = False,
 ) -> bool:
-    r""" Removes the wallet from chain for senate voting.
+    r"""Removes the wallet from chain for senate voting.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         wait_for_inclusion (bool):
             If set, waits for the extrinsic to enter a block before returning true,
             or returns false if the extrinsic fails to enter the block within the timeout.
         wait_for_finalization (bool):
@@ -180,53 +211,72 @@
         prompt (bool):
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or included in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    wallet.coldkey # unlock coldkey
-    wallet.hotkey # unlock hotkey
+    wallet.coldkey  # unlock coldkey
+    wallet.hotkey  # unlock hotkey
 
     if prompt:
         # Prompt user for confirmation.
-        if not Confirm.ask( "Cast a vote of {}?".format( vote ) ):
+        if not Confirm.ask("Cast a vote of {}?".format(vote)):
             return False
 
-    with bittensor.__console__.status( ":satellite: Casting vote.." ):
-       with subtensor.substrate as substrate:
+    with bittensor.__console__.status(":satellite: Casting vote.."):
+        with subtensor.substrate as substrate:
             # create extrinsic call
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='vote',
+                call_module="SubtensorModule",
+                call_function="vote",
                 call_params={
                     "hotkey": wallet.hotkey.ss58_address,
                     "proposal": proposal_hash,
                     "index": proposal_idx,
-                    "approve": vote
-                }
+                    "approve": vote,
+                },
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion=wait_for_inclusion, wait_for_finalization=wait_for_finalization )
 
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
             # process if vote successful
             response.process_events()
             if not response.is_success:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(response.error_message))
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: error:{}".format(
+                        response.error_message
+                    )
+                )
                 time.sleep(0.5)
 
             # Successful vote, final check for data
             else:
-                vote_data = subtensor.get_vote_data( proposal_hash )
-                has_voted = vote_data["ayes"].count( wallet.hotkey.ss58_address ) > 0 or vote_data["nays"].count( wallet.hotkey.ss58_address ) > 0
+                vote_data = subtensor.get_vote_data(proposal_hash)
+                has_voted = (
+                    vote_data["ayes"].count(wallet.hotkey.ss58_address) > 0
+                    or vote_data["nays"].count(wallet.hotkey.ss58_address) > 0
+                )
 
                 if has_voted:
-                    bittensor.__console__.print(":white_heavy_check_mark: [green]Vote cast.[/green]")
+                    bittensor.__console__.print(
+                        ":white_heavy_check_mark: [green]Vote cast.[/green]"
+                    )
                     return True
                 else:
                     # hotkey not found in ayes/nays
-                    bittensor.__console__.print(":cross_mark: [red]Unknown error. Couldn't find vote.[/red]")
+                    bittensor.__console__.print(
+                        ":cross_mark: [red]Unknown error. Couldn't find vote.[/red]"
+                    )
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/serving.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/serving.py`

 * *Files 16% similar despite different names*

```diff
@@ -19,28 +19,29 @@
 
 import json
 from rich.prompt import Confirm
 import bittensor.utils.networking as net
 from ..errors import *
 from ..types import AxonServeCallParams
 
-def serve_extrinsic (
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.wallet',
+
+def serve_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
     ip: str,
     port: int,
     protocol: int,
     netuid: int,
     placeholder1: int = 0,
     placeholder2: int = 0,
     wait_for_inclusion: bool = False,
-    wait_for_finalization = True,
+    wait_for_finalization=True,
     prompt: bool = False,
 ) -> bool:
-    r""" Subscribes an bittensor endpoint to the substensor chain.
+    r"""Subscribes an bittensor endpoint to the substensor chain.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         ip (str):
             endpoint host port i.e. 192.122.31.4
         port (int):
             endpoint port number i.e. 9221
@@ -63,96 +64,111 @@
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
     # Decrypt hotkey
     wallet.hotkey
-    params: 'AxonServeCallParams' = {
-        'version': bittensor.__version_as_int__,
-        'ip': net.ip_to_int(ip),
-        'port': port,
-        'ip_type': net.ip_version(ip),
-        'netuid': netuid,
-        'coldkey': wallet.coldkeypub.ss58_address,
-        'protocol': protocol,
-        'placeholder1': placeholder1,
-        'placeholder2': placeholder2,
+    params: "AxonServeCallParams" = {
+        "version": bittensor.__version_as_int__,
+        "ip": net.ip_to_int(ip),
+        "port": port,
+        "ip_type": net.ip_version(ip),
+        "netuid": netuid,
+        "coldkey": wallet.coldkeypub.ss58_address,
+        "protocol": protocol,
+        "placeholder1": placeholder1,
+        "placeholder2": placeholder2,
     }
     with bittensor.__console__.status(":satellite: Checking Axon..."):
-        neuron = subtensor.get_neuron_for_pubkey_and_subnet( wallet.hotkey.ss58_address, netuid = netuid )
+        neuron = subtensor.get_neuron_for_pubkey_and_subnet(
+            wallet.hotkey.ss58_address, netuid=netuid
+        )
         neuron_up_to_date = not neuron.is_null and params == {
-            'version': neuron.axon_info.version,
-            'ip': net.ip_to_int(neuron.axon_info.ip),
-            'port': neuron.axon_info.port,
-            'ip_type': neuron.axon_info.ip_type,
-            'netuid': neuron.netuid,
-            'coldkey': neuron.coldkey,
-            'protocol': neuron.axon_info.protocol,
-            'placeholder1': neuron.axon_info.placeholder1,
-            'placeholder2': neuron.axon_info.placeholder2,
+            "version": neuron.axon_info.version,
+            "ip": net.ip_to_int(neuron.axon_info.ip),
+            "port": neuron.axon_info.port,
+            "ip_type": neuron.axon_info.ip_type,
+            "netuid": neuron.netuid,
+            "coldkey": neuron.coldkey,
+            "protocol": neuron.axon_info.protocol,
+            "placeholder1": neuron.axon_info.placeholder1,
+            "placeholder2": neuron.axon_info.placeholder2,
         }
     output = params.copy()
-    output['coldkey'] = wallet.coldkeypub.ss58_address
-    output['hotkey'] = wallet.hotkey.ss58_address
+    output["coldkey"] = wallet.coldkeypub.ss58_address
+    output["hotkey"] = wallet.hotkey.ss58_address
     if neuron_up_to_date:
-        bittensor.__console__.print(f":white_heavy_check_mark: [green]Axon already Served[/green]\n"
-                                    f"[green not bold]- coldkey: [/green not bold][white not bold]{output['coldkey']}[/white not bold] \n"
-                                    f"[green not bold]- hotkey: [/green not bold][white not bold]{output['hotkey']}[/white not bold] \n"
-                                    f"[green not bold]- Status: [/green not bold] |"
-                                    f"[green not bold] ip: [/green not bold][white not bold]{net.int_to_ip(output['ip'])}[/white not bold] |"
-                                    f"[green not bold] ip_type: [/green not bold][white not bold]{output['ip_type']}[/white not bold] |"
-                                    f"[green not bold] port: [/green not bold][white not bold]{output['port']}[/white not bold] | "
-                                    f"[green not bold] netuid: [/green not bold][white not bold]{output['netuid']}[/white not bold] |"
-                                    f"[green not bold] protocol: [/green not bold][white not bold]{output['protocol']}[/white not bold] |"
-                                    f"[green not bold] version: [/green not bold][white not bold]{output['version']}[/white not bold] |"
+        bittensor.__console__.print(
+            f":white_heavy_check_mark: [green]Axon already Served[/green]\n"
+            f"[green not bold]- coldkey: [/green not bold][white not bold]{output['coldkey']}[/white not bold] \n"
+            f"[green not bold]- hotkey: [/green not bold][white not bold]{output['hotkey']}[/white not bold] \n"
+            f"[green not bold]- Status: [/green not bold] |"
+            f"[green not bold] ip: [/green not bold][white not bold]{net.int_to_ip(output['ip'])}[/white not bold] |"
+            f"[green not bold] ip_type: [/green not bold][white not bold]{output['ip_type']}[/white not bold] |"
+            f"[green not bold] port: [/green not bold][white not bold]{output['port']}[/white not bold] | "
+            f"[green not bold] netuid: [/green not bold][white not bold]{output['netuid']}[/white not bold] |"
+            f"[green not bold] protocol: [/green not bold][white not bold]{output['protocol']}[/white not bold] |"
+            f"[green not bold] version: [/green not bold][white not bold]{output['version']}[/white not bold] |"
         )
 
-
         return True
 
     if prompt:
         output = params.copy()
-        output['coldkey'] = wallet.coldkeypub.ss58_address
-        output['hotkey'] = wallet.hotkey.ss58_address
-        if not Confirm.ask("Do you want to serve axon:\n  [bold white]{}[/bold white]".format(
-            json.dumps(output, indent=4, sort_keys=True)
-        )):
+        output["coldkey"] = wallet.coldkeypub.ss58_address
+        output["hotkey"] = wallet.hotkey.ss58_address
+        if not Confirm.ask(
+            "Do you want to serve axon:\n  [bold white]{}[/bold white]".format(
+                json.dumps(output, indent=4, sort_keys=True)
+            )
+        ):
             return False
 
-    with bittensor.__console__.status(":satellite: Serving axon on: [white]{}:{}[/white] ...".format(subtensor.network, netuid)):
+    with bittensor.__console__.status(
+        ":satellite: Serving axon on: [white]{}:{}[/white] ...".format(
+            subtensor.network, netuid
+        )
+    ):
         success, error_message = subtensor._do_serve_axon(
-            wallet = wallet,
-            call_params = params,
+            wallet=wallet,
+            call_params=params,
             wait_for_finalization=wait_for_finalization,
             wait_for_inclusion=wait_for_inclusion,
         )
 
         if wait_for_inclusion or wait_for_finalization:
             if success == True:
-                bittensor.__console__.print(':white_heavy_check_mark: [green]Served[/green]\n  [bold white]{}[/bold white]'.format(
-                    json.dumps(params, indent=4, sort_keys=True)
-                ))
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Served[/green]\n  [bold white]{}[/bold white]".format(
+                        json.dumps(params, indent=4, sort_keys=True)
+                    )
+                )
                 return True
             else:
-                bittensor.__console__.print(':cross_mark: [green]Failed to Serve axon[/green] error: {}'.format(error_message))
+                bittensor.__console__.print(
+                    ":cross_mark: [green]Failed to Serve axon[/green] error: {}".format(
+                        error_message
+                    )
+                )
                 return False
         else:
             return True
 
-def serve_axon_extrinsic (
-    subtensor: 'bittensor.Subtensor',
+
+def serve_axon_extrinsic(
+    subtensor: "bittensor.Subtensor",
     netuid: int,
-    axon: 'bittensor.Axon',
+    axon: "bittensor.Axon",
     use_upnpc: bool = False,
     wait_for_inclusion: bool = False,
     wait_for_finalization: bool = True,
     prompt: bool = False,
 ) -> bool:
-    r""" Serves the axon to the network.
+    r"""Serves the axon to the network.
     Args:
         netuid ( int ):
             The netuid being served on.
         axon (bittensor.Axon):
             Axon to serve.
         use_upnpc (:type:bool, `optional`):
             If true, the axon attempts port forward through your router before
@@ -175,38 +191,58 @@
 
     # ---- Setup UPNPC ----
     if use_upnpc:
         if prompt:
             if not Confirm.ask("Attempt port forwarding with upnpc?"):
                 return False
         try:
-            external_port = net.upnpc_create_port_map( port = axon.port )
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Forwarded port: {}[/green]".format( axon.port ))
-            bittensor.logging.success(prefix = 'Forwarded port', sufix = '<blue>{}</blue>'.format( axon.port ))
+            external_port = net.upnpc_create_port_map(port=axon.port)
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Forwarded port: {}[/green]".format(
+                    axon.port
+                )
+            )
+            bittensor.logging.success(
+                prefix="Forwarded port", sufix="<blue>{}</blue>".format(axon.port)
+            )
         except net.UPNPCException as upnpc_exception:
-            raise RuntimeError('Failed to hole-punch with upnpc with exception {}'.format( upnpc_exception )) from upnpc_exception
+            raise RuntimeError(
+                "Failed to hole-punch with upnpc with exception {}".format(
+                    upnpc_exception
+                )
+            ) from upnpc_exception
     else:
         external_port = axon.external_port
 
     # ---- Get external ip ----
     if axon.external_ip == None:
         try:
             external_ip = net.get_external_ip()
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Found external ip: {}[/green]".format( external_ip ))
-            bittensor.logging.success(prefix = 'External IP', sufix = '<blue>{}</blue>'.format( external_ip ))
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Found external ip: {}[/green]".format(
+                    external_ip
+                )
+            )
+            bittensor.logging.success(
+                prefix="External IP", sufix="<blue>{}</blue>".format(external_ip)
+            )
         except Exception as E:
-            raise RuntimeError('Unable to attain your external ip. Check your internet connection. error: {}'.format(E)) from E
+            raise RuntimeError(
+                "Unable to attain your external ip. Check your internet connection. error: {}".format(
+                    E
+                )
+            ) from E
     else:
         external_ip = axon.external_ip
 
     # ---- Subscribe to chain ----
     serve_success = subtensor.serve(
-            wallet = axon.wallet,
-            ip = external_ip,
-            port = external_port,
-            netuid = netuid,
-            protocol = 4,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+        wallet=axon.wallet,
+        ip=external_ip,
+        port=external_port,
+        netuid=netuid,
+        protocol=4,
+        wait_for_inclusion=wait_for_inclusion,
+        wait_for_finalization=wait_for_finalization,
+        prompt=prompt,
     )
     return serve_success
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/set_weights.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/set_weights.py`

 * *Files 8% similar despite different names*

```diff
@@ -21,28 +21,30 @@
 import torch
 from rich.prompt import Confirm
 from typing import Union
 import bittensor.utils.weight_utils as weight_utils
 from ..errors import *
 
 from loguru import logger
+
 logger = logger.opt(colors=True)
 
+
 def set_weights_extrinsic(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        netuid: int,
-        uids: Union[torch.LongTensor, list],
-        weights: Union[torch.FloatTensor, list],
-        version_key: int = 0,
-        wait_for_inclusion:bool = False,
-        wait_for_finalization:bool = False,
-        prompt:bool = False
-    ) -> bool:
-    r""" Sets the given weights and values on chain for wallet hotkey account.
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    netuid: int,
+    uids: Union[torch.LongTensor, list],
+    weights: Union[torch.FloatTensor, list],
+    version_key: int = 0,
+    wait_for_inclusion: bool = False,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Sets the given weights and values on chain for wallet hotkey account.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         netuid (int):
             netuid of the subent to set weights for.
         uids (Union[torch.LongTensor, list]):
             uint64 uids of destination neurons.
@@ -60,58 +62,95 @@
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
     # First convert types.
-    if isinstance( uids, list ):
-        uids = torch.tensor( uids, dtype = torch.int64 )
-    if isinstance( weights, list ):
-        weights = torch.tensor( weights, dtype = torch.float32 )
+    if isinstance(uids, list):
+        uids = torch.tensor(uids, dtype=torch.int64)
+    if isinstance(weights, list):
+        weights = torch.tensor(weights, dtype=torch.float32)
 
     # Reformat and normalize.
-    weight_uids, weight_vals = weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+    weight_uids, weight_vals = weight_utils.convert_weights_and_uids_for_emit(
+        uids, weights
+    )
 
     # Ask before moving on.
     if prompt:
-        if not Confirm.ask("Do you want to set weights:\n[bold white]  weights: {}\n  uids: {}[/bold white ]?".format( [float(v/65535) for v in weight_vals], weight_uids) ):
+        if not Confirm.ask(
+            "Do you want to set weights:\n[bold white]  weights: {}\n  uids: {}[/bold white ]?".format(
+                [float(v / 65535) for v in weight_vals], weight_uids
+            )
+        ):
             return False
 
-    with bittensor.__console__.status(":satellite: Setting weights on [white]{}[/white] ...".format(subtensor.network)):
+    with bittensor.__console__.status(
+        ":satellite: Setting weights on [white]{}[/white] ...".format(subtensor.network)
+    ):
         try:
             success, error_message = subtensor._do_set_weights(
-                wallet = wallet,
-                netuid = netuid,
-                uids = weight_uids,
-                vals = weight_vals,
-                version_key = version_key,
+                wallet=wallet,
+                netuid=netuid,
+                uids=weight_uids,
+                vals=weight_vals,
+                version_key=version_key,
+                wait_for_finalization=wait_for_finalization,
+                wait_for_inclusion=wait_for_inclusion,
             )
 
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
             if success == True:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-                bittensor.logging.success(  prefix = 'Set weights', sufix = '<green>Finalized: </green>' + str(success) )
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Finalized[/green]"
+                )
+                bittensor.logging.success(
+                    prefix="Set weights",
+                    sufix="<green>Finalized: </green>" + str(success),
+                )
                 return True
             else:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(error_message))
-                bittensor.logging.warning(  prefix = 'Set weights', sufix = '<red>Failed: </red>' + str(error_message) )
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: error:{}".format(error_message)
+                )
+                bittensor.logging.warning(
+                    prefix="Set weights",
+                    sufix="<red>Failed: </red>" + str(error_message),
+                )
                 return False
 
         except Exception as e:
-
             # TODO( devs ): lets remove all of the bittensor.__console__ calls and replace with loguru.
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(e))
-            bittensor.logging.warning(  prefix = 'Set weights', sufix = '<red>Failed: </red>' + str(e) )
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: error:{}".format(e)
+            )
+            bittensor.logging.warning(
+                prefix="Set weights", sufix="<red>Failed: </red>" + str(e)
+            )
             return False
 
     # TODO( devs ): this code is dead.
     if response.is_success:
-        bittensor.__console__.print("Set weights:\n[bold white]  weights: {}\n  uids: {}[/bold white ]".format( [float(v/4294967295) for v in weight_vals], weight_uids ))
-        message = '<green>Success: </green>' + f'Set {len(uids)} weights, top 5 weights' + str(list(zip(uids.tolist()[:5], [round (w,4) for w in weights.tolist()[:5]] )))
-        logger.debug('Set weights:'.ljust(20) +  message)
+        bittensor.__console__.print(
+            "Set weights:\n[bold white]  weights: {}\n  uids: {}[/bold white ]".format(
+                [float(v / 4294967295) for v in weight_vals], weight_uids
+            )
+        )
+        message = (
+            "<green>Success: </green>"
+            + f"Set {len(uids)} weights, top 5 weights"
+            + str(
+                list(
+                    zip(uids.tolist()[:5], [round(w, 4) for w in weights.tolist()[:5]])
+                )
+            )
+        )
+        logger.debug("Set weights:".ljust(20) + message)
         return True
 
-    return False
+    return False
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/staking.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/staking.py`

 * *Files 7% similar despite different names*

```diff
@@ -20,24 +20,25 @@
 
 from rich.prompt import Confirm
 from time import sleep
 from typing import List, Dict, Union, Optional
 from bittensor.utils.balance import Balance
 from ..errors import *
 
+
 def add_stake_extrinsic(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        hotkey_ss58: Optional[str] = None,
-        amount: Union[Balance, float] = None,
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Adds the specified amount of stake to passed hotkey uid.
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    hotkey_ss58: Optional[str] = None,
+    amount: Union[Balance, float] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Adds the specified amount of stake to passed hotkey uid.
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object.
         hotkey_ss58 (Optional[str]):
             ss58 address of the hotkey account to stake to
             defaults to the wallet's hotkey.
         amount (Union[Balance, float]):
@@ -67,112 +68,160 @@
     # Default to wallet's own hotkey if the value is not passed.
     if hotkey_ss58 is None:
         hotkey_ss58 = wallet.hotkey.ss58_address
 
     # Flag to indicate if we are using the wallet's own hotkey.
     own_hotkey: bool
 
-    with bittensor.__console__.status(":satellite: Syncing with chain: [white]{}[/white] ...".format(subtensor.network)):
-        old_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
+    with bittensor.__console__.status(
+        ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+            subtensor.network
+        )
+    ):
+        old_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
         # Get hotkey owner
-        hotkey_owner = subtensor.get_hotkey_owner( hotkey_ss58 )
-        own_hotkey = (wallet.coldkeypub.ss58_address == hotkey_owner)
+        hotkey_owner = subtensor.get_hotkey_owner(hotkey_ss58)
+        own_hotkey = wallet.coldkeypub.ss58_address == hotkey_owner
         if not own_hotkey:
             # This is not the wallet's own hotkey so we are delegating.
-            if not subtensor.is_hotkey_delegate( hotkey_ss58 ):
-                raise NotDelegateError("Hotkey: {} is not a delegate.".format(hotkey_ss58))
+            if not subtensor.is_hotkey_delegate(hotkey_ss58):
+                raise NotDelegateError(
+                    "Hotkey: {} is not a delegate.".format(hotkey_ss58)
+                )
 
             # Get hotkey take
-            hotkey_take = subtensor.get_delegate_take( hotkey_ss58 )
+            hotkey_take = subtensor.get_delegate_take(hotkey_ss58)
 
         # Get current stake
-        old_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58 )
+        old_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+            coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58
+        )
 
     # Convert to bittensor.Balance
     if amount == None:
         # Stake it all.
-        staking_balance = bittensor.Balance.from_tao( old_balance.tao )
-    elif not isinstance(amount, bittensor.Balance ):
-        staking_balance = bittensor.Balance.from_tao( amount )
+        staking_balance = bittensor.Balance.from_tao(old_balance.tao)
+    elif not isinstance(amount, bittensor.Balance):
+        staking_balance = bittensor.Balance.from_tao(amount)
     else:
         staking_balance = amount
 
     # Remove existential balance to keep key alive.
-    if staking_balance > bittensor.Balance.from_rao( 1000 ):
-        staking_balance = staking_balance - bittensor.Balance.from_rao( 1000 )
+    if staking_balance > bittensor.Balance.from_rao(1000):
+        staking_balance = staking_balance - bittensor.Balance.from_rao(1000)
     else:
         staking_balance = staking_balance
 
     # Check enough to stake.
     if staking_balance > old_balance:
-        bittensor.__console__.print(":cross_mark: [red]Not enough stake[/red]:[bold white]\n  balance:{}\n  amount: {}\n  coldkey: {}[/bold white]".format(old_balance, staking_balance, wallet.name))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Not enough stake[/red]:[bold white]\n  balance:{}\n  amount: {}\n  coldkey: {}[/bold white]".format(
+                old_balance, staking_balance, wallet.name
+            )
+        )
         return False
 
     # Ask before moving on.
     if prompt:
         if not own_hotkey:
             # We are delegating.
-            if not Confirm.ask("Do you want to delegate:[bold white]\n  amount: {}\n  to: {}\n  take: {}\n  owner: {}[/bold white]".format( staking_balance, wallet.hotkey_str, hotkey_take, hotkey_owner) ):
+            if not Confirm.ask(
+                "Do you want to delegate:[bold white]\n  amount: {}\n  to: {}\n  take: {}\n  owner: {}[/bold white]".format(
+                    staking_balance, wallet.hotkey_str, hotkey_take, hotkey_owner
+                )
+            ):
                 return False
         else:
-            if not Confirm.ask("Do you want to stake:[bold white]\n  amount: {}\n  to: {}[/bold white]".format( staking_balance, wallet.hotkey_str) ):
+            if not Confirm.ask(
+                "Do you want to stake:[bold white]\n  amount: {}\n  to: {}[/bold white]".format(
+                    staking_balance, wallet.hotkey_str
+                )
+            ):
                 return False
 
     try:
-        with bittensor.__console__.status(":satellite: Staking to: [bold white]{}[/bold white] ...".format(subtensor.network)):
+        with bittensor.__console__.status(
+            ":satellite: Staking to: [bold white]{}[/bold white] ...".format(
+                subtensor.network
+            )
+        ):
             staking_response: bool = __do_add_stake_single(
-                subtensor = subtensor,
-                wallet = wallet,
-                hotkey_ss58 = hotkey_ss58,
-                amount = staking_balance,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization,
+                subtensor=subtensor,
+                wallet=wallet,
+                hotkey_ss58=hotkey_ss58,
+                amount=staking_balance,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
 
-        if staking_response == True: # If we successfully staked.
+        if staking_response == True:  # If we successfully staked.
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-            with bittensor.__console__.status(":satellite: Checking Balance on: [white]{}[/white] ...".format(subtensor.network)):
-                new_balance = subtensor.get_balance( address = wallet.coldkeypub.ss58_address )
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Finalized[/green]"
+            )
+            with bittensor.__console__.status(
+                ":satellite: Checking Balance on: [white]{}[/white] ...".format(
+                    subtensor.network
+                )
+            ):
+                new_balance = subtensor.get_balance(
+                    address=wallet.coldkeypub.ss58_address
+                )
                 block = subtensor.get_current_block()
                 new_stake = subtensor.get_stake_for_coldkey_and_hotkey(
                     coldkey_ss58=wallet.coldkeypub.ss58_address,
-                    hotkey_ss58= wallet.hotkey.ss58_address,
-                    block=block
-                ) # Get current stake
-
-                bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_balance, new_balance ))
-                bittensor.__console__.print("Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_stake, new_stake ))
+                    hotkey_ss58=wallet.hotkey.ss58_address,
+                    block=block,
+                )  # Get current stake
+
+                bittensor.__console__.print(
+                    "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        old_balance, new_balance
+                    )
+                )
+                bittensor.__console__.print(
+                    "Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        old_stake, new_stake
+                    )
+                )
                 return True
         else:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: Error unknown."
+            )
             return False
 
     except NotRegisteredError as e:
-        bittensor.__console__.print(":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(wallet.hotkey_str))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(
+                wallet.hotkey_str
+            )
+        )
         return False
     except StakeError as e:
         bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
         return False
 
 
-def add_stake_multiple_extrinsic (
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        hotkey_ss58s: List[str],
-        amounts: List[Union[Balance, float]] = None,
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Adds stake to each hotkey_ss58 in the list, using each amount, from a common coldkey.
+def add_stake_multiple_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    hotkey_ss58s: List[str],
+    amounts: List[Union[Balance, float]] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Adds stake to each hotkey_ss58 in the list, using each amount, from a common coldkey.
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object for the coldkey.
         hotkey_ss58s (List[str]):
             List of hotkeys to stake to.
         amounts (List[Union[Balance, float]]):
             List of amounts to stake. If None, stake all to the first hotkey.
@@ -186,157 +235,222 @@
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or included in the block.
             flag is true if any wallet was staked.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    if not isinstance(hotkey_ss58s, list) or not all(isinstance(hotkey_ss58, str) for hotkey_ss58 in hotkey_ss58s):
+    if not isinstance(hotkey_ss58s, list) or not all(
+        isinstance(hotkey_ss58, str) for hotkey_ss58 in hotkey_ss58s
+    ):
         raise TypeError("hotkey_ss58s must be a list of str")
 
     if len(hotkey_ss58s) == 0:
         return True
 
     if amounts is not None and len(amounts) != len(hotkey_ss58s):
         raise ValueError("amounts must be a list of the same length as hotkey_ss58s")
 
-    if amounts is not None and not all(isinstance(amount, (Balance, float)) for amount in amounts):
-        raise TypeError("amounts must be a [list of bittensor.Balance or float] or None")
+    if amounts is not None and not all(
+        isinstance(amount, (Balance, float)) for amount in amounts
+    ):
+        raise TypeError(
+            "amounts must be a [list of bittensor.Balance or float] or None"
+        )
 
     if amounts is None:
         amounts = [None] * len(hotkey_ss58s)
     else:
         # Convert to Balance
-        amounts = [bittensor.Balance.from_tao(amount) if isinstance(amount, float) else amount for amount in amounts ]
+        amounts = [
+            bittensor.Balance.from_tao(amount) if isinstance(amount, float) else amount
+            for amount in amounts
+        ]
 
         if sum(amount.tao for amount in amounts) == 0:
             # Staking 0 tao
             return True
 
     # Decrypt coldkey.
     wallet.coldkey
 
     old_stakes = []
-    with bittensor.__console__.status(":satellite: Syncing with chain: [white]{}[/white] ...".format(subtensor.network)):
-        old_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
+    with bittensor.__console__.status(
+        ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+            subtensor.network
+        )
+    ):
+        old_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
 
         # Get the old stakes.
         for hotkey_ss58 in hotkey_ss58s:
-            old_stakes.append( subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58 ) )
+            old_stakes.append(
+                subtensor.get_stake_for_coldkey_and_hotkey(
+                    coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58
+                )
+            )
 
     # Remove existential balance to keep key alive.
     ## Keys must maintain a balance of at least 1000 rao to stay alive.
-    total_staking_rao = sum([amount.rao if amount is not None else 0 for amount in amounts])
+    total_staking_rao = sum(
+        [amount.rao if amount is not None else 0 for amount in amounts]
+    )
     if total_staking_rao == 0:
         # Staking all to the first wallet.
         if old_balance.rao > 1000:
             old_balance -= bittensor.Balance.from_rao(1000)
 
     elif total_staking_rao < 1000:
         # Staking less than 1000 rao to the wallets.
         pass
     else:
         # Staking more than 1000 rao to the wallets.
         ## Reduce the amount to stake to each wallet to keep the balance above 1000 rao.
         percent_reduction = 1 - (1000 / total_staking_rao)
-        amounts = [Balance.from_tao(amount.tao * percent_reduction) for amount in amounts]
+        amounts = [
+            Balance.from_tao(amount.tao * percent_reduction) for amount in amounts
+        ]
 
     successful_stakes = 0
-    for idx, (hotkey_ss58, amount, old_stake) in enumerate(zip(hotkey_ss58s, amounts, old_stakes)):
+    for idx, (hotkey_ss58, amount, old_stake) in enumerate(
+        zip(hotkey_ss58s, amounts, old_stakes)
+    ):
         staking_all = False
         # Convert to bittensor.Balance
         if amount == None:
             # Stake it all.
-            staking_balance = bittensor.Balance.from_tao( old_balance.tao )
+            staking_balance = bittensor.Balance.from_tao(old_balance.tao)
             staking_all = True
         else:
             # Amounts are cast to balance earlier in the function
             assert isinstance(amount, bittensor.Balance)
             staking_balance = amount
 
         # Check enough to stake
         if staking_balance > old_balance:
-            bittensor.__console__.print(":cross_mark: [red]Not enough balance[/red]: [green]{}[/green] to stake: [blue]{}[/blue] from coldkey: [white]{}[/white]".format(old_balance, staking_balance, wallet.name))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Not enough balance[/red]: [green]{}[/green] to stake: [blue]{}[/blue] from coldkey: [white]{}[/white]".format(
+                    old_balance, staking_balance, wallet.name
+                )
+            )
             continue
 
         # Ask before moving on.
         if prompt:
-            if not Confirm.ask("Do you want to stake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format( staking_balance, wallet.hotkey_str) ):
+            if not Confirm.ask(
+                "Do you want to stake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format(
+                    staking_balance, wallet.hotkey_str
+                )
+            ):
                 continue
 
         try:
             staking_response: bool = __do_add_stake_single(
-                subtensor = subtensor,
-                wallet = wallet,
-                hotkey_ss58 = hotkey_ss58,
-                amount = staking_balance,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization,
+                subtensor=subtensor,
+                wallet=wallet,
+                hotkey_ss58=hotkey_ss58,
+                amount=staking_balance,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-        
-            if staking_response == True: # If we successfully staked.
+
+            if staking_response == True:  # If we successfully staked.
                 # We only wait here if we expect finalization.
 
                 if idx < len(hotkey_ss58s) - 1:
                     # Wait for tx rate limit.
                     tx_rate_limit_blocks = subtensor.tx_rate_limit()
                     if tx_rate_limit_blocks > 0:
-                        bittensor.__console__.print(":hourglass: [yellow]Waiting for tx rate limit: [white]{}[/white] blocks[/yellow]".format(tx_rate_limit_blocks))
-                        sleep( tx_rate_limit_blocks * 12 ) # 12 seconds per block
+                        bittensor.__console__.print(
+                            ":hourglass: [yellow]Waiting for tx rate limit: [white]{}[/white] blocks[/yellow]".format(
+                                tx_rate_limit_blocks
+                            )
+                        )
+                        sleep(tx_rate_limit_blocks * 12)  # 12 seconds per block
 
                 if not wait_for_finalization and not wait_for_inclusion:
-                    bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                    bittensor.__console__.print(
+                        ":white_heavy_check_mark: [green]Sent[/green]"
+                    )
                     old_balance -= staking_balance
                     successful_stakes += 1
                     if staking_all:
                         # If staked all, no need to continue
                         break
 
                     continue
 
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Finalized[/green]"
+                )
 
                 block = subtensor.get_current_block()
-                new_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58, block = block )
-                new_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address, block = block )
-                bittensor.__console__.print("Stake ({}): [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( hotkey_ss58, old_stake, new_stake ))
+                new_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+                    coldkey_ss58=wallet.coldkeypub.ss58_address,
+                    hotkey_ss58=hotkey_ss58,
+                    block=block,
+                )
+                new_balance = subtensor.get_balance(
+                    wallet.coldkeypub.ss58_address, block=block
+                )
+                bittensor.__console__.print(
+                    "Stake ({}): [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        hotkey_ss58, old_stake, new_stake
+                    )
+                )
                 old_balance = new_balance
                 successful_stakes += 1
                 if staking_all:
                     # If staked all, no need to continue
                     break
 
             else:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: Error unknown."
+                )
                 continue
 
         except NotRegisteredError as e:
-            bittensor.__console__.print(":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(hotkey_ss58))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(
+                    hotkey_ss58
+                )
+            )
             continue
         except StakeError as e:
-            bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Stake Error: {}[/red]".format(e)
+            )
             continue
 
-
     if successful_stakes != 0:
-        with bittensor.__console__.status(":satellite: Checking Balance on: ([white]{}[/white] ...".format(subtensor.network)):
-            new_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
-        bittensor.__console__.print("Balance: [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_balance, new_balance ))
+        with bittensor.__console__.status(
+            ":satellite: Checking Balance on: ([white]{}[/white] ...".format(
+                subtensor.network
+            )
+        ):
+            new_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
+        bittensor.__console__.print(
+            "Balance: [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                old_balance, new_balance
+            )
+        )
         return True
 
     return False
 
+
 def __do_add_stake_single(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        hotkey_ss58: str,
-        amount: 'bittensor.Balance',
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-    ) -> bool:
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    hotkey_ss58: str,
+    amount: "bittensor.Balance",
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+) -> bool:
     r"""
     Executes a stake call to the chain using the wallet and amount specified.
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object.
         hotkey_ss58 (str):
             Hotkey to stake to.
@@ -361,26 +475,25 @@
             If the hotkey is not a delegate.
         NotRegisteredError:
             If the hotkey is not registered in any subnets.
 
     """
     # Decrypt keys,
     wallet.coldkey
-    
-    hotkey_owner = subtensor.get_hotkey_owner( hotkey_ss58 )
-    own_hotkey = (wallet.coldkeypub.ss58_address == hotkey_owner)
+
+    hotkey_owner = subtensor.get_hotkey_owner(hotkey_ss58)
+    own_hotkey = wallet.coldkeypub.ss58_address == hotkey_owner
     if not own_hotkey:
         # We are delegating.
         # Verify that the hotkey is a delegate.
-        if not subtensor.is_hotkey_delegate( hotkey_ss58 = hotkey_ss58 ):
+        if not subtensor.is_hotkey_delegate(hotkey_ss58=hotkey_ss58):
             raise NotDelegateError("Hotkey: {} is not a delegate.".format(hotkey_ss58))
 
     success = subtensor._do_stake(
-        wallet = wallet,
-        hotkey_ss58 = hotkey_ss58,
-        amount = amount,
-        wait_for_inclusion = wait_for_inclusion,
-        wait_for_finalization = wait_for_finalization,
+        wallet=wallet,
+        hotkey_ss58=hotkey_ss58,
+        amount=amount,
+        wait_for_inclusion=wait_for_inclusion,
+        wait_for_finalization=wait_for_finalization,
     )
 
     return success
-
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/transfer.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/transfer.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,25 +20,26 @@
 
 from rich.prompt import Confirm
 from typing import List, Dict, Union
 from bittensor.utils.balance import Balance
 from bittensor.utils import is_valid_bittensor_address_or_public_key
 from ..errors import *
 
+
 def transfer_extrinsic(
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        dest: str,
-        amount: Union[Balance, float],
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        keep_alive: bool = True,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Transfers funds from this wallet to the destination public key address
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    dest: str,
+    amount: Union[Balance, float],
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    keep_alive: bool = True,
+    prompt: bool = False,
+) -> bool:
+    r"""Transfers funds from this wallet to the destination public key address
     Args:
         wallet (bittensor.wallet):
             Bittensor wallet object to make transfer from.
         dest (str, ss58_address or ed25519):
             Destination public key address of reciever.
         amount (Union[Balance, int]):
             Amount to stake as bittensor balance, or float interpreted as Tao.
@@ -54,77 +55,101 @@
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             Flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
     # Validate destination address.
-    if not is_valid_bittensor_address_or_public_key( dest ):
-        bittensor.__console__.print(":cross_mark: [red]Invalid destination address[/red]:[bold white]\n  {}[/bold white]".format(dest))
+    if not is_valid_bittensor_address_or_public_key(dest):
+        bittensor.__console__.print(
+            ":cross_mark: [red]Invalid destination address[/red]:[bold white]\n  {}[/bold white]".format(
+                dest
+            )
+        )
         return False
 
-    if isinstance( dest, bytes):
+    if isinstance(dest, bytes):
         # Convert bytes to hex string.
         dest = "0x" + dest.hex()
 
     # Unlock wallet coldkey.
     wallet.coldkey
 
     # Convert to bittensor.Balance
-    if not isinstance(amount, bittensor.Balance ):
-        transfer_balance = bittensor.Balance.from_tao( amount )
+    if not isinstance(amount, bittensor.Balance):
+        transfer_balance = bittensor.Balance.from_tao(amount)
     else:
         transfer_balance = amount
 
     # Check balance.
     with bittensor.__console__.status(":satellite: Checking Balance..."):
-        account_balance = subtensor.get_balance( wallet.coldkey.ss58_address )
+        account_balance = subtensor.get_balance(wallet.coldkey.ss58_address)
         # check existential deposit.
         existential_deposit = subtensor.get_existential_deposit()
 
     with bittensor.__console__.status(":satellite: Transferring..."):
         fee = subtensor.get_transfer_fee(
-            wallet=wallet,
-            dest = dest,
-            value = transfer_balance.rao
+            wallet=wallet, dest=dest, value=transfer_balance.rao
         )
 
     if not keep_alive:
         # Check if the transfer should keep_alive the account
         existential_deposit = bittensor.Balance(0)
 
     # Check if we have enough balance.
     if account_balance < (transfer_balance + fee + existential_deposit):
-        bittensor.__console__.print(":cross_mark: [red]Not enough balance[/red]:[bold white]\n  balance: {}\n  amount: {}\n  for fee: {}[/bold white]".format( account_balance, transfer_balance, fee ))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Not enough balance[/red]:[bold white]\n  balance: {}\n  amount: {}\n  for fee: {}[/bold white]".format(
+                account_balance, transfer_balance, fee
+            )
+        )
         return False
 
     # Ask before moving on.
     if prompt:
-        if not Confirm.ask("Do you want to transfer:[bold white]\n  amount: {}\n  from: {}:{}\n  to: {}\n  for fee: {}[/bold white]".format( transfer_balance, wallet.name, wallet.coldkey.ss58_address, dest, fee )):
+        if not Confirm.ask(
+            "Do you want to transfer:[bold white]\n  amount: {}\n  from: {}:{}\n  to: {}\n  for fee: {}[/bold white]".format(
+                transfer_balance, wallet.name, wallet.coldkey.ss58_address, dest, fee
+            )
+        ):
             return False
 
     with bittensor.__console__.status(":satellite: Transferring..."):
         success, block_hash, err_msg = subtensor._do_transfer(
             wallet,
             dest,
             transfer_balance,
             wait_for_finalization=wait_for_finalization,
             wait_for_inclusion=wait_for_inclusion,
         )
 
         if success:
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-            bittensor.__console__.print("[green]Block Hash: {}[/green]".format( block_hash ))
-
-            explorer_url = bittensor.utils.get_explorer_url_for_network( subtensor.network, block_hash, bittensor.__network_explorer_map__ )
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Finalized[/green]"
+            )
+            bittensor.__console__.print(
+                "[green]Block Hash: {}[/green]".format(block_hash)
+            )
+
+            explorer_url = bittensor.utils.get_explorer_url_for_network(
+                subtensor.network, block_hash, bittensor.__network_explorer_map__
+            )
             if explorer_url is not None:
-                bittensor.__console__.print("[green]Explorer Link: {}[/green]".format( explorer_url ))
+                bittensor.__console__.print(
+                    "[green]Explorer Link: {}[/green]".format(explorer_url)
+                )
         else:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: error:{}".format(err_msg))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: error:{}".format(err_msg)
+            )
 
     if success:
         with bittensor.__console__.status(":satellite: Checking Balance..."):
-            new_balance = subtensor.get_balance( wallet.coldkey.ss58_address )
-            bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(account_balance, new_balance))
+            new_balance = subtensor.get_balance(wallet.coldkey.ss58_address)
+            bittensor.__console__.print(
+                "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                    account_balance, new_balance
+                )
+            )
             return True
 
-    return False
+    return False
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/extrinsics/unstaking.py` & `bittensor-5.3.2/bittensor/_subtensor/extrinsics/unstaking.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,19 +20,20 @@
 
 from rich.prompt import Confirm
 from time import sleep
 from typing import List, Dict, Union, Optional
 from bittensor.utils.balance import Balance
 from ..errors import *
 
+
 def __do_remove_stake_single(
-    subtensor: 'bittensor.Subtensor',
-    wallet: 'bittensor.wallet',
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
     hotkey_ss58: str,
-    amount: 'bittensor.Balance',
+    amount: "bittensor.Balance",
     wait_for_inclusion: bool = True,
     wait_for_finalization: bool = False,
 ) -> bool:
     r"""
     Executes an unstake call to the chain using the wallet and amount specified.
     Args:
         wallet (bittensor.wallet):
@@ -60,33 +61,34 @@
             If the hotkey is not registered in any subnets.
 
     """
     # Decrypt keys,
     wallet.coldkey
 
     success = subtensor._do_unstake(
-        wallet = wallet,
-        hotkey_ss58 = hotkey_ss58,
-        amount = amount,
-        wait_for_inclusion = wait_for_inclusion,
-        wait_for_finalization = wait_for_finalization,
+        wallet=wallet,
+        hotkey_ss58=hotkey_ss58,
+        amount=amount,
+        wait_for_inclusion=wait_for_inclusion,
+        wait_for_finalization=wait_for_finalization,
     )
 
     return success
 
-def unstake_extrinsic (
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        hotkey_ss58: Optional[str] = None,
-        amount: Union[Balance, float] = None,
-        wait_for_inclusion:bool = True,
-        wait_for_finalization:bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Removes stake into the wallet coldkey from the specified hotkey uid.
+
+def unstake_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    hotkey_ss58: Optional[str] = None,
+    amount: Union[Balance, float] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Removes stake into the wallet coldkey from the specified hotkey uid.
     Args:
         wallet (bittensor.wallet):
             bittensor wallet object.
         hotkey_ss58 (Optional[str]):
             ss58 address of the hotkey to unstake from.
             by default, the wallet hotkey is used.
         amount (Union[Balance, float]):
@@ -104,86 +106,130 @@
             flag is true if extrinsic was finalized or uncluded in the block.
             If we did not wait for finalization / inclusion, the response is true.
     """
     # Decrypt keys,
     wallet.coldkey
 
     if hotkey_ss58 is None:
-        hotkey_ss58 = wallet.hotkey.ss58_address # Default to wallet's own hotkey.
+        hotkey_ss58 = wallet.hotkey.ss58_address  # Default to wallet's own hotkey.
 
-    with bittensor.__console__.status(":satellite: Syncing with chain: [white]{}[/white] ...".format(subtensor.network)):
-        old_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
-        old_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58 )
+    with bittensor.__console__.status(
+        ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+            subtensor.network
+        )
+    ):
+        old_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
+        old_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+            coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58
+        )
 
     # Convert to bittensor.Balance
     if amount == None:
         # Unstake it all.
         unstaking_balance = old_stake
-    elif not isinstance(amount, bittensor.Balance ):
-        unstaking_balance = bittensor.Balance.from_tao( amount )
+    elif not isinstance(amount, bittensor.Balance):
+        unstaking_balance = bittensor.Balance.from_tao(amount)
     else:
         unstaking_balance = amount
 
     # Check enough to unstake.
     stake_on_uid = old_stake
     if unstaking_balance > stake_on_uid:
-        bittensor.__console__.print(":cross_mark: [red]Not enough stake[/red]: [green]{}[/green] to unstake: [blue]{}[/blue] from hotkey: [white]{}[/white]".format(stake_on_uid, unstaking_balance, wallet.hotkey_str))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Not enough stake[/red]: [green]{}[/green] to unstake: [blue]{}[/blue] from hotkey: [white]{}[/white]".format(
+                stake_on_uid, unstaking_balance, wallet.hotkey_str
+            )
+        )
         return False
 
     # Ask before moving on.
     if prompt:
-        if not Confirm.ask("Do you want to unstake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format( unstaking_balance, wallet.hotkey_str) ):
+        if not Confirm.ask(
+            "Do you want to unstake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format(
+                unstaking_balance, wallet.hotkey_str
+            )
+        ):
             return False
 
-
     try:
-        with bittensor.__console__.status(":satellite: Unstaking from chain: [white]{}[/white] ...".format(subtensor.network)):
+        with bittensor.__console__.status(
+            ":satellite: Unstaking from chain: [white]{}[/white] ...".format(
+                subtensor.network
+            )
+        ):
             staking_response: bool = __do_remove_stake_single(
-                subtensor = subtensor,
-                wallet = wallet,
-                hotkey_ss58 = hotkey_ss58,
-                amount = unstaking_balance,
-                wait_for_inclusion = wait_for_inclusion,
-                wait_for_finalization = wait_for_finalization,
+                subtensor=subtensor,
+                wallet=wallet,
+                hotkey_ss58=hotkey_ss58,
+                amount=unstaking_balance,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
 
-        if staking_response == True: # If we successfully unstaked.
+        if staking_response == True:  # If we successfully unstaked.
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
-            bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-            with bittensor.__console__.status(":satellite: Checking Balance on: [white]{}[/white] ...".format(subtensor.network)):
-                new_balance = subtensor.get_balance( address = wallet.coldkeypub.ss58_address )
-                new_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58 ) # Get stake on hotkey.
-                bittensor.__console__.print("Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_balance, new_balance ))
-                bittensor.__console__.print("Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_stake, new_stake ))
+            bittensor.__console__.print(
+                ":white_heavy_check_mark: [green]Finalized[/green]"
+            )
+            with bittensor.__console__.status(
+                ":satellite: Checking Balance on: [white]{}[/white] ...".format(
+                    subtensor.network
+                )
+            ):
+                new_balance = subtensor.get_balance(
+                    address=wallet.coldkeypub.ss58_address
+                )
+                new_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+                    coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58
+                )  # Get stake on hotkey.
+                bittensor.__console__.print(
+                    "Balance:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        old_balance, new_balance
+                    )
+                )
+                bittensor.__console__.print(
+                    "Stake:\n  [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                        old_stake, new_stake
+                    )
+                )
                 return True
         else:
-            bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+            bittensor.__console__.print(
+                ":cross_mark: [red]Failed[/red]: Error unknown."
+            )
             return False
 
     except NotRegisteredError as e:
-        bittensor.__console__.print(":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(wallet.hotkey_str))
+        bittensor.__console__.print(
+            ":cross_mark: [red]Hotkey: {} is not registered.[/red]".format(
+                wallet.hotkey_str
+            )
+        )
         return False
     except StakeError as e:
         bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
         return False
 
-def unstake_multiple_extrinsic (
-        subtensor: 'bittensor.Subtensor',
-        wallet: 'bittensor.wallet',
-        hotkey_ss58s: List[str],
-        amounts: List[Union[Balance, float]] = None,
-        wait_for_inclusion: bool = True,
-        wait_for_finalization: bool = False,
-        prompt: bool = False,
-    ) -> bool:
-    r""" Removes stake from each hotkey_ss58 in the list, using each amount, to a common coldkey.
+
+def unstake_multiple_extrinsic(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.wallet",
+    hotkey_ss58s: List[str],
+    amounts: List[Union[Balance, float]] = None,
+    wait_for_inclusion: bool = True,
+    wait_for_finalization: bool = False,
+    prompt: bool = False,
+) -> bool:
+    r"""Removes stake from each hotkey_ss58 in the list, using each amount, to a common coldkey.
     Args:
         wallet (bittensor.wallet):
             The wallet with the coldkey to unstake to.
         hotkey_ss58s (List[str]):
             List of hotkeys to unstake from.
         amounts (List[Union[Balance, float]]):
             List of amounts to unstake. If None, unstake all.
@@ -197,113 +243,175 @@
             If true, the call waits for confirmation from the user before proceeding.
     Returns:
         success (bool):
             flag is true if extrinsic was finalized or included in the block.
             flag is true if any wallet was unstaked.
             If we did not wait for finalization / inclusion, the response is true.
     """
-    if not isinstance(hotkey_ss58s, list) or not all(isinstance(hotkey_ss58, str) for hotkey_ss58 in hotkey_ss58s):
+    if not isinstance(hotkey_ss58s, list) or not all(
+        isinstance(hotkey_ss58, str) for hotkey_ss58 in hotkey_ss58s
+    ):
         raise TypeError("hotkey_ss58s must be a list of str")
 
     if len(hotkey_ss58s) == 0:
         return True
 
     if amounts is not None and len(amounts) != len(hotkey_ss58s):
         raise ValueError("amounts must be a list of the same length as hotkey_ss58s")
 
-    if amounts is not None and not all(isinstance(amount, (Balance, float)) for amount in amounts):
-        raise TypeError("amounts must be a [list of bittensor.Balance or float] or None")
+    if amounts is not None and not all(
+        isinstance(amount, (Balance, float)) for amount in amounts
+    ):
+        raise TypeError(
+            "amounts must be a [list of bittensor.Balance or float] or None"
+        )
 
     if amounts is None:
         amounts = [None] * len(hotkey_ss58s)
     else:
         # Convert to Balance
-        amounts = [bittensor.Balance.from_tao(amount) if isinstance(amount, float) else amount for amount in amounts ]
+        amounts = [
+            bittensor.Balance.from_tao(amount) if isinstance(amount, float) else amount
+            for amount in amounts
+        ]
 
         if sum(amount.tao for amount in amounts) == 0:
             # Staking 0 tao
             return True
 
     # Unlock coldkey.
     wallet.coldkey
 
     old_stakes = []
-    with bittensor.__console__.status(":satellite: Syncing with chain: [white]{}[/white] ...".format(subtensor.network)):
-        old_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
+    with bittensor.__console__.status(
+        ":satellite: Syncing with chain: [white]{}[/white] ...".format(
+            subtensor.network
+        )
+    ):
+        old_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
 
         for hotkey_ss58 in hotkey_ss58s:
-            old_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58 ) # Get stake on hotkey.
-            old_stakes.append(old_stake) # None if not registered.
+            old_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+                coldkey_ss58=wallet.coldkeypub.ss58_address, hotkey_ss58=hotkey_ss58
+            )  # Get stake on hotkey.
+            old_stakes.append(old_stake)  # None if not registered.
 
     successful_unstakes = 0
-    for idx, (hotkey_ss58, amount, old_stake) in enumerate(zip(hotkey_ss58s, amounts, old_stakes)):
+    for idx, (hotkey_ss58, amount, old_stake) in enumerate(
+        zip(hotkey_ss58s, amounts, old_stakes)
+    ):
         # Covert to bittensor.Balance
         if amount == None:
             # Unstake it all.
             unstaking_balance = old_stake
-        elif not isinstance(amount, bittensor.Balance ):
-            unstaking_balance = bittensor.Balance.from_tao( amount )
+        elif not isinstance(amount, bittensor.Balance):
+            unstaking_balance = bittensor.Balance.from_tao(amount)
         else:
             unstaking_balance = amount
 
         # Check enough to unstake.
         stake_on_uid = old_stake
         if unstaking_balance > stake_on_uid:
-            bittensor.__console__.print(":cross_mark: [red]Not enough stake[/red]: [green]{}[/green] to unstake: [blue]{}[/blue] from hotkey: [white]{}[/white]".format(stake_on_uid, unstaking_balance, wallet.hotkey_str))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Not enough stake[/red]: [green]{}[/green] to unstake: [blue]{}[/blue] from hotkey: [white]{}[/white]".format(
+                    stake_on_uid, unstaking_balance, wallet.hotkey_str
+                )
+            )
             continue
 
         # Ask before moving on.
         if prompt:
-            if not Confirm.ask("Do you want to unstake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format( unstaking_balance, wallet.hotkey_str) ):
+            if not Confirm.ask(
+                "Do you want to unstake:\n[bold white]  amount: {}\n  hotkey: {}[/bold white ]?".format(
+                    unstaking_balance, wallet.hotkey_str
+                )
+            ):
                 continue
 
         try:
-            with bittensor.__console__.status(":satellite: Unstaking from chain: [white]{}[/white] ...".format(subtensor.network)):
+            with bittensor.__console__.status(
+                ":satellite: Unstaking from chain: [white]{}[/white] ...".format(
+                    subtensor.network
+                )
+            ):
                 staking_response: bool = __do_remove_stake_single(
-                    subtensor = subtensor,
-                    wallet = wallet,
-                    hotkey_ss58 = hotkey_ss58,
-                    amount = unstaking_balance,
-                    wait_for_inclusion = wait_for_inclusion,
-                    wait_for_finalization = wait_for_finalization,
+                    subtensor=subtensor,
+                    wallet=wallet,
+                    hotkey_ss58=hotkey_ss58,
+                    amount=unstaking_balance,
+                    wait_for_inclusion=wait_for_inclusion,
+                    wait_for_finalization=wait_for_finalization,
                 )
 
-            if staking_response == True: # If we successfully unstaked.
+            if staking_response == True:  # If we successfully unstaked.
                 # We only wait here if we expect finalization.
 
                 if idx < len(hotkey_ss58s) - 1:
                     # Wait for tx rate limit.
                     tx_rate_limit_blocks = subtensor.tx_rate_limit()
                     if tx_rate_limit_blocks > 0:
-                        bittensor.__console__.print(":hourglass: [yellow]Waiting for tx rate limit: [white]{}[/white] blocks[/yellow]".format(tx_rate_limit_blocks))
-                        sleep( tx_rate_limit_blocks * 12 ) # 12 seconds per block
+                        bittensor.__console__.print(
+                            ":hourglass: [yellow]Waiting for tx rate limit: [white]{}[/white] blocks[/yellow]".format(
+                                tx_rate_limit_blocks
+                            )
+                        )
+                        sleep(tx_rate_limit_blocks * 12)  # 12 seconds per block
 
                 if not wait_for_finalization and not wait_for_inclusion:
-                    bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                    bittensor.__console__.print(
+                        ":white_heavy_check_mark: [green]Sent[/green]"
+                    )
                     successful_unstakes += 1
                     continue
 
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Finalized[/green]")
-                with bittensor.__console__.status(":satellite: Checking Balance on: [white]{}[/white] ...".format(subtensor.network)):
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Finalized[/green]"
+                )
+                with bittensor.__console__.status(
+                    ":satellite: Checking Balance on: [white]{}[/white] ...".format(
+                        subtensor.network
+                    )
+                ):
                     block = subtensor.get_current_block()
-                    new_stake = subtensor.get_stake_for_coldkey_and_hotkey( coldkey_ss58 = wallet.coldkeypub.ss58_address, hotkey_ss58 = hotkey_ss58, block = block )
-                    bittensor.__console__.print("Stake ({}): [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( hotkey_ss58, stake_on_uid, new_stake ))
+                    new_stake = subtensor.get_stake_for_coldkey_and_hotkey(
+                        coldkey_ss58=wallet.coldkeypub.ss58_address,
+                        hotkey_ss58=hotkey_ss58,
+                        block=block,
+                    )
+                    bittensor.__console__.print(
+                        "Stake ({}): [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                            hotkey_ss58, stake_on_uid, new_stake
+                        )
+                    )
                     successful_unstakes += 1
             else:
-                bittensor.__console__.print(":cross_mark: [red]Failed[/red]: Error unknown.")
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed[/red]: Error unknown."
+                )
                 continue
 
         except NotRegisteredError as e:
-            bittensor.__console__.print(":cross_mark: [red]{} is not registered.[/red]".format(hotkey_ss58))
+            bittensor.__console__.print(
+                ":cross_mark: [red]{} is not registered.[/red]".format(hotkey_ss58)
+            )
             continue
         except StakeError as e:
-            bittensor.__console__.print(":cross_mark: [red]Stake Error: {}[/red]".format(e))
+            bittensor.__console__.print(
+                ":cross_mark: [red]Stake Error: {}[/red]".format(e)
+            )
             continue
 
-
     if successful_unstakes != 0:
-        with bittensor.__console__.status(":satellite: Checking Balance on: ([white]{}[/white] ...".format(subtensor.network)):
-            new_balance = subtensor.get_balance( wallet.coldkeypub.ss58_address )
-        bittensor.__console__.print("Balance: [blue]{}[/blue] :arrow_right: [green]{}[/green]".format( old_balance, new_balance ))
+        with bittensor.__console__.status(
+            ":satellite: Checking Balance on: ([white]{}[/white] ...".format(
+                subtensor.network
+            )
+        ):
+            new_balance = subtensor.get_balance(wallet.coldkeypub.ss58_address)
+        bittensor.__console__.print(
+            "Balance: [blue]{}[/blue] :arrow_right: [green]{}[/green]".format(
+                old_balance, new_balance
+            )
+        )
         return True
 
-    return False
+    return False
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/subtensor_impl.py` & `bittensor-5.3.2/bittensor/_subtensor/subtensor_impl.py`

 * *Files 10% similar despite different names*

```diff
@@ -25,314 +25,353 @@
 from substrateinterface.base import QueryMapResult, SubstrateInterface
 
 from bittensor.utils.balance import Balance
 from bittensor.utils import U16_NORMALIZED_FLOAT, U64_MAX, RAOPERTAO, U16_MAX
 from bittensor.utils.registration import POWSolution
 
 # Local imports.
-from .chain_data import NeuronInfo, DelegateInfo, PrometheusInfo, SubnetInfo, NeuronInfoLite, axon_info, ProposalVoteData, ProposalCallData
+from .chain_data import (
+    NeuronInfo,
+    DelegateInfo,
+    PrometheusInfo,
+    SubnetInfo,
+    NeuronInfoLite,
+    axon_info,
+    ProposalVoteData,
+    ProposalCallData,
+)
 from .errors import *
 from .extrinsics.staking import add_stake_extrinsic, add_stake_multiple_extrinsic
 from .extrinsics.unstaking import unstake_extrinsic, unstake_multiple_extrinsic
 from .extrinsics.serving import serve_extrinsic, serve_axon_extrinsic
 from .extrinsics.registration import register_extrinsic, burned_register_extrinsic
 from .extrinsics.transfer import transfer_extrinsic
 from .extrinsics.set_weights import set_weights_extrinsic
 from .extrinsics.prometheus import prometheus_extrinsic
-from .extrinsics.delegation import delegate_extrinsic, nominate_extrinsic,undelegate_extrinsic
-from .extrinsics.senate import register_senate_extrinsic, leave_senate_extrinsic, vote_senate_extrinsic
+from .extrinsics.delegation import (
+    delegate_extrinsic,
+    nominate_extrinsic,
+    undelegate_extrinsic,
+)
+from .extrinsics.senate import (
+    register_senate_extrinsic,
+    leave_senate_extrinsic,
+    vote_senate_extrinsic,
+)
 from .types import AxonServeCallParams, PrometheusServeCallParams
 
 # Logging
 from loguru import logger
+
 logger = logger.opt(colors=True)
 
+
 class Subtensor:
     """
     Handles interactions with the subtensor chain.
     """
+
     def __init__(
         self,
-        substrate: 'SubstrateInterface',
+        substrate: "SubstrateInterface",
         network: str,
         chain_endpoint: str,
     ):
-        r""" Initializes a subtensor chain interface.
-            Args:
-                substrate (:obj:`SubstrateInterface`, `required`):
-                    substrate websocket client.
-                network (default='local', type=str)
-                    The subtensor network flag. The likely choices are:
-                            -- local (local running network)
-                            -- nobunaga (staging network)
-                            -- finney (main network)
-                    If this option is set it overloads subtensor.chain_endpoint with
-                    an entry point node from that network.
-                chain_endpoint (default=None, type=str)
-                    The subtensor endpoint flag. If set, overrides the network argument.
+        r"""Initializes a subtensor chain interface.
+        Args:
+            substrate (:obj:`SubstrateInterface`, `required`):
+                substrate websocket client.
+            network (default='local', type=str)
+                The subtensor network flag. The likely choices are:
+                        -- local (local running network)
+                        -- nobunaga (staging network)
+                        -- finney (main network)
+                If this option is set it overloads subtensor.chain_endpoint with
+                an entry point node from that network.
+            chain_endpoint (default=None, type=str)
+                The subtensor endpoint flag. If set, overrides the network argument.
         """
         self.network = network
         self.chain_endpoint = chain_endpoint
         self.substrate = substrate
 
     def __str__(self) -> str:
         if self.network == self.chain_endpoint:
             # Connecting to chain endpoint without network known.
-            return "Subtensor({})".format( self.chain_endpoint )
+            return "Subtensor({})".format(self.chain_endpoint)
         else:
             # Connecting to network with endpoint known.
-            return "Subtensor({}, {})".format( self.network, self.chain_endpoint )
+            return "Subtensor({}, {})".format(self.network, self.chain_endpoint)
 
     def __repr__(self) -> str:
         return self.__str__()
 
     #####################
     #### Delegation #####
     #####################
     def nominate(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         wait_for_finalization: bool = False,
-        wait_for_inclusion: bool = True
+        wait_for_inclusion: bool = True,
     ) -> bool:
-        """ Becomes a delegate for the hotkey."""
+        """Becomes a delegate for the hotkey."""
         return nominate_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            wait_for_finalization = wait_for_finalization,
-            wait_for_inclusion = wait_for_inclusion
+            subtensor=self,
+            wallet=wallet,
+            wait_for_finalization=wait_for_finalization,
+            wait_for_inclusion=wait_for_inclusion,
         )
 
     def delegate(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         delegate_ss58: Optional[str] = None,
         amount: Union[Balance, float] = None,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Adds the specified amount of stake to the passed delegate using the passed wallet. """
+        """Adds the specified amount of stake to the passed delegate using the passed wallet."""
         return delegate_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            delegate_ss58 = delegate_ss58,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+            subtensor=self,
+            wallet=wallet,
+            delegate_ss58=delegate_ss58,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
         )
 
     def undelegate(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         delegate_ss58: Optional[str] = None,
         amount: Union[Balance, float] = None,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Removes the specified amount of stake from the passed delegate using the passed wallet. """
+        """Removes the specified amount of stake from the passed delegate using the passed wallet."""
         return undelegate_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            delegate_ss58 = delegate_ss58,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+            subtensor=self,
+            wallet=wallet,
+            delegate_ss58=delegate_ss58,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
         )
 
     #####################
     #### Set Weights ####
     #####################
     def set_weights(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         netuid: int,
         uids: Union[torch.LongTensor, list],
         weights: Union[torch.FloatTensor, list],
         version_key: int = bittensor.__version_as_int__,
-        wait_for_inclusion:bool = False,
-        wait_for_finalization:bool = False,
-        prompt:bool = False
+        wait_for_inclusion: bool = False,
+        wait_for_finalization: bool = False,
+        prompt: bool = False,
     ) -> bool:
         return set_weights_extrinsic(
             subtensor=self,
             wallet=wallet,
             netuid=netuid,
             uids=uids,
             weights=weights,
             version_key=version_key,
             wait_for_inclusion=wait_for_inclusion,
             wait_for_finalization=wait_for_finalization,
             prompt=prompt,
         )
-    
+
     def _do_set_weights(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         uids: List[int],
         vals: List[int],
         netuid: int,
         version_key: int = bittensor.__version_as_int__,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
-    ) -> Tuple[bool, Optional[str]]: # (success, error_message)
+    ) -> Tuple[bool, Optional[str]]:  # (success, error_message)
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='set_weights',
-                call_params = {
-                    'dests': uids,
-                    'weights': vals,
-                    'netuid': netuid,
-                    'version_key': version_key,
-                }
+                call_module="SubtensorModule",
+                call_function="set_weights",
+                call_params={
+                    "dests": uids,
+                    "weights": vals,
+                    "netuid": netuid,
+                    "version_key": version_key,
+                },
             )
             # Period dictates how long the extrinsic will stay as part of waiting pool
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.hotkey, era={'period':100})
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.hotkey, era={"period": 100}
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
+            )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True, None
 
             response.process_events()
             if response.is_success:
                 return True, None
             else:
                 return False, response.error_message
 
     ######################
     #### Registration ####
     ######################
-    def register (
+    def register(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         netuid: int,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
         prompt: bool = False,
         max_allowed_attempts: int = 3,
         output_in_place: bool = True,
         cuda: bool = False,
         dev_id: Union[List[int], int] = 0,
         TPB: int = 256,
         num_processes: Optional[int] = None,
         update_interval: Optional[int] = None,
         log_verbose: bool = False,
     ) -> bool:
-        """ Registers the wallet to chain."""
+        """Registers the wallet to chain."""
         return register_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            netuid = netuid,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt,
-            max_allowed_attempts = max_allowed_attempts,
-            output_in_place = output_in_place,
-            cuda = cuda,
-            dev_id = dev_id,
-            TPB = TPB,
-            num_processes = num_processes,
-            update_interval = update_interval,
-            log_verbose = log_verbose,
+            subtensor=self,
+            wallet=wallet,
+            netuid=netuid,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
+            max_allowed_attempts=max_allowed_attempts,
+            output_in_place=output_in_place,
+            cuda=cuda,
+            dev_id=dev_id,
+            TPB=TPB,
+            num_processes=num_processes,
+            update_interval=update_interval,
+            log_verbose=log_verbose,
         )
 
-    def burned_register (
+    def burned_register(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         netuid: int,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
-        prompt: bool = False
+        prompt: bool = False,
     ) -> bool:
-        """ Registers the wallet to chain by recycling TAO."""
+        """Registers the wallet to chain by recycling TAO."""
         return burned_register_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            netuid = netuid,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+            subtensor=self,
+            wallet=wallet,
+            netuid=netuid,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
         )
-    
+
     def _do_pow_register(
         self,
         netuid: int,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         pow_result: POWSolution,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
-        """ Sends a (POW) register extrinsic to the chain.
-            Args:
-                netuid (int): the subnet to register on.
-                wallet (bittensor.Wallet): the wallet to register.
-                pow_result (POWSolution): the pow result to register.
-                wait_for_inclusion (bool): if true, waits for the extrinsic to be included in a block.
-                wait_for_finalization (bool): if true, waits for the extrinsic to be finalized.
-            Returns:
-                success (bool): True if the extrinsic was included in a block.
-                error (Optional[str]): None on success or not waiting for inclusion/finalization, otherwise the error message.
-        """ 
+        """Sends a (POW) register extrinsic to the chain.
+        Args:
+            netuid (int): the subnet to register on.
+            wallet (bittensor.Wallet): the wallet to register.
+            pow_result (POWSolution): the pow result to register.
+            wait_for_inclusion (bool): if true, waits for the extrinsic to be included in a block.
+            wait_for_finalization (bool): if true, waits for the extrinsic to be finalized.
+        Returns:
+            success (bool): True if the extrinsic was included in a block.
+            error (Optional[str]): None on success or not waiting for inclusion/finalization, otherwise the error message.
+        """
         with self.substrate as substrate:
             # create extrinsic call
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='register',
+                call_module="SubtensorModule",
+                call_function="register",
                 call_params={
-                    'netuid': netuid,
-                    'block_number': pow_result.block_number,
-                    'nonce': pow_result.nonce,
-                    'work': [int(byte_) for byte_ in pow_result.seal],
-                    'hotkey': wallet.hotkey.ss58_address,
-                    'coldkey': wallet.coldkeypub.ss58_address,
-                }
+                    "netuid": netuid,
+                    "block_number": pow_result.block_number,
+                    "nonce": pow_result.nonce,
+                    "work": [int(byte_) for byte_ in pow_result.seal],
+                    "hotkey": wallet.hotkey.ss58_address,
+                    "coldkey": wallet.coldkeypub.ss58_address,
+                },
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.hotkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.hotkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion=wait_for_inclusion, wait_for_finalization=wait_for_finalization )
 
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True, None
 
             # process if registration successful, try again if pow is still valid
             response.process_events()
             if not response.is_success:
                 return False, response.error_message
             # Successful registration
             else:
                 return True, None
-            
+
     def _do_burned_register(
         self,
         netuid: int,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         with self.substrate as substrate:
             # create extrinsic call
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='burned_register',
-                call_params={
-                    'netuid': netuid,
-                    'hotkey': wallet.hotkey.ss58_address
-                }
+                call_module="SubtensorModule",
+                call_function="burned_register",
+                call_params={"netuid": netuid, "hotkey": wallet.hotkey.ss58_address},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion=wait_for_inclusion, wait_for_finalization=wait_for_finalization )
 
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True
 
             # process if registration successful, try again if pow is still valid
             response.process_events()
             if not response.is_success:
                 return False, response.error_message
             # Successful registration
@@ -340,191 +379,225 @@
                 return True, None
 
     ##################
     #### Transfer ####
     ##################
     def transfer(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         dest: str,
         amount: Union[Balance, float],
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Transfers funds from this wallet to the destination public key address"""
+        """Transfers funds from this wallet to the destination public key address"""
         return transfer_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            dest = dest,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+            subtensor=self,
+            wallet=wallet,
+            dest=dest,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
         )
-    
+
     def get_transfer_fee(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         dest: str,
         value: Union[Balance, float, int],
     ) -> Balance:
         if isinstance(value, float):
             transfer_balance = bittensor.Balance.from_tao(value)
         elif isinstance(value, int):
             transfer_balance = bittensor.Balance.from_rao(value)
 
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='Balances',
-                call_function='transfer',
-                call_params={
-                    'dest': dest,
-                    'value': transfer_balance.rao
-                }
+                call_module="Balances",
+                call_function="transfer",
+                call_params={"dest": dest, "value": transfer_balance.rao},
             )
 
             try:
-                payment_info = substrate.get_payment_info( call = call, keypair = wallet.coldkeypub )
+                payment_info = substrate.get_payment_info(
+                    call=call, keypair=wallet.coldkeypub
+                )
             except Exception as e:
-                bittensor.__console__.print(":cross_mark: [red]Failed to get payment info[/red]:[bold white]\n  {}[/bold white]".format(e))
+                bittensor.__console__.print(
+                    ":cross_mark: [red]Failed to get payment info[/red]:[bold white]\n  {}[/bold white]".format(
+                        e
+                    )
+                )
                 payment_info = {
-                    'partialFee': 2e7, # assume  0.02 Tao
+                    "partialFee": 2e7,  # assume  0.02 Tao
                 }
 
-        fee = bittensor.Balance.from_rao( payment_info['partialFee'] )
+        fee = bittensor.Balance.from_rao(payment_info["partialFee"])
         return fee
-    
+
     def _do_transfer(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         dest: str,
         transfer_balance: Balance,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> Tuple[bool, Optional[str], Optional[str]]:
-        """ Sends a transfer extrinsic to the chain.
-            Args:
-                wallet (:obj:`bittensor.wallet`): Wallet object.
-                dest (:obj:`str`): Destination public key address.
-                transfer_balance (:obj:`bittensor.Balance`): Amount to transfer.
-                wait_for_inclusion (:obj:`bool`): If true, waits for inclusion.
-                wait_for_finalization (:obj:`bool`): If true, waits for finalization.
-            Returns:
-                success (:obj:`bool`): True if transfer was successful.
-                block_hash (:obj:`str`): Block hash of the transfer. 
-                    (On success and if wait_for_ finalization/inclusion is True)
-                error (:obj:`str`): Error message if transfer failed.
+        """Sends a transfer extrinsic to the chain.
+        Args:
+            wallet (:obj:`bittensor.wallet`): Wallet object.
+            dest (:obj:`str`): Destination public key address.
+            transfer_balance (:obj:`bittensor.Balance`): Amount to transfer.
+            wait_for_inclusion (:obj:`bool`): If true, waits for inclusion.
+            wait_for_finalization (:obj:`bool`): If true, waits for finalization.
+        Returns:
+            success (:obj:`bool`): True if transfer was successful.
+            block_hash (:obj:`str`): Block hash of the transfer.
+                (On success and if wait_for_ finalization/inclusion is True)
+            error (:obj:`str`): Error message if transfer failed.
         """
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='Balances',
-                call_function='transfer',
-                call_params={
-                    'dest': dest,
-                    'value': transfer_balance.rao
-                }
+                call_module="Balances",
+                call_function="transfer",
+                call_params={"dest": dest, "value": transfer_balance.rao},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
-                bittensor.__console__.print(":white_heavy_check_mark: [green]Sent[/green]")
+                bittensor.__console__.print(
+                    ":white_heavy_check_mark: [green]Sent[/green]"
+                )
                 return True, None, None
 
             # Otherwise continue with finalization.
             response.process_events()
             if response.is_success:
                 block_hash = response.block_hash
                 return True, block_hash, None
             else:
                 return False, None, response.error_message
 
     def get_existential_deposit(
         self,
         block: Optional[int] = None,
     ) -> Optional[Balance]:
-        """ Returns the existential deposit for the chain. """
+        """Returns the existential deposit for the chain."""
         result = self.query_constant(
-            module_name='Balances',
-            constant_name='ExistentialDeposit',
-            block = block,
+            module_name="Balances",
+            constant_name="ExistentialDeposit",
+            block=block,
         )
 
         if result is None:
             return None
 
         return Balance.from_rao(result.value)
 
     #################
     #### Serving ####
     #################
-    def serve (
+    def serve(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         ip: str,
         port: int,
         protocol: int,
         netuid: int,
         placeholder1: int = 0,
         placeholder2: int = 0,
         wait_for_inclusion: bool = False,
-        wait_for_finalization = True,
+        wait_for_finalization=True,
         prompt: bool = False,
     ) -> bool:
-        return serve_extrinsic( self, wallet, ip, port, protocol, netuid , placeholder1, placeholder2, wait_for_inclusion, wait_for_finalization)
+        return serve_extrinsic(
+            self,
+            wallet,
+            ip,
+            port,
+            protocol,
+            netuid,
+            placeholder1,
+            placeholder2,
+            wait_for_inclusion,
+            wait_for_finalization,
+        )
 
-    def serve_axon (
+    def serve_axon(
         self,
         netuid: int,
-        axon: 'bittensor.Axon',
+        axon: "bittensor.Axon",
         use_upnpc: bool = False,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
         prompt: bool = False,
     ) -> bool:
-        return serve_axon_extrinsic( self, netuid, axon, use_upnpc, wait_for_inclusion, wait_for_finalization)
-    
+        return serve_axon_extrinsic(
+            self, netuid, axon, use_upnpc, wait_for_inclusion, wait_for_finalization
+        )
+
     def _do_serve_axon(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         call_params: AxonServeCallParams,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='serve_axon',
-                call_params=call_params
+                call_module="SubtensorModule",
+                call_function="serve_axon",
+                call_params=call_params,
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.hotkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.hotkey)
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             if wait_for_inclusion or wait_for_finalization:
                 response.process_events()
                 if response.is_success:
                     return True, None
                 else:
                     return False, response.error_message
             else:
                 return True, None
 
-    def serve_prometheus (
+    def serve_prometheus(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         port: int,
         netuid: int,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> bool:
-        return prometheus_extrinsic( self, wallet = wallet, port = port, netuid = netuid, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization)
+        return prometheus_extrinsic(
+            self,
+            wallet=wallet,
+            port=port,
+            netuid=netuid,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+        )
 
     def _do_serve_prometheus(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         call_params: PrometheusServeCallParams,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         """
         Sends a serve prometheus extrinsic to the chain.
         Args:
@@ -534,163 +607,199 @@
             wait_for_finalization (:obj:`bool`): If true, waits for finalization.
         Returns:
             success (:obj:`bool`): True if serve prometheus was successful.
             error (:obj:`Optional[str]`): Error message if serve prometheus failed, None otherwise.
         """
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='serve_prometheus',
-                call_params = call_params
+                call_module="SubtensorModule",
+                call_function="serve_prometheus",
+                call_params=call_params,
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.hotkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.hotkey)
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             if wait_for_inclusion or wait_for_finalization:
                 response.process_events()
                 if response.is_success:
                     return True, None
                 else:
                     return False, response.error_message
             else:
                 return True, None
-    
+
     #################
     #### Staking ####
     #################
     def add_stake(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         hotkey_ss58: Optional[str] = None,
         amount: Union[Balance, float] = None,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Adds the specified amount of stake to passed hotkey uid. """
+        """Adds the specified amount of stake to passed hotkey uid."""
         return add_stake_extrinsic(
-            subtensor = self,
-            wallet = wallet,
-            hotkey_ss58 = hotkey_ss58,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
-            prompt = prompt
+            subtensor=self,
+            wallet=wallet,
+            hotkey_ss58=hotkey_ss58,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
+            prompt=prompt,
         )
 
-    def add_stake_multiple (
+    def add_stake_multiple(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         hotkey_ss58s: List[str],
         amounts: List[Union[Balance, float]] = None,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Adds stake to each hotkey_ss58 in the list, using each amount, from a common coldkey."""
-        return add_stake_multiple_extrinsic( self, wallet, hotkey_ss58s, amounts, wait_for_inclusion, wait_for_finalization, prompt)
-    
+        """Adds stake to each hotkey_ss58 in the list, using each amount, from a common coldkey."""
+        return add_stake_multiple_extrinsic(
+            self,
+            wallet,
+            hotkey_ss58s,
+            amounts,
+            wait_for_inclusion,
+            wait_for_finalization,
+            prompt,
+        )
+
     def _do_stake(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         hotkey_ss58: str,
         amount: Balance,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
-        """ Sends a stake extrinsic to the chain.
-            Args:
-                wallet (:obj:`bittensor.Wallet`): Wallet object that can sign the extrinsic.
-                hotkey_ss58 (:obj:`str`): Hotkey ss58 address to stake to.
-                amount (:obj:`bittensor.Balance`): Amount to stake.
-                wait_for_inclusion (:obj:`bool`): If true, waits for inclusion before returning.
-                wait_for_finalization (:obj:`bool`): If true, waits for finalization before returning.
-            Returns:
-                success (:obj:`bool`): True if the extrinsic was successful.
-            Raises:
-                StakeError: If the extrinsic failed.
+        """Sends a stake extrinsic to the chain.
+        Args:
+            wallet (:obj:`bittensor.Wallet`): Wallet object that can sign the extrinsic.
+            hotkey_ss58 (:obj:`str`): Hotkey ss58 address to stake to.
+            amount (:obj:`bittensor.Balance`): Amount to stake.
+            wait_for_inclusion (:obj:`bool`): If true, waits for inclusion before returning.
+            wait_for_finalization (:obj:`bool`): If true, waits for finalization before returning.
+        Returns:
+            success (:obj:`bool`): True if the extrinsic was successful.
+        Raises:
+            StakeError: If the extrinsic failed.
         """
         with self.substrate as substrate:
             call = substrate.compose_call(
-            call_module='SubtensorModule',
-            call_function='add_stake',
-            call_params={
-                'hotkey': hotkey_ss58,
-                'amount_staked': amount.rao
-                }
+                call_module="SubtensorModule",
+                call_function="add_stake",
+                call_params={"hotkey": hotkey_ss58, "amount_staked": amount.rao},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True
 
             response.process_events()
             if response.is_success:
                 return True
             else:
                 raise StakeError(response.error_message)
 
     ###################
     #### Unstaking ####
     ###################
-    def unstake_multiple (
+    def unstake_multiple(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         hotkey_ss58s: List[str],
         amounts: List[Union[Balance, float]] = None,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Removes stake from each hotkey_ss58 in the list, using each amount, to a common coldkey. """
-        return unstake_multiple_extrinsic( self, wallet, hotkey_ss58s, amounts, wait_for_inclusion, wait_for_finalization, prompt)
+        """Removes stake from each hotkey_ss58 in the list, using each amount, to a common coldkey."""
+        return unstake_multiple_extrinsic(
+            self,
+            wallet,
+            hotkey_ss58s,
+            amounts,
+            wait_for_inclusion,
+            wait_for_finalization,
+            prompt,
+        )
 
-    def unstake (
+    def unstake(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         hotkey_ss58: Optional[str] = None,
         amount: Union[Balance, float] = None,
-        wait_for_inclusion:bool = True,
-        wait_for_finalization:bool = False,
+        wait_for_inclusion: bool = True,
+        wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        """ Removes stake into the wallet coldkey from the specified hotkey uid."""
-        return unstake_extrinsic( self, wallet, hotkey_ss58, amount, wait_for_inclusion, wait_for_finalization, prompt )
-    
+        """Removes stake into the wallet coldkey from the specified hotkey uid."""
+        return unstake_extrinsic(
+            self,
+            wallet,
+            hotkey_ss58,
+            amount,
+            wait_for_inclusion,
+            wait_for_finalization,
+            prompt,
+        )
+
     def _do_unstake(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         hotkey_ss58: str,
         amount: Balance,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
-        """ Sends an unstake extrinsic to the chain.
-            Args:
-                wallet (:obj:`bittensor.Wallet`): Wallet object that can sign the extrinsic.
-                hotkey_ss58 (:obj:`str`): Hotkey ss58 address to unstake from.
-                amount (:obj:`bittensor.Balance`): Amount to unstake.
-                wait_for_inclusion (:obj:`bool`): If true, waits for inclusion before returning.
-                wait_for_finalization (:obj:`bool`): If true, waits for finalization before returning.
-            Returns:
-                success (:obj:`bool`): True if the extrinsic was successful.
-            Raises:
-                StakeError: If the extrinsic failed.
+        """Sends an unstake extrinsic to the chain.
+        Args:
+            wallet (:obj:`bittensor.Wallet`): Wallet object that can sign the extrinsic.
+            hotkey_ss58 (:obj:`str`): Hotkey ss58 address to unstake from.
+            amount (:obj:`bittensor.Balance`): Amount to unstake.
+            wait_for_inclusion (:obj:`bool`): If true, waits for inclusion before returning.
+            wait_for_finalization (:obj:`bool`): If true, waits for finalization before returning.
+        Returns:
+            success (:obj:`bool`): True if the extrinsic was successful.
+        Raises:
+            StakeError: If the extrinsic failed.
         """
         with self.substrate as substrate:
             call = substrate.compose_call(
-            call_module='SubtensorModule',
-            call_function='remove_stake',
-            call_params={
-                'hotkey': hotkey_ss58,
-                'amount_unstaked': amount.rao
-                }
+                call_module="SubtensorModule",
+                call_function="remove_stake",
+                call_params={"hotkey": hotkey_ss58, "amount_unstaked": amount.rao},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True
 
             response.process_events()
             if response.is_success:
                 return True
@@ -699,907 +808,1190 @@
 
     ################
     #### Senate ####
     ################
 
     def register_senate(
         self,
-        wallet: 'bittensor.wallet',
-        wait_for_inclusion:bool = True,
-        wait_for_finalization:bool = False,
+        wallet: "bittensor.wallet",
+        wait_for_inclusion: bool = True,
+        wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        return register_senate_extrinsic( self, wallet, wait_for_inclusion, wait_for_finalization, prompt )
-    
+        return register_senate_extrinsic(
+            self, wallet, wait_for_inclusion, wait_for_finalization, prompt
+        )
+
     def leave_senate(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        return leave_senate_extrinsic( self, wallet, wait_for_inclusion, wait_for_finalization, prompt )
-    
+        return leave_senate_extrinsic(
+            self, wallet, wait_for_inclusion, wait_for_finalization, prompt
+        )
+
     def vote_senate(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         proposal_hash: str,
         proposal_idx: int,
         vote: bool,
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
         prompt: bool = False,
     ) -> bool:
-        return vote_senate_extrinsic( self, wallet, proposal_hash, proposal_idx, vote, wait_for_inclusion, wait_for_finalization, prompt )
-    
+        return vote_senate_extrinsic(
+            self,
+            wallet,
+            proposal_hash,
+            proposal_idx,
+            vote,
+            wait_for_inclusion,
+            wait_for_finalization,
+            prompt,
+        )
+
     def is_senate_member(
         self,
         hotkey_ss58: str,
         block: Optional[int] = None,
     ) -> bool:
-        senate_members = self.query_module(module="SenateMembers", name="Members", block=block ).serialize()
-        return senate_members.count( hotkey_ss58 ) > 0
-    
+        senate_members = self.query_module(
+            module="SenateMembers", name="Members", block=block
+        ).serialize()
+        return senate_members.count(hotkey_ss58) > 0
+
     def get_vote_data(
-        self,
-        proposal_hash: str,
-        block: Optional[int] = None,
+        self, proposal_hash: str, block: Optional[int] = None
     ) -> Optional[ProposalVoteData]:
-        vote_data = self.query_module(module="Triumvirate", name="Voting", block=block, params=[proposal_hash])
+        vote_data = self.query_module(
+            module="Triumvirate", name="Voting", block=block, params=[proposal_hash]
+        )
         return vote_data.serialize() if vote_data != None else None
-    
+
     get_proposal_vote_data = get_vote_data
-    
+
     def get_senate_members(
         self,
         block: Optional[int] = None,
     ) -> Optional[List[str]]:
-        senate_members = self.query_module("SenateMembers", "Members", block=block )
-        
+        senate_members = self.query_module("SenateMembers", "Members", block=block)
+
         return senate_members.serialize() if senate_members != None else None
-    
+
     def get_proposal_call_data(
         self,
         proposal_hash: str,
         block: Optional[int] = None,
-    ) -> Optional['bittensor.ProposalCallData']:
-        proposal_data = self.query_module(module="Triumvirate", name="ProposalOf", block=block, params=[proposal_hash])
+    ) -> Optional["bittensor.ProposalCallData"]:
+        proposal_data = self.query_module(
+            module="Triumvirate", name="ProposalOf", block=block, params=[proposal_hash]
+        )
 
         return proposal_data.serialize() if proposal_data != None else None
-    
+
     def get_proposal_hashes(
         self,
         block: Optional[int] = None,
     ) -> Optional[List[str]]:
-        proposal_hashes = self.query_module(module="Triumvirate", name="Proposals", block=block)
+        proposal_hashes = self.query_module(
+            module="Triumvirate", name="Proposals", block=block
+        )
 
         return proposal_hashes.serialize() if proposal_hashes != None else None
 
     def get_proposals(
         self,
         block: Optional[int] = None,
-    ) -> Optional[Dict[str, Tuple['bittensor.ProposalCallData', 'bittensor.ProposalVoteData']]]:
+    ) -> Optional[
+        Dict[str, Tuple["bittensor.ProposalCallData", "bittensor.ProposalVoteData"]]
+    ]:
         proposals = {}
-        proposal_hashes: List = self.get_proposal_hashes( block=block )
-        
+        proposal_hashes: List = self.get_proposal_hashes(block=block)
+
         for proposal_hash in proposal_hashes:
             proposals[proposal_hash] = (
-                self.get_proposal_call_data( proposal_hash, block=block ),
-                self.get_proposal_vote_data( proposal_hash, block=block )
+                self.get_proposal_call_data(proposal_hash, block=block),
+                self.get_proposal_vote_data(proposal_hash, block=block),
             )
 
         return proposals
 
     ########################
     #### Standard Calls ####
     ########################
 
     """ Queries subtensor named storage with params and block. """
-    def query_subtensor( self, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> Optional[object]:
+
+    def query_subtensor(
+        self,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> Optional[object]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.query(
-                    module='SubtensorModule',
-                    storage_function = name,
-                    params = params,
-                    block_hash = None if block == None else substrate.get_block_hash(block)
+                    module="SubtensorModule",
+                    storage_function=name,
+                    params=params,
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         return make_substrate_call_with_retry()
 
     """ Queries subtensor map storage with params and block. """
-    def query_map_subtensor( self, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> QueryMapResult:
+
+    def query_map_subtensor(
+        self,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> QueryMapResult:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.query_map(
-                    module='SubtensorModule',
-                    storage_function = name,
-                    params = params,
-                    block_hash = None if block == None else substrate.get_block_hash(block)
+                    module="SubtensorModule",
+                    storage_function=name,
+                    params=params,
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         return make_substrate_call_with_retry()
 
     """ Gets a constant from subtensor with module_name, constant_name, and block. """
-    def query_constant( self, module_name: str, constant_name: str, block: Optional[int] = None ) -> Optional[object]:
+
+    def query_constant(
+        self, module_name: str, constant_name: str, block: Optional[int] = None
+    ) -> Optional[object]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.get_constant(
                     module_name=module_name,
                     constant_name=constant_name,
-                    block_hash = None if block == None else substrate.get_block_hash(block)
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         return make_substrate_call_with_retry()
-    
+
     """ Queries any module storage with params and block. """
-    def query_module( self, module: str, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> Optional[object]:
+
+    def query_module(
+        self,
+        module: str,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> Optional[object]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.query(
                     module=module,
-                    storage_function = name,
-                    params = params,
-                    block_hash = None if block == None else substrate.get_block_hash(block)
+                    storage_function=name,
+                    params=params,
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         return make_substrate_call_with_retry()
-    
+
     """ Queries any module map storage with params and block. """
-    def query_map( self, module: str, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> Optional[object]:
+
+    def query_map(
+        self,
+        module: str,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> Optional[object]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.query_map(
                     module=module,
-                    storage_function = name,
-                    params = params,
-                    block_hash = None if block == None else substrate.get_block_hash(block)
+                    storage_function=name,
+                    params=params,
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         return make_substrate_call_with_retry()
 
     #####################################
     #### Hyper parameter calls. ####
     #####################################
 
     """ Returns network Rho hyper parameter """
-    def rho (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor( "Rho", block, [netuid] ).value
+
+    def rho(self, netuid: int, block: Optional[int] = None) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("Rho", block, [netuid]).value
 
     """ Returns network Kappa hyper parameter """
-    def kappa (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return U16_NORMALIZED_FLOAT( self.query_subtensor( "Kappa", block, [netuid] ).value )
+
+    def kappa(self, netuid: int, block: Optional[int] = None) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return U16_NORMALIZED_FLOAT(
+            self.query_subtensor("Kappa", block, [netuid]).value
+        )
 
     """ Returns network Difficulty hyper parameter """
-    def difficulty (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor( "Difficulty", block, [netuid] ).value
+
+    def difficulty(self, netuid: int, block: Optional[int] = None) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("Difficulty", block, [netuid]).value
 
     """ Returns network Burn hyper parameter """
-    def burn (self, netuid: int, block: Optional[int] = None ) -> Optional[bittensor.Balance]:
-        if not self.subnet_exists( netuid, block ): return None
-        return bittensor.Balance.from_rao( self.query_subtensor( "Burn", block, [netuid] ).value )
+
+    def burn(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[bittensor.Balance]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("Burn", block, [netuid]).value
+        )
 
     """ Returns network ImmunityPeriod hyper parameter """
-    def immunity_period (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ImmunityPeriod", block, [netuid] ).value
+
+    def immunity_period(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ImmunityPeriod", block, [netuid]).value
 
     """ Returns network ValidatorBatchSize hyper parameter """
-    def validator_batch_size (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ValidatorBatchSize", block, [netuid] ).value
+
+    def validator_batch_size(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ValidatorBatchSize", block, [netuid]).value
 
     """ Returns network ValidatorPruneLen hyper parameter """
-    def validator_prune_len (self, netuid: int, block: Optional[int] = None ) -> int:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ValidatorPruneLen", block, [netuid] ).value
+
+    def validator_prune_len(self, netuid: int, block: Optional[int] = None) -> int:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ValidatorPruneLen", block, [netuid]).value
 
     """ Returns network ValidatorLogitsDivergence hyper parameter """
-    def validator_logits_divergence (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return U16_NORMALIZED_FLOAT(self.query_subtensor("ValidatorLogitsDivergence", block, [netuid]).value)
+
+    def validator_logits_divergence(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return U16_NORMALIZED_FLOAT(
+            self.query_subtensor("ValidatorLogitsDivergence", block, [netuid]).value
+        )
 
     """ Returns network ValidatorSequenceLength hyper parameter """
-    def validator_sequence_length (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ValidatorSequenceLength", block, [netuid] ).value
+
+    def validator_sequence_length(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ValidatorSequenceLength", block, [netuid]).value
 
     """ Returns network ValidatorEpochsPerReset hyper parameter """
-    def validator_epochs_per_reset (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ValidatorEpochsPerReset", block, [netuid] ).value
+
+    def validator_epochs_per_reset(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ValidatorEpochsPerReset", block, [netuid]).value
 
     """ Returns network ValidatorEpochLen hyper parameter """
-    def validator_epoch_length (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("ValidatorEpochLen", block, [netuid] ).value
+
+    def validator_epoch_length(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ValidatorEpochLen", block, [netuid]).value
 
     """ Returns network ValidatorEpochLen hyper parameter """
-    def validator_exclude_quantile (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return U16_NORMALIZED_FLOAT( self.query_subtensor("ValidatorExcludeQuantile", block, [netuid] ).value )
+
+    def validator_exclude_quantile(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return U16_NORMALIZED_FLOAT(
+            self.query_subtensor("ValidatorExcludeQuantile", block, [netuid]).value
+        )
 
     """ Returns network MaxAllowedValidators hyper parameter """
-    def max_allowed_validators(self, netuid: int, block: Optional[int] = None) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor( 'MaxAllowedValidators', block, [netuid] ).value
+
+    def max_allowed_validators(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("MaxAllowedValidators", block, [netuid]).value
 
     """ Returns network MinAllowedWeights hyper parameter """
-    def min_allowed_weights (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor("MinAllowedWeights", block, [netuid] ).value
+
+    def min_allowed_weights(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("MinAllowedWeights", block, [netuid]).value
 
     """ Returns network MaxWeightsLimit hyper parameter """
-    def max_weight_limit (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return U16_NORMALIZED_FLOAT( self.query_subtensor('MaxWeightsLimit', block, [netuid] ).value )
+
+    def max_weight_limit(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return U16_NORMALIZED_FLOAT(
+            self.query_subtensor("MaxWeightsLimit", block, [netuid]).value
+        )
 
     """ Returns network ScalingLawPower hyper parameter """
-    def scaling_law_power (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('ScalingLawPower', block, [netuid] ).value / 100.
+
+    def scaling_law_power(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("ScalingLawPower", block, [netuid]).value / 100.0
 
     """ Returns network SynergyScalingLawPower hyper parameter """
-    def synergy_scaling_law_power (self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('SynergyScalingLawPower', block, [netuid] ).value / 100.
+
+    def synergy_scaling_law_power(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return (
+            self.query_subtensor("SynergyScalingLawPower", block, [netuid]).value
+            / 100.0
+        )
 
     """ Returns network SubnetworkN hyper parameter """
-    def subnetwork_n (self, netuid: int, block: Optional[int] = None ) -> int:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('SubnetworkN', block, [netuid] ).value
+
+    def subnetwork_n(self, netuid: int, block: Optional[int] = None) -> int:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("SubnetworkN", block, [netuid]).value
 
     """ Returns network MaxAllowedUids hyper parameter """
-    def max_n (self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('MaxAllowedUids', block, [netuid] ).value
+
+    def max_n(self, netuid: int, block: Optional[int] = None) -> Optional[int]:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("MaxAllowedUids", block, [netuid]).value
 
     """ Returns network BlocksSinceLastStep hyper parameter """
-    def blocks_since_epoch (self, netuid: int, block: Optional[int] = None) -> int:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('BlocksSinceLastStep', block, [netuid] ).value
+
+    def blocks_since_epoch(self, netuid: int, block: Optional[int] = None) -> int:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("BlocksSinceLastStep", block, [netuid]).value
 
     """ Returns network Tempo hyper parameter """
-    def tempo (self, netuid: int, block: Optional[int] = None) -> int:
-        if not self.subnet_exists( netuid, block ): return None
-        return self.query_subtensor('Tempo', block, [netuid] ).value
+
+    def tempo(self, netuid: int, block: Optional[int] = None) -> int:
+        if not self.subnet_exists(netuid, block):
+            return None
+        return self.query_subtensor("Tempo", block, [netuid]).value
 
     ##########################
     #### Account functions ###
     ##########################
 
     """ Returns the total stake held on a hotkey including delegative """
-    def get_total_stake_for_hotkey( self, ss58_address: str, block: Optional[int] = None ) -> Optional['bittensor.Balance']:
-        return bittensor.Balance.from_rao( self.query_subtensor( 'TotalHotkeyStake', block, [ss58_address] ).value )
+
+    def get_total_stake_for_hotkey(
+        self, ss58_address: str, block: Optional[int] = None
+    ) -> Optional["bittensor.Balance"]:
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("TotalHotkeyStake", block, [ss58_address]).value
+        )
 
     """ Returns the total stake held on a coldkey across all hotkeys including delegates"""
-    def get_total_stake_for_coldkey( self, ss58_address: str, block: Optional[int] = None ) -> Optional['bittensor.Balance']:
-        return bittensor.Balance.from_rao( self.query_subtensor( 'TotalColdkeyStake', block, [ss58_address] ).value )
+
+    def get_total_stake_for_coldkey(
+        self, ss58_address: str, block: Optional[int] = None
+    ) -> Optional["bittensor.Balance"]:
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("TotalColdkeyStake", block, [ss58_address]).value
+        )
 
     """ Returns the stake under a coldkey - hotkey pairing """
-    def get_stake_for_coldkey_and_hotkey( self, hotkey_ss58: str, coldkey_ss58: str, block: Optional[int] = None ) -> Optional['bittensor.Balance']:
-        return bittensor.Balance.from_rao( self.query_subtensor( 'Stake', block, [hotkey_ss58, coldkey_ss58] ).value )
+
+    def get_stake_for_coldkey_and_hotkey(
+        self, hotkey_ss58: str, coldkey_ss58: str, block: Optional[int] = None
+    ) -> Optional["bittensor.Balance"]:
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("Stake", block, [hotkey_ss58, coldkey_ss58]).value
+        )
 
     """ Returns a list of stake tuples (coldkey, balance) for each delegating coldkey including the owner"""
-    def get_stake( self, hotkey_ss58: str, block: Optional[int] = None ) -> List[Tuple[str,'bittensor.Balance']]:
-        return [ (r[0].value, bittensor.Balance.from_rao( r[1].value ))  for r in self.query_map_subtensor( 'Stake', block, [hotkey_ss58] ) ]
+
+    def get_stake(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> List[Tuple[str, "bittensor.Balance"]]:
+        return [
+            (r[0].value, bittensor.Balance.from_rao(r[1].value))
+            for r in self.query_map_subtensor("Stake", block, [hotkey_ss58])
+        ]
 
     """ Returns true if the hotkey is known by the chain and there are accounts. """
-    def does_hotkey_exist( self, hotkey_ss58: str, block: Optional[int] = None ) -> bool:
-        return (self.query_subtensor( 'Owner', block, [hotkey_ss58 ] ).value != "5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM")
+
+    def does_hotkey_exist(self, hotkey_ss58: str, block: Optional[int] = None) -> bool:
+        return (
+            self.query_subtensor("Owner", block, [hotkey_ss58]).value
+            != "5C4hrfjw9DjXZTzV3MwzrrAr9P1MJhSrvWGWqi1eSuyUpnhM"
+        )
 
     """ Returns the coldkey owner of the passed hotkey """
-    def get_hotkey_owner( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional[str]:
-        if self.does_hotkey_exist( hotkey_ss58, block ):
-            return self.query_subtensor( 'Owner', block, [hotkey_ss58 ] ).value
+
+    def get_hotkey_owner(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional[str]:
+        if self.does_hotkey_exist(hotkey_ss58, block):
+            return self.query_subtensor("Owner", block, [hotkey_ss58]).value
         else:
             return None
 
     """ Returns the axon information for this hotkey account """
-    def get_axon_info( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional[axon_info]:
-        result = self.query_subtensor( 'Axons', block, [hotkey_ss58 ] )
+
+    def get_axon_info(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional[axon_info]:
+        result = self.query_subtensor("Axons", block, [hotkey_ss58])
         if result != None:
             return axon_info(
-                ip = bittensor.utils.networking.ip_from_int( result.value.ip ),
-                ip_type = result.value.ip_type,
-                port = result.value.port,
-                protocol = result.value.protocol,
-                version = result.value.version,
-                placeholder1 = result.value.placeholder1,
-                placeholder2 = result.value.placeholder2,
+                ip=bittensor.utils.networking.ip_from_int(result.value.ip),
+                ip_type=result.value.ip_type,
+                port=result.value.port,
+                protocol=result.value.protocol,
+                version=result.value.version,
+                placeholder1=result.value.placeholder1,
+                placeholder2=result.value.placeholder2,
             )
         else:
             return None
 
     """ Returns the prometheus information for this hotkey account """
-    def get_prometheus_info( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional[axon_info]:
-        result = self.query_subtensor( 'Prometheus', block, [hotkey_ss58 ] )
+
+    def get_prometheus_info(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional[axon_info]:
+        result = self.query_subtensor("Prometheus", block, [hotkey_ss58])
         if result != None:
-            return PrometheusInfo (
-                ip = bittensor.utils.networking.ip_from_int( result.value.ip ),
-                ip_type = result.value.ip_type,
-                port = result.value.port,
-                version = result.value.version,
-                block = result.value.block,
+            return PrometheusInfo(
+                ip=bittensor.utils.networking.ip_from_int(result.value.ip),
+                ip_type=result.value.ip_type,
+                port=result.value.port,
+                version=result.value.version,
+                block=result.value.block,
             )
         else:
             return None
 
     ###########################
     #### Global Parameters ####
     ###########################
 
     @property
-    def block (self) -> int:
-        r""" Returns current chain block.
+    def block(self) -> int:
+        r"""Returns current chain block.
         Returns:
             block (int):
                 Current chain block.
         """
         return self.get_current_block()
 
-    def total_issuance (self, block: Optional[int] = None ) -> 'bittensor.Balance':
-        return bittensor.Balance.from_rao( self.query_subtensor( 'TotalIssuance', block ).value )
+    def total_issuance(self, block: Optional[int] = None) -> "bittensor.Balance":
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("TotalIssuance", block).value
+        )
+
+    def total_stake(self, block: Optional[int] = None) -> "bittensor.Balance":
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("TotalStake", block).value
+        )
 
-    def total_stake (self,block: Optional[int] = None ) -> 'bittensor.Balance':
-        return bittensor.Balance.from_rao( self.query_subtensor( "TotalStake", block ).value )
+    def serving_rate_limit(self, block: Optional[int] = None) -> Optional[int]:
+        return self.query_subtensor("ServingRateLimit", block).value
 
-    def serving_rate_limit (self, block: Optional[int] = None ) -> Optional[int]:
-        return self.query_subtensor( "ServingRateLimit", block ).value
-    
-    def tx_rate_limit (self, block: Optional[int] = None ) -> Optional[int]:
-        return self.query_subtensor( "TxRateLimit", block ).value
+    def tx_rate_limit(self, block: Optional[int] = None) -> Optional[int]:
+        return self.query_subtensor("TxRateLimit", block).value
 
     #####################################
     #### Network Parameters ####
     #####################################
 
-    def subnet_exists( self, netuid: int, block: Optional[int] = None ) -> bool:
-        return self.query_subtensor( 'NetworksAdded', block, [netuid] ).value
+    def subnet_exists(self, netuid: int, block: Optional[int] = None) -> bool:
+        return self.query_subtensor("NetworksAdded", block, [netuid]).value
 
-    def get_all_subnet_netuids( self, block: Optional[int] = None ) -> List[int]:
+    def get_all_subnet_netuids(self, block: Optional[int] = None) -> List[int]:
         subnet_netuids = []
-        result = self.query_map_subtensor( 'NetworksAdded', block )
+        result = self.query_map_subtensor("NetworksAdded", block)
         if result.records:
             for netuid, exists in result:
                 if exists:
-                    subnet_netuids.append( netuid.value )
+                    subnet_netuids.append(netuid.value)
 
         return subnet_netuids
 
-    def get_total_subnets( self, block: Optional[int] = None ) -> int:
-        return self.query_subtensor( 'TotalNetworks', block ).value
+    def get_total_subnets(self, block: Optional[int] = None) -> int:
+        return self.query_subtensor("TotalNetworks", block).value
 
-    def get_subnet_modality( self, netuid: int, block: Optional[int] = None ) -> Optional[int]:
-        return self.query_subtensor( 'NetworkModality', block, [netuid] ).value
-
-    def get_subnet_connection_requirement( self, netuid_0: int, netuid_1: int, block: Optional[int] = None) -> Optional[int]:
-        return self.query_subtensor( 'NetworkConnect', block, [netuid_0, netuid_1] ).value
-
-    def get_emission_value_by_subnet( self, netuid: int, block: Optional[int] = None ) -> Optional[float]:
-        return bittensor.Balance.from_rao( self.query_subtensor( 'EmissionValues', block, [ netuid ] ).value )
+    def get_subnet_modality(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        return self.query_subtensor("NetworkModality", block, [netuid]).value
+
+    def get_subnet_connection_requirement(
+        self, netuid_0: int, netuid_1: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        return self.query_subtensor("NetworkConnect", block, [netuid_0, netuid_1]).value
+
+    def get_emission_value_by_subnet(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[float]:
+        return bittensor.Balance.from_rao(
+            self.query_subtensor("EmissionValues", block, [netuid]).value
+        )
 
-    def get_subnet_connection_requirements( self, netuid: int, block: Optional[int] = None) -> Dict[str, int]:
-        result = self.query_map_subtensor( 'NetworkConnect', block, [netuid] )
+    def get_subnet_connection_requirements(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Dict[str, int]:
+        result = self.query_map_subtensor("NetworkConnect", block, [netuid])
         if result.records:
             requirements = {}
             for tuple in result.records:
                 requirements[str(tuple[0].value)] = tuple[1].value
         else:
             return {}
 
-    def get_subnets( self, block: Optional[int] = None ) -> List[int]:
+    def get_subnets(self, block: Optional[int] = None) -> List[int]:
         subnets = []
-        result = self.query_map_subtensor( 'NetworksAdded', block )
+        result = self.query_map_subtensor("NetworksAdded", block)
         if result.records:
             for network in result.records:
-                subnets.append( network[0].value )
+                subnets.append(network[0].value)
             return subnets
         else:
             return []
 
-    def get_all_subnets_info( self, block: Optional[int] = None ) -> List[SubnetInfo]:
+    def get_all_subnets_info(self, block: Optional[int] = None) -> List[SubnetInfo]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = []
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="subnetInfo_getSubnetsInfo", # custom rpc method
-                    params=params
+                    method="subnetInfo_getSubnetsInfo",  # custom rpc method
+                    params=params,
                 )
 
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return []
 
-        return SubnetInfo.list_from_vec_u8( result )
+        return SubnetInfo.list_from_vec_u8(result)
 
-    def get_subnet_info( self, netuid: int, block: Optional[int] = None ) -> Optional[SubnetInfo]:
+    def get_subnet_info(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[SubnetInfo]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [netuid]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="subnetInfo_getSubnetInfo", # custom rpc method
-                    params=params
+                    method="subnetInfo_getSubnetInfo",  # custom rpc method
+                    params=params,
                 )
 
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return None
 
-        return SubnetInfo.from_vec_u8( result )
+        return SubnetInfo.from_vec_u8(result)
 
     ####################
     #### Nomination ####
     ####################
-    def is_hotkey_delegate( self, hotkey_ss58: str, block: Optional[int] = None ) -> bool:
-        return hotkey_ss58 in [ info.hotkey_ss58 for info in self.get_delegates( block = block ) ]
+    def is_hotkey_delegate(self, hotkey_ss58: str, block: Optional[int] = None) -> bool:
+        return hotkey_ss58 in [
+            info.hotkey_ss58 for info in self.get_delegates(block=block)
+        ]
 
-    def get_delegate_take( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional[float]:
-        return U16_NORMALIZED_FLOAT( self.query_subtensor( 'Delegates', block, [ hotkey_ss58 ] ).value )
+    def get_delegate_take(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional[float]:
+        return U16_NORMALIZED_FLOAT(
+            self.query_subtensor("Delegates", block, [hotkey_ss58]).value
+        )
 
-    def get_nominators_for_hotkey( self, hotkey_ss58: str, block: Optional[int] = None ) -> List[Tuple[str, Balance]]:
-        result = self.query_map_subtensor( 'Stake', block, [ hotkey_ss58 ] )
+    def get_nominators_for_hotkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> List[Tuple[str, Balance]]:
+        result = self.query_map_subtensor("Stake", block, [hotkey_ss58])
         if result.records:
             return [(record[0].value, record[1].value) for record in result.records]
         else:
             return 0
 
-    def get_delegate_by_hotkey( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional[DelegateInfo]:
+    def get_delegate_by_hotkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional[DelegateInfo]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry(encoded_hotkey: List[int]):
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [encoded_hotkey]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="delegateInfo_getDelegate", # custom rpc method
-                    params=params
+                    method="delegateInfo_getDelegate",  # custom rpc method
+                    params=params,
                 )
 
-        hotkey_bytes: bytes = bittensor.utils.ss58_address_to_bytes( hotkey_ss58 )
-        encoded_hotkey: List[int] = [ int( byte ) for byte in hotkey_bytes ]
+        hotkey_bytes: bytes = bittensor.utils.ss58_address_to_bytes(hotkey_ss58)
+        encoded_hotkey: List[int] = [int(byte) for byte in hotkey_bytes]
         json_body = make_substrate_call_with_retry(encoded_hotkey)
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return None
 
-        return DelegateInfo.from_vec_u8( result )
+        return DelegateInfo.from_vec_u8(result)
 
-    def get_delegates( self, block: Optional[int] = None ) -> List[DelegateInfo]:
+    def get_delegates(self, block: Optional[int] = None) -> List[DelegateInfo]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = []
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="delegateInfo_getDelegates", # custom rpc method
-                    params=params
+                    method="delegateInfo_getDelegates",  # custom rpc method
+                    params=params,
                 )
+
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return []
 
-        return DelegateInfo.list_from_vec_u8( result )
+        return DelegateInfo.list_from_vec_u8(result)
+
+    def get_delegated(
+        self, coldkey_ss58: str, block: Optional[int] = None
+    ) -> List[Tuple[DelegateInfo, Balance]]:
+        """Returns the list of delegates that a given coldkey is staked to."""
 
-    def get_delegated( self, coldkey_ss58: str, block: Optional[int] = None ) -> List[Tuple[DelegateInfo, Balance]]:
-        """ Returns the list of delegates that a given coldkey is staked to.
-        """
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry(encoded_coldkey: List[int]):
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [encoded_coldkey]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="delegateInfo_getDelegated", # custom rpc method
-                    params=params
+                    method="delegateInfo_getDelegated",  # custom rpc method
+                    params=params,
                 )
 
-        coldkey_bytes: bytes = bittensor.utils.ss58_address_to_bytes( coldkey_ss58 )
-        encoded_coldkey: List[int] = [ int( byte ) for byte in coldkey_bytes ]
+        coldkey_bytes: bytes = bittensor.utils.ss58_address_to_bytes(coldkey_ss58)
+        encoded_coldkey: List[int] = [int(byte) for byte in coldkey_bytes]
         json_body = make_substrate_call_with_retry(encoded_coldkey)
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return []
 
-        return DelegateInfo.delegated_list_from_vec_u8( result )
-
+        return DelegateInfo.delegated_list_from_vec_u8(result)
 
     ########################################
     #### Neuron information per subnet ####
     ########################################
 
-    def is_hotkey_registered_any( self, hotkey_ss58: str, block: Optional[int] = None) -> bool:
-        return len( self.get_netuids_for_hotkey( hotkey_ss58, block) ) > 0
+    def is_hotkey_registered_any(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> bool:
+        return len(self.get_netuids_for_hotkey(hotkey_ss58, block)) > 0
 
-    def is_hotkey_registered_on_subnet( self, hotkey_ss58: str, netuid: int, block: Optional[int] = None) -> bool:
-        return self.get_uid_for_hotkey_on_subnet( hotkey_ss58, netuid, block ) != None
+    def is_hotkey_registered_on_subnet(
+        self, hotkey_ss58: str, netuid: int, block: Optional[int] = None
+    ) -> bool:
+        return self.get_uid_for_hotkey_on_subnet(hotkey_ss58, netuid, block) != None
 
-    def is_hotkey_registered( self, hotkey_ss58: str, netuid: Optional[int] = None, block: Optional[int] = None) -> bool:
+    def is_hotkey_registered(
+        self,
+        hotkey_ss58: str,
+        netuid: Optional[int] = None,
+        block: Optional[int] = None,
+    ) -> bool:
         if netuid == None:
-            return self.is_hotkey_registered_any( hotkey_ss58, block )
+            return self.is_hotkey_registered_any(hotkey_ss58, block)
         else:
-            return self.is_hotkey_registered_on_subnet( hotkey_ss58, netuid, block )
-
-    def get_uid_for_hotkey_on_subnet( self, hotkey_ss58: str, netuid: int, block: Optional[int] = None) -> Optional[int]:
-        return self.query_subtensor( 'Uids', block, [ netuid, hotkey_ss58 ] ).value
+            return self.is_hotkey_registered_on_subnet(hotkey_ss58, netuid, block)
 
-    def get_all_uids_for_hotkey( self, hotkey_ss58: str, block: Optional[int] = None) -> List[int]:
-        return [ self.get_uid_for_hotkey_on_subnet( hotkey_ss58, netuid, block) for netuid in self.get_netuids_for_hotkey( hotkey_ss58, block)]
+    def get_uid_for_hotkey_on_subnet(
+        self, hotkey_ss58: str, netuid: int, block: Optional[int] = None
+    ) -> Optional[int]:
+        return self.query_subtensor("Uids", block, [netuid, hotkey_ss58]).value
+
+    def get_all_uids_for_hotkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> List[int]:
+        return [
+            self.get_uid_for_hotkey_on_subnet(hotkey_ss58, netuid, block)
+            for netuid in self.get_netuids_for_hotkey(hotkey_ss58, block)
+        ]
 
-    def get_netuids_for_hotkey( self, hotkey_ss58: str, block: Optional[int] = None) -> List[int]:
-        result = self.query_map_subtensor( 'IsNetworkMember', block, [ hotkey_ss58 ] )
+    def get_netuids_for_hotkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> List[int]:
+        result = self.query_map_subtensor("IsNetworkMember", block, [hotkey_ss58])
         netuids = []
         for netuid, is_member in result.records:
             if is_member:
-                netuids.append( netuid.value )
+                netuids.append(netuid.value)
         return netuids
 
-    def get_neuron_for_pubkey_and_subnet( self, hotkey_ss58: str, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfo]:
-        return self.neuron_for_uid( self.get_uid_for_hotkey_on_subnet(hotkey_ss58, netuid, block=block), netuid, block = block)
+    def get_neuron_for_pubkey_and_subnet(
+        self, hotkey_ss58: str, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfo]:
+        return self.neuron_for_uid(
+            self.get_uid_for_hotkey_on_subnet(hotkey_ss58, netuid, block=block),
+            netuid,
+            block=block,
+        )
 
-    def get_all_neurons_for_pubkey( self, hotkey_ss58: str, block: Optional[int] = None ) -> List[NeuronInfo]:
-        netuids = self.get_netuids_for_hotkey( hotkey_ss58, block)
+    def get_all_neurons_for_pubkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> List[NeuronInfo]:
+        netuids = self.get_netuids_for_hotkey(hotkey_ss58, block)
         uids = [self.get_uid_for_hotkey_on_subnet(hotkey_ss58, net) for net in netuids]
-        return [self.neuron_for_uid( uid, net ) for uid, net in list(zip(uids, netuids))]
+        return [self.neuron_for_uid(uid, net) for uid, net in list(zip(uids, netuids))]
 
-    def neuron_has_validator_permit( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[bool]:
-        return self.query_subtensor( 'ValidatorPermit', block, [ netuid, uid ] ).value
-
-    def neuron_for_wallet( self, wallet: 'bittensor.Wallet', netuid = int, block: Optional[int] = None ) -> Optional[NeuronInfo]:
-        return self.get_neuron_for_pubkey_and_subnet ( wallet.hotkey.ss58_address, netuid = netuid, block = block )
+    def neuron_has_validator_permit(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[bool]:
+        return self.query_subtensor("ValidatorPermit", block, [netuid, uid]).value
+
+    def neuron_for_wallet(
+        self, wallet: "bittensor.Wallet", netuid=int, block: Optional[int] = None
+    ) -> Optional[NeuronInfo]:
+        return self.get_neuron_for_pubkey_and_subnet(
+            wallet.hotkey.ss58_address, netuid=netuid, block=block
+        )
 
-    def neuron_for_uid( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfo]:
-        r""" Returns a list of neuron from the chain.
+    def neuron_for_uid(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfo]:
+        r"""Returns a list of neuron from the chain.
         Args:
             uid ( int ):
                 The uid of the neuron to query for.
             netuid ( int ):
                 The uid of the network to query for.
             block ( int ):
                 The neuron at a particular block
         Returns:
             neuron (Optional[NeuronInfo]):
                 neuron metadata associated with uid or None if it does not exist.
         """
-        if uid == None: return NeuronInfo._null_neuron()
+        if uid == None:
+            return NeuronInfo._null_neuron()
+
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [netuid, uid]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="neuronInfo_getNeuron", # custom rpc method
-                    params=params
+                    method="neuronInfo_getNeuron", params=params  # custom rpc method
                 )
+
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return NeuronInfo._null_neuron()
 
-        return NeuronInfo.from_vec_u8( result )
+        return NeuronInfo.from_vec_u8(result)
 
-    def neurons(self, netuid: int, block: Optional[int] = None ) -> List[NeuronInfo]:
-        r""" Returns a list of neuron from the chain.
+    def neurons(self, netuid: int, block: Optional[int] = None) -> List[NeuronInfo]:
+        r"""Returns a list of neuron from the chain.
         Args:
             netuid ( int ):
                 The netuid of the subnet to pull neurons from.
             block ( Optional[int] ):
                 block to sync from.
         Returns:
             neuron (List[NeuronInfo]):
                 List of neuron metadata objects.
         """
-        neurons_lite = self.neurons_lite( netuid = netuid, block = block )
-        weights = self.weights( block = block, netuid = netuid )
-        bonds = self.bonds( block = block, netuid = netuid )
-
-        weights_as_dict = {
-            uid: w for uid, w in weights
-        }
-        bonds_as_dict = {
-            uid: b for uid, b in bonds
-        }
+        neurons_lite = self.neurons_lite(netuid=netuid, block=block)
+        weights = self.weights(block=block, netuid=netuid)
+        bonds = self.bonds(block=block, netuid=netuid)
+
+        weights_as_dict = {uid: w for uid, w in weights}
+        bonds_as_dict = {uid: b for uid, b in bonds}
 
         neurons = [
-            NeuronInfo.from_weights_bonds_and_neuron_lite( neuron_lite, weights_as_dict, bonds_as_dict ) for neuron_lite in neurons_lite
+            NeuronInfo.from_weights_bonds_and_neuron_lite(
+                neuron_lite, weights_as_dict, bonds_as_dict
+            )
+            for neuron_lite in neurons_lite
         ]
 
         return neurons
-       
 
-    def neuron_for_uid_lite( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfoLite]:
-        r""" Returns a list of neuron lite from the chain.
+    def neuron_for_uid_lite(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfoLite]:
+        r"""Returns a list of neuron lite from the chain.
         Args:
             uid ( int ):
                 The uid of the neuron to query for.
             netuid ( int ):
                 The uid of the network to query for.
             block ( int ):
                 The neuron at a particular block
         Returns:
             neuron (Optional[NeuronInfoLite]):
                 neuron metadata associated with uid or None if it does not exist.
         """
-        if uid == None: return NeuronInfoLite._null_neuron()
+        if uid == None:
+            return NeuronInfoLite._null_neuron()
+
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [netuid, uid]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="neuronInfo_getNeuronLite", # custom rpc method
-                    params=params
+                    method="neuronInfo_getNeuronLite",  # custom rpc method
+                    params=params,
                 )
+
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return NeuronInfoLite._null_neuron()
 
-        return NeuronInfoLite.from_vec_u8( result )
+        return NeuronInfoLite.from_vec_u8(result)
 
-    def neurons_lite(self, netuid: int, block: Optional[int] = None ) -> List[NeuronInfoLite]:
-        r""" Returns a list of neuron lite from the chain.
+    def neurons_lite(
+        self, netuid: int, block: Optional[int] = None
+    ) -> List[NeuronInfoLite]:
+        r"""Returns a list of neuron lite from the chain.
         Args:
             netuid ( int ):
                 The netuid of the subnet to pull neurons from.
             block ( Optional[int] ):
                 block to sync from.
         Returns:
             neuron (List[NeuronInfoLite]):
                 List of neuron lite metadata objects.
         """
+
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
-                block_hash = None if block == None else substrate.get_block_hash( block )
+                block_hash = None if block == None else substrate.get_block_hash(block)
                 params = [netuid]
                 if block_hash:
                     params = params + [block_hash]
                 return substrate.rpc_request(
-                    method="neuronInfo_getNeuronsLite", # custom rpc method
-                    params=params
+                    method="neuronInfo_getNeuronsLite",  # custom rpc method
+                    params=params,
                 )
 
         json_body = make_substrate_call_with_retry()
-        result = json_body['result']
+        result = json_body["result"]
 
         if result in (None, []):
             return []
 
-        return NeuronInfoLite.list_from_vec_u8( result )
+        return NeuronInfoLite.list_from_vec_u8(result)
 
-    def metagraph( self, netuid: int, lite: bool = True, block: Optional[int] = None ) -> 'bittensor.Metagraph':
-        r""" Returns a synced metagraph for the subnet.
+    def metagraph(
+        self, netuid: int, lite: bool = True, block: Optional[int] = None
+    ) -> "bittensor.Metagraph":
+        r"""Returns a synced metagraph for the subnet.
         Args:
             netuid ( int ):
                 The network uid of the subnet to query.
             lite (bool, default=True):
                 If true, returns a metagraph using the lite sync (no weights, no bonds)
             block ( Optional[int] ):
                 block to sync from, or None for latest block.
         Returns:
             metagraph ( `bittensor.Metagraph` ):
                 The metagraph for the subnet at the block.
-        """        
-        metagraph_ = bittensor.metagraph( network = self.network, netuid = netuid, lite = lite, sync = False )
-        metagraph_.sync( block = block, lite = lite, subtensor = self )
+        """
+        metagraph_ = bittensor.metagraph(
+            network=self.network, netuid=netuid, lite=lite, sync=False
+        )
+        metagraph_.sync(block=block, lite=lite, subtensor=self)
 
         return metagraph_
-    
-    def weights(self, netuid: int, block: Optional[int] = None) -> List[Tuple[int, List[Tuple[int, int]]]]:
+
+    def weights(
+        self, netuid: int, block: Optional[int] = None
+    ) -> List[Tuple[int, List[Tuple[int, int]]]]:
         w_map = []
-        w_map_encoded = self.query_map_subtensor(name="Weights", block=block, params = [netuid])
+        w_map_encoded = self.query_map_subtensor(
+            name="Weights", block=block, params=[netuid]
+        )
         if w_map_encoded.records:
             for uid, w in w_map_encoded:
                 w_map.append((uid.serialize(), w.serialize()))
 
         return w_map
-    
-    def bonds(self, netuid: int, block: Optional[int] = None) -> List[Tuple[int, List[Tuple[int, int]]]]:
+
+    def bonds(
+        self, netuid: int, block: Optional[int] = None
+    ) -> List[Tuple[int, List[Tuple[int, int]]]]:
         b_map = []
-        b_map_encoded = self.query_map_subtensor(name="Bonds", block=block, params = [netuid])
+        b_map_encoded = self.query_map_subtensor(
+            name="Bonds", block=block, params=[netuid]
+        )
         if b_map_encoded.records:
             for uid, b in b_map_encoded:
                 b_map.append((uid.serialize(), b.serialize()))
 
         return b_map
-    
+
     ################
     ## Extrinsics ##
     ################
 
     def _do_delegation(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         delegate_ss58: str,
-        amount: 'bittensor.Balance',
+        amount: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
         with self.substrate as substrate:
             call = substrate.compose_call(
-            call_module='SubtensorModule',
-            call_function='add_stake',
-            call_params={
-                'hotkey': delegate_ss58,
-                'amount_staked': amount.rao
-                }
+                call_module="SubtensorModule",
+                call_function="add_stake",
+                call_params={"hotkey": delegate_ss58, "amount_staked": amount.rao},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True
             response.process_events()
             if response.is_success:
                 return True
             else:
                 raise StakeError(response.error_message)
 
     def _do_undelegation(
-            self,
-            wallet: 'bittensor.wallet',
-            delegate_ss58: str,
-            amount: 'bittensor.Balance',
-            wait_for_inclusion: bool = True,
-            wait_for_finalization: bool = False,
-        ) -> bool:
+        self,
+        wallet: "bittensor.wallet",
+        delegate_ss58: str,
+        amount: "bittensor.Balance",
+        wait_for_inclusion: bool = True,
+        wait_for_finalization: bool = False,
+    ) -> bool:
         with self.substrate as substrate:
             call = substrate.compose_call(
-            call_module='SubtensorModule',
-            call_function='remove_stake',
-            call_params={
-                'hotkey': delegate_ss58,
-                'amount_unstaked': amount.rao
-                }
+                call_module="SubtensorModule",
+                call_function="remove_stake",
+                call_params={"hotkey": delegate_ss58, "amount_unstaked": amount.rao},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey )
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True
             response.process_events()
             if response.is_success:
                 return True
             else:
                 raise StakeError(response.error_message)
 
     def _do_nominate(
-            self,
-            wallet: 'bittensor.wallet',
-            wait_for_inclusion: bool = True,
-            wait_for_finalization: bool = False,
-        ) -> bool:
+        self,
+        wallet: "bittensor.wallet",
+        wait_for_inclusion: bool = True,
+        wait_for_finalization: bool = False,
+    ) -> bool:
         with self.substrate as substrate:
             call = substrate.compose_call(
-                call_module='SubtensorModule',
-                call_function='become_delegate',
-                call_params = {
-                    'hotkey': wallet.hotkey.ss58_address
-                }
+                call_module="SubtensorModule",
+                call_function="become_delegate",
+                call_params={"hotkey": wallet.hotkey.ss58_address},
+            )
+            extrinsic = substrate.create_signed_extrinsic(
+                call=call, keypair=wallet.coldkey
+            )  # sign with coldkey
+            response = substrate.submit_extrinsic(
+                extrinsic,
+                wait_for_inclusion=wait_for_inclusion,
+                wait_for_finalization=wait_for_finalization,
             )
-            extrinsic = substrate.create_signed_extrinsic( call = call, keypair = wallet.coldkey ) # sign with coldkey
-            response = substrate.submit_extrinsic( extrinsic, wait_for_inclusion = wait_for_inclusion, wait_for_finalization = wait_for_finalization )
             # We only wait here if we expect finalization.
             if not wait_for_finalization and not wait_for_inclusion:
                 return True
             response.process_events()
             if response.is_success:
                 return True
             else:
                 raise NominationError(response.error_message)
 
     ################
     #### Legacy ####
     ################
 
     def get_balance(self, address: str, block: int = None) -> Balance:
-        r""" Returns the token balance for the passed ss58_address address
+        r"""Returns the token balance for the passed ss58_address address
         Args:
             address (Substrate address format, default = 42):
                 ss58 chain address.
         Return:
             balance (bittensor.utils.balance.Balance):
                 account balance
         """
         try:
+
             @retry(delay=2, tries=3, backoff=2, max_delay=4)
             def make_substrate_call_with_retry():
                 with self.substrate as substrate:
                     return substrate.query(
-                        module='System',
-                        storage_function='Account',
+                        module="System",
+                        storage_function="Account",
                         params=[address],
-                        block_hash = None if block == None else substrate.get_block_hash( block )
+                        block_hash=None
+                        if block == None
+                        else substrate.get_block_hash(block),
                     )
+
             result = make_substrate_call_with_retry()
         except scalecodec.exceptions.RemainingScaleBytesNotEmptyException:
-            bittensor.logging.error( "Your wallet it legacy formatted, you need to run btcli stake --ammount 0 to reformat it." )
+            bittensor.logging.error(
+                "Your wallet it legacy formatted, you need to run btcli stake --ammount 0 to reformat it."
+            )
             return Balance(1000)
-        return Balance( result.value['data']['free'] )
+        return Balance(result.value["data"]["free"])
 
     def get_current_block(self) -> int:
-        r""" Returns the current block number on the chain.
+        r"""Returns the current block number on the chain.
         Returns:
             block_number (int):
                 Current chain blocknumber.
         """
+
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.get_block_number(None)
+
         return make_substrate_call_with_retry()
 
     def get_balances(self, block: int = None) -> Dict[str, Balance]:
         @retry(delay=2, tries=3, backoff=2, max_delay=4)
         def make_substrate_call_with_retry():
             with self.substrate as substrate:
                 return substrate.query_map(
-                    module='System',
-                    storage_function='Account',
-                    block_hash = None if block == None else substrate.get_block_hash( block )
+                    module="System",
+                    storage_function="Account",
+                    block_hash=None
+                    if block == None
+                    else substrate.get_block_hash(block),
                 )
+
         result = make_substrate_call_with_retry()
         return_dict = {}
         for r in result:
-            bal = bittensor.Balance( int( r[1]['data']['free'].value ) )
+            bal = bittensor.Balance(int(r[1]["data"]["free"].value))
             return_dict[r[0].value] = bal
         return return_dict
 
     @staticmethod
     def _null_neuron() -> NeuronInfo:
         neuron = NeuronInfo(
-            uid = 0,
-            netuid = 0,
-            active =  0,
-            stake = '0',
-            rank = 0,
-            emission = 0,
-            incentive = 0,
-            consensus = 0,
-            trust = 0,
-            validator_trust = 0,
-            dividends = 0,
-            last_update = 0,
-            validator_permit = False,
-            weights = [],
-            bonds = [],
-            prometheus_info = None,
-            axon_info = None,
-            is_null = True,
-            coldkey = "000000000000000000000000000000000000000000000000",
-            hotkey = "000000000000000000000000000000000000000000000000"
+            uid=0,
+            netuid=0,
+            active=0,
+            stake="0",
+            rank=0,
+            emission=0,
+            incentive=0,
+            consensus=0,
+            trust=0,
+            validator_trust=0,
+            dividends=0,
+            last_update=0,
+            validator_permit=False,
+            weights=[],
+            bonds=[],
+            prometheus_info=None,
+            axon_info=None,
+            is_null=True,
+            coldkey="000000000000000000000000000000000000000000000000",
+            hotkey="000000000000000000000000000000000000000000000000",
         )
         return neuron
 
     def get_block_hash(self, block_id: int) -> str:
-        return self.substrate.get_block_hash( block_id = block_id )
+        return self.substrate.get_block_hash(block_id=block_id)
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/subtensor_mock.py` & `bittensor-5.3.2/bittensor/_subtensor/subtensor_mock.py`

 * *Files 8% similar despite different names*

```diff
@@ -24,1350 +24,1454 @@
 from collections.abc import Mapping
 
 import bittensor
 from bittensor.utils import RAOPERTAO, U16_NORMALIZED_FLOAT
 from bittensor.utils.registration import POWSolution
 from hashlib import sha256
 
-from .chain_data import (NeuronInfo, NeuronInfoLite, PrometheusInfo, DelegateInfo,
-                         SubnetInfo, axon_info)
+from .chain_data import (
+    NeuronInfo,
+    NeuronInfoLite,
+    PrometheusInfo,
+    DelegateInfo,
+    SubnetInfo,
+    axon_info,
+)
 from .errors import *
 from .subtensor_impl import Subtensor, AxonServeCallParams, PrometheusServeCallParams
 
 BlockNumber = int
 
+
 class InfoDict(Mapping):
     @abstractclassmethod
     def default(cls):
         raise NotImplementedError
-    
+
     def __getitem__(self, key):
         return getattr(self, key)
-    
+
     def __setitem__(self, key, value):
         return setattr(self, key, value)
 
     def __iter__(self):
         return iter(self.__dict__)
-    
+
     def __len__(self):
         return len(self.__dict__)
 
+
 @dataclass
 class AxonInfoDict(InfoDict):
     block: int
     version: int
-    ip: int # integer representation of ip address
+    ip: int  # integer representation of ip address
     port: int
     ip_type: int
     protocol: int
-    placeholder1: int # placeholder for future use
+    placeholder1: int  # placeholder for future use
     placeholder2: int
 
     @classmethod
     def default(cls):
         return cls(
             block=0,
             version=0,
             ip=0,
             port=0,
             ip_type=0,
             protocol=0,
             placeholder1=0,
             placeholder2=0,
         )
-    
+
+
 @dataclass
 class PrometheusInfoDict(InfoDict):
     block: int
     version: int
-    ip: int # integer representation of ip address
+    ip: int  # integer representation of ip address
     port: int
     ip_type: int
 
     @classmethod
     def default(cls):
-        return cls(
-            block=0,
-            version=0,
-            ip=0,
-            port=0,
-            ip_type=0,
-        )
+        return cls(block=0, version=0, ip=0, port=0, ip_type=0)
+
 
 @dataclass
 class MockSubtensorValue:
     value: Optional[Any]
 
+
 class MockMapResult:
     records: Optional[List[Tuple[MockSubtensorValue, MockSubtensorValue]]]
 
-    def __init__(self, records: Optional[List[Tuple[Union[Any, MockSubtensorValue], Union[Any, MockSubtensorValue]]]] = None):
+    def __init__(
+        self,
+        records: Optional[
+            List[Tuple[Union[Any, MockSubtensorValue], Union[Any, MockSubtensorValue]]]
+        ] = None,
+    ):
         _records = [
-                (MockSubtensorValue( value=record[0] ), MockSubtensorValue( value=record[1] )) 
-                    # Make sure record is a tuple of MockSubtensorValue (dict with value attr)
-                    if not (isinstance(record, tuple) and all(isinstance(item, dict) and hasattr(item, 'value') for item in record))
-                else record 
-            for record in records 
+            (MockSubtensorValue(value=record[0]), MockSubtensorValue(value=record[1]))
+            # Make sure record is a tuple of MockSubtensorValue (dict with value attr)
+            if not (
+                isinstance(record, tuple)
+                and all(
+                    isinstance(item, dict) and hasattr(item, "value") for item in record
+                )
+            )
+            else record
+            for record in records
         ]
-        
+
         self.records = _records
 
     def __iter__(self):
         return iter(self.records)
 
+
 class MockSystemState(TypedDict):
-    Account: Dict[str, Dict[int, int]] # address -> block -> balance
+    Account: Dict[str, Dict[int, int]]  # address -> block -> balance
 
-class MockSubtensorState(TypedDict):
-    Rho: Dict[int, Dict[BlockNumber, int]] # netuid -> block -> rho
-    Kappa: Dict[int, Dict[BlockNumber, int]] # netuid -> block -> kappa
-    Difficulty: Dict[int, Dict[BlockNumber, int]] # netuid -> block -> difficulty
-    ImmunityPeriod: Dict[int, Dict[BlockNumber, int]] # netuid -> block -> immunity_period
-    ValidatorBatchSize: Dict[int, Dict[BlockNumber, int]] # netuid -> block -> validator_batch_size
-    Active: Dict[int, Dict[BlockNumber, bool]] # (netuid, uid), block -> active
-    Stake:  Dict[str, Dict[str, Dict[int, int]]] # (hotkey, coldkey) -> block -> stake
 
-    Delegates: Dict[str, Dict[int, float]] # address -> block -> delegate_take
+class MockSubtensorState(TypedDict):
+    Rho: Dict[int, Dict[BlockNumber, int]]  # netuid -> block -> rho
+    Kappa: Dict[int, Dict[BlockNumber, int]]  # netuid -> block -> kappa
+    Difficulty: Dict[int, Dict[BlockNumber, int]]  # netuid -> block -> difficulty
+    ImmunityPeriod: Dict[
+        int, Dict[BlockNumber, int]
+    ]  # netuid -> block -> immunity_period
+    ValidatorBatchSize: Dict[
+        int, Dict[BlockNumber, int]
+    ]  # netuid -> block -> validator_batch_size
+    Active: Dict[int, Dict[BlockNumber, bool]]  # (netuid, uid), block -> active
+    Stake: Dict[str, Dict[str, Dict[int, int]]]  # (hotkey, coldkey) -> block -> stake
+    Delegates: Dict[str, Dict[int, float]]  # address -> block -> delegate_take
+    NetworksAdded: Dict[int, Dict[BlockNumber, bool]]  # netuid -> block -> added
 
-    NetworksAdded: Dict[int, Dict[BlockNumber, bool]] # netuid -> block -> added
 
 class MockChainState(TypedDict):
     System: MockSystemState
     SubtensorModule: MockSubtensorState
-    
+
+
 class MockSubtensor(Subtensor):
     """
-    A Mock Subtensor class for running tests. 
+    A Mock Subtensor class for running tests.
     This should mock only methods that make queries to the chain.
     e.g. We mock `Subtensor.query_subtensor` instead of all query methods.
 
     This class will also store a local (mock) state of the chain.
     """
+
     chain_state: MockChainState
     block_number: int
 
     @classmethod
     def reset(cls) -> None:
         bittensor.__GLOBAL_MOCK_STATE__.clear()
 
         _ = cls()
 
     def setup(self) -> None:
-        if not hasattr(self, 'chain_state') or getattr(self, 'chain_state') is None:
+        if not hasattr(self, "chain_state") or getattr(self, "chain_state") is None:
             self.chain_state = {
-                'System': {
-                    'Account': {}
+                "System": {"Account": {}},
+                "Balances": {
+                    "ExistentialDeposit": {0: 500},
                 },
-                'Balances': {
-                    'ExistentialDeposit': {
-                        0: 500
-                    },
-                },
-                'SubtensorModule': {
-                    'NetworksAdded': {},
-                    'Rho': {},
-                    'Kappa': {},
-                    'Difficulty': {},
-                    'ImmunityPeriod': {},
-                    'ValidatorBatchSize': {},
-                    'ValidatorSequenceLength': {},
-                    'ValidatorEpochsPerReset': {},
-                    'ValidatorEpochLength': {},
-                    'MaxAllowedValidators': {},
-                    'MinAllowedWeights': {},
-                    'MaxWeightLimit': {},
-                    'SynergyScalingLawPower': {},
-                    'ScalingLawPower': {},
-                    'SubnetworkN': {},
-                    'MaxAllowedUids': {},
-                    'NetworkModality': {},
-                    'BlocksSinceLastStep': {},
-                    'Tempo': {},
-                    'NetworkConnect': {},
-                    'EmissionValues': {},
-                    'Burn': {},
-
-                    'Active': {},
-
-                    'Uids': {},
-                    'Keys': {},
-                    'Owner': {},
-                    'IsNetworkMember': {},
-                    'LastUpdate': {},
-                    
-                    'Rank': {},
-                    'Emission': {},
-                    'Incentive': {},
-                    'Consensus': {},
-                    'Trust': {},
-                    'ValidatorTrust': {},
-                    'Dividends': {},
-                    'PruningScores': {},
-                    'ValidatorPermit': {},
-
-                    'Weights': {},
-                    'Bonds': {},
-                    
-                    'Stake': {},
-                    'TotalStake': {
-                        0: 0
-                    },
-                    'TotalIssuance': {
-                        0: 0
-                    },
-                    'TotalHotkeyStake': {},
-                    'TotalColdkeyStake': {},
-                    
-                    'TxRateLimit': {
-                        0: 0 # No limit
-                    },
-
-                    'Delegates': {},
-
-                    'Axons': {},
-                    'Prometheus': {},
+                "SubtensorModule": {
+                    "NetworksAdded": {},
+                    "Rho": {},
+                    "Kappa": {},
+                    "Difficulty": {},
+                    "ImmunityPeriod": {},
+                    "ValidatorBatchSize": {},
+                    "ValidatorSequenceLength": {},
+                    "ValidatorEpochsPerReset": {},
+                    "ValidatorEpochLength": {},
+                    "MaxAllowedValidators": {},
+                    "MinAllowedWeights": {},
+                    "MaxWeightLimit": {},
+                    "SynergyScalingLawPower": {},
+                    "ScalingLawPower": {},
+                    "SubnetworkN": {},
+                    "MaxAllowedUids": {},
+                    "NetworkModality": {},
+                    "BlocksSinceLastStep": {},
+                    "Tempo": {},
+                    "NetworkConnect": {},
+                    "EmissionValues": {},
+                    "Burn": {},
+                    "Active": {},
+                    "Uids": {},
+                    "Keys": {},
+                    "Owner": {},
+                    "IsNetworkMember": {},
+                    "LastUpdate": {},
+                    "Rank": {},
+                    "Emission": {},
+                    "Incentive": {},
+                    "Consensus": {},
+                    "Trust": {},
+                    "ValidatorTrust": {},
+                    "Dividends": {},
+                    "PruningScores": {},
+                    "ValidatorPermit": {},
+                    "Weights": {},
+                    "Bonds": {},
+                    "Stake": {},
+                    "TotalStake": {0: 0},
+                    "TotalIssuance": {0: 0},
+                    "TotalHotkeyStake": {},
+                    "TotalColdkeyStake": {},
+                    "TxRateLimit": {0: 0},  # No limit
+                    "Delegates": {},
+                    "Axons": {},
+                    "Prometheus": {},
                 },
             }
 
             self.block_number = 0
 
-            self.network = 'mock'
-            self.chain_endpoint = 'mock_endpoint'
+            self.network = "mock"
+            self.chain_endpoint = "mock_endpoint"
             self.substrate = MagicMock()
 
     def __init__(self) -> None:
         self.__dict__ = bittensor.__GLOBAL_MOCK_STATE__
-        
-        if not hasattr(self, 'chain_state') or getattr(self, 'chain_state') is None:
+
+        if not hasattr(self, "chain_state") or getattr(self, "chain_state") is None:
             self.setup()
 
     def get_block_hash(self, block_id: int) -> str:
-        return '0x' + sha256(str(block_id).encode()).hexdigest()[:64]
-        
+        return "0x" + sha256(str(block_id).encode()).hexdigest()[:64]
 
-    def create_subnet( self, netuid: int ) -> None:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+    def create_subnet(self, netuid: int) -> None:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             # Per Subnet
-            subtensor_state['Rho'][netuid] = {}
-            subtensor_state['Rho'][netuid][0] = 10
-            subtensor_state['Kappa'][netuid] = {}
-            subtensor_state['Kappa'][netuid][0] = 32_767
-            subtensor_state['Difficulty'][netuid] = {}
-            subtensor_state['Difficulty'][netuid][0] = 10_000_000
-            subtensor_state['ImmunityPeriod'][netuid] = {}
-            subtensor_state['ImmunityPeriod'][netuid][0] = 4096
-            subtensor_state['ValidatorBatchSize'][netuid] = {}
-            subtensor_state['ValidatorBatchSize'][netuid][0] = 32
-            subtensor_state['ValidatorSequenceLength'][netuid] = {}
-            subtensor_state['ValidatorSequenceLength'][netuid][0] = 256
-            subtensor_state['ValidatorEpochsPerReset'][netuid] = {}
-            subtensor_state['ValidatorEpochsPerReset'][netuid][0] = 60
-            subtensor_state['ValidatorEpochLength'][netuid] = {}
-            subtensor_state['ValidatorEpochLength'][netuid][0] = 100
-            subtensor_state['MaxAllowedValidators'][netuid] = {}
-            subtensor_state['MaxAllowedValidators'][netuid][0] = 128
-            subtensor_state['MinAllowedWeights'][netuid] = {}
-            subtensor_state['MinAllowedWeights'][netuid][0] = 1024
-            subtensor_state['MaxWeightLimit'][netuid] = {}
-            subtensor_state['MaxWeightLimit'][netuid][0] = 1_000
-            subtensor_state['SynergyScalingLawPower'][netuid] = {}
-            subtensor_state['SynergyScalingLawPower'][netuid][0] = 50
-            subtensor_state['ScalingLawPower'][netuid] = {}
-            subtensor_state['ScalingLawPower'][netuid][0] = 50
-            subtensor_state['SubnetworkN'][netuid] = {}
-            subtensor_state['SubnetworkN'][netuid][0] = 0
-            subtensor_state['MaxAllowedUids'][netuid] = {}
-            subtensor_state['MaxAllowedUids'][netuid][0] = 4096
-            subtensor_state['NetworkModality'][netuid] = {}
-            subtensor_state['NetworkModality'][netuid][0] = 0
-            subtensor_state['BlocksSinceLastStep'][netuid] = {}
-            subtensor_state['BlocksSinceLastStep'][netuid][0] = 0
-            subtensor_state['Tempo'][netuid] = {}
-            subtensor_state['Tempo'][netuid][0] = 99
+            subtensor_state["Rho"][netuid] = {}
+            subtensor_state["Rho"][netuid][0] = 10
+            subtensor_state["Kappa"][netuid] = {}
+            subtensor_state["Kappa"][netuid][0] = 32_767
+            subtensor_state["Difficulty"][netuid] = {}
+            subtensor_state["Difficulty"][netuid][0] = 10_000_000
+            subtensor_state["ImmunityPeriod"][netuid] = {}
+            subtensor_state["ImmunityPeriod"][netuid][0] = 4096
+            subtensor_state["ValidatorBatchSize"][netuid] = {}
+            subtensor_state["ValidatorBatchSize"][netuid][0] = 32
+            subtensor_state["ValidatorSequenceLength"][netuid] = {}
+            subtensor_state["ValidatorSequenceLength"][netuid][0] = 256
+            subtensor_state["ValidatorEpochsPerReset"][netuid] = {}
+            subtensor_state["ValidatorEpochsPerReset"][netuid][0] = 60
+            subtensor_state["ValidatorEpochLength"][netuid] = {}
+            subtensor_state["ValidatorEpochLength"][netuid][0] = 100
+            subtensor_state["MaxAllowedValidators"][netuid] = {}
+            subtensor_state["MaxAllowedValidators"][netuid][0] = 128
+            subtensor_state["MinAllowedWeights"][netuid] = {}
+            subtensor_state["MinAllowedWeights"][netuid][0] = 1024
+            subtensor_state["MaxWeightLimit"][netuid] = {}
+            subtensor_state["MaxWeightLimit"][netuid][0] = 1_000
+            subtensor_state["SynergyScalingLawPower"][netuid] = {}
+            subtensor_state["SynergyScalingLawPower"][netuid][0] = 50
+            subtensor_state["ScalingLawPower"][netuid] = {}
+            subtensor_state["ScalingLawPower"][netuid][0] = 50
+            subtensor_state["SubnetworkN"][netuid] = {}
+            subtensor_state["SubnetworkN"][netuid][0] = 0
+            subtensor_state["MaxAllowedUids"][netuid] = {}
+            subtensor_state["MaxAllowedUids"][netuid][0] = 4096
+            subtensor_state["NetworkModality"][netuid] = {}
+            subtensor_state["NetworkModality"][netuid][0] = 0
+            subtensor_state["BlocksSinceLastStep"][netuid] = {}
+            subtensor_state["BlocksSinceLastStep"][netuid][0] = 0
+            subtensor_state["Tempo"][netuid] = {}
+            subtensor_state["Tempo"][netuid][0] = 99
             # subtensor_state['NetworkConnect'][netuid] = {}
             # subtensor_state['NetworkConnect'][netuid][0] = {}
-            subtensor_state['EmissionValues'][netuid] = {}
-            subtensor_state['EmissionValues'][netuid][0] = 0
-            subtensor_state['Burn'][netuid] = {}
-            subtensor_state['Burn'][netuid][0] = 0
-            
+            subtensor_state["EmissionValues"][netuid] = {}
+            subtensor_state["EmissionValues"][netuid][0] = 0
+            subtensor_state["Burn"][netuid] = {}
+            subtensor_state["Burn"][netuid][0] = 0
+
             # Per-UID/Hotkey
 
-            subtensor_state['Uids'][netuid] = {}
-            subtensor_state['Keys'][netuid] = {}
-            subtensor_state['Owner'][netuid] = {}
-            
-            subtensor_state['LastUpdate'][netuid] = {}
-            subtensor_state['Active'][netuid] = {}
-            subtensor_state['Rank'][netuid] = {}
-            subtensor_state['Emission'][netuid] = {}
-            subtensor_state['Incentive'][netuid] = {}
-            subtensor_state['Consensus'][netuid] = {}
-            subtensor_state['Trust'][netuid] = {}
-            subtensor_state['ValidatorTrust'][netuid] = {}
-            subtensor_state['Dividends'][netuid] = {}
-            subtensor_state['PruningScores'][netuid] = {}
-            subtensor_state['PruningScores'][netuid][0] = {}
-            subtensor_state['ValidatorPermit'][netuid] = {}
+            subtensor_state["Uids"][netuid] = {}
+            subtensor_state["Keys"][netuid] = {}
+            subtensor_state["Owner"][netuid] = {}
+
+            subtensor_state["LastUpdate"][netuid] = {}
+            subtensor_state["Active"][netuid] = {}
+            subtensor_state["Rank"][netuid] = {}
+            subtensor_state["Emission"][netuid] = {}
+            subtensor_state["Incentive"][netuid] = {}
+            subtensor_state["Consensus"][netuid] = {}
+            subtensor_state["Trust"][netuid] = {}
+            subtensor_state["ValidatorTrust"][netuid] = {}
+            subtensor_state["Dividends"][netuid] = {}
+            subtensor_state["PruningScores"][netuid] = {}
+            subtensor_state["PruningScores"][netuid][0] = {}
+            subtensor_state["ValidatorPermit"][netuid] = {}
 
-            subtensor_state['Weights'][netuid] = {}
-            subtensor_state['Bonds'][netuid] = {}
+            subtensor_state["Weights"][netuid] = {}
+            subtensor_state["Bonds"][netuid] = {}
 
-            subtensor_state['Axons'][netuid] = {}
-            subtensor_state['Prometheus'][netuid] = {}
+            subtensor_state["Axons"][netuid] = {}
+            subtensor_state["Prometheus"][netuid] = {}
 
-            subtensor_state['NetworksAdded'][netuid] = {}
-            subtensor_state['NetworksAdded'][netuid][0] = True
+            subtensor_state["NetworksAdded"][netuid] = {}
+            subtensor_state["NetworksAdded"][netuid][0] = True
 
         else:
             raise Exception("Subnet already exists")
 
-    def set_difficulty( self, netuid: int, difficulty: int ) -> None:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+    def set_difficulty(self, netuid: int, difficulty: int) -> None:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             raise Exception("Subnet does not exist")
 
-        subtensor_state['Difficulty'][netuid][self.block_number] = difficulty    
+        subtensor_state["Difficulty"][netuid][self.block_number] = difficulty
 
     def _register_neuron(
         self,
         netuid: int,
-        hotkey: str, 
+        hotkey: str,
         coldkey: str,
     ) -> int:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             raise Exception("Subnet does not exist")
 
-        subnetwork_n = self._get_most_recent_storage(subtensor_state['SubnetworkN'][netuid])
-        
-        if subnetwork_n > 0 and any(self._get_most_recent_storage(subtensor_state['Keys'][netuid][uid]) == hotkey for uid in range(subnetwork_n)):
+        subnetwork_n = self._get_most_recent_storage(
+            subtensor_state["SubnetworkN"][netuid]
+        )
+
+        if subnetwork_n > 0 and any(
+            self._get_most_recent_storage(subtensor_state["Keys"][netuid][uid])
+            == hotkey
+            for uid in range(subnetwork_n)
+        ):
             # already_registered
             raise Exception("Hotkey already registered")
         else:
             # Not found
-            if subnetwork_n >= self._get_most_recent_storage(subtensor_state['MaxAllowedUids'][netuid]):
+            if subnetwork_n >= self._get_most_recent_storage(
+                subtensor_state["MaxAllowedUids"][netuid]
+            ):
                 # Subnet full, replace neuron randomly
-                uid = randint(0, subnetwork_n-1)
+                uid = randint(0, subnetwork_n - 1)
             else:
                 # Subnet not full, add new neuron
                 # Append as next uid and increment subnetwork_n
                 uid = subnetwork_n
-                subtensor_state['SubnetworkN'][netuid][self.block_number] = subnetwork_n + 1
+                subtensor_state["SubnetworkN"][netuid][self.block_number] = (
+                    subnetwork_n + 1
+                )
+
+            subtensor_state["Stake"][hotkey] = {}
+            subtensor_state["Stake"][hotkey][coldkey] = {}
+            subtensor_state["Stake"][hotkey][coldkey][self.block_number] = 0
 
-            subtensor_state['Stake'][hotkey] = {}
-            subtensor_state['Stake'][hotkey][coldkey] = {}
-            subtensor_state['Stake'][hotkey][coldkey][self.block_number] = 0
-            
-            subtensor_state['Uids'][netuid][hotkey] = {}
-            subtensor_state['Uids'][netuid][hotkey][self.block_number] = uid
+            subtensor_state["Uids"][netuid][hotkey] = {}
+            subtensor_state["Uids"][netuid][hotkey][self.block_number] = uid
 
-            subtensor_state['Keys'][netuid][uid] = {}
-            subtensor_state['Keys'][netuid][uid][self.block_number] = hotkey
+            subtensor_state["Keys"][netuid][uid] = {}
+            subtensor_state["Keys"][netuid][uid][self.block_number] = hotkey
 
-            subtensor_state['Owner'][hotkey] = {}
-            subtensor_state['Owner'][hotkey][self.block_number] = coldkey
+            subtensor_state["Owner"][hotkey] = {}
+            subtensor_state["Owner"][hotkey][self.block_number] = coldkey
 
-            subtensor_state['Active'][netuid][uid] = {}
-            subtensor_state['Active'][netuid][uid][self.block_number] = True
+            subtensor_state["Active"][netuid][uid] = {}
+            subtensor_state["Active"][netuid][uid][self.block_number] = True
 
-            subtensor_state['LastUpdate'][netuid][uid] = {}
-            subtensor_state['LastUpdate'][netuid][uid][self.block_number] = self.block_number
-            
-            subtensor_state['Rank'][netuid][uid] = {}
-            subtensor_state['Rank'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["LastUpdate"][netuid][uid] = {}
+            subtensor_state["LastUpdate"][netuid][uid][
+                self.block_number
+            ] = self.block_number
 
-            subtensor_state['Emission'][netuid][uid] = {}
-            subtensor_state['Emission'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Rank"][netuid][uid] = {}
+            subtensor_state["Rank"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['Incentive'][netuid][uid] = {}
-            subtensor_state['Incentive'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Emission"][netuid][uid] = {}
+            subtensor_state["Emission"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['Consensus'][netuid][uid] = {}
-            subtensor_state['Consensus'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Incentive"][netuid][uid] = {}
+            subtensor_state["Incentive"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['Trust'][netuid][uid] = {}
-            subtensor_state['Trust'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Consensus"][netuid][uid] = {}
+            subtensor_state["Consensus"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['ValidatorTrust'][netuid][uid] = {}
-            subtensor_state['ValidatorTrust'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Trust"][netuid][uid] = {}
+            subtensor_state["Trust"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['Dividends'][netuid][uid] = {}
-            subtensor_state['Dividends'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["ValidatorTrust"][netuid][uid] = {}
+            subtensor_state["ValidatorTrust"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['PruningScores'][netuid][uid] = {}
-            subtensor_state['PruningScores'][netuid][uid][self.block_number] = 0.0
+            subtensor_state["Dividends"][netuid][uid] = {}
+            subtensor_state["Dividends"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['ValidatorPermit'][netuid][uid] = {}
-            subtensor_state['ValidatorPermit'][netuid][uid][self.block_number] = False
+            subtensor_state["PruningScores"][netuid][uid] = {}
+            subtensor_state["PruningScores"][netuid][uid][self.block_number] = 0.0
 
-            subtensor_state['Weights'][netuid][uid] = {}
-            subtensor_state['Weights'][netuid][uid][self.block_number] = []
+            subtensor_state["ValidatorPermit"][netuid][uid] = {}
+            subtensor_state["ValidatorPermit"][netuid][uid][self.block_number] = False
 
-            subtensor_state['Bonds'][netuid][uid] = {}
-            subtensor_state['Bonds'][netuid][uid][self.block_number] = []
+            subtensor_state["Weights"][netuid][uid] = {}
+            subtensor_state["Weights"][netuid][uid][self.block_number] = []
 
-            subtensor_state['Axons'][netuid][hotkey] = {}
-            subtensor_state['Axons'][netuid][hotkey][self.block_number] = {}
+            subtensor_state["Bonds"][netuid][uid] = {}
+            subtensor_state["Bonds"][netuid][uid][self.block_number] = []
 
-            subtensor_state['Prometheus'][netuid][hotkey] = {}
-            subtensor_state['Prometheus'][netuid][hotkey][self.block_number] = {}
+            subtensor_state["Axons"][netuid][hotkey] = {}
+            subtensor_state["Axons"][netuid][hotkey][self.block_number] = {}
+
+            subtensor_state["Prometheus"][netuid][hotkey] = {}
+            subtensor_state["Prometheus"][netuid][hotkey][self.block_number] = {}
+
+            if hotkey not in subtensor_state["IsNetworkMember"]:
+                subtensor_state["IsNetworkMember"][hotkey] = {}
+            subtensor_state["IsNetworkMember"][hotkey][netuid] = {}
+            subtensor_state["IsNetworkMember"][hotkey][netuid][self.block_number] = True
 
-            if hotkey not in subtensor_state['IsNetworkMember']:
-                subtensor_state['IsNetworkMember'][hotkey] = {}
-            subtensor_state['IsNetworkMember'][hotkey][netuid] = {}
-            subtensor_state['IsNetworkMember'][hotkey][netuid][self.block_number] = True
-            
             return uid
-        
+
     @staticmethod
     def _convert_to_balance(
-        balance: Union['bittensor.Balance', float, int]
-    ) -> 'bittensor.Balance':
+        balance: Union["bittensor.Balance", float, int]
+    ) -> "bittensor.Balance":
         if isinstance(balance, float):
             balance = bittensor.Balance.from_tao(balance)
 
         if isinstance(balance, int):
             balance = bittensor.Balance.from_rao(balance)
 
         return balance
-    
 
     def force_register_neuron(
         self,
         netuid: int,
-        hotkey: str, 
+        hotkey: str,
         coldkey: str,
-        stake: Union['bittensor.Balance', float, int] = bittensor.Balance(0),
-        balance: Union['bittensor.Balance', float, int] = bittensor.Balance(0),
+        stake: Union["bittensor.Balance", float, int] = bittensor.Balance(0),
+        balance: Union["bittensor.Balance", float, int] = bittensor.Balance(0),
     ) -> int:
         """
         Force register a neuron on the mock chain, returning the UID.
         """
         stake = self._convert_to_balance(stake)
         balance = self._convert_to_balance(balance)
 
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             raise Exception("Subnet does not exist")
 
-        uid = self._register_neuron(
-            netuid=netuid,
-            hotkey=hotkey,
-            coldkey=coldkey,
-        )
+        uid = self._register_neuron(netuid=netuid, hotkey=hotkey, coldkey=coldkey)
 
-        subtensor_state['TotalStake'][self.block_number] = self._get_most_recent_storage(subtensor_state['TotalStake']) + stake.rao
-        subtensor_state['Stake'][hotkey][coldkey][self.block_number] = stake.rao
+        subtensor_state["TotalStake"][self.block_number] = (
+            self._get_most_recent_storage(subtensor_state["TotalStake"]) + stake.rao
+        )
+        subtensor_state["Stake"][hotkey][coldkey][self.block_number] = stake.rao
 
         if balance.rao > 0:
             self.force_set_balance(coldkey, balance)
         self.force_set_balance(coldkey, balance)
 
         return uid
 
     def force_set_balance(
         self,
         ss58_address: str,
-        balance: Union['bittensor.Balance', float, int] = bittensor.Balance(0),
+        balance: Union["bittensor.Balance", float, int] = bittensor.Balance(0),
     ) -> Tuple[bool, Optional[str]]:
         """
         Returns:
             Tuple[bool, Optional[str]]: (success, err_msg)
         """
         balance = self._convert_to_balance(balance)
 
-        if ss58_address not in self.chain_state['System']['Account']:
-            self.chain_state['System']['Account'][ss58_address] = {
-                'data': {
-                    'free': {
+        if ss58_address not in self.chain_state["System"]["Account"]:
+            self.chain_state["System"]["Account"][ss58_address] = {
+                "data": {
+                    "free": {
                         0: 0,
                     },
                 },
             }
 
         old_balance = self.get_balance(ss58_address, self.block_number)
         diff = balance.rao - old_balance.rao
 
         # Update total issuance
-        self.chain_state['SubtensorModule']['TotalIssuance'][self.block_number] = self._get_most_recent_storage(self.chain_state['SubtensorModule']['TotalIssuance']) + diff
+        self.chain_state["SubtensorModule"]["TotalIssuance"][self.block_number] = (
+            self._get_most_recent_storage(
+                self.chain_state["SubtensorModule"]["TotalIssuance"]
+            )
+            + diff
+        )
 
-        self.chain_state['System']['Account'][ss58_address] = {
-            'data': {
-                'free': {
-                    self.block_number: balance.rao
-                }
-            }
+        self.chain_state["System"]["Account"][ss58_address] = {
+            "data": {"free": {self.block_number: balance.rao}}
         }
 
         return True, None
-    
+
     # Alias for force_set_balance
     sudo_force_set_balance = force_set_balance
-        
-    def do_block_step( self ) -> None:
+
+    def do_block_step(self) -> None:
         self.block_number += 1
 
         # Doesn't do epoch
-        subtensor_state = self.chain_state['SubtensorModule']
-        for subnet in subtensor_state['NetworksAdded']:
-            subtensor_state['BlocksSinceLastStep'][subnet][self.block_number] = self._get_most_recent_storage(subtensor_state['BlocksSinceLastStep'][subnet]) + 1
+        subtensor_state = self.chain_state["SubtensorModule"]
+        for subnet in subtensor_state["NetworksAdded"]:
+            subtensor_state["BlocksSinceLastStep"][subnet][self.block_number] = (
+                self._get_most_recent_storage(
+                    subtensor_state["BlocksSinceLastStep"][subnet]
+                )
+                + 1
+            )
 
-    def _handle_type_default( self, name: str, params: List[object] ) -> object:
+    def _handle_type_default(self, name: str, params: List[object]) -> object:
         defaults_mapping = {
-            'TotalStake': 0,
-            'TotalHotkeyStake': 0,
-            'TotalColdkeyStake': 0,
-            'Stake': 0,
+            "TotalStake": 0,
+            "TotalHotkeyStake": 0,
+            "TotalColdkeyStake": 0,
+            "Stake": 0,
         }
 
         return defaults_mapping.get(name, None)
 
-    def query_subtensor( self, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> MockSubtensorValue:
+    def query_subtensor(
+        self,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> MockSubtensorValue:
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
-        state = self.chain_state['SubtensorModule'][name]
+        state = self.chain_state["SubtensorModule"][name]
         if state is not None:
             # Use prefix
             if len(params) > 0:
                 while state is not None and len(params) > 0:
                     state = state.get(params.pop(0), None)
                     if state is None:
                         return SimpleNamespace(
-                            value = self._handle_type_default(name, params)
+                            value=self._handle_type_default(name, params)
                         )
-                    
+
             # Use block
             state_at_block = state.get(block, None)
             while state_at_block is None and block > 0:
                 block -= 1
                 state_at_block = self.state.get(block, None)
             if state_at_block is not None:
-                return SimpleNamespace(
-                    value=state_at_block
-                )
+                return SimpleNamespace(value=state_at_block)
 
-            return SimpleNamespace(
-                value = self._handle_type_default(name, params)
-            )
+            return SimpleNamespace(value=self._handle_type_default(name, params))
         else:
-            return SimpleNamespace(
-                value = self._handle_type_default(name, params)
-            )
-            
-    def query_map_subtensor( self, name: str, block: Optional[int] = None, params: Optional[List[object]] = [] ) -> Optional[MockMapResult]:
+            return SimpleNamespace(value=self._handle_type_default(name, params))
+
+    def query_map_subtensor(
+        self,
+        name: str,
+        block: Optional[int] = None,
+        params: Optional[List[object]] = [],
+    ) -> Optional[MockMapResult]:
         """
         Note: Double map requires one param
         """
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
-        state = self.chain_state['SubtensorModule'][name]
+        state = self.chain_state["SubtensorModule"][name]
         if state is not None:
             # Use prefix
             if len(params) > 0:
                 while state is not None and len(params) > 0:
                     state = state.get(params.pop(0), None)
                     if state is None:
                         return MockMapResult([])
-            
+
             # Check if single map or double map
             if len(state.keys()) == 0:
                 return MockMapResult([])
-        
+
             inner = list(state.values())[0]
             # Should have at least one key
             if len(inner.keys()) == 0:
                 raise Exception("Invalid state")
-            
+
             # Check if double map
             if isinstance(list(inner.values())[0], dict):
                 # is double map
                 raise ChainQueryError("Double map requires one param")
-            
+
             # Iterate over each key and add value to list, max at block
             records = []
             for key in state:
                 result = self._get_most_recent_storage(state[key], block)
                 if result is None:
-                    continue # Skip if no result for this key at `block` or earlier
+                    continue  # Skip if no result for this key at `block` or earlier
 
                 records.append((key, result))
 
             return MockMapResult(records)
         else:
             return MockMapResult([])
 
-    def query_constant( self, module_name: str, constant_name: str, block: Optional[int] = None ) -> Optional[object]:
+    def query_constant(
+        self, module_name: str, constant_name: str, block: Optional[int] = None
+    ) -> Optional[object]:
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
         state = self.chain_state.get(module_name, None)
         if state is not None:
             if constant_name in state:
                 state = state[constant_name]
             else:
                 return None
-                    
+
             # Use block
             state_at_block = self._get_most_recent_storage(state, block)
             if state_at_block is not None:
                 return SimpleNamespace(value=state_at_block)
 
-            return state_at_block # Can be None
+            return state_at_block  # Can be None
         else:
             return None
 
-    def get_current_block( self ) -> int:
+    def get_current_block(self) -> int:
         return self.block_number
 
     # ==== Balance RPC methods ====
 
-    def get_balance(self, address: str, block: int = None) -> 'bittensor.Balance':
+    def get_balance(self, address: str, block: int = None) -> "bittensor.Balance":
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
-        state = self.chain_state['System']['Account']
+        state = self.chain_state["System"]["Account"]
         if state is not None:
             if address in state:
                 state = state[address]
             else:
                 return bittensor.Balance(0)
-                    
+
             # Use block
-            balance_state = state['data']['free']
-            state_at_block = self._get_most_recent_storage(balance_state, block) # Can be None
+            balance_state = state["data"]["free"]
+            state_at_block = self._get_most_recent_storage(
+                balance_state, block
+            )  # Can be None
             if state_at_block is not None:
                 bal_as_int = state_at_block
                 return bittensor.Balance.from_rao(bal_as_int)
             else:
                 return bittensor.Balance(0)
         else:
             return bittensor.Balance(0)
 
-    def get_balances(self, block: int = None) -> Dict[str, 'bittensor.Balance']:
+    def get_balances(self, block: int = None) -> Dict[str, "bittensor.Balance"]:
         balances = {}
-        for address in self.chain_state['System']['Account']:
+        for address in self.chain_state["System"]["Account"]:
             balances[address] = self.get_balance(address, block)
 
         return balances
 
     # ==== Neuron RPC methods ====
 
-    def neuron_for_uid( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfo]:
+    def neuron_for_uid(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfo]:
         if uid is None:
             return NeuronInfo._null_neuron()
-        
+
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
-        if netuid not in self.chain_state['SubtensorModule']['NetworksAdded']:
+        if netuid not in self.chain_state["SubtensorModule"]["NetworksAdded"]:
             return None
-        
-        neuron_info = self._neuron_subnet_exists( uid, netuid, block )
+
+        neuron_info = self._neuron_subnet_exists(uid, netuid, block)
         if neuron_info is None:
             return None
-        
+
         else:
             return neuron_info
 
-    def neurons(self, netuid: int, block: Optional[int] = None ) -> List[NeuronInfo]:
-        if netuid not in self.chain_state['SubtensorModule']['NetworksAdded']:
+    def neurons(self, netuid: int, block: Optional[int] = None) -> List[NeuronInfo]:
+        if netuid not in self.chain_state["SubtensorModule"]["NetworksAdded"]:
             raise Exception("Subnet does not exist")
-        
+
         neurons = []
-        subnet_n = self._get_most_recent_storage( self.chain_state['SubtensorModule']['SubnetworkN'][netuid], block )
-        for uid in range( subnet_n ):
-            neuron_info = self.neuron_for_uid( uid, netuid, block )
+        subnet_n = self._get_most_recent_storage(
+            self.chain_state["SubtensorModule"]["SubnetworkN"][netuid], block
+        )
+        for uid in range(subnet_n):
+            neuron_info = self.neuron_for_uid(uid, netuid, block)
             if neuron_info is not None:
                 neurons.append(neuron_info)
 
         return neurons
 
     @staticmethod
-    def _get_most_recent_storage( storage: Dict[BlockNumber, Any], block_number: Optional[int] = None ) -> Any:
+    def _get_most_recent_storage(
+        storage: Dict[BlockNumber, Any], block_number: Optional[int] = None
+    ) -> Any:
         if block_number is None:
             items = list(storage.items())
             items.sort(key=lambda x: x[0], reverse=True)
             if len(items) == 0:
                 return None
-            
+
             return items[0][1]
-        
+
         else:
             while block_number >= 0:
                 if block_number in storage:
                     return storage[block_number]
-                
+
                 block_number -= 1
-            
+
             return None
-        
-    def _get_axon_info( self, netuid: int, hotkey: str, block: Optional[int] = None ) -> AxonInfoDict:
+
+    def _get_axon_info(
+        self, netuid: int, hotkey: str, block: Optional[int] = None
+    ) -> AxonInfoDict:
         # Axons [netuid][hotkey][block_number]
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['Axons']:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["Axons"]:
             return AxonInfoDict.default()
-        
-        if hotkey not in subtensor_state['Axons'][netuid]:
+
+        if hotkey not in subtensor_state["Axons"][netuid]:
             return AxonInfoDict.default()
-        
-        result = self._get_most_recent_storage(subtensor_state['Axons'][netuid][hotkey], block)
+
+        result = self._get_most_recent_storage(
+            subtensor_state["Axons"][netuid][hotkey], block
+        )
         if not result:
             return AxonInfoDict.default()
-        
+
         return result
 
-    def _get_prometheus_info( self, netuid: int, hotkey: str, block: Optional[int] = None ) -> PrometheusInfoDict:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['Prometheus']:
+    def _get_prometheus_info(
+        self, netuid: int, hotkey: str, block: Optional[int] = None
+    ) -> PrometheusInfoDict:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["Prometheus"]:
             return PrometheusInfoDict.default()
-        
-        if hotkey not in subtensor_state['Prometheus'][netuid]:
+
+        if hotkey not in subtensor_state["Prometheus"][netuid]:
             return PrometheusInfoDict.default()
-        
-        result = self._get_most_recent_storage(subtensor_state['Prometheus'][netuid][hotkey], block)
+
+        result = self._get_most_recent_storage(
+            subtensor_state["Prometheus"][netuid][hotkey], block
+        )
         if not result:
             return PrometheusInfoDict.default()
-        
+
         return result
 
-    def _neuron_subnet_exists( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfo]:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+    def _neuron_subnet_exists(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfo]:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             return None
-        
-        if self._get_most_recent_storage(subtensor_state['SubnetworkN'][netuid]) <= uid:
+
+        if self._get_most_recent_storage(subtensor_state["SubnetworkN"][netuid]) <= uid:
             return None
-        
-        hotkey = self._get_most_recent_storage(subtensor_state['Keys'][netuid][uid])
+
+        hotkey = self._get_most_recent_storage(subtensor_state["Keys"][netuid][uid])
         if hotkey is None:
             return None
 
+        axon_info_ = self._get_axon_info(netuid, hotkey, block)
 
-        axon_info_ = self._get_axon_info( netuid, hotkey, block )
+        prometheus_info = self._get_prometheus_info(netuid, hotkey, block)
 
-        prometheus_info = self._get_prometheus_info( netuid, hotkey, block )
+        coldkey = self._get_most_recent_storage(subtensor_state["Owner"][hotkey], block)
+        active = self._get_most_recent_storage(
+            subtensor_state["Active"][netuid][uid], block
+        )
+        rank = self._get_most_recent_storage(
+            subtensor_state["Rank"][netuid][uid], block
+        )
+        emission = self._get_most_recent_storage(
+            subtensor_state["Emission"][netuid][uid], block
+        )
+        incentive = self._get_most_recent_storage(
+            subtensor_state["Incentive"][netuid][uid], block
+        )
+        consensus = self._get_most_recent_storage(
+            subtensor_state["Consensus"][netuid][uid], block
+        )
+        trust = self._get_most_recent_storage(
+            subtensor_state["Trust"][netuid][uid], block
+        )
+        validator_trust = self._get_most_recent_storage(
+            subtensor_state["ValidatorTrust"][netuid][uid], block
+        )
+        dividends = self._get_most_recent_storage(
+            subtensor_state["Dividends"][netuid][uid], block
+        )
+        pruning_score = self._get_most_recent_storage(
+            subtensor_state["PruningScores"][netuid][uid], block
+        )
+        last_update = self._get_most_recent_storage(
+            subtensor_state["LastUpdate"][netuid][uid], block
+        )
+        validator_permit = self._get_most_recent_storage(
+            subtensor_state["ValidatorPermit"][netuid][uid], block
+        )
 
+        weights = self._get_most_recent_storage(
+            subtensor_state["Weights"][netuid][uid], block
+        )
+        bonds = self._get_most_recent_storage(
+            subtensor_state["Bonds"][netuid][uid], block
+        )
 
-        coldkey = self._get_most_recent_storage(subtensor_state['Owner'][hotkey], block)
-        active = self._get_most_recent_storage(subtensor_state['Active'][netuid][uid], block)
-        rank = self._get_most_recent_storage(subtensor_state['Rank'][netuid][uid], block)
-        emission = self._get_most_recent_storage(subtensor_state['Emission'][netuid][uid], block)
-        incentive = self._get_most_recent_storage(subtensor_state['Incentive'][netuid][uid], block)
-        consensus = self._get_most_recent_storage(subtensor_state['Consensus'][netuid][uid], block)
-        trust = self._get_most_recent_storage(subtensor_state['Trust'][netuid][uid], block)
-        validator_trust = self._get_most_recent_storage(subtensor_state['ValidatorTrust'][netuid][uid], block)
-        dividends = self._get_most_recent_storage(subtensor_state['Dividends'][netuid][uid], block)
-        pruning_score = self._get_most_recent_storage(subtensor_state['PruningScores'][netuid][uid], block)
-        last_update = self._get_most_recent_storage(subtensor_state['LastUpdate'][netuid][uid], block)
-        validator_permit = self._get_most_recent_storage(subtensor_state['ValidatorPermit'][netuid][uid], block)
-        
-        weights = self._get_most_recent_storage(subtensor_state['Weights'][netuid][uid], block)
-        bonds = self._get_most_recent_storage(subtensor_state['Bonds'][netuid][uid], block)
-
-        stake_dict = {coldkey: bittensor.Balance.from_rao(self._get_most_recent_storage(
-            subtensor_state['Stake'][hotkey][coldkey], block
-        )) for coldkey in subtensor_state['Stake'][hotkey]}
+        stake_dict = {
+            coldkey: bittensor.Balance.from_rao(
+                self._get_most_recent_storage(
+                    subtensor_state["Stake"][hotkey][coldkey], block
+                )
+            )
+            for coldkey in subtensor_state["Stake"][hotkey]
+        }
 
         stake = sum(stake_dict.values())
 
-
         weights = [[int(weight[0]), int(weight[1])] for weight in weights]
         bonds = [[int(bond[0]), int(bond[1])] for bond in bonds]
         rank = U16_NORMALIZED_FLOAT(rank)
         emission = emission / RAOPERTAO
         incentive = U16_NORMALIZED_FLOAT(incentive)
         consensus = U16_NORMALIZED_FLOAT(consensus)
         trust = U16_NORMALIZED_FLOAT(trust)
         validator_trust = U16_NORMALIZED_FLOAT(validator_trust)
         dividends = U16_NORMALIZED_FLOAT(dividends)
         prometheus_info = PrometheusInfo.fix_decoded_values(prometheus_info)
-        axon_info_ = axon_info.from_neuron_info( {
-            'hotkey': hotkey,
-            'coldkey': coldkey,
-            'axon_info': axon_info_,
-        })
+        axon_info_ = axon_info.from_neuron_info(
+            {
+                "hotkey": hotkey,
+                "coldkey": coldkey,
+                "axon_info": axon_info_,
+            }
+        )
 
         neuron_info = NeuronInfo(
-            hotkey = hotkey,
-            coldkey = coldkey,
-            uid = uid,
-            netuid = netuid,
-            active = active,
-            rank = rank,
-            emission = emission,
-            incentive = incentive,
-            consensus = consensus,
-            trust = trust,
-            validator_trust = validator_trust,
-            dividends = dividends,
-            pruning_score = pruning_score,
-            last_update = last_update,
-            validator_permit = validator_permit,
-            stake = stake,
-            stake_dict = stake_dict,
+            hotkey=hotkey,
+            coldkey=coldkey,
+            uid=uid,
+            netuid=netuid,
+            active=active,
+            rank=rank,
+            emission=emission,
+            incentive=incentive,
+            consensus=consensus,
+            trust=trust,
+            validator_trust=validator_trust,
+            dividends=dividends,
+            pruning_score=pruning_score,
+            last_update=last_update,
+            validator_permit=validator_permit,
+            stake=stake,
+            stake_dict=stake_dict,
             total_stake=stake,
             prometheus_info=prometheus_info,
             axon_info=axon_info_,
-            weights = weights,
-            bonds = bonds,
+            weights=weights,
+            bonds=bonds,
             is_null=False,
         )
 
         return neuron_info
 
-
-    def neuron_for_uid_lite( self, uid: int, netuid: int, block: Optional[int] = None ) -> Optional[NeuronInfoLite]:
+    def neuron_for_uid_lite(
+        self, uid: int, netuid: int, block: Optional[int] = None
+    ) -> Optional[NeuronInfoLite]:
         if block:
             if self.block_number < block:
                 raise Exception("Cannot query block in the future")
-            
+
         else:
             block = self.block_number
 
-        if netuid not in self.chain_state['SubtensorModule']['NetworksAdded']:
+        if netuid not in self.chain_state["SubtensorModule"]["NetworksAdded"]:
             raise Exception("Subnet does not exist")
-        
-        neuron_info = self._neuron_subnet_exists( uid, netuid, block )
+
+        neuron_info = self._neuron_subnet_exists(uid, netuid, block)
         if neuron_info is None:
             return None
-        
+
         else:
             neuron_info_dict = neuron_info.__dict__
             del neuron_info
-            del neuron_info_dict['weights']
-            del neuron_info_dict['bonds']
+            del neuron_info_dict["weights"]
+            del neuron_info_dict["bonds"]
 
-            neuron_info_lite = NeuronInfoLite(
-                **neuron_info_dict
-            )
+            neuron_info_lite = NeuronInfoLite(**neuron_info_dict)
             return neuron_info_lite
 
-    def neurons_lite(self, netuid: int, block: Optional[int] = None ) -> List[NeuronInfoLite]:
-        if netuid not in self.chain_state['SubtensorModule']['NetworksAdded']:
+    def neurons_lite(
+        self, netuid: int, block: Optional[int] = None
+    ) -> List[NeuronInfoLite]:
+        if netuid not in self.chain_state["SubtensorModule"]["NetworksAdded"]:
             raise Exception("Subnet does not exist")
-        
+
         neurons = []
-        subnet_n = self._get_most_recent_storage( self.chain_state['SubtensorModule']['SubnetworkN'][netuid] )
+        subnet_n = self._get_most_recent_storage(
+            self.chain_state["SubtensorModule"]["SubnetworkN"][netuid]
+        )
         for uid in range(subnet_n):
-            neuron_info = self.neuron_for_uid_lite( uid, netuid, block )
+            neuron_info = self.neuron_for_uid_lite(uid, netuid, block)
             if neuron_info is not None:
                 neurons.append(neuron_info)
 
         return neurons
-    
+
     # Extrinsics
     def _do_delegation(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         delegate_ss58: str,
-        amount: 'bittensor.Balance',
+        amount: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
         # Check if delegate
-        if not self.is_hotkey_delegate(
-            hotkey_ss58 = delegate_ss58
-        ):
+        if not self.is_hotkey_delegate(hotkey_ss58=delegate_ss58):
             raise StakeError("Not a delegate")
-        
+
         # do stake
         success = self._do_stake(
-            wallet = wallet,
-            hotkey_ss58 = delegate_ss58,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
+            wallet=wallet,
+            hotkey_ss58=delegate_ss58,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
         )
 
         return success
-    
 
     def _do_undelegation(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         delegate_ss58: str,
-        amount: 'bittensor.Balance',
+        amount: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
         # Check if delegate
-        if not self.is_hotkey_delegate(
-            hotkey_ss58 = delegate_ss58
-        ):
+        if not self.is_hotkey_delegate(hotkey_ss58=delegate_ss58):
             raise StakeError("Not a delegate")
-        
+
         # do unstake
         self._do_unstake(
-            wallet = wallet,
-            hotkey_ss58 = delegate_ss58,
-            amount = amount,
-            wait_for_inclusion = wait_for_inclusion,
-            wait_for_finalization = wait_for_finalization,
+            wallet=wallet,
+            hotkey_ss58=delegate_ss58,
+            amount=amount,
+            wait_for_inclusion=wait_for_inclusion,
+            wait_for_finalization=wait_for_finalization,
         )
-    
+
     def _do_nominate(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
         hotkey_ss58 = wallet.hotkey.ss58_address
         coldkey_ss58 = wallet.coldkeypub.ss58_address
 
-        subtensor_state = self.chain_state['SubtensorModule']
-        if self.is_hotkey_delegate(
-            hotkey_ss58=hotkey_ss58
-        ):
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if self.is_hotkey_delegate(hotkey_ss58=hotkey_ss58):
             return True
-        
+
         else:
-            subtensor_state['Delegates'][hotkey_ss58] = {}
-            subtensor_state['Delegates'][hotkey_ss58][self.block_number] = 0.18 # Constant for now 
+            subtensor_state["Delegates"][hotkey_ss58] = {}
+            subtensor_state["Delegates"][hotkey_ss58][
+                self.block_number
+            ] = 0.18  # Constant for now
 
             return True
-        
+
     def get_transfer_fee(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         dest: str,
-        value: Union['bittensor.Balance', float, int],
-    ) -> 'bittensor.Balance':    
-        return bittensor.Balance( 700 )
-    
+        value: Union["bittensor.Balance", float, int],
+    ) -> "bittensor.Balance":
+        return bittensor.Balance(700)
+
     def _do_transfer(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         dest: str,
-        transfer_balance: 'bittensor.Balance',
+        transfer_balance: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> Tuple[bool, Optional[str], Optional[str]]:
         bal = self.get_balance(wallet.coldkeypub.ss58_address)
         dest_bal = self.get_balance(dest)
         transfer_fee = self.get_transfer_fee(wallet, dest, transfer_balance)
 
         existential_deposit = self.get_existential_deposit()
 
         if bal < transfer_balance + existential_deposit + transfer_fee:
             raise TransferError("Insufficient balance")
-        
+
         # Remove from the free balance
-        self.chain_state['System']['Account'][wallet.coldkeypub.ss58_address]['data']['free'][self.block_number] = (bal - transfer_balance - transfer_fee).rao
+        self.chain_state["System"]["Account"][wallet.coldkeypub.ss58_address]["data"][
+            "free"
+        ][self.block_number] = (bal - transfer_balance - transfer_fee).rao
 
         # Add to the free balance
-        if dest not in self.chain_state['System']['Account']:
-            self.chain_state['System']['Account'][dest] = {
-                'data': {
-                    'free': {},
+        if dest not in self.chain_state["System"]["Account"]:
+            self.chain_state["System"]["Account"][dest] = {
+                "data": {
+                    "free": {},
                 }
             }
 
-        self.chain_state['System']['Account'][dest]['data']['free'][self.block_number] = (dest_bal + transfer_balance).rao
+        self.chain_state["System"]["Account"][dest]["data"]["free"][
+            self.block_number
+        ] = (dest_bal + transfer_balance).rao
 
         return True, None, None
 
     def _do_pow_register(
         self,
         netuid: int,
-        wallet: 'bittensor.Wallet',
-        pow_result: 'POWSolution',
+        wallet: "bittensor.Wallet",
+        pow_result: "POWSolution",
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         # Assume pow result is valid
 
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             raise RegistrationError("Subnet does not exist")
 
         self._register_neuron(
             netuid=netuid,
             hotkey=wallet.hotkey.ss58_address,
             coldkey=wallet.coldkeypub.ss58_address,
         )
 
         return True, None
 
     def _do_burned_register(
         self,
         netuid: int,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
-        subtensor_state = self.chain_state['SubtensorModule']
-        if netuid not in subtensor_state['NetworksAdded']:
+        subtensor_state = self.chain_state["SubtensorModule"]
+        if netuid not in subtensor_state["NetworksAdded"]:
             raise RegistrationError("Subnet does not exist")
-        
-        bal = self.get_balance( wallet.coldkeypub.ss58_address )
-        burn = self.burn( netuid=netuid )
-        existential_deposit = self.get_existential_deposit( )
+
+        bal = self.get_balance(wallet.coldkeypub.ss58_address)
+        burn = self.burn(netuid=netuid)
+        existential_deposit = self.get_existential_deposit()
 
         if bal < burn + existential_deposit:
             raise RegistrationError("Insufficient funds")
 
         self._register_neuron(
             netuid=netuid,
             hotkey=wallet.hotkey.ss58_address,
             coldkey=wallet.coldkeypub.ss58_address,
         )
 
         # Burn the funds
-        self.chain_state['System']['Account'][wallet.coldkeypub.ss58_address]['data']['free'][self.block_number] = (bal - burn).rao
+        self.chain_state["System"]["Account"][wallet.coldkeypub.ss58_address]["data"][
+            "free"
+        ][self.block_number] = (bal - burn).rao
 
         return True, None
 
     def _do_stake(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         hotkey_ss58: str,
-        amount: 'bittensor.Balance',
+        amount: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
-        subtensor_state = self.chain_state['SubtensorModule']
-        
-        bal = self.get_balance( wallet.coldkeypub.ss58_address )
+        subtensor_state = self.chain_state["SubtensorModule"]
+
+        bal = self.get_balance(wallet.coldkeypub.ss58_address)
         curr_stake = self.get_stake_for_coldkey_and_hotkey(
-            hotkey_ss58=hotkey_ss58,
-            coldkey_ss58=wallet.coldkeypub.ss58_address,
+            hotkey_ss58=hotkey_ss58, coldkey_ss58=wallet.coldkeypub.ss58_address
         )
         if curr_stake is None:
             curr_stake = bittensor.Balance(0)
-        existential_deposit = self.get_existential_deposit( )
+        existential_deposit = self.get_existential_deposit()
 
         if bal < amount + existential_deposit:
             raise StakeError("Insufficient funds")
-        
-        stake_state = subtensor_state['Stake']
+
+        stake_state = subtensor_state["Stake"]
 
         # Stake the funds
         if not hotkey_ss58 in stake_state:
             stake_state[hotkey_ss58] = {}
         if not wallet.coldkeypub.ss58_address in stake_state[hotkey_ss58]:
             stake_state[hotkey_ss58][wallet.coldkeypub.ss58_address] = {}
-        
-        stake_state[hotkey_ss58][wallet.coldkeypub.ss58_address][self.block_number] = amount.rao
+
+        stake_state[hotkey_ss58][wallet.coldkeypub.ss58_address][
+            self.block_number
+        ] = amount.rao
 
         # Add to total_stake storage
-        subtensor_state['TotalStake'][self.block_number] = self._get_most_recent_storage(subtensor_state['TotalStake']) + amount.rao
+        subtensor_state["TotalStake"][self.block_number] = (
+            self._get_most_recent_storage(subtensor_state["TotalStake"]) + amount.rao
+        )
 
-        total_hotkey_stake_state = subtensor_state['TotalHotkeyStake']
+        total_hotkey_stake_state = subtensor_state["TotalHotkeyStake"]
         if not hotkey_ss58 in total_hotkey_stake_state:
             total_hotkey_stake_state[hotkey_ss58] = {}
 
-        total_coldkey_stake_state = subtensor_state['TotalColdkeyStake']
+        total_coldkey_stake_state = subtensor_state["TotalColdkeyStake"]
         if not wallet.coldkeypub.ss58_address in total_coldkey_stake_state:
             total_coldkey_stake_state[wallet.coldkeypub.ss58_address] = {}
 
         curr_total_hotkey_stake = self.query_subtensor(
-            name='TotalHotkeyStake',
+            name="TotalHotkeyStake",
             params=[hotkey_ss58],
             block=min(self.block_number - 1, 0),
         )
         curr_total_coldkey_stake = self.query_subtensor(
-            name='TotalColdkeyStake',
+            name="TotalColdkeyStake",
             params=[wallet.coldkeypub.ss58_address],
             block=min(self.block_number - 1, 0),
         )
 
-        total_hotkey_stake_state[hotkey_ss58][self.block_number] = curr_total_hotkey_stake.value + amount.rao
-        total_coldkey_stake_state[wallet.coldkeypub.ss58_address][self.block_number] = curr_total_coldkey_stake.value + amount.rao
-        
+        total_hotkey_stake_state[hotkey_ss58][self.block_number] = (
+            curr_total_hotkey_stake.value + amount.rao
+        )
+        total_coldkey_stake_state[wallet.coldkeypub.ss58_address][self.block_number] = (
+            curr_total_coldkey_stake.value + amount.rao
+        )
+
         # Remove from free balance
-        self.chain_state['System']['Account'][wallet.coldkeypub.ss58_address]['data']['free'][self.block_number] = (bal - amount).rao
+        self.chain_state["System"]["Account"][wallet.coldkeypub.ss58_address]["data"][
+            "free"
+        ][self.block_number] = (bal - amount).rao
 
         return True
 
     def _do_unstake(
         self,
-        wallet: 'bittensor.Wallet',
+        wallet: "bittensor.Wallet",
         hotkey_ss58: str,
-        amount: 'bittensor.Balance',
+        amount: "bittensor.Balance",
         wait_for_inclusion: bool = True,
         wait_for_finalization: bool = False,
     ) -> bool:
-        subtensor_state = self.chain_state['SubtensorModule']
-        
-        bal = self.get_balance( wallet.coldkeypub.ss58_address )
+        subtensor_state = self.chain_state["SubtensorModule"]
+
+        bal = self.get_balance(wallet.coldkeypub.ss58_address)
         curr_stake = self.get_stake_for_coldkey_and_hotkey(
-            hotkey_ss58=hotkey_ss58,
-            coldkey_ss58=wallet.coldkeypub.ss58_address,
+            hotkey_ss58=hotkey_ss58, coldkey_ss58=wallet.coldkeypub.ss58_address
         )
         if curr_stake is None:
             curr_stake = bittensor.Balance(0)
 
         if curr_stake < amount:
             raise StakeError("Insufficient funds")
-        
-        stake_state = subtensor_state['Stake']
+
+        stake_state = subtensor_state["Stake"]
 
         if curr_stake.rao == 0:
             return True
-        
+
         # Unstake the funds
         # We know that the hotkey has stake, so we can just remove it
-        stake_state[hotkey_ss58][wallet.coldkeypub.ss58_address][self.block_number] = (curr_stake - amount).rao
+        stake_state[hotkey_ss58][wallet.coldkeypub.ss58_address][self.block_number] = (
+            curr_stake - amount
+        ).rao
         # Add to the free balance
-        if wallet.coldkeypub.ss58_address not in self.chain_state['System']['Account']:
-            self.chain_state['System']['Account'][wallet.coldkeypub.ss58_address] = {
-                'data': {
-                    'free': {},
+        if wallet.coldkeypub.ss58_address not in self.chain_state["System"]["Account"]:
+            self.chain_state["System"]["Account"][wallet.coldkeypub.ss58_address] = {
+                "data": {
+                    "free": {},
                 }
             }
 
         # Remove from total stake storage
-        subtensor_state['TotalStake'][self.block_number] = self._get_most_recent_storage(subtensor_state['TotalStake']) - amount.rao
+        subtensor_state["TotalStake"][self.block_number] = (
+            self._get_most_recent_storage(subtensor_state["TotalStake"]) - amount.rao
+        )
 
-        total_hotkey_stake_state = subtensor_state['TotalHotkeyStake']
+        total_hotkey_stake_state = subtensor_state["TotalHotkeyStake"]
         if not hotkey_ss58 in total_hotkey_stake_state:
             total_hotkey_stake_state[hotkey_ss58] = {}
-            total_hotkey_stake_state[hotkey_ss58][self.block_number] = 0 # Shouldn't happen
+            total_hotkey_stake_state[hotkey_ss58][
+                self.block_number
+            ] = 0  # Shouldn't happen
 
-        total_coldkey_stake_state = subtensor_state['TotalColdkeyStake']
+        total_coldkey_stake_state = subtensor_state["TotalColdkeyStake"]
         if not wallet.coldkeypub.ss58_address in total_coldkey_stake_state:
             total_coldkey_stake_state[wallet.coldkeypub.ss58_address] = {}
-            total_coldkey_stake_state[wallet.coldkeypub.ss58_address][self.block_number] = amount.rao # Shouldn't happen
-
-        total_hotkey_stake_state[hotkey_ss58][self.block_number] = self._get_most_recent_storage(subtensor_state['TotalHotkeyStake'][hotkey_ss58]) - amount.rao
-        total_coldkey_stake_state[wallet.coldkeypub.ss58_address][self.block_number] = self._get_most_recent_storage(subtensor_state['TotalColdkeyStake'][wallet.coldkeypub.ss58_address]) - amount.rao
+            total_coldkey_stake_state[wallet.coldkeypub.ss58_address][
+                self.block_number
+            ] = amount.rao  # Shouldn't happen
+
+        total_hotkey_stake_state[hotkey_ss58][self.block_number] = (
+            self._get_most_recent_storage(
+                subtensor_state["TotalHotkeyStake"][hotkey_ss58]
+            )
+            - amount.rao
+        )
+        total_coldkey_stake_state[wallet.coldkeypub.ss58_address][self.block_number] = (
+            self._get_most_recent_storage(
+                subtensor_state["TotalColdkeyStake"][wallet.coldkeypub.ss58_address]
+            )
+            - amount.rao
+        )
 
-        self.chain_state['System']['Account'][wallet.coldkeypub.ss58_address]['data']['free'][self.block_number] = (bal + amount).rao
+        self.chain_state["System"]["Account"][wallet.coldkeypub.ss58_address]["data"][
+            "free"
+        ][self.block_number] = (bal + amount).rao
 
         return True
 
+    def get_delegate_by_hotkey(
+        self, hotkey_ss58: str, block: Optional[int] = None
+    ) -> Optional["bittensor.DelegateInfo"]:
+        subtensor_state = self.chain_state["SubtensorModule"]
 
-    def get_delegate_by_hotkey( self, hotkey_ss58: str, block: Optional[int] = None ) -> Optional['bittensor.DelegateInfo']:
-        subtensor_state = self.chain_state['SubtensorModule']
-
-        if hotkey_ss58 not in subtensor_state['Delegates']:
+        if hotkey_ss58 not in subtensor_state["Delegates"]:
             return None
-        
+
         newest_state = self._get_most_recent_storage(
-            subtensor_state['Delegates'][hotkey_ss58],
-            block
+            subtensor_state["Delegates"][hotkey_ss58], block
         )
         if newest_state is None:
             return None
-        
+
         nom_result = []
-        nominators = subtensor_state['Stake'][hotkey_ss58]
+        nominators = subtensor_state["Stake"][hotkey_ss58]
         for nominator in nominators:
             nom_amount = self.get_stake_for_coldkey_and_hotkey(
-                hotkey_ss58=hotkey_ss58,
-                coldkey_ss58=nominator,
-                block=block,
+                hotkey_ss58=hotkey_ss58, coldkey_ss58=nominator, block=block
             )
             if nom_amount is not None and nom_amount.rao > 0:
                 nom_result.append((nominator, nom_amount))
 
         registered_subnets = []
         for subnet in self.get_all_subnet_netuids(block=block):
             uid = self.get_uid_for_hotkey_on_subnet(
-                hotkey_ss58=hotkey_ss58,
-                netuid=subnet,
-                block=block,
+                hotkey_ss58=hotkey_ss58, netuid=subnet, block=block
             )
 
             if uid is not None:
                 registered_subnets.append((subnet, uid))
 
         info = DelegateInfo(
             hotkey_ss58=hotkey_ss58,
             total_stake=self.get_total_stake_for_hotkey(
                 ss58_address=hotkey_ss58,
-            ) or bittensor.Balance(0),
+            )
+            or bittensor.Balance(0),
             nominators=nom_result,
-            owner_ss58=self.get_hotkey_owner(
-                hotkey_ss58=hotkey_ss58,
-                block=block,
-            ),
+            owner_ss58=self.get_hotkey_owner(hotkey_ss58=hotkey_ss58, block=block),
             take=0.18,
-            validator_permits=[subnet for subnet, uid in registered_subnets if self.neuron_has_validator_permit( uid = uid, netuid = subnet, block=block )],
+            validator_permits=[
+                subnet
+                for subnet, uid in registered_subnets
+                if self.neuron_has_validator_permit(uid=uid, netuid=subnet, block=block)
+            ],
             registrations=[subnet for subnet, _ in registered_subnets],
-            return_per_1000=bittensor.Balance.from_tao(1234567), # Doesn't matter for mock?
-            total_daily_return=bittensor.Balance.from_tao(1234567), # Doesn't matter for mock?
+            return_per_1000=bittensor.Balance.from_tao(
+                1234567
+            ),  # Doesn't matter for mock?
+            total_daily_return=bittensor.Balance.from_tao(
+                1234567
+            ),  # Doesn't matter for mock?
         )
 
         return info
 
-
-    def get_delegates( self, block: Optional[int] = None ) -> List['bittensor.DelegateInfo']:
-        subtensor_state = self.chain_state['SubtensorModule']
+    def get_delegates(
+        self, block: Optional[int] = None
+    ) -> List["bittensor.DelegateInfo"]:
+        subtensor_state = self.chain_state["SubtensorModule"]
         delegates_info = []
-        for hotkey in subtensor_state['Delegates']:
+        for hotkey in subtensor_state["Delegates"]:
             info = self.get_delegate_by_hotkey(
                 hotkey_ss58=hotkey,
                 block=block,
             )
             if info is not None:
                 delegates_info.append(info)
 
         return delegates_info
 
-    def get_delegated( self, coldkey_ss58: str, block: Optional[int] = None ) -> List[Tuple['bittensor.DelegateInfo', 'bittensor.Balance']]:
-        """ Returns the list of delegates that a given coldkey is staked to.
-        """
+    def get_delegated(
+        self, coldkey_ss58: str, block: Optional[int] = None
+    ) -> List[Tuple["bittensor.DelegateInfo", "bittensor.Balance"]]:
+        """Returns the list of delegates that a given coldkey is staked to."""
         delegates = self.get_delegates(block=block)
 
         result = []
         for delegate in delegates:
             if coldkey_ss58 in delegate.nominators:
                 result.append((delegate, delegate.nominators[coldkey_ss58]))
 
         return result
-    
 
-    def get_all_subnets_info( self, block: Optional[int] = None ) -> List[SubnetInfo]:
-        subtensor_state = self.chain_state['SubtensorModule']
+    def get_all_subnets_info(self, block: Optional[int] = None) -> List[SubnetInfo]:
+        subtensor_state = self.chain_state["SubtensorModule"]
         result = []
-        for subnet in subtensor_state['NetworksAdded']:
+        for subnet in subtensor_state["NetworksAdded"]:
             info = self.get_subnet_info(
                 netuid=subnet,
                 block=block,
             )
             if info is not None:
                 result.append(info)
 
         return result
 
-    def get_subnet_info( self, netuid: int, block: Optional[int] = None ) -> Optional[SubnetInfo]:
+    def get_subnet_info(
+        self, netuid: int, block: Optional[int] = None
+    ) -> Optional[SubnetInfo]:
         if not self.subnet_exists(
             netuid=netuid,
             block=block,
         ):
             return None
-        
-        def query_subnet_info( name: str ) -> Optional[object]:
-            return self.query_subtensor(
-                name=name,
-                block=block,
-                params=[netuid]
-            ).value
-        
+
+        def query_subnet_info(name: str) -> Optional[object]:
+            return self.query_subtensor(name=name, block=block, params=[netuid]).value
+
         info = SubnetInfo(
             netuid=netuid,
-            rho = query_subnet_info(
-                name = 'Rho',
+            rho=query_subnet_info(
+                name="Rho",
             ),
             kappa=query_subnet_info(
-                name = 'Kappa',
+                name="Kappa",
             ),
             difficulty=query_subnet_info(
-                name = 'Difficulty',
+                name="Difficulty",
             ),
             immunity_period=query_subnet_info(
-                name = 'ImmunityPeriod',
+                name="ImmunityPeriod",
             ),
             validator_batch_size=query_subnet_info(
-                name = 'ValidatorBatchSize',
+                name="ValidatorBatchSize",
             ),
             validator_sequence_length=query_subnet_info(
-                name = 'ValidatorSequenceLength',
+                name="ValidatorSequenceLength",
             ),
             validator_epochs_per_reset=query_subnet_info(
-                name = 'ValidatorEpochsPerReset',
+                name="ValidatorEpochsPerReset",
             ),
             validator_epoch_length=query_subnet_info(
-                name = 'ValidatorEpochLength',
+                name="ValidatorEpochLength",
             ),
             max_allowed_validators=query_subnet_info(
-                name = 'MaxAllowedValidators',
+                name="MaxAllowedValidators",
             ),
             min_allowed_weights=query_subnet_info(
-                name = 'MinAllowedWeights',
+                name="MinAllowedWeights",
             ),
             max_weight_limit=query_subnet_info(
-                name = 'MaxWeightLimit',
+                name="MaxWeightLimit",
             ),
             scaling_law_power=query_subnet_info(
-                name = 'ScalingLawPower',
+                name="ScalingLawPower",
             ),
             synergy_scaling_law_power=query_subnet_info(
-                name = 'SynergyScalingLawPower',
+                name="SynergyScalingLawPower",
             ),
             subnetwork_n=query_subnet_info(
-                name = 'SubnetworkN',
+                name="SubnetworkN",
             ),
             max_n=query_subnet_info(
-                name = 'MaxAllowedUids',
+                name="MaxAllowedUids",
             ),
             blocks_since_epoch=query_subnet_info(
-                name = 'BlocksSinceLastStep',
+                name="BlocksSinceLastStep",
             ),
             tempo=query_subnet_info(
-                name = 'Tempo',
+                name="Tempo",
             ),
             modality=query_subnet_info(
-                name = 'NetworkModality',
+                name="NetworkModality",
             ),
             connection_requirements={
-                str(netuid_.value): percentile.value for netuid_, percentile in self.query_map_subtensor(
-                    name = 'NetworkConnect',
-                    block = block,
-                    params = [netuid]
+                str(netuid_.value): percentile.value
+                for netuid_, percentile in self.query_map_subtensor(
+                    name="NetworkConnect", block=block, params=[netuid]
                 ).records
             },
             emission_value=query_subnet_info(
-                name = 'EmissionValues',
+                name="EmissionValues",
             ),
             burn=query_subnet_info(
-                name = 'Burn',
+                name="Burn",
             ),
         )
 
         return info
 
     def _do_serve_prometheus(
         self,
-        wallet: 'bittensor.wallet',
-        call_params: 'PrometheusServeCallParams',
+        wallet: "bittensor.wallet",
+        call_params: "PrometheusServeCallParams",
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         return True, None
-    
+
     def _do_set_weights(
         self,
-        wallet: 'bittensor.wallet',
+        wallet: "bittensor.wallet",
         netuid: int,
         uids: int,
         vals: List[int],
         version_key: int,
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
         return True, None
-    
+
     def _do_serve_axon(
         self,
-        wallet: 'bittensor.wallet',
-        call_params: 'AxonServeCallParams',
+        wallet: "bittensor.wallet",
+        call_params: "AxonServeCallParams",
         wait_for_inclusion: bool = False,
         wait_for_finalization: bool = True,
     ) -> Tuple[bool, Optional[str]]:
-        return True, None
+        return True, None
```

### Comparing `bittensor-5.3.1/bittensor/_subtensor/types.py` & `bittensor-5.3.2/bittensor/_subtensor/types.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,26 +13,30 @@
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 from typing import TypedDict
 
+
 class AxonServeCallParams(TypedDict):
     """
     Axon serve chain call parameters.
     """
+
     version: int
     ip: int
     port: int
     ip_type: int
     netuid: int
 
+
 class PrometheusServeCallParams(TypedDict):
     """
     Prometheus serve chain call parameters.
     """
+
     version: int
     ip: int
     port: int
     ip_type: int
-    netuid: int
+    netuid: int
```

### Comparing `bittensor-5.3.1/bittensor/_synapse/synapse.py` & `bittensor-5.3.2/bittensor/_synapse/synapse.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,8 +1,8 @@
- # The MIT License (MIT)
+# The MIT License (MIT)
 # Copyright © 2021 Yuma Rao
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -21,162 +21,193 @@
 import asyncio
 import bittensor
 
 from typing import Union, Optional, Callable, List, Dict, Tuple
 from abc import ABC, abstractmethod
 from dataclasses import dataclass
 
+
 @dataclass
-class SynapseCall( ABC ):
-    """ Base class for all synapse calls."""
+class SynapseCall(ABC):
+    """Base class for all synapse calls."""
 
-    is_forward: bool # If it is an forward of backward
-    name: str # The name of the call.
+    is_forward: bool  # If it is an forward of backward
+    name: str  # The name of the call.
 
     def __init__(
         self,
-        synapse: 'bittensor.Synapse',
+        synapse: "bittensor.Synapse",
         request_proto: object,
         context: grpc.ServicerContext,
     ):
         metadata = dict(context.invocation_metadata())
         (
             _,
             sender_hotkey,
             _,
             _,
         ) = synapse.axon.auth_interceptor.parse_signature(metadata)
-        
+
         self.completed = False
         self.start_time = time.time()
         self.timeout = request_proto.timeout
         self.src_version = request_proto.version
         self.src_hotkey = sender_hotkey
         self.dest_hotkey = synapse.axon.wallet.hotkey.ss58_address
         self.dest_version = bittensor.__version_as_int__
-        self.return_code: bittensor.proto.ReturnCode = bittensor.proto.ReturnCode.Success
-        self.return_message: str = 'Success'
+        self.return_code: bittensor.proto.ReturnCode = (
+            bittensor.proto.ReturnCode.Success
+        )
+        self.return_message: str = "Success"
         self.priority: float = 0
 
     def __repr__(self) -> str:
         return f"SynapseCall( from: {self.src_hotkey}, forward: {self.is_forward}, start: {self.start_time}, timeout: {self.timeout}, priority: {self.priority}, completed: {self.completed})"
 
-    def __str__(self) -> str: return self.__repr__()
+    def __str__(self) -> str:
+        return self.__repr__()
 
     @abstractmethod
-    def get_inputs_shape( self ) -> torch.Size: ...
+    def get_inputs_shape(self) -> torch.Size:
+        ...
 
     @abstractmethod
-    def get_outputs_shape( self ) -> torch.Size: ...
+    def get_outputs_shape(self) -> torch.Size:
+        ...
 
     @abstractmethod
-    def get_response_proto( self ) -> object: ...
+    def get_response_proto(self) -> object:
+        ...
 
-    def _get_response_proto( self ) -> object:
+    def _get_response_proto(self) -> object:
         proto = self.get_response_proto()
         proto.return_code = self.return_code
         proto.return_message = self.return_message
         return proto
 
     @abstractmethod
-    def apply( self ): ...
+    def apply(self):
+        ...
 
-    def _apply( self ):
+    def _apply(self):
         # TODO(const): measure apply time.
         self.apply()
 
     def end(self):
         self.end_time = time.time()
         self.elapsed = self.end_time - self.start_time
         self.completed = True
 
-    def log_outbound( self ):
+    def log_outbound(self):
         bittensor.logging.rpc_log(
-            axon = True,
-            forward = self.is_forward,
-            is_response = False,
-            code = self.return_code,
-            call_time = 0,
-            pubkey = self.src_hotkey,
-            uid = None,
-            inputs = self.get_outputs_shape(),
-            outputs = self.get_outputs_shape(),
-            message = self.return_message,
-            synapse = self.name,
+            axon=True,
+            forward=self.is_forward,
+            is_response=False,
+            code=self.return_code,
+            call_time=0,
+            pubkey=self.src_hotkey,
+            uid=None,
+            inputs=self.get_outputs_shape(),
+            outputs=self.get_outputs_shape(),
+            message=self.return_message,
+            synapse=self.name,
         )
 
-    def log_inbound( self ):
+    def log_inbound(self):
         bittensor.logging.rpc_log(
-            axon = True,
-            forward = self.is_forward,
-            is_response = True,
-            code = self.return_code,
-            call_time = self.elapsed if self.completed else 0,
-            pubkey = self.src_hotkey,
-            uid = None,
-            inputs = self.get_inputs_shape(),
-            outputs = self.get_inputs_shape(),
-            message = self.return_message,
-            synapse = self.name
+            axon=True,
+            forward=self.is_forward,
+            is_response=True,
+            code=self.return_code,
+            call_time=self.elapsed if self.completed else 0,
+            pubkey=self.src_hotkey,
+            uid=None,
+            inputs=self.get_inputs_shape(),
+            outputs=self.get_inputs_shape(),
+            message=self.return_message,
+            synapse=self.name,
         )
 
-class Synapse( ABC ):
+
+class Synapse(ABC):
     name: str
 
-    def __init__( self, axon: bittensor.axon ):
+    def __init__(self, axon: bittensor.axon):
         self.axon = axon
 
     @abstractmethod
-    def blacklist( self, call: SynapseCall ) -> Union[ Tuple[bool, str], bool ]: ...
+    def blacklist(self, call: SynapseCall) -> Union[Tuple[bool, str], bool]:
+        ...
 
-    def _blacklist( self, call: SynapseCall ) -> Union[ bool, str ]:
-        blacklist = self.blacklist( call )
-        if isinstance( blacklist, tuple ): return blacklist
-        elif isinstance( blacklist, bool ): return blacklist, "no reason specified"
+    def _blacklist(self, call: SynapseCall) -> Union[bool, str]:
+        blacklist = self.blacklist(call)
+        if isinstance(blacklist, tuple):
+            return blacklist
+        elif isinstance(blacklist, bool):
+            return blacklist, "no reason specified"
         else:
-            raise ValueError('Blacklist response had type {} expected one of bool or Tuple[bool, str]'.format( blacklist ))
+            raise ValueError(
+                "Blacklist response had type {} expected one of bool or Tuple[bool, str]".format(
+                    blacklist
+                )
+            )
 
     @abstractmethod
-    def priority( self, call: SynapseCall ) -> float: ...
+    def priority(self, call: SynapseCall) -> float:
+        ...
 
-    def apply( self, call: SynapseCall ) -> object:
-        bittensor.logging.trace( 'Synapse: {} received call: {}'.format( self.name, call ) )
+    def apply(self, call: SynapseCall) -> object:
+        bittensor.logging.trace("Synapse: {} received call: {}".format(self.name, call))
         try:
             call.log_inbound()
 
             # Check blacklist.
-            blacklist, reason = self._blacklist( call )
+            blacklist, reason = self._blacklist(call)
             if blacklist:
                 call.return_code = bittensor.proto.ReturnCode.Blacklisted
                 call.return_message = reason
-                bittensor.logging.info( 'Synapse: {} blacklisted call: {} reason: {}'.format( self.name, call, reason) )
+                bittensor.logging.info(
+                    "Synapse: {} blacklisted call: {} reason: {}".format(
+                        self.name, call, reason
+                    )
+                )
 
             # Make call.
             else:
                 # Queue the forward call with priority.
-                call.priority = self.priority( call )
+                call.priority = self.priority(call)
                 future = self.axon.priority_threadpool.submit(
                     call._apply,
-                    priority = call.priority,
+                    priority=call.priority,
+                )
+                bittensor.logging.trace(
+                    "Synapse: {} loaded future: {}".format(self.name, future)
+                )
+                future.result(timeout=call.timeout)
+                bittensor.logging.trace(
+                    "Synapse: {} completed call: {}".format(self.name, call)
                 )
-                bittensor.logging.trace( 'Synapse: {} loaded future: {}'.format( self.name, future ) )
-                future.result( timeout = call.timeout )
-                bittensor.logging.trace( 'Synapse: {} completed call: {}'.format( self.name, call ) )
 
         # Catch timeouts
         except asyncio.TimeoutError:
-            bittensor.logging.trace( 'Synapse: {} timeout: {}'.format( self.name, call.timeout ) )
+            bittensor.logging.trace(
+                "Synapse: {} timeout: {}".format(self.name, call.timeout)
+            )
             call.return_code = bittensor.proto.ReturnCode.Timeout
-            call.return_message = 'GRPC request timeout after: {}s'.format( call.timeout)
+            call.return_message = "GRPC request timeout after: {}s".format(call.timeout)
 
         # Catch unknown exceptions.
         except Exception as e:
-            bittensor.logging.trace( 'Synapse: {} unknown error: {}'.format( self.name, str(e) ) )
+            bittensor.logging.trace(
+                "Synapse: {} unknown error: {}".format(self.name, str(e))
+            )
             call.return_code = bittensor.proto.ReturnCode.UnknownException
             call.return_message = str(e)
 
         # Finally return the call.
         finally:
-            bittensor.logging.trace( 'Synapse: {} finalize call {}'.format( self.name, call ) )
+            bittensor.logging.trace(
+                "Synapse: {} finalize call {}".format(self.name, call)
+            )
             call.end()
             call.log_outbound()
             return call._get_response_proto()
```

### Comparing `bittensor-5.3.1/bittensor/_synapse/text_prompting/synapse.py` & `bittensor-5.3.2/bittensor/_synapse/text_prompting/synapse.py`

 * *Files 10% similar despite different names*

```diff
@@ -20,98 +20,113 @@
 import bittensor
 
 from typing import List, Dict, Union, Callable
 from abc import abstractmethod
 import json
 
 
-class SynapseForward( bittensor.SynapseCall ):
+class SynapseForward(bittensor.SynapseCall):
     name: str = "text_prompting_forward"
     is_forward: bool = True
     completion: str = ""
 
     def __init__(
-            self,
-            synapse: "TextPromptingSynapse",
-            request_proto: bittensor.proto.ForwardTextPromptingRequest,
-            forward_callback: Callable,
-            context: grpc.ServicerContext
-        ):
-        super().__init__( synapse = synapse, request_proto = request_proto, context = context )
+        self,
+        synapse: "TextPromptingSynapse",
+        request_proto: bittensor.proto.ForwardTextPromptingRequest,
+        forward_callback: Callable,
+        context: grpc.ServicerContext,
+    ):
+        super().__init__(synapse=synapse, request_proto=request_proto, context=context)
         self.messages = request_proto.messages
-        self.formatted_messages = [ json.loads(message) for message in self.messages ]
+        self.formatted_messages = [json.loads(message) for message in self.messages]
         self.forward_callback = forward_callback
 
-    def apply( self ):
-        bittensor.logging.trace( "SynapseForward.apply()" )
-        self.completion = self.forward_callback( messages = self.formatted_messages )
-        bittensor.logging.trace( "SynapseForward.apply() = ", self.completion )
-
-    def get_response_proto( self ) -> bittensor.proto.ForwardTextPromptingResponse:
-        bittensor.logging.trace( "SynapseForward.get_response_proto()" )
-        return bittensor.ForwardTextPromptingResponse( response = self.completion )
+    def apply(self):
+        bittensor.logging.trace("SynapseForward.apply()")
+        self.completion = self.forward_callback(messages=self.formatted_messages)
+        bittensor.logging.trace("SynapseForward.apply() = ", self.completion)
+
+    def get_response_proto(self) -> bittensor.proto.ForwardTextPromptingResponse:
+        bittensor.logging.trace("SynapseForward.get_response_proto()")
+        return bittensor.ForwardTextPromptingResponse(response=self.completion)
 
     def get_inputs_shape(self) -> Union[torch.Size, None]:
-        bittensor.logging.trace( "SynapseForward.get_inputs_shape()" )
-        return torch.Size( [ len(message) for message in self.messages ] )
+        bittensor.logging.trace("SynapseForward.get_inputs_shape()")
+        return torch.Size([len(message) for message in self.messages])
 
     def get_outputs_shape(self) -> Union[torch.Size, None]:
-        bittensor.logging.trace( "SynapseForward.get_outputs_shape()" )
-        return torch.Size( [ len(self.completion) ]  )
+        bittensor.logging.trace("SynapseForward.get_outputs_shape()")
+        return torch.Size([len(self.completion)])
 
-class SynapseBackward( bittensor.SynapseCall ):
+
+class SynapseBackward(bittensor.SynapseCall):
     name: str = "text_prompting_backward"
     is_forward: bool = False
 
     def __init__(
-            self,
-            synapse: "TextPromptingSynapse",
-            request_proto: bittensor.proto.BackwardTextPromptingRequest,
-            backward_callback: Callable,
-            context: grpc.ServicerContext
-        ):
-        super().__init__( synapse = synapse, request_proto = request_proto, context = context )
-        self.formatted_messages = [ message for message in request_proto.messages ]
-        self.formatted_rewards = torch.tensor( [ request_proto.rewards ], dtype = torch.float32 )
+        self,
+        synapse: "TextPromptingSynapse",
+        request_proto: bittensor.proto.BackwardTextPromptingRequest,
+        backward_callback: Callable,
+        context: grpc.ServicerContext,
+    ):
+        super().__init__(synapse=synapse, request_proto=request_proto, context=context)
+        self.formatted_messages = [message for message in request_proto.messages]
+        self.formatted_rewards = torch.tensor(
+            [request_proto.rewards], dtype=torch.float32
+        )
         self.completion = request_proto.response
         self.backward_callback = backward_callback
 
-    def apply( self ):
+    def apply(self):
         self.backward_callback(
-            rewards = self.formatted_rewards,
-            messages = self.formatted_messages,
-            response = self.completion,
+            rewards=self.formatted_rewards,
+            messages=self.formatted_messages,
+            response=self.completion,
         )
 
-    def get_response_proto( self ) -> bittensor.proto.BackwardTextPromptingResponse:
-        return bittensor.BackwardTextPromptingResponse( )
+    def get_response_proto(self) -> bittensor.proto.BackwardTextPromptingResponse:
+        return bittensor.BackwardTextPromptingResponse()
 
     def get_inputs_shape(self) -> torch.Size:
-        return torch.Size( [ len(message) for message in self.formatted_messages ] )
+        return torch.Size([len(message) for message in self.formatted_messages])
 
     def get_outputs_shape(self) -> torch.Size:
-        return torch.Size( [ 0 ] )
+        return torch.Size([0])
 
 
-class TextPromptingSynapse( bittensor.Synapse, bittensor.grpc.TextPromptingServicer ):
+class TextPromptingSynapse(bittensor.Synapse, bittensor.grpc.TextPromptingServicer):
     name: str = "text_prompting_synapse"
 
-    def __init__(self, axon: "bittensor.axon" ):
-        super().__init__( axon = axon )
+    def __init__(self, axon: "bittensor.axon"):
+        super().__init__(axon=axon)
         self.axon = axon
-        bittensor.grpc.add_TextPromptingServicer_to_server( self, self.axon.server )
+        bittensor.grpc.add_TextPromptingServicer_to_server(self, self.axon.server)
 
     @abstractmethod
-    def forward( self, messages: List[Dict[str, str]] ) -> str: ...
+    def forward(self, messages: List[Dict[str, str]]) -> str:
+        ...
 
     @abstractmethod
-    def backward( self, messages: List[Dict[str, str]], response: str, rewards: torch.FloatTensor ) -> str: ...
-
-    def Forward( self, request: bittensor.proto.ForwardTextPromptingRequest, context: grpc.ServicerContext ) -> bittensor.proto.ForwardTextPromptingResponse:
-        call = SynapseForward( self, request, self.forward, context )
-        bittensor.logging.trace( 'Forward: {} '.format( call ) )
-        return self.apply( call = call )
-
-    def Backward( self, request: bittensor.proto.BackwardTextPromptingRequest, context: grpc.ServicerContext ) -> bittensor.proto.BackwardTextPromptingResponse:
-        call = SynapseBackward( self, request, self.backward, context )
-        bittensor.logging.trace( 'Backward: {}'.format( call ) )
-        return self.apply( call = call )
+    def backward(
+        self, messages: List[Dict[str, str]], response: str, rewards: torch.FloatTensor
+    ) -> str:
+        ...
+
+    def Forward(
+        self,
+        request: bittensor.proto.ForwardTextPromptingRequest,
+        context: grpc.ServicerContext,
+    ) -> bittensor.proto.ForwardTextPromptingResponse:
+        call = SynapseForward(self, request, self.forward, context)
+        bittensor.logging.trace("Forward: {} ".format(call))
+        return self.apply(call=call)
+
+    def Backward(
+        self,
+        request: bittensor.proto.BackwardTextPromptingRequest,
+        context: grpc.ServicerContext,
+    ) -> bittensor.proto.BackwardTextPromptingResponse:
+        call = SynapseBackward(self, request, self.backward, context)
+        bittensor.logging.trace("Backward: {}".format(call))
+        return self.apply(call=call)
```

### Comparing `bittensor-5.3.1/bittensor/_threadpool/__init__.py` & `bittensor-5.3.2/bittensor/_threadpool/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -19,83 +19,108 @@
 
 import os
 import argparse
 import copy
 import bittensor
 from . import priority_thread_pool_impl
 
+
 class prioritythreadpool:
-    """ Factory method for creating priority threadpool
-    """
+    """Factory method for creating priority threadpool"""
+
     def __new__(
-            cls,
-            config: 'bittensor.config' = None,
-            max_workers: int = None,
-            maxsize: int = None,
-        ):
-        r""" Initializes a priority thread pool.
-            Args:
-                config (:obj:`bittensor.Config`, `optional`):
-                    bittensor.subtensor.config()
-                max_workers (default=10, type=int)
-.                   The maximum number of threads in thread pool
-                maxsize (default=-1, type=int)
-                    The maximum number of tasks in the priority queue
+        cls,
+        config: "bittensor.config" = None,
+        max_workers: int = None,
+        maxsize: int = None,
+    ):
+        r"""Initializes a priority thread pool.
+                    Args:
+                        config (:obj:`bittensor.Config`, `optional`):
+                            bittensor.subtensor.config()
+                        max_workers (default=10, type=int)
+        .                   The maximum number of threads in thread pool
+                        maxsize (default=-1, type=int)
+                            The maximum number of tasks in the priority queue
         """
         if config == None:
             config = prioritythreadpool.config()
-        config = copy.deepcopy( config )
-        config.priority.max_workers = max_workers if max_workers != None else config.priority.max_workers
-        config.priority.maxsize = maxsize if maxsize != None else config.priority.maxsize
-
-        prioritythreadpool.check_config( config )
-        return priority_thread_pool_impl.PriorityThreadPoolExecutor(maxsize = config.priority.maxsize, max_workers = config.priority.max_workers)
+        config = copy.deepcopy(config)
+        config.priority.max_workers = (
+            max_workers if max_workers != None else config.priority.max_workers
+        )
+        config.priority.maxsize = (
+            maxsize if maxsize != None else config.priority.maxsize
+        )
+
+        prioritythreadpool.check_config(config)
+        return priority_thread_pool_impl.PriorityThreadPoolExecutor(
+            maxsize=config.priority.maxsize, max_workers=config.priority.max_workers
+        )
 
     @classmethod
-    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None ):
-        """ Accept specific arguments from parser
-        """
-        prefix_str = '' if prefix == None else prefix + '.'
+    def add_args(cls, parser: argparse.ArgumentParser, prefix: str = None):
+        """Accept specific arguments from parser"""
+        prefix_str = "" if prefix == None else prefix + "."
         if prefix is not None:
             if bittensor.defaults.get(prefix, d=None) == None:
                 setattr(bittensor.defaults, prefix, bittensor.Config())
             getattr(bittensor.defaults, prefix).priority = bittensor.defaults.priority
         try:
-            parser.add_argument('--' + prefix_str + 'priority.max_workers', type = int, help='''maximum number of threads in thread pool''', default = bittensor.defaults.priority.max_workers)
-            parser.add_argument('--' + prefix_str + 'priority.maxsize', type=int, help='''maximum size of tasks in priority queue''', default = bittensor.defaults.priority.maxsize)
+            parser.add_argument(
+                "--" + prefix_str + "priority.max_workers",
+                type=int,
+                help="""maximum number of threads in thread pool""",
+                default=bittensor.defaults.priority.max_workers,
+            )
+            parser.add_argument(
+                "--" + prefix_str + "priority.maxsize",
+                type=int,
+                help="""maximum size of tasks in priority queue""",
+                default=bittensor.defaults.priority.maxsize,
+            )
         except argparse.ArgumentError:
             # re-parsing arguments.
             pass
 
     @classmethod
     def help(cls):
-        """ Print help to stdout
-        """
+        """Print help to stdout"""
         parser = argparse.ArgumentParser()
-        cls.add_args( parser )
-        print (cls.__new__.__doc__)
+        cls.add_args(parser)
+        print(cls.__new__.__doc__)
         parser.print_help()
 
     @classmethod
     def add_defaults(cls, defaults):
-        """ Adds parser defaults to object from enviroment variables.
-        """
+        """Adds parser defaults to object from enviroment variables."""
         defaults.priority = bittensor.Config()
         defaults.priority = bittensor.Config()
-        defaults.priority.max_workers = os.getenv('BT_PRIORITY_MAX_WORKERS') if os.getenv('BT_PRIORITY_MAX_WORKERS') != None else 5
-        defaults.priority.maxsize = os.getenv('BT_PRIORITY_MAXSIZE') if os.getenv('BT_PRIORITY_MAXSIZE') != None else 10
+        defaults.priority.max_workers = (
+            os.getenv("BT_PRIORITY_MAX_WORKERS")
+            if os.getenv("BT_PRIORITY_MAX_WORKERS") != None
+            else 5
+        )
+        defaults.priority.maxsize = (
+            os.getenv("BT_PRIORITY_MAXSIZE")
+            if os.getenv("BT_PRIORITY_MAXSIZE") != None
+            else 10
+        )
 
     @classmethod
-    def config(cls) -> 'bittensor.Config':
-        """ Get config from the argument parser
-            Return: bittensor.config object
+    def config(cls) -> "bittensor.Config":
+        """Get config from the argument parser
+        Return: bittensor.config object
         """
         parser = argparse.ArgumentParser()
-        prioritythreadpool.add_args( parser )
-        return bittensor.config( parser )
+        prioritythreadpool.add_args(parser)
+        return bittensor.config(parser)
 
     @classmethod
-    def check_config(cls, config: 'bittensor.Config' ):
-        """ Check config for threadpool worker number and size
-        """
-        assert isinstance(config.priority.max_workers, int), 'priority.max_workers must be a int'
-        assert isinstance(config.priority.maxsize, int), 'priority.maxsize must be a int'
+    def check_config(cls, config: "bittensor.Config"):
+        """Check config for threadpool worker number and size"""
+        assert isinstance(
+            config.priority.max_workers, int
+        ), "priority.max_workers must be a int"
+        assert isinstance(
+            config.priority.maxsize, int
+        ), "priority.maxsize must be a int"
```

### Comparing `bittensor-5.3.1/bittensor/_threadpool/priority_thread_pool_impl.py` & `bittensor-5.3.2/bittensor/_threadpool/priority_thread_pool_impl.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,13 @@
-
 # Copyright 2009 Brian Quinlan. All Rights Reserved.
 # Licensed to PSF under a Contributor Agreement.
 
 """Implements ThreadPoolExecutor."""
 
-__author__ = 'Brian Quinlan (brian@sweetapp.com)'
+__author__ = "Brian Quinlan (brian@sweetapp.com)"
 
 import os
 import sys
 import bittensor
 from concurrent.futures import _base
 import itertools
 import queue
@@ -31,47 +30,50 @@
 # To work around this problem, an exit handler is installed which tells the
 # workers to exit when their work queues are empty and then waits until the
 # threads finish.
 
 _threads_queues = weakref.WeakKeyDictionary()
 _shutdown = False
 
+
 class _WorkItem(object):
     def __init__(self, future, fn, start_time, args, kwargs):
         self.future = future
         self.fn = fn
         self.start_time = start_time
         self.args = args
         self.kwargs = kwargs
 
     def run(self):
-        """ Run the given work item
-        """
+        """Run the given work item"""
         # Checks if future is canceled or if work item is stale
-        if (not self.future.set_running_or_notify_cancel()) or (time.time()-self.start_time > bittensor.__blocktime__):
+        if (not self.future.set_running_or_notify_cancel()) or (
+            time.time() - self.start_time > bittensor.__blocktime__
+        ):
             return
 
         try:
             result = self.fn(*self.args, **self.kwargs)
         except BaseException as exc:
             self.future.set_exception(exc)
             # Break a reference cycle with the exception 'exc'
             self = None
         else:
             self.future.set_result(result)
 
 
 NULL_ENTRY = (sys.maxsize, _WorkItem(None, None, time.time(), (), {}))
 
+
 def _worker(executor_reference, work_queue, initializer, initargs):
     if initializer is not None:
         try:
             initializer(*initargs)
         except BaseException:
-            _base.LOGGER.critical('Exception in initializer:', exc_info=True)
+            _base.LOGGER.critical("Exception in initializer:", exc_info=True)
             executor = executor_reference()
             if executor is not None:
                 executor._initializer_failed()
             return
     try:
         while True:
             work_item = work_queue.get(block=True)
@@ -96,32 +98,38 @@
                 if executor is not None:
                     executor._shutdown = True
                 # Notice other workers
                 work_queue.put(NULL_ENTRY)
                 return
             del executor
     except BaseException:
-        logger.error('work_item', work_item)
-        _base.LOGGER.critical('Exception in worker', exc_info=True)
+        logger.error("work_item", work_item)
+        _base.LOGGER.critical("Exception in worker", exc_info=True)
 
 
 class BrokenThreadPool(_base.BrokenExecutor):
     """
     Raised when a worker thread in a ThreadPoolExecutor failed initializing.
     """
 
 
 class PriorityThreadPoolExecutor(_base.Executor):
-    """ Base threadpool executor with a priority queue
-    """
+    """Base threadpool executor with a priority queue"""
+
     # Used to assign unique thread names when thread_name_prefix is not supplied.
     _counter = itertools.count().__next__
 
-    def __init__(self, maxsize = -1, max_workers=None, thread_name_prefix='',
-                 initializer=None, initargs=()):
+    def __init__(
+        self,
+        maxsize=-1,
+        max_workers=None,
+        thread_name_prefix="",
+        initializer=None,
+        initargs=(),
+    ):
         """Initializes a new ThreadPoolExecutor instance.
         Args:
             max_workers: The maximum number of threads that can be used to
                 execute the given calls.
             thread_name_prefix: An optional name prefix to give our threads.
             initializer: An callable used to initialize worker threads.
             initargs: A tuple of arguments to pass to the initializer.
@@ -133,85 +141,91 @@
         if max_workers <= 0:
             raise ValueError("max_workers must be greater than 0")
 
         if initializer is not None and not callable(initializer):
             raise TypeError("initializer must be a callable")
 
         self._max_workers = max_workers
-        self._work_queue = queue.PriorityQueue(maxsize = maxsize)
+        self._work_queue = queue.PriorityQueue(maxsize=maxsize)
         self._idle_semaphore = threading.Semaphore(0)
         self._threads = set()
         self._broken = False
         self._shutdown = False
         self._shutdown_lock = threading.Lock()
-        self._thread_name_prefix = (thread_name_prefix or
-                                    ("ThreadPoolExecutor-%d" % self._counter()))
+        self._thread_name_prefix = thread_name_prefix or (
+            "ThreadPoolExecutor-%d" % self._counter()
+        )
         self._initializer = initializer
         self._initargs = initargs
 
     @property
     def is_empty(self):
         return self._work_queue.empty()
 
     def submit(self, fn, *args, **kwargs):
         with self._shutdown_lock:
             if self._broken:
                 raise BrokenThreadPool(self._broken)
 
             if self._shutdown:
-                raise RuntimeError('cannot schedule new futures after shutdown')
+                raise RuntimeError("cannot schedule new futures after shutdown")
             if _shutdown:
-                raise RuntimeError('cannot schedule new futures after '
-                                   'interpreter shutdown')
+                raise RuntimeError(
+                    "cannot schedule new futures after " "interpreter shutdown"
+                )
 
-            priority = kwargs.get('priority', random.randint(0, 1000000))
+            priority = kwargs.get("priority", random.randint(0, 1000000))
             if priority == 0:
                 priority = random.randint(1, 100)
-            eplison = random.uniform(0,0.01) * priority
+            eplison = random.uniform(0, 0.01) * priority
             start_time = time.time()
-            if 'priority' in kwargs:
-                del kwargs['priority']
-
+            if "priority" in kwargs:
+                del kwargs["priority"]
 
             f = _base.Future()
             w = _WorkItem(f, fn, start_time, args, kwargs)
             self._work_queue.put((-float(priority + eplison), w), block=False)
             self._adjust_thread_count()
             return f
-    submit.__doc__ = _base.Executor.submit.__doc__
 
+    submit.__doc__ = _base.Executor.submit.__doc__
 
     def _adjust_thread_count(self):
         # if idle threads are available, don't spin new threads
         if self._idle_semaphore.acquire(timeout=0):
             return
 
         # When the executor gets lost, the weakref callback will wake up
         # the worker threads.
         def weakref_cb(_, q=self._work_queue):
             q.put(NULL_ENTRY)
 
         num_threads = len(self._threads)
         if num_threads < self._max_workers:
-            thread_name = '%s_%d' % (self._thread_name_prefix or self,
-                                     num_threads)
-            t = threading.Thread(name=thread_name, target=_worker,
-                                 args=(weakref.ref(self, weakref_cb),
-                                       self._work_queue,
-                                       self._initializer,
-                                       self._initargs))
+            thread_name = "%s_%d" % (self._thread_name_prefix or self, num_threads)
+            t = threading.Thread(
+                name=thread_name,
+                target=_worker,
+                args=(
+                    weakref.ref(self, weakref_cb),
+                    self._work_queue,
+                    self._initializer,
+                    self._initargs,
+                ),
+            )
             t.daemon = True
             t.start()
             self._threads.add(t)
             _threads_queues[t] = self._work_queue
 
     def _initializer_failed(self):
         with self._shutdown_lock:
-            self._broken = ('A thread initializer failed, the thread pool '
-                            'is not usable anymore')
+            self._broken = (
+                "A thread initializer failed, the thread pool " "is not usable anymore"
+            )
             # Drain work queue and mark pending futures failed
             while True:
                 try:
                     work_item = self._work_queue.get_nowait()
                 except queue.Empty:
                     break
                 if work_item is not None:
@@ -224,8 +238,9 @@
 
         if wait:
             for t in self._threads:
                 try:
                     t.join(timeout=2)
                 except Exception:
                     pass
+
     shutdown.__doc__ = _base.Executor.shutdown.__doc__
```

### Comparing `bittensor-5.3.1/bittensor/_tokenizer/__init__.py` & `bittensor-5.3.2/bittensor/_tokenizer/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,32 +19,31 @@
 
 from transformers import AutoTokenizer
 import bittensor
 from bittensor.utils.tokenizer_utils import prep_tokenizer
 
 
 class tokenizer:
-    """ Implementation of the bittensor tokenizer
-    """
+    """Implementation of the bittensor tokenizer"""
+
     cached_tokenizer_for_version: dict = {}
 
-    def __new__( cls, version: str = None ):
+    def __new__(cls, version: str = None):
         if version == None:
             version = bittensor.__version__
         if version not in cls.cached_tokenizer_for_version:
-            _tokenizer = cls.get_tokenizer_for_version( version )
-            cls.cached_tokenizer_for_version[ version ] = _tokenizer
+            _tokenizer = cls.get_tokenizer_for_version(version)
+            cls.cached_tokenizer_for_version[version] = _tokenizer
         else:
-            _tokenizer = cls.cached_tokenizer_for_version[ version ]
+            _tokenizer = cls.cached_tokenizer_for_version[version]
         return _tokenizer
 
     # Tokenizer
     # NOTE (const): tokenizers are guaranteed to improve and expand as time progresses. We version the tokenizer here.
     # neurons must be aware that versions will increase and be ready to convert between tokenizers.
     # TODO (const): Add functionality to allow tokenizer conversion. i.e. for input token conversion.
     @classmethod
-    def get_tokenizer_for_version( cls, version = bittensor.__version__ ):
-        """ Return the GPT2 tokenizer with bittersor's special tokens
-        """
-        _tokenizer = AutoTokenizer.from_pretrained('gpt2', local_files_only=False)
+    def get_tokenizer_for_version(cls, version=bittensor.__version__):
+        """Return the GPT2 tokenizer with bittersor's special tokens"""
+        _tokenizer = AutoTokenizer.from_pretrained("gpt2", local_files_only=False)
         _tokenizer = prep_tokenizer(_tokenizer)
         return _tokenizer
```

### Comparing `bittensor-5.3.1/bittensor/utils/__init__.py` & `bittensor-5.3.2/bittensor/utils/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,104 +12,120 @@
 
 from .registration import create_pow, __reregister_wallet as reregister
 
 RAOPERTAO = 1e9
 U16_MAX = 65535
 U64_MAX = 18446744073709551615
 
-def indexed_values_to_dataframe (
-        prefix: Union[str, int],
-        index: Union[list, torch.LongTensor],
-        values: Union[list, torch.Tensor],
-        filter_zeros: bool = False
-    ) -> 'pandas.DataFrame':
+
+def indexed_values_to_dataframe(
+    prefix: Union[str, int],
+    index: Union[list, torch.LongTensor],
+    values: Union[list, torch.Tensor],
+    filter_zeros: bool = False,
+) -> "pandas.DataFrame":
     # Type checking.
     if not isinstance(prefix, str) and not isinstance(prefix, numbers.Number):
-        raise ValueError('Passed prefix must have type str or Number')
+        raise ValueError("Passed prefix must have type str or Number")
     if isinstance(prefix, numbers.Number):
         prefix = str(prefix)
     if not isinstance(index, list) and not isinstance(index, torch.Tensor):
-        raise ValueError('Passed uids must have type list or torch.Tensor')
+        raise ValueError("Passed uids must have type list or torch.Tensor")
     if not isinstance(values, list) and not isinstance(values, torch.Tensor):
-        raise ValueError('Passed values must have type list or torch.Tensor')
+        raise ValueError("Passed values must have type list or torch.Tensor")
     if not isinstance(index, list):
         index = index.tolist()
     if not isinstance(values, list):
         values = values.tolist()
 
-    index = [ idx_i for idx_i in index if idx_i < len(values) and idx_i >= 0 ]
-    dataframe = pandas.DataFrame(columns=[prefix], index = index )
+    index = [idx_i for idx_i in index if idx_i < len(values) and idx_i >= 0]
+    dataframe = pandas.DataFrame(columns=[prefix], index=index)
     for idx_i in index:
-        value_i = values[ idx_i ]
+        value_i = values[idx_i]
         if value_i > 0 or not filter_zeros:
-            dataframe.loc[idx_i] = pandas.Series( { str(prefix): value_i } )
+            dataframe.loc[idx_i] = pandas.Series({str(prefix): value_i})
     return dataframe
 
 
-def unbiased_topk( values, k, dim=0, sorted = True, largest = True):
-    r""" Selects topk as in torch.topk but does not bias lower indices when values are equal.
-        Args:
-            values: (torch.Tensor)
-                Values to index into.
-            k: (int):
-                Number to take.
-
-        Return:
-            topk: (torch.Tensor):
-                topk k values.
-            indices: (torch.LongTensor)
-                indices of the topk values.
-    """
-    permutation = torch.randperm(values.shape[ dim ])
-    permuted_values = values[ permutation ]
-    topk, indices = torch.topk( permuted_values,  k, dim = dim, sorted=sorted, largest=largest )
-    return topk, permutation[ indices ]
+def unbiased_topk(values, k, dim=0, sorted=True, largest=True):
+    r"""Selects topk as in torch.topk but does not bias lower indices when values are equal.
+    Args:
+        values: (torch.Tensor)
+            Values to index into.
+        k: (int):
+            Number to take.
+
+    Return:
+        topk: (torch.Tensor):
+            topk k values.
+        indices: (torch.LongTensor)
+            indices of the topk values.
+    """
+    permutation = torch.randperm(values.shape[dim])
+    permuted_values = values[permutation]
+    topk, indices = torch.topk(
+        permuted_values, k, dim=dim, sorted=sorted, largest=largest
+    )
+    return topk, permutation[indices]
 
 
 def version_checking():
     response = requests.get(bittensor.__pipaddress__)
-    latest_version = response.json()['info']['version']
+    latest_version = response.json()["info"]["version"]
     version_split = latest_version.split(".")
-    latest_version_as_int = (100 * int(version_split[0])) + (10 * int(version_split[1])) + (1 * int(version_split[2]))
+    latest_version_as_int = (
+        (100 * int(version_split[0]))
+        + (10 * int(version_split[1]))
+        + (1 * int(version_split[2]))
+    )
 
     if latest_version_as_int > bittensor.__version_as_int__:
-        print('\u001b[33mBittensor Version: Current {}/Latest {}\nPlease update to the latest version at your earliest convenience\u001b[0m'.format(bittensor.__version__,latest_version))
+        print(
+            "\u001b[33mBittensor Version: Current {}/Latest {}\nPlease update to the latest version at your earliest convenience\u001b[0m".format(
+                bittensor.__version__, latest_version
+            )
+        )
 
 
-def strtobool_with_default( default: bool ) -> Callable[[str], Union[bool, Literal['==SUPRESS==']]]:
+def strtobool_with_default(
+    default: bool,
+) -> Callable[[str], Union[bool, Literal["==SUPRESS=="]]]:
     """
     Creates a strtobool function with a default value.
 
     Args:
         default(bool): The default value to return if the string is empty.
 
     Returns:
         The strtobool function with the default value.
     """
     return lambda x: strtobool(x) if x != "" else default
 
 
-def strtobool(val: str) -> Union[bool, Literal['==SUPRESS==']]:
+def strtobool(val: str) -> Union[bool, Literal["==SUPRESS=="]]:
     """
     Converts a string to a boolean value.
 
     truth-y values are 'y', 'yes', 't', 'true', 'on', and '1';
     false-y values are 'n', 'no', 'f', 'false', 'off', and '0'.
 
     Raises ValueError if 'val' is anything else.
     """
     val = val.lower()
-    if val in ('y', 'yes', 't', 'true', 'on', '1'):
+    if val in ("y", "yes", "t", "true", "on", "1"):
         return True
-    elif val in ('n', 'no', 'f', 'false', 'off', '0'):
+    elif val in ("n", "no", "f", "false", "off", "0"):
         return False
     else:
         raise ValueError("invalid truth value %r" % (val,))
 
-def get_explorer_root_url_by_network_from_map(network: str, network_map: Dict[str, str]) -> Optional[str]:
+
+def get_explorer_root_url_by_network_from_map(
+    network: str, network_map: Dict[str, str]
+) -> Optional[str]:
     r"""
     Returns the explorer root url for the given network name from the given network map.
 
     Args:
         network(str): The network to get the explorer url for.
         network_map(Dict[str, str]): The network map to get the explorer url from.
 
@@ -120,15 +136,17 @@
     explorer_url: Optional[str] = None
     if network in network_map:
         explorer_url = network_map[network]
 
     return explorer_url
 
 
-def get_explorer_url_for_network(network: str, block_hash: str, network_map: Dict[str, str]) -> Optional[str]:
+def get_explorer_url_for_network(
+    network: str, block_hash: str, network_map: Dict[str, str]
+) -> Optional[str]:
     r"""
     Returns the explorer url for the given block hash and network.
 
     Args:
         network(str): The network to get the explorer url for.
         block_hash(str): The block hash to get the explorer url for.
         network_map(Dict[str, str]): The network map to get the explorer url from.
@@ -136,41 +154,54 @@
     Returns:
         The explorer url for the given block hash and network.
         Or None if the network is not known.
     """
 
     explorer_url: Optional[str] = None
     # Will be None if the network is not known. i.e. not in network_map
-    explorer_root_url: Optional[str] = get_explorer_root_url_by_network_from_map(network, network_map)
+    explorer_root_url: Optional[str] = get_explorer_root_url_by_network_from_map(
+        network, network_map
+    )
 
     if explorer_root_url is not None:
         # We are on a known network.
-        explorer_url = "{root_url}/query/{block_hash}".format( root_url=explorer_root_url, block_hash = block_hash )
+        explorer_url = "{root_url}/query/{block_hash}".format(
+            root_url=explorer_root_url, block_hash=block_hash
+        )
 
     return explorer_url
 
+
 def ss58_address_to_bytes(ss58_address: str) -> bytes:
     """Converts a ss58 address to a bytes object."""
-    account_id_hex: str = scalecodec.ss58_decode(ss58_address, bittensor.__ss58_format__)
+    account_id_hex: str = scalecodec.ss58_decode(
+        ss58_address, bittensor.__ss58_format__
+    )
     return bytes.fromhex(account_id_hex)
 
-def U16_NORMALIZED_FLOAT( x: int ) -> float:
-    return float( x ) / float( U16_MAX )
 
-def U64_NORMALIZED_FLOAT( x: int ) -> float:
-    return float( x ) / float( U64_MAX )
+def U16_NORMALIZED_FLOAT(x: int) -> float:
+    return float(x) / float(U16_MAX)
+
+
+def U64_NORMALIZED_FLOAT(x: int) -> float:
+    return float(x) / float(U64_MAX)
+
 
 def u8_key_to_ss58(u8_key: List[int]) -> str:
     r"""
     Converts a u8-encoded account key to an ss58 address.
 
     Args:
         u8_key (List[int]): The u8-encoded account key.
     """
     # First byte is length, then 32 bytes of key.
-    return scalecodec.ss58_encode( bytes(u8_key).hex(), bittensor.__ss58_format__)
+    return scalecodec.ss58_encode(bytes(u8_key).hex(), bittensor.__ss58_format__)
 
-def type_or_suppress(type_func: Callable[[str], Any]) -> Callable[[str], Union[Any, Literal['==SUPRESS==']]]:
-    def _type_or_suppress(value: str) -> Union[Any, Literal['==SUPRESS==']]:
+
+def type_or_suppress(
+    type_func: Callable[[str], Any]
+) -> Callable[[str], Union[Any, Literal["==SUPRESS=="]]]:
+    def _type_or_suppress(value: str) -> Union[Any, Literal["==SUPRESS=="]]:
         return value if value == argparse.SUPPRESS else type_func(value)
-    
+
     return _type_or_suppress
```

### Comparing `bittensor-5.3.1/bittensor/utils/_register_cuda.py` & `bittensor-5.3.2/bittensor/utils/_register_cuda.py`

 * *Files 10% similar despite different names*

```diff
@@ -6,15 +6,23 @@
 import numpy as np
 from Crypto.Hash import keccak
 
 from contextlib import redirect_stdout
 import io
 
 
-def solve_cuda(nonce_start: np.int64, update_interval: np.int64, TPB: int, block_and_hotkey_hash_bytes: bytes, difficulty: int, limit: int, dev_id: int = 0) -> Tuple[np.int64, bytes]:
+def solve_cuda(
+    nonce_start: np.int64,
+    update_interval: np.int64,
+    TPB: int,
+    block_and_hotkey_hash_bytes: bytes,
+    difficulty: int,
+    limit: int,
+    dev_id: int = 0,
+) -> Tuple[np.int64, bytes]:
     """
     Solves the PoW problem using CUDA.
     Args:
         nonce_start: int64
             Starting nonce.
         update_interval: int64
             Number of nonces to solve before updating block information.
@@ -26,87 +34,93 @@
             Difficulty of the PoW problem.
         limit: int256
             Upper limit of the nonce.
         dev_id: int (default=0)
             The CUDA device ID
     Returns:
         Tuple[int64, bytes]
-            Tuple of the nonce and the seal corresponding to the solution.  
-            Returns -1 for nonce if no solution is found.     
-    """ 
+            Tuple of the nonce and the seal corresponding to the solution.
+            Returns -1 for nonce if no solution is found.
+    """
 
     try:
         import cubit
     except ImportError:
         raise ImportError("Please install cubit")
 
-
     upper = int(limit // difficulty)
 
-    upper_bytes = upper.to_bytes(32, byteorder='little', signed=False)
+    upper_bytes = upper.to_bytes(32, byteorder="little", signed=False)
 
-    def _hex_bytes_to_u8_list( hex_bytes: bytes ):
-        hex_chunks = [int(hex_bytes[i:i+2], 16) for i in range(0, len(hex_bytes), 2)]
+    def _hex_bytes_to_u8_list(hex_bytes: bytes):
+        hex_chunks = [
+            int(hex_bytes[i : i + 2], 16) for i in range(0, len(hex_bytes), 2)
+        ]
         return hex_chunks
 
-    def _create_seal_hash( block_and_hotkey_hash_hex: bytes, nonce:int ) -> bytes:
-        nonce_bytes = binascii.hexlify(nonce.to_bytes(8, 'little'))
+    def _create_seal_hash(block_and_hotkey_hash_hex: bytes, nonce: int) -> bytes:
+        nonce_bytes = binascii.hexlify(nonce.to_bytes(8, "little"))
         pre_seal = nonce_bytes + block_and_hotkey_hash_hex
-        seal_sh256 = hashlib.sha256( bytearray(_hex_bytes_to_u8_list(pre_seal)) ).digest()
+        seal_sh256 = hashlib.sha256(bytearray(_hex_bytes_to_u8_list(pre_seal))).digest()
         kec = keccak.new(digest_bits=256)
-        seal = kec.update( seal_sh256 ).digest()
+        seal = kec.update(seal_sh256).digest()
         return seal
 
-    def _seal_meets_difficulty( seal:bytes, difficulty:int ):
+    def _seal_meets_difficulty(seal: bytes, difficulty: int):
         seal_number = int.from_bytes(seal, "big")
         product = seal_number * difficulty
-        limit = int(math.pow(2,256)) - 1  
+        limit = int(math.pow(2, 256)) - 1
 
         return product < limit
 
     # Call cython function
     # int blockSize, uint64 nonce_start, uint64 update_interval, const unsigned char[:] limit,
     # const unsigned char[:] block_bytes, int dev_id
     block_and_hotkey_hash_hex = binascii.hexlify(block_and_hotkey_hash_bytes)[:64]
 
-    solution = cubit.solve_cuda(TPB, nonce_start, update_interval, upper_bytes, block_and_hotkey_hash_hex, dev_id) # 0 is first GPU
+    solution = cubit.solve_cuda(
+        TPB,
+        nonce_start,
+        update_interval,
+        upper_bytes,
+        block_and_hotkey_hash_hex,
+        dev_id,
+    )  # 0 is first GPU
     seal = None
     if solution != -1:
         seal = _create_seal_hash(block_and_hotkey_hash_hex, solution)
         if _seal_meets_difficulty(seal, difficulty):
             return solution, seal
         else:
-            return -1, b'\x00' * 32
+            return -1, b"\x00" * 32
 
     return solution, seal
 
+
 def reset_cuda():
     """
     Resets the CUDA environment.
     """
     try:
         import cubit
     except ImportError:
         raise ImportError("Please install cubit")
-        
+
     cubit.reset_cuda()
 
+
 def log_cuda_errors() -> str:
     """
     Logs any CUDA errors.
     """
     try:
         import cubit
     except ImportError:
         raise ImportError("Please install cubit")
 
     f = io.StringIO()
     with redirect_stdout(f):
         cubit.log_cuda_errors()
 
     s = f.getvalue()
-    
-    return s
-        
-    
-
 
+    return s
```

### Comparing `bittensor-5.3.1/bittensor/utils/balance.py` & `bittensor-5.3.2/bittensor/utils/balance.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,25 +14,26 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 from typing import Union
 
 import bittensor
 
+
 class Balance:
     """
     Represents the bittensor balance of the wallet, stored as rao (int)
     The Balance object is immutable, and can be used as a number or as a string
     Can only guarantee that the balance is accurate to 9 decimal places (tao)
 
     Note: In operations between Balance and int/float, the other value is assumed to be in rao
     """
 
-    unit: str = bittensor.__tao_symbol__ # This is the tao unit
-    rao_unit: str = bittensor.__rao_symbol__ # This is the rao unit
+    unit: str = bittensor.__tao_symbol__  # This is the tao unit
+    rao_unit: str = bittensor.__rao_symbol__  # This is the rao unit
     rao: int
     tao: float
 
     def __init__(self, balance: Union[int, float]):
         if isinstance(balance, int):
             self.rao = balance
         elif isinstance(balance, float):
@@ -108,21 +109,21 @@
                 return self.rao < other_rao
             except ValueError:
                 raise NotImplementedError("Unsupported type")
 
     def __le__(self, other: Union[int, float, "Balance"]):
         try:
             return self < other or self == other
-        except (TypeError):
+        except TypeError:
             raise NotImplementedError("Unsupported type")
 
     def __ge__(self, other: Union[int, float, "Balance"]):
         try:
             return self > other or self == other
-        except (TypeError):
+        except TypeError:
             raise NotImplementedError("Unsupported type")
 
     def __add__(self, other: Union[int, float, "Balance"]):
         if hasattr(other, "rao"):
             return Balance.from_rao(int(self.rao + other.rao))
         else:
             try:
@@ -130,27 +131,27 @@
                 return Balance.from_rao(int(self.rao + other))
             except (ValueError, TypeError):
                 raise NotImplementedError("Unsupported type")
 
     def __radd__(self, other: Union[int, float, "Balance"]):
         try:
             return self + other
-        except (TypeError):
+        except TypeError:
             raise NotImplementedError("Unsupported type")
 
     def __sub__(self, other: Union[int, float, "Balance"]):
         try:
             return self + -other
-        except (TypeError):
+        except TypeError:
             raise NotImplementedError("Unsupported type")
 
     def __rsub__(self, other: Union[int, float, "Balance"]):
         try:
             return -self + other
-        except (TypeError):
+        except TypeError:
             raise NotImplementedError("Unsupported type")
 
     def __mul__(self, other: Union[int, float, "Balance"]):
         if hasattr(other, "rao"):
             return Balance.from_rao(int(self.rao * other.rao))
         else:
             try:
```

### Comparing `bittensor-5.3.1/bittensor/utils/codes.py` & `bittensor-5.3.2/bittensor/utils/codes.py`

 * *Files 11% similar despite different names*

```diff
@@ -18,135 +18,136 @@
 # DEALINGS IN THE SOFTWARE.
 
 from loguru import logger
 import bittensor
 
 logger = logger.opt(colors=True)
 
-def code_to_string( code: 'bittensor.proto.ReturnCode' ) -> str:
-    """ Return code -> string
-    """
+
+def code_to_string(code: "bittensor.proto.ReturnCode") -> str:
+    """Return code -> string"""
     if code == 0:
-        return 'NoReturn'
+        return "NoReturn"
     elif code == 1:
-        return 'Success'
+        return "Success"
     elif code == 2:
-        return 'Timeout'
+        return "Timeout"
     elif code == 3:
-        return 'Backoff'
+        return "Backoff"
     elif code == 4:
-        return 'Unavailable'
+        return "Unavailable"
     elif code == 5:
-        return 'NotImplemented'
+        return "NotImplemented"
     elif code == 6:
-        return 'EmptyRequest'
+        return "EmptyRequest"
     elif code == 7:
-        return 'EmptyResponse'
+        return "EmptyResponse"
     elif code == 8:
-        return 'InvalidResponse'
+        return "InvalidResponse"
     elif code == 9:
-        return 'InvalidRequest'
+        return "InvalidRequest"
     elif code == 10:
-        return 'RequestShapeException'
+        return "RequestShapeException"
     elif code == 11:
-        return 'ResponseShapeException'
+        return "ResponseShapeException"
     elif code == 12:
-        return 'RequestSerializationException'
+        return "RequestSerializationException"
     elif code == 13:
-        return 'ResponseSerializationException'
+        return "ResponseSerializationException"
     elif code == 14:
-        return 'RequestDeserializationException'
+        return "RequestDeserializationException"
     elif code == 15:
-        return 'ResponseDeserializationException'
+        return "ResponseDeserializationException"
     elif code == 16:
-        return 'NotServingNucleus'
+        return "NotServingNucleus"
     elif code == 17:
-        return 'NucleusTimeout'
+        return "NucleusTimeout"
     elif code == 18:
-        return 'NucleusFull'
+        return "NucleusFull"
     elif code == 19:
-        return 'RequestIncompatibleVersion'
+        return "RequestIncompatibleVersion"
     elif code == 20:
-        return 'ResponseIncompatibleVersion'
+        return "ResponseIncompatibleVersion"
     elif code == 21:
-        return 'SenderUnknown'
+        return "SenderUnknown"
     elif code == 22:
-        return 'UnknownException'
+        return "UnknownException"
     elif code == 23:
-        return 'Unauthenticated'
+        return "Unauthenticated"
     elif code == 24:
-        return 'BadEndpoint'
+        return "BadEndpoint"
     elif code == 25:
-        return 'Blacklisted'
+        return "Blacklisted"
     else:
-        return 'UnknownCode'
+        return "UnknownCode"
+
 
-def code_to_loguru_color( code: 'bittensor.proto.ReturnCode' ) -> str:
-    """ Return code -> loguru color
-    """
+def code_to_loguru_color(code: "bittensor.proto.ReturnCode") -> str:
+    """Return code -> loguru color"""
     if code == 0:
-        return 'red'
+        return "red"
     elif code == 1:
-        return 'green'
+        return "green"
     elif code == 2:
-        return 'yellow'
+        return "yellow"
     elif code == 3:
-        return 'yellow'
+        return "yellow"
     elif code == 4:
-        return 'red'
+        return "red"
     elif code == 5:
-        return 'red'
+        return "red"
     elif code == 6:
-        return 'red'
+        return "red"
     elif code == 7:
-        return 'red'
+        return "red"
     elif code == 8:
-        return 'red'
+        return "red"
     elif code == 9:
-        return 'red'
+        return "red"
     elif code == 10:
-        return 'red'
+        return "red"
     elif code == 11:
-        return 'red'
+        return "red"
     elif code == 12:
-        return 'red'
+        return "red"
     elif code == 13:
-        return 'red'
+        return "red"
     elif code == 14:
-        return 'red'
+        return "red"
     elif code == 15:
-        return 'red'
+        return "red"
     elif code == 16:
-        return 'red'
+        return "red"
     elif code == 17:
-        return 'yellow'
+        return "yellow"
     elif code == 18:
-        return 'yellow'
+        return "yellow"
     elif code == 19:
-        return 'red'
+        return "red"
     elif code == 20:
-        return 'red'
+        return "red"
     elif code == 21:
-        return 'red'
+        return "red"
     elif code == 22:
-        return 'red'
+        return "red"
     elif code == 23:
-        return 'red'
+        return "red"
     elif code == 24:
-        return 'red'
+        return "red"
     elif code == 25:
-        return 'magenta'
+        return "magenta"
     else:
-        return 'red'
+        return "red"
+
 
-def code_to_synapse( code: 'bittensor.proto.Synapse.SynapseType'):
+def code_to_synapse(code: "bittensor.proto.Synapse.SynapseType"):
     """Return Code -> Synapse Type"""
     if code == 1:
-        return 'text_last_hidden_state'
+        return "text_last_hidden_state"
     elif code == 2:
-        return 'text_causal_lm'
+        return "text_causal_lm"
     elif code == 3:
-        return 'text_seq_2_seq'
+        return "text_seq_2_seq"
     elif code == 4:
-        return 'text_causal_lm_next'
+        return "text_causal_lm_next"
     else:
-        return 'Null'
+        return "Null"
```

### Comparing `bittensor-5.3.1/bittensor/utils/formatting.py` & `bittensor-5.3.2/bittensor/utils/formatting.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,16 +1,22 @@
 import math
 
+
 def get_human_readable(num, suffix="H"):
     for unit in ["", "K", "M", "G", "T", "P", "E", "Z"]:
         if abs(num) < 1000.0:
             return f"{num:3.1f}{unit}{suffix}"
         num /= 1000.0
     return f"{num:.1f}Y{suffix}"
 
+
 def millify(n: int):
-    millnames = ['',' K',' M',' B',' T']
+    millnames = ["", " K", " M", " B", " T"]
     n = float(n)
-    millidx = max(0,min(len(millnames)-1,
-                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))
+    millidx = max(
+        0,
+        min(
+            len(millnames) - 1, int(math.floor(0 if n == 0 else math.log10(abs(n)) / 3))
+        ),
+    )
 
-    return '{:.2f}{}'.format(n / 10**(3 * millidx), millnames[millidx])
+    return "{:.2f}{}".format(n / 10 ** (3 * millidx), millnames[millidx])
```

### Comparing `bittensor-5.3.1/bittensor/utils/networking.py` & `bittensor-5.3.2/bittensor/utils/networking.py`

 * *Files 8% similar despite different names*

```diff
@@ -22,198 +22,217 @@
 import json
 import miniupnpc
 import netaddr
 import requests
 
 from loguru import logger
 
+
 def int_to_ip(int_val: int) -> str:
-    r""" Maps an integer to a unique ip-string
-        Args:
-            int_val  (:type:`int128`, `required`):
-                The integer representation of an ip. Must be in the range (0, 3.4028237e+38).
-
-        Returns:
-            str_val (:tyep:`str`, `required):
-                The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
-
-        Raises:
-            netaddr.core.AddrFormatError (Exception):
-                Raised when the passed int_vals is not a valid ip int value.
+    r"""Maps an integer to a unique ip-string
+    Args:
+        int_val  (:type:`int128`, `required`):
+            The integer representation of an ip. Must be in the range (0, 3.4028237e+38).
+
+    Returns:
+        str_val (:tyep:`str`, `required):
+            The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
+
+    Raises:
+        netaddr.core.AddrFormatError (Exception):
+            Raised when the passed int_vals is not a valid ip int value.
     """
     return str(netaddr.IPAddress(int_val))
 
+
 def ip_to_int(str_val: str) -> int:
-    r""" Maps an ip-string to a unique integer.
-        arg:
-            str_val (:tyep:`str`, `required):
-                The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
-
-        Returns:
-            int_val  (:type:`int128`, `required`):
-                The integer representation of an ip. Must be in the range (0, 3.4028237e+38).
-
-        Raises:
-            netaddr.core.AddrFormatError (Exception):
-                Raised when the passed str_val is not a valid ip string value.
+    r"""Maps an ip-string to a unique integer.
+    arg:
+        str_val (:tyep:`str`, `required):
+            The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
+
+    Returns:
+        int_val  (:type:`int128`, `required`):
+            The integer representation of an ip. Must be in the range (0, 3.4028237e+38).
+
+    Raises:
+        netaddr.core.AddrFormatError (Exception):
+            Raised when the passed str_val is not a valid ip string value.
     """
     return int(netaddr.IPAddress(str_val))
 
+
 def ip_version(str_val: str) -> int:
-    r""" Returns the ip version (IPV4 or IPV6).
-        arg:
-            str_val (:tyep:`str`, `required):
-                The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
-
-        Returns:
-            int_val  (:type:`int128`, `required`):
-                The ip version (Either 4 or 6 for IPv4/IPv6)
-
-        Raises:
-            netaddr.core.AddrFormatError (Exception):
-                Raised when the passed str_val is not a valid ip string value.
+    r"""Returns the ip version (IPV4 or IPV6).
+    arg:
+        str_val (:tyep:`str`, `required):
+            The string representation of an ip. Of form *.*.*.* for ipv4 or *::*:*:*:* for ipv6
+
+    Returns:
+        int_val  (:type:`int128`, `required`):
+            The ip version (Either 4 or 6 for IPv4/IPv6)
+
+    Raises:
+        netaddr.core.AddrFormatError (Exception):
+            Raised when the passed str_val is not a valid ip string value.
     """
     return int(netaddr.IPAddress(str_val).version)
 
-def ip__str__(ip_type:int, ip_str:str, port:int):
-    """ Return a formatted ip string
-    """
+
+def ip__str__(ip_type: int, ip_str: str, port: int):
+    """Return a formatted ip string"""
     return "/ipv%i/%s:%i" % (ip_type, ip_str, port)
 
+
 class ExternalIPNotFound(Exception):
-    """ Raised if we cannot attain your external ip from CURL/URLLIB/IPIFY/AWS """
+    """Raised if we cannot attain your external ip from CURL/URLLIB/IPIFY/AWS"""
+
 
 def get_external_ip() -> str:
-    r""" Checks CURL/URLLIB/IPIFY/AWS for your external ip.
-        Returns:
-            external_ip  (:obj:`str` `required`):
-                Your routers external facing ip as a string.
-
-        Raises:
-            ExternalIPNotFound (Exception):
-                Raised if all external ip attempts fail.
+    r"""Checks CURL/URLLIB/IPIFY/AWS for your external ip.
+    Returns:
+        external_ip  (:obj:`str` `required`):
+            Your routers external facing ip as a string.
+
+    Raises:
+        ExternalIPNotFound (Exception):
+            Raised if all external ip attempts fail.
     """
     # --- Try AWS
     try:
-        external_ip = requests.get('https://checkip.amazonaws.com').text.strip()
+        external_ip = requests.get("https://checkip.amazonaws.com").text.strip()
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     # --- Try ipconfig.
     try:
-        process =  os.popen('curl -s ifconfig.me')
+        process = os.popen("curl -s ifconfig.me")
         external_ip = process.readline()
         process.close()
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     # --- Try ipinfo.
     try:
-        process =  os.popen('curl -s https://ipinfo.io')
-        external_ip = json.loads(process.read())['ip']
+        process = os.popen("curl -s https://ipinfo.io")
+        external_ip = json.loads(process.read())["ip"]
         process.close()
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     # --- Try myip.dnsomatic
     try:
-        process = os.popen('curl -s myip.dnsomatic.com')
-        external_ip  = process.readline()
+        process = os.popen("curl -s myip.dnsomatic.com")
+        external_ip = process.readline()
         process.close()
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     # --- Try urllib ipv6
     try:
-        external_ip = urllib.request.urlopen('https://ident.me').read().decode('utf8')
+        external_ip = urllib.request.urlopen("https://ident.me").read().decode("utf8")
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     # --- Try Wikipedia
     try:
-        external_ip = requests.get('https://www.wikipedia.org').headers['X-Client-IP']
+        external_ip = requests.get("https://www.wikipedia.org").headers["X-Client-IP"]
         assert isinstance(ip_to_int(external_ip), int)
         return str(external_ip)
     except Exception:
         pass
 
     raise ExternalIPNotFound
 
 
 class UPNPCException(Exception):
-    """ Raised when trying to perform a port mapping on your router. """
+    """Raised when trying to perform a port mapping on your router."""
 
 
 def upnpc_create_port_map(port: int):
-    r""" Creates a upnpc port map on your router from passed external_port to local port.
+    r"""Creates a upnpc port map on your router from passed external_port to local port.
 
-        Args:
-            port (int, `required`):
-                The local machine port to map from your external port.
-
-        Return:
-            external_port (int, `required`):
-                The external port mapped to the local port on your machine.
-
-        Raises:
-            UPNPCException (Exception):
-                Raised if UPNPC port mapping fails, for instance, if upnpc is not enabled on your router.
+    Args:
+        port (int, `required`):
+            The local machine port to map from your external port.
+
+    Return:
+        external_port (int, `required`):
+            The external port mapped to the local port on your machine.
+
+    Raises:
+        UPNPCException (Exception):
+            Raised if UPNPC port mapping fails, for instance, if upnpc is not enabled on your router.
     """
     try:
         upnp = miniupnpc.UPnP()
         upnp.discoverdelay = 200
-        logger.debug('UPNPC: Using UPnP to open a port on your router ...')
-        logger.debug('UPNPC: Discovering... delay={}ms', upnp.discoverdelay)
+        logger.debug("UPNPC: Using UPnP to open a port on your router ...")
+        logger.debug("UPNPC: Discovering... delay={}ms", upnp.discoverdelay)
         ndevices = upnp.discover()
         upnp.selectigd()
-        logger.debug('UPNPC: ' + str(ndevices) + ' device(s) detected')
+        logger.debug("UPNPC: " + str(ndevices) + " device(s) detected")
 
         ip = upnp.lanaddr
         external_ip = upnp.externalipaddress()
 
-        logger.debug('UPNPC: your local ip address: ' + str(ip))
-        logger.debug('UPNPC: your external ip address: ' + str(external_ip))
-        logger.debug('UPNPC: status = ' + str(upnp.statusinfo()) + " connection type = " + str(upnp.connectiontype()))
+        logger.debug("UPNPC: your local ip address: " + str(ip))
+        logger.debug("UPNPC: your external ip address: " + str(external_ip))
+        logger.debug(
+            "UPNPC: status = "
+            + str(upnp.statusinfo())
+            + " connection type = "
+            + str(upnp.connectiontype())
+        )
 
         # find a free port for the redirection
         external_port = port
-        rc = upnp.getspecificportmapping(external_port, 'TCP')
+        rc = upnp.getspecificportmapping(external_port, "TCP")
         while rc != None and external_port < 65536:
             external_port += 1
-            rc = upnp.getspecificportmapping(external_port, 'TCP')
+            rc = upnp.getspecificportmapping(external_port, "TCP")
         if rc != None:
             raise UPNPCException("UPNPC: No available external ports for port mapping.")
 
-        logger.info('UPNPC: trying to redirect remote: {}:{} => local: {}:{} over TCP', external_ip, external_port, ip, port)
-        upnp.addportmapping(external_port, 'TCP', ip, port, 'Bittensor: %u' % external_port, '')
-        logger.info('UPNPC: Create Success')
+        logger.info(
+            "UPNPC: trying to redirect remote: {}:{} => local: {}:{} over TCP",
+            external_ip,
+            external_port,
+            ip,
+            port,
+        )
+        upnp.addportmapping(
+            external_port, "TCP", ip, port, "Bittensor: %u" % external_port, ""
+        )
+        logger.info("UPNPC: Create Success")
 
         return external_port
 
     except Exception as e:
         raise UPNPCException(e) from e
 
+
 def get_formatted_ws_endpoint_url(endpoint_url: str) -> str:
     """
     Returns a formatted websocket endpoint url.
     Note: The port (or lack thereof) is left unchanged
     Args:
         endpoint_url (str, `required`):
             The endpoint url to format.
     Returns:
         formatted_endpoint_url (str, `required`):
             The formatted endpoint url. In the form of ws://<endpoint_url> or wss://<endpoint_url>
     """
     if endpoint_url[0:6] != "wss://" and endpoint_url[0:5] != "ws://":
         endpoint_url = "ws://{}".format(endpoint_url)
 
-    return endpoint_url
+    return endpoint_url
```

### Comparing `bittensor-5.3.1/bittensor/utils/registration.py` & `bittensor-5.3.2/bittensor/utils/registration.py`

 * *Files 22% similar despite different names*

```diff
@@ -20,42 +20,48 @@
 
 from .formatting import get_human_readable, millify
 from ._register_cuda import solve_cuda
 
 
 class CUDAException(Exception):
     """An exception raised when an error occurs in the CUDA environment."""
+
     pass
 
-def _hex_bytes_to_u8_list( hex_bytes: bytes ):
-    hex_chunks = [int(hex_bytes[i:i+2], 16) for i in range(0, len(hex_bytes), 2)]
+
+def _hex_bytes_to_u8_list(hex_bytes: bytes):
+    hex_chunks = [int(hex_bytes[i : i + 2], 16) for i in range(0, len(hex_bytes), 2)]
     return hex_chunks
 
-def _create_seal_hash( block_and_hotkey_hash_bytes: bytes, nonce:int ) -> bytes:
-    nonce_bytes = binascii.hexlify(nonce.to_bytes(8, 'little'))
+
+def _create_seal_hash(block_and_hotkey_hash_bytes: bytes, nonce: int) -> bytes:
+    nonce_bytes = binascii.hexlify(nonce.to_bytes(8, "little"))
     pre_seal = nonce_bytes + binascii.hexlify(block_and_hotkey_hash_bytes)[:64]
-    seal_sh256 = hashlib.sha256( bytearray(_hex_bytes_to_u8_list(pre_seal)) ).digest()
+    seal_sh256 = hashlib.sha256(bytearray(_hex_bytes_to_u8_list(pre_seal))).digest()
     kec = keccak.new(digest_bits=256)
-    seal = kec.update( seal_sh256 ).digest()
+    seal = kec.update(seal_sh256).digest()
     return seal
 
-def _seal_meets_difficulty( seal:bytes, difficulty:int, limit: int ):
+
+def _seal_meets_difficulty(seal: bytes, difficulty: int, limit: int):
     seal_number = int.from_bytes(seal, "big")
     product = seal_number * difficulty
     return product < limit
 
+
 @dataclass
 class POWSolution:
     """A solution to the registration PoW problem."""
+
     nonce: int
     block_number: int
     difficulty: int
     seal: bytes
 
-    def is_stale(self, subtensor: 'bittensor.Subtensor') -> bool:
+    def is_stale(self, subtensor: "bittensor.Subtensor") -> bool:
         """Returns True if the POW is stale.
         This means the block the POW is solved for is within 3 blocks of the current block.
         """
         return self.block_number < subtensor.get_current_block() - 3
 
 
 class _SolverBase(multiprocessing.Process):
@@ -96,29 +102,43 @@
             The main process will set the array to the new difficulty when a new block is finalized in the network.
             The solver process will get the new difficulty from this array when newBlockEvent is set.
         check_block: multiprocessing.Lock
             The lock to prevent this process from getting the new block data while the main process is updating the data.
         limit: int
             The limit of the pow solve for a valid solution.
     """
+
     proc_num: int
     num_proc: int
     update_interval: int
     finished_queue: multiprocessing.Queue
     solution_queue: multiprocessing.Queue
     newBlockEvent: multiprocessing.Event
     stopEvent: multiprocessing.Event
     hotkey_bytes: bytes
     curr_block: multiprocessing.Array
     curr_block_num: multiprocessing.Value
     curr_diff: multiprocessing.Array
     check_block: multiprocessing.Lock
     limit: int
 
-    def __init__(self, proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit):
+    def __init__(
+        self,
+        proc_num,
+        num_proc,
+        update_interval,
+        finished_queue,
+        solution_queue,
+        stopEvent,
+        curr_block,
+        curr_block_num,
+        curr_diff,
+        check_block,
+        limit,
+    ):
         multiprocessing.Process.__init__(self, daemon=True)
         self.proc_num = proc_num
         self.num_proc = num_proc
         self.update_interval = update_interval
         self.finished_queue = finished_queue
         self.solution_queue = solution_queue
         self.newBlockEvent = multiprocessing.Event()
@@ -128,87 +148,133 @@
         self.curr_diff = curr_diff
         self.check_block = check_block
         self.stopEvent = stopEvent
         self.limit = limit
 
     def run(self):
         raise NotImplementedError("_SolverBase is an abstract class")
+
     @staticmethod
-    def create_shared_memory() -> Tuple[multiprocessing.Array, multiprocessing.Value, multiprocessing.Array]:
-        """Creates shared memory for the solver processes to use.
-        """
-        curr_block = multiprocessing.Array('h', 32, lock=True) # byte array
-        curr_block_num = multiprocessing.Value('i', 0, lock=True) # int
-        curr_diff = multiprocessing.Array('Q', [0, 0], lock=True) # [high, low]
+    def create_shared_memory() -> (
+        Tuple[multiprocessing.Array, multiprocessing.Value, multiprocessing.Array]
+    ):
+        """Creates shared memory for the solver processes to use."""
+        curr_block = multiprocessing.Array("h", 32, lock=True)  # byte array
+        curr_block_num = multiprocessing.Value("i", 0, lock=True)  # int
+        curr_diff = multiprocessing.Array("Q", [0, 0], lock=True)  # [high, low]
 
         return curr_block, curr_block_num, curr_diff
 
+
 class _Solver(_SolverBase):
     def run(self):
         block_number: int
         block_and_hotkey_hash_bytes: bytes
         block_difficulty: int
-        nonce_limit = int(math.pow(2,64)) - 1
+        nonce_limit = int(math.pow(2, 64)) - 1
 
         # Start at random nonce
-        nonce_start = random.randint( 0, nonce_limit )
+        nonce_start = random.randint(0, nonce_limit)
         nonce_end = nonce_start + self.update_interval
         while not self.stopEvent.is_set():
             if self.newBlockEvent.is_set():
                 with self.check_block:
                     block_number = self.curr_block_num.value
                     block_and_hotkey_hash_bytes = bytes(self.curr_block)
                     block_difficulty = _registration_diff_unpack(self.curr_diff)
 
                 self.newBlockEvent.clear()
 
             # Do a block of nonces
-            solution = _solve_for_nonce_block(nonce_start, nonce_end, block_and_hotkey_hash_bytes, block_difficulty, self.limit, block_number)
+            solution = _solve_for_nonce_block(
+                nonce_start,
+                nonce_end,
+                block_and_hotkey_hash_bytes,
+                block_difficulty,
+                self.limit,
+                block_number,
+            )
             if solution is not None:
                 self.solution_queue.put(solution)
 
             try:
                 # Send time
                 self.finished_queue.put_nowait(self.proc_num)
             except Full:
                 pass
 
-            nonce_start = random.randint( 0, nonce_limit )
+            nonce_start = random.randint(0, nonce_limit)
             nonce_start = nonce_start % nonce_limit
             nonce_end = nonce_start + self.update_interval
 
 
 class _CUDASolver(_SolverBase):
     dev_id: int
     TPB: int
 
-    def __init__(self, proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit, dev_id: int, TPB: int):
-        super().__init__(proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit)
+    def __init__(
+        self,
+        proc_num,
+        num_proc,
+        update_interval,
+        finished_queue,
+        solution_queue,
+        stopEvent,
+        curr_block,
+        curr_block_num,
+        curr_diff,
+        check_block,
+        limit,
+        dev_id: int,
+        TPB: int,
+    ):
+        super().__init__(
+            proc_num,
+            num_proc,
+            update_interval,
+            finished_queue,
+            solution_queue,
+            stopEvent,
+            curr_block,
+            curr_block_num,
+            curr_diff,
+            check_block,
+            limit,
+        )
         self.dev_id = dev_id
         self.TPB = TPB
 
     def run(self):
-        block_number: int = 0 # dummy value
-        block_and_hotkey_hash_bytes: bytes = b'0' * 32 # dummy value
-        block_difficulty: int = int(math.pow(2,64)) - 1 # dummy value
-        nonce_limit = int(math.pow(2,64)) - 1 # U64MAX
+        block_number: int = 0  # dummy value
+        block_and_hotkey_hash_bytes: bytes = b"0" * 32  # dummy value
+        block_difficulty: int = int(math.pow(2, 64)) - 1  # dummy value
+        nonce_limit = int(math.pow(2, 64)) - 1  # U64MAX
 
         # Start at random nonce
-        nonce_start = random.randint( 0, nonce_limit )
+        nonce_start = random.randint(0, nonce_limit)
         while not self.stopEvent.is_set():
             if self.newBlockEvent.is_set():
                 with self.check_block:
                     block_number = self.curr_block_num.value
                     block_and_hotkey_hash_bytes = bytes(self.curr_block)
                     block_difficulty = _registration_diff_unpack(self.curr_diff)
 
                 self.newBlockEvent.clear()
 
             # Do a block of nonces
-            solution = _solve_for_nonce_block_cuda(nonce_start, self.update_interval, block_and_hotkey_hash_bytes, block_difficulty, self.limit, block_number, self.dev_id, self.TPB)
+            solution = _solve_for_nonce_block_cuda(
+                nonce_start,
+                self.update_interval,
+                block_and_hotkey_hash_bytes,
+                block_difficulty,
+                self.limit,
+                block_number,
+                self.dev_id,
+                self.TPB,
+            )
             if solution is not None:
                 self.solution_queue.put(solution)
 
             try:
                 # Signal that a nonce_block was finished using queue
                 # send our proc_num
                 self.finished_queue.put(self.proc_num)
@@ -216,35 +282,50 @@
                 pass
 
             # increase nonce by number of nonces processed
             nonce_start += self.update_interval * self.TPB
             nonce_start = nonce_start % nonce_limit
 
 
-def _solve_for_nonce_block_cuda(nonce_start: int, update_interval: int, block_and_hotkey_hash_bytes: bytes, difficulty: int, limit: int, block_number: int, dev_id: int, TPB: int) -> Optional[POWSolution]:
+def _solve_for_nonce_block_cuda(
+    nonce_start: int,
+    update_interval: int,
+    block_and_hotkey_hash_bytes: bytes,
+    difficulty: int,
+    limit: int,
+    block_number: int,
+    dev_id: int,
+    TPB: int,
+) -> Optional[POWSolution]:
     """Tries to solve the POW on a CUDA device for a block of nonces (nonce_start, nonce_start + update_interval * TPB"""
     solution, seal = solve_cuda(
-                    nonce_start,
-                    update_interval,
-                    TPB,
-                    block_and_hotkey_hash_bytes,
-                    difficulty,
-                    limit,
-                    dev_id)
-    
-
+        nonce_start,
+        update_interval,
+        TPB,
+        block_and_hotkey_hash_bytes,
+        difficulty,
+        limit,
+        dev_id,
+    )
 
-    if (solution != -1):
+    if solution != -1:
         # Check if solution is valid (i.e. not -1)
         return POWSolution(solution, block_number, difficulty, seal)
 
     return None
 
 
-def _solve_for_nonce_block(nonce_start: int, nonce_end: int, block_and_hotkey_hash_bytes: bytes, difficulty: int, limit: int, block_number: int) -> Optional[POWSolution]:
+def _solve_for_nonce_block(
+    nonce_start: int,
+    nonce_end: int,
+    block_and_hotkey_hash_bytes: bytes,
+    difficulty: int,
+    limit: int,
+    block_number: int,
+) -> Optional[POWSolution]:
     """Tries to solve the POW for a block of nonces (nonce_start, nonce_end)"""
     for nonce in range(nonce_start, nonce_end):
         # Create seal.
         seal = _create_seal_hash(block_and_hotkey_hash_bytes, nonce)
 
         # Check if seal meets difficulty
         if _seal_meets_difficulty(seal, difficulty, limit):
@@ -258,26 +339,35 @@
     """Unpacks the packed two 32-bit integers into one 64-bit integer. Little endian."""
     return int(packed_diff[0] << 32 | packed_diff[1])
 
 
 def _registration_diff_pack(diff: int, packed_diff: multiprocessing.Array):
     """Packs the difficulty into two 32-bit integers. Little endian."""
     packed_diff[0] = diff >> 32
-    packed_diff[1] = diff & 0xFFFFFFFF # low 32 bits
+    packed_diff[1] = diff & 0xFFFFFFFF  # low 32 bits
 
 
 def _hash_block_with_hotkey(block_bytes: bytes, hotkey_bytes: bytes) -> bytes:
     """Hashes the block with the hotkey using Keccak-256 to get 32 bytes"""
     kec = keccak.new(digest_bits=256)
     kec = kec.update(bytearray(block_bytes + hotkey_bytes))
     block_and_hotkey_hash_bytes = kec.digest()
     return block_and_hotkey_hash_bytes
 
 
-def _update_curr_block(curr_diff: multiprocessing.Array, curr_block: multiprocessing.Array, curr_block_num: multiprocessing.Value, block_number: int, block_bytes: bytes, diff: int, hotkey_bytes: bytes, lock: multiprocessing.Lock):
+def _update_curr_block(
+    curr_diff: multiprocessing.Array,
+    curr_block: multiprocessing.Array,
+    curr_block_num: multiprocessing.Value,
+    block_number: int,
+    block_bytes: bytes,
+    diff: int,
+    hotkey_bytes: bytes,
+    lock: multiprocessing.Lock,
+):
     with lock:
         curr_block_num.value = block_number
         # Hash the block with the hotkey
         block_and_hotkey_hash_bytes = _hash_block_with_hotkey(block_bytes, hotkey_bytes)
         for i in range(32):
             curr_block[i] = block_and_hotkey_hash_bytes[i]
         _registration_diff_pack(diff, curr_diff)
@@ -286,74 +376,94 @@
 def get_cpu_count() -> int:
     try:
         return len(os.sched_getaffinity(0))
     except AttributeError:
         # OSX does not have sched_getaffinity
         return os.cpu_count()
 
+
 @dataclass
 class RegistrationStatistics:
     """Statistics for a registration."""
+
     time_spent_total: float
     rounds_total: int
     time_average: float
     time_spent: float
     hash_rate_perpetual: float
     hash_rate: float
     difficulty: int
     block_number: int
     block_hash: bytes
 
 
 class RegistrationStatisticsLogger:
     """Logs statistics for a registration."""
+
     console: rich_console.Console
     status: Optional[rich_status.Status]
 
-    def __init__( self, console: rich_console.Console, output_in_place: bool = True) -> None:
+    def __init__(
+        self, console: rich_console.Console, output_in_place: bool = True
+    ) -> None:
         self.console = console
 
         if output_in_place:
             self.status = self.console.status("Solving")
         else:
             self.status = None
 
-    def start( self ) -> None:
+    def start(self) -> None:
         if self.status is not None:
             self.status.start()
 
-    def stop( self ) -> None:
+    def stop(self) -> None:
         if self.status is not None:
             self.status.stop()
 
-
-    def get_status_message(cls, stats: RegistrationStatistics, verbose: bool = False) -> str:
-        message = \
-        "Solving\n" + \
-        f"Time Spent (total): [bold white]{timedelta(seconds=stats.time_spent_total)}[/bold white]\n" + \
-        (
-            f"Time Spent This Round: {timedelta(seconds=stats.time_spent)}\n" + \
-            f"Time Spent Average: {timedelta(seconds=stats.time_average)}\n" if verbose else ""
-        ) + \
-        f"Registration Difficulty: [bold white]{millify(stats.difficulty)}[/bold white]\n" + \
-        f"Iters (Inst/Perp): [bold white]{get_human_readable(stats.hash_rate, 'H')}/s / " + \
-            f"{get_human_readable(stats.hash_rate_perpetual, 'H')}/s[/bold white]\n" + \
-        f"Block Number: [bold white]{stats.block_number}[/bold white]\n" + \
-        f"Block Hash: [bold white]{stats.block_hash.encode('utf-8')}[/bold white]\n"
+    def get_status_message(
+        cls, stats: RegistrationStatistics, verbose: bool = False
+    ) -> str:
+        message = (
+            "Solving\n"
+            + f"Time Spent (total): [bold white]{timedelta(seconds=stats.time_spent_total)}[/bold white]\n"
+            + (
+                f"Time Spent This Round: {timedelta(seconds=stats.time_spent)}\n"
+                + f"Time Spent Average: {timedelta(seconds=stats.time_average)}\n"
+                if verbose
+                else ""
+            )
+            + f"Registration Difficulty: [bold white]{millify(stats.difficulty)}[/bold white]\n"
+            + f"Iters (Inst/Perp): [bold white]{get_human_readable(stats.hash_rate, 'H')}/s / "
+            + f"{get_human_readable(stats.hash_rate_perpetual, 'H')}/s[/bold white]\n"
+            + f"Block Number: [bold white]{stats.block_number}[/bold white]\n"
+            + f"Block Hash: [bold white]{stats.block_hash.encode('utf-8')}[/bold white]\n"
+        )
         return message
 
-
-    def update( self, stats: RegistrationStatistics, verbose: bool = False ) -> None:
+    def update(self, stats: RegistrationStatistics, verbose: bool = False) -> None:
         if self.status is not None:
-            self.status.update( self.get_status_message(stats, verbose=verbose) )
+            self.status.update(self.get_status_message(stats, verbose=verbose))
         else:
-            self.console.log( self.get_status_message(stats, verbose=verbose), )
+            self.console.log(
+                self.get_status_message(stats, verbose=verbose),
+            )
 
 
-def _solve_for_difficulty_fast( subtensor, wallet: 'bittensor.Wallet', netuid: int, output_in_place: bool = True, num_processes: Optional[int] = None, update_interval: Optional[int] = None,  n_samples: int = 10, alpha_: float = 0.80, log_verbose: bool = False ) -> Optional[POWSolution]:
+def _solve_for_difficulty_fast(
+    subtensor,
+    wallet: "bittensor.Wallet",
+    netuid: int,
+    output_in_place: bool = True,
+    num_processes: Optional[int] = None,
+    update_interval: Optional[int] = None,
+    n_samples: int = 10,
+    alpha_: float = 0.80,
+    log_verbose: bool = False,
+) -> Optional[POWSolution]:
     """
     Solves the POW for registration using multiprocessing.
     Args:
         subtensor
             Subtensor to connect to for block information and to submit.
         wallet:
             Wallet to use for registration.
@@ -380,151 +490,181 @@
     if num_processes == None:
         # get the number of allowed processes for this process
         num_processes = min(1, get_cpu_count())
 
     if update_interval is None:
         update_interval = 50_000
 
-    limit = int(math.pow(2,256)) - 1
+    limit = int(math.pow(2, 256)) - 1
 
     curr_block, curr_block_num, curr_diff = _Solver.create_shared_memory()
 
     # Establish communication queues
     ## See the _Solver class for more information on the queues.
     stopEvent = multiprocessing.Event()
     stopEvent.clear()
 
     solution_queue = multiprocessing.Queue()
     finished_queues = [multiprocessing.Queue() for _ in range(num_processes)]
     check_block = multiprocessing.Lock()
 
     hotkey_bytes = wallet.hotkey.public_key
     # Start consumers
-    solvers = [ _Solver(i, num_processes, update_interval, finished_queues[i], solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit)
-                for i in range(num_processes) ]
+    solvers = [
+        _Solver(
+            i,
+            num_processes,
+            update_interval,
+            finished_queues[i],
+            solution_queue,
+            stopEvent,
+            curr_block,
+            curr_block_num,
+            curr_diff,
+            check_block,
+            limit,
+        )
+        for i in range(num_processes)
+    ]
 
     # Get first block
-    block_number, difficulty, block_hash = _get_block_with_retry(subtensor = subtensor, netuid = netuid)
+    block_number, difficulty, block_hash = _get_block_with_retry(
+        subtensor=subtensor, netuid=netuid
+    )
 
     block_bytes = bytes.fromhex(block_hash[2:])
     old_block_number = block_number
     # Set to current block
-    _update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, hotkey_bytes, check_block)
+    _update_curr_block(
+        curr_diff,
+        curr_block,
+        curr_block_num,
+        block_number,
+        block_bytes,
+        difficulty,
+        hotkey_bytes,
+        check_block,
+    )
 
     # Set new block events for each solver to start at the initial block
     for worker in solvers:
         worker.newBlockEvent.set()
 
     for worker in solvers:
-        worker.start() # start the solver processes
+        worker.start()  # start the solver processes
 
-    start_time = time.time() # time that the registration started
-    time_last = start_time # time that the last work blocks completed
+    start_time = time.time()  # time that the registration started
+    time_last = start_time  # time that the last work blocks completed
 
     curr_stats = RegistrationStatistics(
-        time_spent_total = 0.0,
-        time_average = 0.0,
-        rounds_total = 0,
-        time_spent = 0.0,
-        hash_rate_perpetual = 0.0,
-        hash_rate = 0.0,
-        difficulty = difficulty,
-        block_number = block_number,
-        block_hash = block_hash
+        time_spent_total=0.0,
+        time_average=0.0,
+        rounds_total=0,
+        time_spent=0.0,
+        hash_rate_perpetual=0.0,
+        hash_rate=0.0,
+        difficulty=difficulty,
+        block_number=block_number,
+        block_hash=block_hash,
     )
 
     start_time_perpetual = time.time()
 
-
     console = bittensor.__console__
     logger = RegistrationStatisticsLogger(console, output_in_place)
     logger.start()
 
     solution = None
 
-    hash_rates = [0] * n_samples # The last n true hash_rates
-    weights = [alpha_ ** i for i in range(n_samples)] # weights decay by alpha
+    hash_rates = [0] * n_samples  # The last n true hash_rates
+    weights = [alpha_**i for i in range(n_samples)]  # weights decay by alpha
 
     while not subtensor.is_hotkey_registered(
-                        netuid = netuid,
-                        hotkey_ss58 = wallet.hotkey.ss58_address,
+        netuid=netuid,
+        hotkey_ss58=wallet.hotkey.ss58_address,
     ):
         # Wait until a solver finds a solution
         try:
             solution = solution_queue.get(block=True, timeout=0.25)
             if solution is not None:
                 break
         except Empty:
             # No solution found, try again
             pass
 
         # check for new block
         old_block_number = _check_for_newest_block_and_update(
-            subtensor = subtensor,
-            netuid = netuid,
-            hotkey_bytes = hotkey_bytes,
+            subtensor=subtensor,
+            netuid=netuid,
+            hotkey_bytes=hotkey_bytes,
             old_block_number=old_block_number,
             curr_diff=curr_diff,
             curr_block=curr_block,
             curr_block_num=curr_block_num,
             curr_stats=curr_stats,
             update_curr_block=_update_curr_block,
             check_block=check_block,
-            solvers=solvers
+            solvers=solvers,
         )
 
         num_time = 0
         for finished_queue in finished_queues:
             try:
                 proc_num = finished_queue.get(timeout=0.1)
                 num_time += 1
 
             except Empty:
                 continue
 
-        time_now = time.time() # get current time
-        time_since_last = time_now - time_last # get time since last work block(s)
+        time_now = time.time()  # get current time
+        time_since_last = time_now - time_last  # get time since last work block(s)
         if num_time > 0 and time_since_last > 0.0:
             # create EWMA of the hash_rate to make measure more robust
 
             hash_rate_ = (num_time * update_interval) / time_since_last
             hash_rates.append(hash_rate_)
-            hash_rates.pop(0) # remove the 0th data point
-            curr_stats.hash_rate = sum([hash_rates[i]*weights[i] for i in range(n_samples)])/(sum(weights))
+            hash_rates.pop(0)  # remove the 0th data point
+            curr_stats.hash_rate = sum(
+                [hash_rates[i] * weights[i] for i in range(n_samples)]
+            ) / (sum(weights))
 
             # update time last to now
             time_last = time_now
 
-            curr_stats.time_average = (curr_stats.time_average*curr_stats.rounds_total + curr_stats.time_spent)/(curr_stats.rounds_total+num_time)
+            curr_stats.time_average = (
+                curr_stats.time_average * curr_stats.rounds_total
+                + curr_stats.time_spent
+            ) / (curr_stats.rounds_total + num_time)
             curr_stats.rounds_total += num_time
 
         # Update stats
         curr_stats.time_spent = time_since_last
         new_time_spent_total = time_now - start_time_perpetual
-        curr_stats.hash_rate_perpetual = (curr_stats.rounds_total*update_interval)/ new_time_spent_total
+        curr_stats.hash_rate_perpetual = (
+            curr_stats.rounds_total * update_interval
+        ) / new_time_spent_total
         curr_stats.time_spent_total = new_time_spent_total
 
         # Update the logger
         logger.update(curr_stats, verbose=log_verbose)
 
     # exited while, solution contains the nonce or wallet is registered
-    stopEvent.set() # stop all other processes
+    stopEvent.set()  # stop all other processes
     logger.stop()
 
     # terminate and wait for all solvers to exit
     _terminate_workers_and_wait_for_exit(solvers)
 
     return solution
 
 
-@backoff.on_exception(backoff.constant,
-                            Exception,
-                            interval=1,
-                            max_tries=3)
-def _get_block_with_retry(subtensor: 'bittensor.Subtensor', netuid: int) -> Tuple[int, int, bytes]:
+@backoff.on_exception(backoff.constant, Exception, interval=1, max_tries=3)
+def _get_block_with_retry(
+    subtensor: "bittensor.Subtensor", netuid: int
+) -> Tuple[int, int, bytes]:
     """
     Gets the current block number, difficulty, and block hash from the substrate node.
 
     Args:
         subtensor (:obj:`bittensor.Subtensor`, `required`):
             The subtensor object to use to get the block number, difficulty, and block hash.
 
@@ -542,53 +682,55 @@
             The current block hash.
 
     Raises:
         Exception: If the block hash is None.
         ValueError: If the difficulty is None.
     """
     block_number = subtensor.get_current_block()
-    difficulty = subtensor.difficulty(netuid = netuid)
-    block_hash = subtensor.get_block_hash( block_number )
+    difficulty = subtensor.difficulty(netuid=netuid)
+    block_hash = subtensor.get_block_hash(block_number)
     if block_hash is None:
-        raise Exception("Network error. Could not connect to substrate to get block hash")
+        raise Exception(
+            "Network error. Could not connect to substrate to get block hash"
+        )
     if difficulty is None:
         raise ValueError("Chain error. Difficulty is None")
     return block_number, difficulty, block_hash
 
 
-class _UsingSpawnStartMethod():
+class _UsingSpawnStartMethod:
     def __init__(self, force: bool = False):
         self._old_start_method = None
         self._force = force
 
     def __enter__(self):
         self._old_start_method = multiprocessing.get_start_method(allow_none=True)
         if self._old_start_method == None:
-            self._old_start_method = 'spawn' # default to spawn
+            self._old_start_method = "spawn"  # default to spawn
 
-        multiprocessing.set_start_method('spawn', force=self._force)
+        multiprocessing.set_start_method("spawn", force=self._force)
 
     def __exit__(self, *args):
         # restore the old start method
         multiprocessing.set_start_method(self._old_start_method, force=True)
 
 
 def _check_for_newest_block_and_update(
-        subtensor: 'bittensor.Subtensor',
-        netuid: int,
-        old_block_number: int,
-        hotkey_bytes: bytes,
-        curr_diff: multiprocessing.Array,
-        curr_block: multiprocessing.Array,
-        curr_block_num: multiprocessing.Value,
-        update_curr_block: Callable,
-        check_block: 'multiprocessing.Lock',
-        solvers: List[_Solver],
-        curr_stats: RegistrationStatistics
-    ) -> int:
+    subtensor: "bittensor.Subtensor",
+    netuid: int,
+    old_block_number: int,
+    hotkey_bytes: bytes,
+    curr_diff: multiprocessing.Array,
+    curr_block: multiprocessing.Array,
+    curr_block_num: multiprocessing.Value,
+    update_curr_block: Callable,
+    check_block: "multiprocessing.Lock",
+    solvers: List[_Solver],
+    curr_stats: RegistrationStatistics,
+) -> int:
     """
     Checks for a new block and updates the current block information if a new block is found.
 
     Args:
         subtensor (:obj:`bittensor.Subtensor`, `required`):
             The subtensor object to use for getting the current block.
         netuid (:obj:`int`, `required`):
@@ -615,32 +757,54 @@
     Returns:
         (int) The current block number.
     """
     block_number = subtensor.get_current_block()
     if block_number != old_block_number:
         old_block_number = block_number
         # update block information
-        block_number, difficulty, block_hash = _get_block_with_retry(subtensor = subtensor, netuid = netuid)
+        block_number, difficulty, block_hash = _get_block_with_retry(
+            subtensor=subtensor, netuid=netuid
+        )
         block_bytes = bytes.fromhex(block_hash[2:])
 
-        update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, hotkey_bytes, check_block)
+        update_curr_block(
+            curr_diff,
+            curr_block,
+            curr_block_num,
+            block_number,
+            block_bytes,
+            difficulty,
+            hotkey_bytes,
+            check_block,
+        )
         # Set new block events for each solver
 
         for worker in solvers:
             worker.newBlockEvent.set()
 
         # update stats
         curr_stats.block_number = block_number
         curr_stats.block_hash = block_hash
         curr_stats.difficulty = difficulty
 
     return old_block_number
 
 
-def _solve_for_difficulty_fast_cuda( subtensor: 'bittensor.Subtensor', wallet: 'bittensor.Wallet', netuid: int, output_in_place: bool = True, update_interval: int = 50_000, TPB: int = 512, dev_id: Union[List[int], int] = 0, n_samples: int = 10, alpha_: float = 0.80, log_verbose: bool = False ) -> Optional[POWSolution]:
+def _solve_for_difficulty_fast_cuda(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
+    netuid: int,
+    output_in_place: bool = True,
+    update_interval: int = 50_000,
+    TPB: int = 512,
+    dev_id: Union[List[int], int] = 0,
+    n_samples: int = 10,
+    alpha_: float = 0.80,
+    log_verbose: bool = False,
+) -> Optional[POWSolution]:
     """
     Solves the registration fast using CUDA
     Args:
         subtensor: bittensor.Subtensor
             The subtensor node to grab blocks
         wallet: bittensor.Wallet
             The wallet to register
@@ -669,15 +833,15 @@
 
     if update_interval is None:
         update_interval = 50_000
 
     if not torch.cuda.is_available():
         raise Exception("CUDA not available")
 
-    limit = int(math.pow(2,256)) - 1
+    limit = int(math.pow(2, 256)) - 1
 
     # Set mp start to use spawn so CUDA doesn't complain
     with _UsingSpawnStartMethod(force=True):
         curr_block, curr_block_num, curr_diff = _CUDASolver.create_shared_memory()
 
         ## Create a worker per CUDA device
         num_processes = len(dev_id)
@@ -687,151 +851,186 @@
         stopEvent.clear()
         solution_queue = multiprocessing.Queue()
         finished_queues = [multiprocessing.Queue() for _ in range(num_processes)]
         check_block = multiprocessing.Lock()
 
         hotkey_bytes = wallet.hotkey.public_key
         # Start workers
-        solvers = [ _CUDASolver(i, num_processes, update_interval, finished_queues[i], solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit, dev_id[i], TPB)
-                    for i in range(num_processes) ]
-
+        solvers = [
+            _CUDASolver(
+                i,
+                num_processes,
+                update_interval,
+                finished_queues[i],
+                solution_queue,
+                stopEvent,
+                curr_block,
+                curr_block_num,
+                curr_diff,
+                check_block,
+                limit,
+                dev_id[i],
+                TPB,
+            )
+            for i in range(num_processes)
+        ]
 
         # Get first block
-        block_number, difficulty, block_hash = _get_block_with_retry(subtensor = subtensor, netuid = netuid)
+        block_number, difficulty, block_hash = _get_block_with_retry(
+            subtensor=subtensor, netuid=netuid
+        )
 
         block_bytes = bytes.fromhex(block_hash[2:])
         old_block_number = block_number
 
         # Set to current block
-        _update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, hotkey_bytes, check_block)
+        _update_curr_block(
+            curr_diff,
+            curr_block,
+            curr_block_num,
+            block_number,
+            block_bytes,
+            difficulty,
+            hotkey_bytes,
+            check_block,
+        )
 
         # Set new block events for each solver to start at the initial block
         for worker in solvers:
             worker.newBlockEvent.set()
 
         for worker in solvers:
-            worker.start() # start the solver processes
+            worker.start()  # start the solver processes
 
-        start_time = time.time() # time that the registration started
-        time_last = start_time # time that the last work blocks completed
+        start_time = time.time()  # time that the registration started
+        time_last = start_time  # time that the last work blocks completed
 
         curr_stats = RegistrationStatistics(
-            time_spent_total = 0.0,
-            time_average = 0.0,
-            rounds_total = 0,
-            time_spent = 0.0,
-            hash_rate_perpetual = 0.0,
-            hash_rate = 0.0, # EWMA hash_rate (H/s)
-            difficulty = difficulty,
-            block_number = block_number,
-            block_hash = block_hash
+            time_spent_total=0.0,
+            time_average=0.0,
+            rounds_total=0,
+            time_spent=0.0,
+            hash_rate_perpetual=0.0,
+            hash_rate=0.0,  # EWMA hash_rate (H/s)
+            difficulty=difficulty,
+            block_number=block_number,
+            block_hash=block_hash,
         )
 
         start_time_perpetual = time.time()
 
         console = bittensor.__console__
         logger = RegistrationStatisticsLogger(console, output_in_place)
         logger.start()
 
-        hash_rates = [0] * n_samples # The last n true hash_rates
-        weights = [alpha_ ** i for i in range(n_samples)] # weights decay by alpha
+        hash_rates = [0] * n_samples  # The last n true hash_rates
+        weights = [alpha_**i for i in range(n_samples)]  # weights decay by alpha
 
         solution = None
         while not subtensor.is_hotkey_registered(
-                            netuid = netuid,
-                            hotkey_ss58 = wallet.hotkey.ss58_address,
+            netuid=netuid,
+            hotkey_ss58=wallet.hotkey.ss58_address,
         ):
             # Wait until a solver finds a solution
             try:
                 solution = solution_queue.get(block=True, timeout=0.15)
                 if solution is not None:
                     break
             except Empty:
                 # No solution found, try again
                 pass
 
             # check for new block
             old_block_number = _check_for_newest_block_and_update(
-                subtensor = subtensor,
-                netuid = netuid,
-                hotkey_bytes = hotkey_bytes,
+                subtensor=subtensor,
+                netuid=netuid,
+                hotkey_bytes=hotkey_bytes,
                 curr_diff=curr_diff,
                 curr_block=curr_block,
                 curr_block_num=curr_block_num,
                 old_block_number=old_block_number,
                 curr_stats=curr_stats,
                 update_curr_block=_update_curr_block,
                 check_block=check_block,
-                solvers=solvers
+                solvers=solvers,
             )
 
             num_time = 0
             # Get times for each solver
             for finished_queue in finished_queues:
                 try:
                     proc_num = finished_queue.get(timeout=0.1)
                     num_time += 1
 
                 except Empty:
                     continue
 
-            time_now = time.time() # get current time
-            time_since_last = time_now - time_last # get time since last work block(s)
+            time_now = time.time()  # get current time
+            time_since_last = time_now - time_last  # get time since last work block(s)
             if num_time > 0 and time_since_last > 0.0:
                 # create EWMA of the hash_rate to make measure more robust
 
                 hash_rate_ = (num_time * TPB * update_interval) / time_since_last
                 hash_rates.append(hash_rate_)
-                hash_rates.pop(0) # remove the 0th data point
-                curr_stats.hash_rate = sum([hash_rates[i]*weights[i] for i in range(n_samples)])/(sum(weights))
+                hash_rates.pop(0)  # remove the 0th data point
+                curr_stats.hash_rate = sum(
+                    [hash_rates[i] * weights[i] for i in range(n_samples)]
+                ) / (sum(weights))
 
                 # update time last to now
                 time_last = time_now
 
-                curr_stats.time_average = (curr_stats.time_average*curr_stats.rounds_total + curr_stats.time_spent)/(curr_stats.rounds_total+num_time)
+                curr_stats.time_average = (
+                    curr_stats.time_average * curr_stats.rounds_total
+                    + curr_stats.time_spent
+                ) / (curr_stats.rounds_total + num_time)
                 curr_stats.rounds_total += num_time
 
             # Update stats
             curr_stats.time_spent = time_since_last
             new_time_spent_total = time_now - start_time_perpetual
-            curr_stats.hash_rate_perpetual = (curr_stats.rounds_total * (TPB * update_interval))/ new_time_spent_total
+            curr_stats.hash_rate_perpetual = (
+                curr_stats.rounds_total * (TPB * update_interval)
+            ) / new_time_spent_total
             curr_stats.time_spent_total = new_time_spent_total
 
             # Update the logger
             logger.update(curr_stats, verbose=log_verbose)
 
         # exited while, found_solution contains the nonce or wallet is registered
 
-        stopEvent.set() # stop all other processes
+        stopEvent.set()  # stop all other processes
         logger.stop()
 
         # terminate and wait for all solvers to exit
         _terminate_workers_and_wait_for_exit(solvers)
 
         return solution
 
 
-def _terminate_workers_and_wait_for_exit(workers: List[multiprocessing.Process]) -> None:
+def _terminate_workers_and_wait_for_exit(
+    workers: List[multiprocessing.Process],
+) -> None:
     for worker in workers:
         worker.terminate()
         worker.join()
 
 
 def create_pow(
-        subtensor,
-        wallet,
-        netuid: int,
-        output_in_place: bool = True,
-        cuda: bool = False,
-        dev_id: Union[List[int], int] = 0,
-        tpb: int = 256,
-        num_processes: int = None,
-        update_interval: int = None,
-        log_verbose: bool = False
-    ) -> Optional[Dict[str, Any]]:
+    subtensor,
+    wallet,
+    netuid: int,
+    output_in_place: bool = True,
+    cuda: bool = False,
+    dev_id: Union[List[int], int] = 0,
+    tpb: int = 256,
+    num_processes: int = None,
+    update_interval: int = None,
+    log_verbose: bool = False,
+) -> Optional[Dict[str, Any]]:
     """
     Creates a proof of work for the given subtensor and wallet.
     Args:
         subtensor (:obj:`bittensor.subtensor.Subtensor`, `required`):
             The subtensor to create a proof of work for.
         wallet (:obj:`bittensor.wallet.Wallet`, `required`):
             The wallet to create a proof of work for.
@@ -859,72 +1058,84 @@
     Returns:
         :obj:`Optional[Dict[str, Any]]`: The proof of work solution or None if
             the wallet is already registered or there is a different error.
 
     Raises:
         :obj:`ValueError`: If the subnet does not exist.
     """
-    if not subtensor.subnet_exists(netuid = netuid):
-        raise ValueError(f'Subnet {netuid} does not exist')
+    if not subtensor.subnet_exists(netuid=netuid):
+        raise ValueError(f"Subnet {netuid} does not exist")
 
     if cuda:
-        solution: Optional[POWSolution] = _solve_for_difficulty_fast_cuda( subtensor, wallet, netuid = netuid, output_in_place=output_in_place, \
-            dev_id=dev_id, TPB=tpb, update_interval=update_interval, log_verbose=log_verbose
+        solution: Optional[POWSolution] = _solve_for_difficulty_fast_cuda(
+            subtensor,
+            wallet,
+            netuid=netuid,
+            output_in_place=output_in_place,
+            dev_id=dev_id,
+            TPB=tpb,
+            update_interval=update_interval,
+            log_verbose=log_verbose,
         )
     else:
-        solution: Optional[POWSolution] = _solve_for_difficulty_fast( subtensor, wallet, netuid = netuid, output_in_place=output_in_place, \
-            num_processes=num_processes, update_interval=update_interval, log_verbose=log_verbose
+        solution: Optional[POWSolution] = _solve_for_difficulty_fast(
+            subtensor,
+            wallet,
+            netuid=netuid,
+            output_in_place=output_in_place,
+            num_processes=num_processes,
+            update_interval=update_interval,
+            log_verbose=log_verbose,
         )
 
     return solution
 
 
 def __reregister_wallet(
-        netuid: int,
-        wallet: 'bittensor.Wallet',
-        subtensor: 'bittensor.Subtensor',
-        reregister: bool = False,
-        prompt: bool = False,
-        **registration_args: Any
-    ) -> Optional['bittensor.Wallet']:
-        """ Re-register this a Wallet on the chain, or exits.
-                Exits if the wallet is not registered on the chain AND
-                reregister is set to False.
-            Args:
-                netuid (int):
-                    The network uid of the subnet to register on.
-                wallet( 'bittensor.Wallet' ):
-                    Bittensor Wallet to re-register
-                reregister (bool, default=False):
-                    If true, re-registers the wallet on the chain.
-                    Exits if False and the wallet is not registered on the chain.
-                prompt (bool):
-                    If true, the call waits for confirmation from the user before proceeding.
-                **registration_args (Any):
-                    The registration arguments to pass to the subtensor register function.
-            Return:
-                wallet (bittensor.Wallet):
-                    The wallet
-
-            Raises:
-                SytemExit(0):
-                    If the wallet is not registered on the chain AND
-                    the config.subtensor.reregister flag is set to False.
-        """
-        wallet.hotkey
+    netuid: int,
+    wallet: "bittensor.Wallet",
+    subtensor: "bittensor.Subtensor",
+    reregister: bool = False,
+    prompt: bool = False,
+    **registration_args: Any,
+) -> Optional["bittensor.Wallet"]:
+    """Re-register this a Wallet on the chain, or exits.
+        Exits if the wallet is not registered on the chain AND
+        reregister is set to False.
+    Args:
+        netuid (int):
+            The network uid of the subnet to register on.
+        wallet( 'bittensor.Wallet' ):
+            Bittensor Wallet to re-register
+        reregister (bool, default=False):
+            If true, re-registers the wallet on the chain.
+            Exits if False and the wallet is not registered on the chain.
+        prompt (bool):
+            If true, the call waits for confirmation from the user before proceeding.
+        **registration_args (Any):
+            The registration arguments to pass to the subtensor register function.
+    Return:
+        wallet (bittensor.Wallet):
+            The wallet
 
-        if not subtensor.is_hotkey_registered_on_subnet(
-            hotkey_ss58=wallet.hotkey.ss58_address,
-            netuid=netuid
-        ):
-            # Check if the wallet should reregister
-            if not reregister:
-                sys.exit(0)
-
-            subtensor.register(
-                wallet = wallet,
-                netuid = netuid,
-                prompt = prompt,
-                **registration_args,
-            )
+    Raises:
+        SytemExit(0):
+            If the wallet is not registered on the chain AND
+            the config.subtensor.reregister flag is set to False.
+    """
+    wallet.hotkey
+
+    if not subtensor.is_hotkey_registered_on_subnet(
+        hotkey_ss58=wallet.hotkey.ss58_address, netuid=netuid
+    ):
+        # Check if the wallet should reregister
+        if not reregister:
+            sys.exit(0)
+
+        subtensor.register(
+            wallet=wallet,
+            netuid=netuid,
+            prompt=prompt,
+            **registration_args,
+        )
 
-        return wallet
+    return wallet
```

### Comparing `bittensor-5.3.1/bittensor/utils/registratrion_old.py` & `bittensor-5.3.2/bittensor/utils/registratrion_old.py`

 * *Files 22% similar despite different names*

```diff
@@ -18,88 +18,94 @@
 from rich import status as rich_status
 
 from ._register_cuda import solve_cuda
 
 
 class CUDAException(Exception):
     """An exception raised when an error occurs in the CUDA environment."""
+
     pass
 
 
-def hex_bytes_to_u8_list( hex_bytes: bytes ):
-    hex_chunks = [int(hex_bytes[i:i+2], 16) for i in range(0, len(hex_bytes), 2)]
+def hex_bytes_to_u8_list(hex_bytes: bytes):
+    hex_chunks = [int(hex_bytes[i : i + 2], 16) for i in range(0, len(hex_bytes), 2)]
     return hex_chunks
 
 
-def u8_list_to_hex( values: list ):
+def u8_list_to_hex(values: list):
     total = 0
     for val in reversed(values):
         total = (total << 8) + val
     return total
 
 
-def create_seal_hash( block_hash:bytes, nonce:int ) -> bytes:
-    block_bytes = block_hash.encode('utf-8')[2:]
-    nonce_bytes = binascii.hexlify(nonce.to_bytes(8, 'little'))
+def create_seal_hash(block_hash: bytes, nonce: int) -> bytes:
+    block_bytes = block_hash.encode("utf-8")[2:]
+    nonce_bytes = binascii.hexlify(nonce.to_bytes(8, "little"))
     pre_seal = nonce_bytes + block_bytes
-    seal_sh256 = hashlib.sha256( bytearray(hex_bytes_to_u8_list(pre_seal)) ).digest()
+    seal_sh256 = hashlib.sha256(bytearray(hex_bytes_to_u8_list(pre_seal))).digest()
     kec = keccak.new(digest_bits=256)
-    seal = kec.update( seal_sh256 ).digest()
+    seal = kec.update(seal_sh256).digest()
     return seal
 
 
-def seal_meets_difficulty( seal:bytes, difficulty:int ):
+def seal_meets_difficulty(seal: bytes, difficulty: int):
     seal_number = int.from_bytes(seal, "big")
     product = seal_number * difficulty
-    limit = int(math.pow(2,256))- 1
+    limit = int(math.pow(2, 256)) - 1
     if product > limit:
         return False
     else:
         return True
 
 
-def solve_for_difficulty( block_hash, difficulty ):
+def solve_for_difficulty(block_hash, difficulty):
     meets = False
     nonce = -1
     while not meets:
         nonce += 1
-        seal = create_seal_hash( block_hash, nonce )
-        meets = seal_meets_difficulty( seal, difficulty )
+        seal = create_seal_hash(block_hash, nonce)
+        meets = seal_meets_difficulty(seal, difficulty)
         if nonce > 1:
             break
     return nonce, seal
 
 
 def get_human_readable(num, suffix="H"):
     for unit in ["", "K", "M", "G", "T", "P", "E", "Z"]:
         if abs(num) < 1000.0:
             return f"{num:3.1f}{unit}{suffix}"
         num /= 1000.0
     return f"{num:.1f}Y{suffix}"
 
 
 def millify(n: int):
-    millnames = ['',' K',' M',' B',' T']
+    millnames = ["", " K", " M", " B", " T"]
     n = float(n)
-    millidx = max(0,min(len(millnames)-1,
-                        int(math.floor(0 if n == 0 else math.log10(abs(n))/3))))
+    millidx = max(
+        0,
+        min(
+            len(millnames) - 1, int(math.floor(0 if n == 0 else math.log10(abs(n)) / 3))
+        ),
+    )
 
-    return '{:.2f}{}'.format(n / 10**(3 * millidx), millnames[millidx])
+    return "{:.2f}{}".format(n / 10 ** (3 * millidx), millnames[millidx])
 
 
-def POWNotStale(subtensor: 'bittensor.Subtensor', pow_result: Dict) -> bool:
+def POWNotStale(subtensor: "bittensor.Subtensor", pow_result: Dict) -> bool:
     """Returns True if the POW is not stale.
     This means the block the POW is solved for is within 3 blocks of the current block.
     """
-    return pow_result['block_number'] >= subtensor.get_current_block() - 3
+    return pow_result["block_number"] >= subtensor.get_current_block() - 3
 
 
 @dataclass
 class POWSolution:
     """A solution to the registration PoW problem."""
+
     nonce: int
     block_number: int
     difficulty: int
     seal: bytes
 
 
 class SolverBase(multiprocessing.Process):
@@ -139,28 +145,42 @@
             The main process will set the array to the new difficulty when a new block is finalized in the network.
             The solver process will get the new difficulty from this array when newBlockEvent is set.
         check_block: multiprocessing.Lock
             The lock to prevent this process from getting the new block data while the main process is updating the data.
         limit: int
             The limit of the pow solve for a valid solution.
     """
+
     proc_num: int
     num_proc: int
     update_interval: int
     finished_queue: multiprocessing.Queue
     solution_queue: multiprocessing.Queue
     newBlockEvent: multiprocessing.Event
     stopEvent: multiprocessing.Event
     curr_block: multiprocessing.Array
     curr_block_num: multiprocessing.Value
     curr_diff: multiprocessing.Array
     check_block: multiprocessing.Lock
     limit: int
 
-    def __init__(self, proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit):
+    def __init__(
+        self,
+        proc_num,
+        num_proc,
+        update_interval,
+        finished_queue,
+        solution_queue,
+        stopEvent,
+        curr_block,
+        curr_block_num,
+        curr_diff,
+        check_block,
+        limit,
+    ):
         multiprocessing.Process.__init__(self, daemon=True)
         self.proc_num = proc_num
         self.num_proc = num_proc
         self.update_interval = update_interval
         self.finished_queue = finished_queue
         self.solution_queue = solution_queue
         self.newBlockEvent = multiprocessing.Event()
@@ -177,72 +197,117 @@
 
 
 class Solver(SolverBase):
     def run(self):
         block_number: int
         block_bytes: bytes
         block_difficulty: int
-        nonce_limit = int(math.pow(2,64)) - 1
+        nonce_limit = int(math.pow(2, 64)) - 1
 
         # Start at random nonce
-        nonce_start = random.randint( 0, nonce_limit )
+        nonce_start = random.randint(0, nonce_limit)
         nonce_end = nonce_start + self.update_interval
         while not self.stopEvent.is_set():
             if self.newBlockEvent.is_set():
                 with self.check_block:
                     block_number = self.curr_block_num.value
                     block_bytes = bytes(self.curr_block)
                     block_difficulty = registration_diff_unpack(self.curr_diff)
 
                 self.newBlockEvent.clear()
 
             # Do a block of nonces
-            solution = solve_for_nonce_block(self, nonce_start, nonce_end, block_bytes, block_difficulty, self.limit, block_number)
+            solution = solve_for_nonce_block(
+                self,
+                nonce_start,
+                nonce_end,
+                block_bytes,
+                block_difficulty,
+                self.limit,
+                block_number,
+            )
             if solution is not None:
                 self.solution_queue.put(solution)
 
             try:
                 # Send time
                 self.finished_queue.put_nowait(self.proc_num)
             except Full:
                 pass
 
-            nonce_start = random.randint( 0, nonce_limit )
+            nonce_start = random.randint(0, nonce_limit)
             nonce_start = nonce_start % nonce_limit
             nonce_end = nonce_start + self.update_interval
 
 
 class CUDASolver(SolverBase):
     dev_id: int
     TPB: int
 
-    def __init__(self, proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit, dev_id: int, TPB: int):
-        super().__init__(proc_num, num_proc, update_interval, finished_queue, solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit)
+    def __init__(
+        self,
+        proc_num,
+        num_proc,
+        update_interval,
+        finished_queue,
+        solution_queue,
+        stopEvent,
+        curr_block,
+        curr_block_num,
+        curr_diff,
+        check_block,
+        limit,
+        dev_id: int,
+        TPB: int,
+    ):
+        super().__init__(
+            proc_num,
+            num_proc,
+            update_interval,
+            finished_queue,
+            solution_queue,
+            stopEvent,
+            curr_block,
+            curr_block_num,
+            curr_diff,
+            check_block,
+            limit,
+        )
         self.dev_id = dev_id
         self.TPB = TPB
 
     def run(self):
-        block_number: int = 0 # dummy value
-        block_bytes: bytes = b'0' * 32 # dummy value
-        block_difficulty: int = int(math.pow(2,64)) - 1 # dummy value
-        nonce_limit = int(math.pow(2,64)) - 1 # U64MAX
+        block_number: int = 0  # dummy value
+        block_bytes: bytes = b"0" * 32  # dummy value
+        block_difficulty: int = int(math.pow(2, 64)) - 1  # dummy value
+        nonce_limit = int(math.pow(2, 64)) - 1  # U64MAX
 
         # Start at random nonce
-        nonce_start = random.randint( 0, nonce_limit )
+        nonce_start = random.randint(0, nonce_limit)
         while not self.stopEvent.is_set():
             if self.newBlockEvent.is_set():
                 with self.check_block:
                     block_number = self.curr_block_num.value
                     block_bytes = bytes(self.curr_block)
                     block_difficulty = registration_diff_unpack(self.curr_diff)
 
                 self.newBlockEvent.clear()
 
             # Do a block of nonces
-            solution = solve_for_nonce_block_cuda(self, nonce_start, self.update_interval, block_bytes, block_difficulty, self.limit, block_number, self.dev_id, self.TPB)
+            solution = solve_for_nonce_block_cuda(
+                self,
+                nonce_start,
+                self.update_interval,
+                block_bytes,
+                block_difficulty,
+                self.limit,
+                block_number,
+                self.dev_id,
+                self.TPB,
+            )
             if solution is not None:
                 self.solution_queue.put(solution)
 
             try:
                 # Signal that a nonce_block was finished using queue
                 # send our proc_num
                 self.finished_queue.put(self.proc_num)
@@ -250,41 +315,54 @@
                 pass
 
             # increase nonce by number of nonces processed
             nonce_start += self.update_interval * self.TPB
             nonce_start = nonce_start % nonce_limit
 
 
-def solve_for_nonce_block_cuda(solver: CUDASolver, nonce_start: int, update_interval: int, block_bytes: bytes, difficulty: int, limit: int, block_number: int, dev_id: int, TPB: int) -> Optional[POWSolution]:
+def solve_for_nonce_block_cuda(
+    solver: CUDASolver,
+    nonce_start: int,
+    update_interval: int,
+    block_bytes: bytes,
+    difficulty: int,
+    limit: int,
+    block_number: int,
+    dev_id: int,
+    TPB: int,
+) -> Optional[POWSolution]:
     """Tries to solve the POW on a CUDA device for a block of nonces (nonce_start, nonce_start + update_interval * TPB"""
     solution, seal = solve_cuda(
-                    nonce_start,
-                    update_interval,
-                    TPB,
-                    block_bytes,
-                    difficulty,
-                    limit,
-                    dev_id)
+        nonce_start, update_interval, TPB, block_bytes, difficulty, limit, dev_id
+    )
 
-    if (solution != -1):
+    if solution != -1:
         # Check if solution is valid (i.e. not -1)
         return POWSolution(solution, block_number, difficulty, seal)
 
     return None
 
 
-def solve_for_nonce_block(solver: Solver, nonce_start: int, nonce_end: int, block_bytes: bytes, difficulty: int, limit: int, block_number: int) -> Optional[POWSolution]:
+def solve_for_nonce_block(
+    solver: Solver,
+    nonce_start: int,
+    nonce_end: int,
+    block_bytes: bytes,
+    difficulty: int,
+    limit: int,
+    block_number: int,
+) -> Optional[POWSolution]:
     """Tries to solve the POW for a block of nonces (nonce_start, nonce_end)"""
     for nonce in range(nonce_start, nonce_end):
         # Create seal.
-        nonce_bytes = binascii.hexlify(nonce.to_bytes(8, 'little'))
+        nonce_bytes = binascii.hexlify(nonce.to_bytes(8, "little"))
         pre_seal = nonce_bytes + block_bytes
-        seal_sh256 = hashlib.sha256( bytearray(hex_bytes_to_u8_list(pre_seal)) ).digest()
+        seal_sh256 = hashlib.sha256(bytearray(hex_bytes_to_u8_list(pre_seal))).digest()
         kec = keccak.new(digest_bits=256)
-        seal = kec.update( seal_sh256 ).digest()
+        seal = kec.update(seal_sh256).digest()
         seal_number = int.from_bytes(seal, "big")
 
         # Check if seal meets difficulty
         product = seal_number * difficulty
         if product < limit:
             # Found a solution, save it.
             return POWSolution(nonce, block_number, difficulty, seal)
@@ -296,92 +374,119 @@
     """Unpacks the packed two 32-bit integers into one 64-bit integer. Little endian."""
     return int(packed_diff[0] << 32 | packed_diff[1])
 
 
 def registration_diff_pack(diff: int, packed_diff: multiprocessing.Array):
     """Packs the difficulty into two 32-bit integers. Little endian."""
     packed_diff[0] = diff >> 32
-    packed_diff[1] = diff & 0xFFFFFFFF # low 32 bits
+    packed_diff[1] = diff & 0xFFFFFFFF  # low 32 bits
 
 
-def update_curr_block(curr_diff: multiprocessing.Array, curr_block: multiprocessing.Array, curr_block_num: multiprocessing.Value, block_number: int, block_bytes: bytes, diff: int, lock: multiprocessing.Lock):
+def update_curr_block(
+    curr_diff: multiprocessing.Array,
+    curr_block: multiprocessing.Array,
+    curr_block_num: multiprocessing.Value,
+    block_number: int,
+    block_bytes: bytes,
+    diff: int,
+    lock: multiprocessing.Lock,
+):
     with lock:
         curr_block_num.value = block_number
         for i in range(64):
             curr_block[i] = block_bytes[i]
         registration_diff_pack(diff, curr_diff)
 
 
 def get_cpu_count():
     try:
         return len(os.sched_getaffinity(0))
     except AttributeError:
         # OSX does not have sched_getaffinity
         return os.cpu_count()
 
+
 @dataclass
 class RegistrationStatistics:
     """Statistics for a registration."""
+
     time_spent_total: float
     rounds_total: int
     time_average: float
     time_spent: float
     hash_rate_perpetual: float
     hash_rate: float
     difficulty: int
     block_number: int
     block_hash: bytes
 
 
 class RegistrationStatisticsLogger:
     """Logs statistics for a registration."""
+
     console: rich_console.Console
     status: Optional[rich_status.Status]
 
-    def __init__( self, console: rich_console.Console, output_in_place: bool = True) -> None:
+    def __init__(
+        self, console: rich_console.Console, output_in_place: bool = True
+    ) -> None:
         self.console = console
 
         if output_in_place:
             self.status = self.console.status("Solving")
         else:
             self.status = None
 
-    def start( self ) -> None:
+    def start(self) -> None:
         if self.status is not None:
             self.status.start()
 
-    def stop( self ) -> None:
+    def stop(self) -> None:
         if self.status is not None:
             self.status.stop()
 
-
-    def get_status_message(cls, stats: RegistrationStatistics, verbose: bool = False) -> str:
-        message = \
-        "Solving\n" + \
-        f"Time Spent (total): [bold white]{timedelta(seconds=stats.time_spent_total)}[/bold white]\n" + \
-        (
-            f"Time Spent This Round: {timedelta(seconds=stats.time_spent)}\n" + \
-            f"Time Spent Average: {timedelta(seconds=stats.time_average)}\n" if verbose else ""
-        ) + \
-        f"Registration Difficulty: [bold white]{millify(stats.difficulty)}[/bold white]\n" + \
-        f"Iters (Inst/Perp): [bold white]{get_human_readable(stats.hash_rate, 'H')}/s / " + \
-            f"{get_human_readable(stats.hash_rate_perpetual, 'H')}/s[/bold white]\n" + \
-        f"Block Number: [bold white]{stats.block_number}[/bold white]\n" + \
-        f"Block Hash: [bold white]{stats.block_hash.encode('utf-8')}[/bold white]\n"
+    def get_status_message(
+        cls, stats: RegistrationStatistics, verbose: bool = False
+    ) -> str:
+        message = (
+            "Solving\n"
+            + f"Time Spent (total): [bold white]{timedelta(seconds=stats.time_spent_total)}[/bold white]\n"
+            + (
+                f"Time Spent This Round: {timedelta(seconds=stats.time_spent)}\n"
+                + f"Time Spent Average: {timedelta(seconds=stats.time_average)}\n"
+                if verbose
+                else ""
+            )
+            + f"Registration Difficulty: [bold white]{millify(stats.difficulty)}[/bold white]\n"
+            + f"Iters (Inst/Perp): [bold white]{get_human_readable(stats.hash_rate, 'H')}/s / "
+            + f"{get_human_readable(stats.hash_rate_perpetual, 'H')}/s[/bold white]\n"
+            + f"Block Number: [bold white]{stats.block_number}[/bold white]\n"
+            + f"Block Hash: [bold white]{stats.block_hash.encode('utf-8')}[/bold white]\n"
+        )
         return message
 
-
-    def update( self, stats: RegistrationStatistics, verbose: bool = False ) -> None:
+    def update(self, stats: RegistrationStatistics, verbose: bool = False) -> None:
         if self.status is not None:
-            self.status.update( self.get_status_message(stats, verbose=verbose) )
+            self.status.update(self.get_status_message(stats, verbose=verbose))
         else:
-            self.console.log( self.get_status_message(stats, verbose=verbose), )
+            self.console.log(
+                self.get_status_message(stats, verbose=verbose),
+            )
 
 
-def solve_for_difficulty_fast( subtensor: 'bittensor.Subtensor', wallet, output_in_place: bool = True, num_processes: Optional[int] = None, update_interval: Optional[int] = None,  n_samples: int = 10, alpha_: float = 0.80, log_verbose: bool = False ) -> Optional[POWSolution]:
+def solve_for_difficulty_fast(
+    subtensor: "bittensor.Subtensor",
+    wallet,
+    output_in_place: bool = True,
+    num_processes: Optional[int] = None,
+    update_interval: Optional[int] = None,
+    n_samples: int = 10,
+    alpha_: float = 0.80,
+    log_verbose: bool = False,
+) -> Optional[POWSolution]:
     """
     Solves the POW for registration using multiprocessing.
     Args:
         subtensor
             Subtensor to connect to for block information and to submit.
         wallet:
             Wallet to use for registration.
@@ -406,188 +511,215 @@
     if num_processes == None:
         # get the number of allowed processes for this process
         num_processes = min(1, get_cpu_count())
 
     if update_interval is None:
         update_interval = 50_000
 
-    limit = int(math.pow(2,256)) - 1
+    limit = int(math.pow(2, 256)) - 1
 
-    curr_block = multiprocessing.Array('h', 64, lock=True) # byte array
-    curr_block_num = multiprocessing.Value('i', 0, lock=True) # int
-    curr_diff = multiprocessing.Array('Q', [0, 0], lock=True) # [high, low]
+    curr_block = multiprocessing.Array("h", 64, lock=True)  # byte array
+    curr_block_num = multiprocessing.Value("i", 0, lock=True)  # int
+    curr_diff = multiprocessing.Array("Q", [0, 0], lock=True)  # [high, low]
 
     # Establish communication queues
     ## See the Solver class for more information on the queues.
     stopEvent = multiprocessing.Event()
     stopEvent.clear()
 
     solution_queue = multiprocessing.Queue()
     finished_queues = [multiprocessing.Queue() for _ in range(num_processes)]
     check_block = multiprocessing.Lock()
 
     # Start consumers
-    solvers = [ Solver(i, num_processes, update_interval, finished_queues[i], solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit)
-                for i in range(num_processes) ]
+    solvers = [
+        Solver(
+            i,
+            num_processes,
+            update_interval,
+            finished_queues[i],
+            solution_queue,
+            stopEvent,
+            curr_block,
+            curr_block_num,
+            curr_diff,
+            check_block,
+            limit,
+        )
+        for i in range(num_processes)
+    ]
 
     # Get first block
     block_number = subtensor.get_current_block()
     difficulty = subtensor.difficulty
-    block_hash = subtensor.substrate.get_block_hash( block_number )
+    block_hash = subtensor.substrate.get_block_hash(block_number)
     while block_hash == None:
-        block_hash = subtensor.substrate.get_block_hash( block_number )
-    block_bytes = block_hash.encode('utf-8')[2:]
+        block_hash = subtensor.substrate.get_block_hash(block_number)
+    block_bytes = block_hash.encode("utf-8")[2:]
     old_block_number = block_number
     # Set to current block
-    update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, check_block)
+    update_curr_block(
+        curr_diff,
+        curr_block,
+        curr_block_num,
+        block_number,
+        block_bytes,
+        difficulty,
+        check_block,
+    )
 
     # Set new block events for each solver to start at the initial block
     for worker in solvers:
         worker.newBlockEvent.set()
 
     for worker in solvers:
-        worker.start() # start the solver processes
+        worker.start()  # start the solver processes
 
-    start_time = time.time() # time that the registration started
-    time_last = start_time # time that the last work blocks completed
+    start_time = time.time()  # time that the registration started
+    time_last = start_time  # time that the last work blocks completed
 
     curr_stats = RegistrationStatistics(
-        time_spent_total = 0.0,
-        time_average = 0.0,
-        rounds_total = 0,
-        time_spent = 0.0,
-        hash_rate_perpetual = 0.0,
-        hash_rate = 0.0,
-        difficulty = difficulty,
-        block_number = block_number,
-        block_hash = block_hash
+        time_spent_total=0.0,
+        time_average=0.0,
+        rounds_total=0,
+        time_spent=0.0,
+        hash_rate_perpetual=0.0,
+        hash_rate=0.0,
+        difficulty=difficulty,
+        block_number=block_number,
+        block_hash=block_hash,
     )
 
     start_time_perpetual = time.time()
 
-
     console = bittensor.__console__
     logger = RegistrationStatisticsLogger(console, output_in_place)
     logger.start()
 
     solution = None
 
-    hash_rates = [0] * n_samples # The last n true hash_rates
-    weights = [alpha_ ** i for i in range(n_samples)] # weights decay by alpha
+    hash_rates = [0] * n_samples  # The last n true hash_rates
+    weights = [alpha_**i for i in range(n_samples)]  # weights decay by alpha
 
     while not subtensor.is_hotkey_registered(
-        hotkey_ss58 = wallet.hotkey.ss58_address,
+        hotkey_ss58=wallet.hotkey.ss58_address,
     ):
         # Wait until a solver finds a solution
         try:
             solution = solution_queue.get(block=True, timeout=0.25)
             if solution is not None:
                 break
         except Empty:
             # No solution found, try again
             pass
 
         # check for new block
         old_block_number = check_for_newest_block_and_update(
-            subtensor = subtensor,
+            subtensor=subtensor,
             old_block_number=old_block_number,
             curr_diff=curr_diff,
             curr_block=curr_block,
             curr_block_num=curr_block_num,
             curr_stats=curr_stats,
             update_curr_block=update_curr_block,
             check_block=check_block,
-            solvers=solvers
+            solvers=solvers,
         )
 
         num_time = 0
         for finished_queue in finished_queues:
             try:
                 proc_num = finished_queue.get(timeout=0.1)
                 num_time += 1
 
             except Empty:
                 continue
 
-        time_now = time.time() # get current time
-        time_since_last = time_now - time_last # get time since last work block(s)
+        time_now = time.time()  # get current time
+        time_since_last = time_now - time_last  # get time since last work block(s)
         if num_time > 0 and time_since_last > 0.0:
             # create EWMA of the hash_rate to make measure more robust
 
             hash_rate_ = (num_time * update_interval) / time_since_last
             hash_rates.append(hash_rate_)
-            hash_rates.pop(0) # remove the 0th data point
-            curr_stats.hash_rate = sum([hash_rates[i]*weights[i] for i in range(n_samples)])/(sum(weights))
+            hash_rates.pop(0)  # remove the 0th data point
+            curr_stats.hash_rate = sum(
+                [hash_rates[i] * weights[i] for i in range(n_samples)]
+            ) / (sum(weights))
 
             # update time last to now
             time_last = time_now
 
-            curr_stats.time_average = (curr_stats.time_average*curr_stats.rounds_total + curr_stats.time_spent)/(curr_stats.rounds_total+num_time)
+            curr_stats.time_average = (
+                curr_stats.time_average * curr_stats.rounds_total
+                + curr_stats.time_spent
+            ) / (curr_stats.rounds_total + num_time)
             curr_stats.rounds_total += num_time
 
         # Update stats
         curr_stats.time_spent = time_since_last
         new_time_spent_total = time_now - start_time_perpetual
-        curr_stats.hash_rate_perpetual = (curr_stats.rounds_total*update_interval)/ new_time_spent_total
+        curr_stats.hash_rate_perpetual = (
+            curr_stats.rounds_total * update_interval
+        ) / new_time_spent_total
         curr_stats.time_spent_total = new_time_spent_total
 
         # Update the logger
         logger.update(curr_stats, verbose=log_verbose)
 
     # exited while, solution contains the nonce or wallet is registered
-    stopEvent.set() # stop all other processes
+    stopEvent.set()  # stop all other processes
     logger.stop()
 
     # terminate and wait for all solvers to exit
     terminate_workers_and_wait_for_exit(solvers)
 
     return solution
 
 
-@backoff.on_exception(backoff.constant,
-                            Exception,
-                            interval=1,
-                            max_tries=3)
-def get_block_with_retry(subtensor: 'bittensor.Subtensor') -> Tuple[int, int, bytes]:
+@backoff.on_exception(backoff.constant, Exception, interval=1, max_tries=3)
+def get_block_with_retry(subtensor: "bittensor.Subtensor") -> Tuple[int, int, bytes]:
     block_number = subtensor.get_current_block()
     difficulty = subtensor.difficulty
-    block_hash = subtensor.substrate.get_block_hash( block_number )
+    block_hash = subtensor.substrate.get_block_hash(block_number)
     if block_hash is None:
-        raise Exception("Network error. Could not connect to substrate to get block hash")
+        raise Exception(
+            "Network error. Could not connect to substrate to get block hash"
+        )
     return block_number, difficulty, block_hash
 
 
-class UsingSpawnStartMethod():
+class UsingSpawnStartMethod:
     def __init__(self, force: bool = False):
         self._old_start_method = None
         self._force = force
 
     def __enter__(self):
         self._old_start_method = multiprocessing.get_start_method(allow_none=True)
         if self._old_start_method == None:
-            self._old_start_method = 'spawn' # default to spawn
+            self._old_start_method = "spawn"  # default to spawn
 
-        multiprocessing.set_start_method('spawn', force=self._force)
+        multiprocessing.set_start_method("spawn", force=self._force)
 
     def __exit__(self, *args):
         # restore the old start method
         multiprocessing.set_start_method(self._old_start_method, force=True)
 
 
 def check_for_newest_block_and_update(
-    subtensor: 'bittensor.Subtensor',
+    subtensor: "bittensor.Subtensor",
     old_block_number: int,
     curr_diff: multiprocessing.Array,
     curr_block: multiprocessing.Array,
     curr_block_num: multiprocessing.Value,
     update_curr_block: Callable,
-    check_block: 'multiprocessing.Lock',
+    check_block: "multiprocessing.Lock",
     solvers: List[Solver],
-    curr_stats: RegistrationStatistics
-    ) -> int:
+    curr_stats: RegistrationStatistics,
+) -> int:
     """
     Checks for a new block and updates the current block information if a new block is found.
     Args:
         subtensor (:obj:`bittensor.Subtensor`, `required`):
             The subtensor object to use for getting the current block.
         old_block_number (:obj:`int`, `required`):
             The old block number to check against.
@@ -608,35 +740,53 @@
     Returns:
         (int) The current block number.
     """
     block_number = subtensor.get_current_block()
     if block_number != old_block_number:
         old_block_number = block_number
         # update block information
-        block_hash = subtensor.substrate.get_block_hash( block_number)
+        block_hash = subtensor.substrate.get_block_hash(block_number)
         while block_hash == None:
-            block_hash = subtensor.substrate.get_block_hash( block_number)
-        block_bytes = block_hash.encode('utf-8')[2:]
+            block_hash = subtensor.substrate.get_block_hash(block_number)
+        block_bytes = block_hash.encode("utf-8")[2:]
         difficulty = subtensor.difficulty
 
-        update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, check_block)
+        update_curr_block(
+            curr_diff,
+            curr_block,
+            curr_block_num,
+            block_number,
+            block_bytes,
+            difficulty,
+            check_block,
+        )
         # Set new block events for each solver
 
         for worker in solvers:
             worker.newBlockEvent.set()
 
         # update stats
         curr_stats.block_number = block_number
         curr_stats.block_hash = block_hash
         curr_stats.difficulty = difficulty
 
     return old_block_number
 
 
-def solve_for_difficulty_fast_cuda( subtensor: 'bittensor.Subtensor', wallet: 'bittensor.Wallet', output_in_place: bool = True, update_interval: int = 50_000, TPB: int = 512, dev_id: Union[List[int], int] = 0, n_samples: int = 10, alpha_: float = 0.80, log_verbose: bool = False ) -> Optional[POWSolution]:
+def solve_for_difficulty_fast_cuda(
+    subtensor: "bittensor.Subtensor",
+    wallet: "bittensor.Wallet",
+    output_in_place: bool = True,
+    update_interval: int = 50_000,
+    TPB: int = 512,
+    dev_id: Union[List[int], int] = 0,
+    n_samples: int = 10,
+    alpha_: float = 0.80,
+    log_verbose: bool = False,
+) -> Optional[POWSolution]:
     """
     Solves the registration fast using CUDA
     Args:
         subtensor: bittensor.Subtensor
             The subtensor node to grab blocks
         wallet: bittensor.Wallet
             The wallet to register
@@ -663,144 +813,174 @@
 
     if update_interval is None:
         update_interval = 50_000
 
     if not torch.cuda.is_available():
         raise Exception("CUDA not available")
 
-    limit = int(math.pow(2,256)) - 1
+    limit = int(math.pow(2, 256)) - 1
 
     # Set mp start to use spawn so CUDA doesn't complain
     with UsingSpawnStartMethod(force=True):
-        curr_block = multiprocessing.Array('h', 64, lock=True) # byte array
-        curr_block_num = multiprocessing.Value('i', 0, lock=True) # int
-        curr_diff = multiprocessing.Array('Q', [0, 0], lock=True) # [high, low]
+        curr_block = multiprocessing.Array("h", 64, lock=True)  # byte array
+        curr_block_num = multiprocessing.Value("i", 0, lock=True)  # int
+        curr_diff = multiprocessing.Array("Q", [0, 0], lock=True)  # [high, low]
 
         ## Create a worker per CUDA device
         num_processes = len(dev_id)
 
         # Establish communication queues
         stopEvent = multiprocessing.Event()
         stopEvent.clear()
         solution_queue = multiprocessing.Queue()
         finished_queues = [multiprocessing.Queue() for _ in range(num_processes)]
         check_block = multiprocessing.Lock()
 
         # Start workers
-        solvers = [ CUDASolver(i, num_processes, update_interval, finished_queues[i], solution_queue, stopEvent, curr_block, curr_block_num, curr_diff, check_block, limit, dev_id[i], TPB)
-                    for i in range(num_processes) ]
-
+        solvers = [
+            CUDASolver(
+                i,
+                num_processes,
+                update_interval,
+                finished_queues[i],
+                solution_queue,
+                stopEvent,
+                curr_block,
+                curr_block_num,
+                curr_diff,
+                check_block,
+                limit,
+                dev_id[i],
+                TPB,
+            )
+            for i in range(num_processes)
+        ]
 
         # Get first block
         block_number = subtensor.get_current_block()
         difficulty = subtensor.difficulty
-        block_hash = subtensor.substrate.get_block_hash( block_number )
+        block_hash = subtensor.substrate.get_block_hash(block_number)
         while block_hash == None:
-            block_hash = subtensor.substrate.get_block_hash( block_number )
-        block_bytes = block_hash.encode('utf-8')[2:]
+            block_hash = subtensor.substrate.get_block_hash(block_number)
+        block_bytes = block_hash.encode("utf-8")[2:]
         old_block_number = block_number
 
         # Set to current block
-        update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, difficulty, check_block)
+        update_curr_block(
+            curr_diff,
+            curr_block,
+            curr_block_num,
+            block_number,
+            block_bytes,
+            difficulty,
+            check_block,
+        )
 
         # Set new block events for each solver to start at the initial block
         for worker in solvers:
             worker.newBlockEvent.set()
 
         for worker in solvers:
-            worker.start() # start the solver processes
+            worker.start()  # start the solver processes
 
-        start_time = time.time() # time that the registration started
-        time_last = start_time # time that the last work blocks completed
+        start_time = time.time()  # time that the registration started
+        time_last = start_time  # time that the last work blocks completed
 
         curr_stats = RegistrationStatistics(
-            time_spent_total = 0.0,
-            time_average = 0.0,
-            rounds_total = 0,
-            time_spent = 0.0,
-            hash_rate_perpetual = 0.0,
-            hash_rate = 0.0, # EWMA hash_rate (H/s)
-            difficulty = difficulty,
-            block_number = block_number,
-            block_hash = block_hash
+            time_spent_total=0.0,
+            time_average=0.0,
+            rounds_total=0,
+            time_spent=0.0,
+            hash_rate_perpetual=0.0,
+            hash_rate=0.0,  # EWMA hash_rate (H/s)
+            difficulty=difficulty,
+            block_number=block_number,
+            block_hash=block_hash,
         )
 
         start_time_perpetual = time.time()
 
         console = bittensor.__console__
         logger = RegistrationStatisticsLogger(console, output_in_place)
         logger.start()
 
-        hash_rates = [0] * n_samples # The last n true hash_rates
-        weights = [alpha_ ** i for i in range(n_samples)] # weights decay by alpha
+        hash_rates = [0] * n_samples  # The last n true hash_rates
+        weights = [alpha_**i for i in range(n_samples)]  # weights decay by alpha
 
         solution = None
         while not subtensor.is_hotkey_registered(
-            hotkey_ss58 = wallet.hotkey.ss58_address,
+            hotkey_ss58=wallet.hotkey.ss58_address,
         ):
             # Wait until a solver finds a solution
             try:
                 solution = solution_queue.get(block=True, timeout=0.15)
                 if solution is not None:
                     break
             except Empty:
                 # No solution found, try again
                 pass
 
             # check for new block
             old_block_number = check_for_newest_block_and_update(
-                subtensor = subtensor,
+                subtensor=subtensor,
                 curr_diff=curr_diff,
                 curr_block=curr_block,
                 curr_block_num=curr_block_num,
                 old_block_number=old_block_number,
                 curr_stats=curr_stats,
                 update_curr_block=update_curr_block,
                 check_block=check_block,
-                solvers=solvers
+                solvers=solvers,
             )
 
             num_time = 0
             # Get times for each solver
             for finished_queue in finished_queues:
                 try:
                     proc_num = finished_queue.get(timeout=0.1)
                     num_time += 1
 
                 except Empty:
                     continue
 
-            time_now = time.time() # get current time
-            time_since_last = time_now - time_last # get time since last work block(s)
+            time_now = time.time()  # get current time
+            time_since_last = time_now - time_last  # get time since last work block(s)
             if num_time > 0 and time_since_last > 0.0:
                 # create EWMA of the hash_rate to make measure more robust
 
                 hash_rate_ = (num_time * TPB * update_interval) / time_since_last
                 hash_rates.append(hash_rate_)
-                hash_rates.pop(0) # remove the 0th data point
-                curr_stats.hash_rate = sum([hash_rates[i]*weights[i] for i in range(n_samples)])/(sum(weights))
+                hash_rates.pop(0)  # remove the 0th data point
+                curr_stats.hash_rate = sum(
+                    [hash_rates[i] * weights[i] for i in range(n_samples)]
+                ) / (sum(weights))
 
                 # update time last to now
                 time_last = time_now
 
-                curr_stats.time_average = (curr_stats.time_average*curr_stats.rounds_total + curr_stats.time_spent)/(curr_stats.rounds_total+num_time)
+                curr_stats.time_average = (
+                    curr_stats.time_average * curr_stats.rounds_total
+                    + curr_stats.time_spent
+                ) / (curr_stats.rounds_total + num_time)
                 curr_stats.rounds_total += num_time
 
             # Update stats
             curr_stats.time_spent = time_since_last
             new_time_spent_total = time_now - start_time_perpetual
-            curr_stats.hash_rate_perpetual = (curr_stats.rounds_total * (TPB * update_interval))/ new_time_spent_total
+            curr_stats.hash_rate_perpetual = (
+                curr_stats.rounds_total * (TPB * update_interval)
+            ) / new_time_spent_total
             curr_stats.time_spent_total = new_time_spent_total
 
             # Update the logger
             logger.update(curr_stats, verbose=log_verbose)
 
         # exited while, found_solution contains the nonce or wallet is registered
 
-        stopEvent.set() # stop all other processes
+        stopEvent.set()  # stop all other processes
         logger.stop()
 
         # terminate and wait for all solvers to exit
         terminate_workers_and_wait_for_exit(solvers)
 
         return solution
 
@@ -816,24 +996,39 @@
     wallet,
     output_in_place: bool = True,
     cuda: bool = False,
     dev_id: Union[List[int], int] = 0,
     tpb: int = 256,
     num_processes: int = None,
     update_interval: int = None,
-    log_verbose: bool = False
-    ) -> Optional[Dict[str, Any]]:
+    log_verbose: bool = False,
+) -> Optional[Dict[str, Any]]:
     if cuda:
-        solution: POWSolution = solve_for_difficulty_fast_cuda( subtensor, wallet, output_in_place=output_in_place, \
-            dev_id=dev_id, TPB=tpb, update_interval=update_interval, log_verbose=log_verbose
+        solution: POWSolution = solve_for_difficulty_fast_cuda(
+            subtensor,
+            wallet,
+            output_in_place=output_in_place,
+            dev_id=dev_id,
+            TPB=tpb,
+            update_interval=update_interval,
+            log_verbose=log_verbose,
         )
     else:
-        solution: POWSolution = solve_for_difficulty_fast( subtensor, wallet, output_in_place=output_in_place, \
-            num_processes=num_processes, update_interval=update_interval, log_verbose=log_verbose
+        solution: POWSolution = solve_for_difficulty_fast(
+            subtensor,
+            wallet,
+            output_in_place=output_in_place,
+            num_processes=num_processes,
+            update_interval=update_interval,
+            log_verbose=log_verbose,
         )
 
-    return None if solution is None else {
-        'nonce': solution.nonce,
-        'difficulty': solution.difficulty,
-        'block_number': solution.block_number,
-        'work': binascii.hexlify(solution.seal)
-    }
+    return (
+        None
+        if solution is None
+        else {
+            "nonce": solution.nonce,
+            "difficulty": solution.difficulty,
+            "block_number": solution.block_number,
+            "work": binascii.hexlify(solution.seal),
+        }
+    )
```

### Comparing `bittensor-5.3.1/bittensor/utils/stats.py` & `bittensor-5.3.2/bittensor/utils/stats.py`

 * *Files 17% similar despite different names*

```diff
@@ -15,66 +15,65 @@
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 import time
 
-class timed_rolling_avg():
-    """ A exponential moving average that updates values based on time since last update.
-    """
+
+class timed_rolling_avg:
+    """A exponential moving average that updates values based on time since last update."""
+
     def __init__(self, initial_value, alpha):
         self.value = initial_value
         self.alpha = alpha
         self.last_update = time.time()
 
     def update(self, new_value):
-        """ Update self.value (the moving average) with the new_value
-        """
+        """Update self.value (the moving average) with the new_value"""
         now = time.time()
         time_delta = now - self.last_update
         self.last_update = now
         new_value = new_value / time_delta
         self.value = (1 - self.alpha) * self.value + self.alpha * new_value
 
-class AmountPerSecondRollingAverage():
-    """ A exponential moving average that counts quantity per second.
-    """
+
+class AmountPerSecondRollingAverage:
+    """A exponential moving average that counts quantity per second."""
+
     def __init__(self, initial_value=0, alpha=0.1):
         self.value = initial_value
         self.alpha = alpha
         self.last_update = None
 
     def event(self, amount):
-        """ Update self.value (the moving average) with the new_value
-        """
+        """Update self.value (the moving average) with the new_value"""
         if self.last_update == None:
             self.last_update = time.time()
         else:
             now = time.time()
             time_delta = now - self.last_update
             self.last_update = now
             new_value = amount / time_delta
             self.value = (1 - self.alpha) * self.value + self.alpha * new_value
 
     def get(self) -> float:
         return float(self.value)
 
 
-class EventsPerSecondRollingAverage():
-    """ A exponential moving average that counts the number of events per second.
-    """
+class EventsPerSecondRollingAverage:
+    """A exponential moving average that counts the number of events per second."""
+
     def __init__(self, initial_value, alpha):
         self.value = initial_value
         self.alpha = alpha
         self.last_update = None
 
     def event(self):
-        """ Update self.value (the moving average) with the new_value
-        """
+        """Update self.value (the moving average) with the new_value"""
         if self.last_update == None:
             self.last_update = time.time()
         else:
             now = time.time()
             time_delta = now - self.last_update
             self.last_update = now
             new_value = 1 / time_delta
```

### Comparing `bittensor-5.3.1/bittensor/utils/test_utils.py` & `bittensor-5.3.2/bittensor/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `bittensor-5.3.1/bittensor/utils/tokenizer_utils.py` & `bittensor-5.3.2/bittensor/utils/tokenizer_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -21,15 +21,17 @@
 
 from typing import List, Dict, Tuple, Any, Union
 from transformers import PreTrainedTokenizerBase
 
 EPSILON = 1e-40
 
 
-def get_tokenizer_alignment_splits(offset_mapping: List[tuple], offset_mapping_std: List[tuple]) -> Dict[int, tuple]:
+def get_tokenizer_alignment_splits(
+    offset_mapping: List[tuple], offset_mapping_std: List[tuple]
+) -> Dict[int, tuple]:
     r"""
     Calculates split depths necessary for tokens to align input offsets to standard offsets.
     Only input offsets may be split, not standard offsets, to create one-to-one, one-to-many, or many-to-one
     token alignments between input-to-standard tokenization.
     Allows for multiple depth splits on a token.
         Args:
             offset_mapping (:obj:`List[tuple]`, `required`):
@@ -45,20 +47,23 @@
     splits = {}
     idx = 0  # index of token segment (server tokenization)
     idx_std = 0  # index of token segment (standard tokenization)
 
     right = offset_mapping[idx][1]  # first right edge
     right_std = offset_mapping_std[idx_std][1]  # first std right edge
 
-    while (idx + 1 < len(offset_mapping) and
-           offset_mapping[idx + 1][1] == right):  # ignore overlapping tokens
+    while (
+        idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+    ):  # ignore overlapping tokens
         idx += 1
 
-    while (idx_std + 1 < len(offset_mapping_std) and
-           offset_mapping_std[idx_std + 1][1] == right_std):  # ignore overlapping tokens
+    while (
+        idx_std + 1 < len(offset_mapping_std)
+        and offset_mapping_std[idx_std + 1][1] == right_std
+    ):  # ignore overlapping tokens
         idx_std += 1
 
     segment_count = 1  # keep count of segments traversed,
     segment_count_std = 1  # to track one-to-many, many-to-one conditions
 
     while idx < len(offset_mapping) and idx_std < len(offset_mapping_std):
         if right < right_std:
@@ -78,16 +83,17 @@
                 continue
 
             idx += 1
             if idx < len(offset_mapping):
                 right = offset_mapping[idx][1]
                 segment_count += 1
 
-            while (idx + 1 < len(offset_mapping) and
-                   offset_mapping[idx + 1][1] == right):  # ignore right-aligned overlapping tokens
+            while (
+                idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+            ):  # ignore right-aligned overlapping tokens
                 idx += 1
 
         elif right_std < right:
             if segment_count_std == 1 and segment_count > 1:  # prevent many-to-many
                 # Examples: [|] edge, [\] next edge, [.] split
                 #  | | | | . |
                 #  |       |    \
@@ -103,46 +109,55 @@
                 segment_count_std = 0
 
             idx_std += 1
             if idx_std < len(offset_mapping_std):
                 right_std = offset_mapping_std[idx_std][1]
                 segment_count_std += 1
 
-            while (idx_std + 1 < len(offset_mapping_std) and
-                   offset_mapping_std[idx_std + 1][1] == right_std):  # ignore right-aligned overlapping tokens
+            while (
+                idx_std + 1 < len(offset_mapping_std)
+                and offset_mapping_std[idx_std + 1][1] == right_std
+            ):  # ignore right-aligned overlapping tokens
                 idx_std += 1
 
         else:  # right == right_std
             idx += 1
             if idx < len(offset_mapping):
                 right = offset_mapping[idx][1]
                 segment_count = 1
 
             idx_std += 1
             if idx_std < len(offset_mapping_std):
                 right_std = offset_mapping_std[idx_std][1]
                 segment_count_std = 1
 
-            while (idx + 1 < len(offset_mapping) and
-                   offset_mapping[idx + 1][1] == right):  # ignore right-aligned overlapping tokens
+            while (
+                idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+            ):  # ignore right-aligned overlapping tokens
                 idx += 1
 
-            while (idx_std + 1 < len(offset_mapping_std) and
-                   offset_mapping_std[idx_std + 1][1] == right_std):  # ignore right-aligned overlapping tokens
+            while (
+                idx_std + 1 < len(offset_mapping_std)
+                and offset_mapping_std[idx_std + 1][1] == right_std
+            ):  # ignore right-aligned overlapping tokens
                 idx_std += 1
 
             continue
 
     for idx in splits:
-        splits[idx] = tuple(splits[idx])  # to enable hashable depths for split_map_cache keying
+        splits[idx] = tuple(
+            splits[idx]
+        )  # to enable hashable depths for split_map_cache keying
 
     return splits
 
 
-def get_tokenizer_sequence_mappings(offset_mapping: List[tuple], offset_mapping_std: List[tuple]) -> List[tuple]:
+def get_tokenizer_sequence_mappings(
+    offset_mapping: List[tuple], offset_mapping_std: List[tuple]
+) -> List[tuple]:
     r"""
     Greedily determine the one-to-one, one-to-many, or many-to-one token alignments
     between input-to-standard tokenizations.
     Disallow many-to-many mappings, but allow for right-aligned overlapping tokens.
         Args:
             offset_mapping (:obj:`List[tuple]`, `required`):
                 Tokenizer offset mappings for a specific sequence [(left_0, right_0), (left_1, right_1), ...].
@@ -165,98 +180,122 @@
     right_std = offset_mapping_std[idx_std][1]  # first std right edge
 
     segment_count = 1  # keep count of segments traversed,
     segment_count_std = 1  # to track one-to-many, many-to-one conditions
     segment_count_overlap = 0  # keep count of overlapping segments
     segment_count_std_overlap = 0
 
-    while (idx + 1 < len(offset_mapping) and
-           offset_mapping[idx + 1][1] == right):  # ignore overlapping tokens
+    while (
+        idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+    ):  # ignore overlapping tokens
         idx += 1
         segment_count_overlap += 1
 
-    while (idx_std + 1 < len(offset_mapping_std) and
-           offset_mapping_std[idx_std + 1][1] == right_std):  # ignore overlapping tokens
+    while (
+        idx_std + 1 < len(offset_mapping_std)
+        and offset_mapping_std[idx_std + 1][1] == right_std
+    ):  # ignore overlapping tokens
         idx_std += 1
         segment_count_std_overlap += 1
 
     while idx < len(offset_mapping) and idx_std < len(offset_mapping_std):
         if right < right_std:
             if segment_count == 1 and segment_count_std > 1:
                 # Examples: [|] edge, [\] next edge, [.] split
                 #  |     . |   \
                 #  | | | |   |
-                print('Unaligned: Expected an aligned std edge.')
-                print('idx, idx_std, right, right_std, segment_count, segment_count_std')
+                print("Unaligned: Expected an aligned std edge.")
+                print(
+                    "idx, idx_std, right, right_std, segment_count, segment_count_std"
+                )
                 print(idx, idx_std, right, right_std, segment_count, segment_count_std)
 
             idx += 1
             if idx < len(offset_mapping):
                 right = offset_mapping[idx][1]
                 segment_count += 1
 
-            while (idx + 1 < len(offset_mapping) and
-                   offset_mapping[idx + 1][1] == right):  # ignore overlapping tokens
+            while (
+                idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+            ):  # ignore overlapping tokens
                 idx += 1
                 segment_count_overlap += 1
 
         elif right_std < right:
             if segment_count_std == 1 and segment_count > 1:
                 # Examples: [|] edge, [\] next edge, [.] split
                 #  | | | | . |
                 #  |       |    \
-                print('Unaligned: Expected an aligned edge.')
-                print('idx, idx_std, right, right_std, segment_count, segment_count_std')
+                print("Unaligned: Expected an aligned edge.")
+                print(
+                    "idx, idx_std, right, right_std, segment_count, segment_count_std"
+                )
                 print(idx, idx_std, right, right_std, segment_count, segment_count_std)
 
             idx_std += 1
             if idx_std < len(offset_mapping_std):
                 right_std = offset_mapping_std[idx_std][1]
                 segment_count_std += 1
 
-            while (idx_std + 1 < len(offset_mapping_std) and
-                   offset_mapping_std[idx_std + 1][1] == right_std):  # ignore overlapping tokens
+            while (
+                idx_std + 1 < len(offset_mapping_std)
+                and offset_mapping_std[idx_std + 1][1] == right_std
+            ):  # ignore overlapping tokens
                 idx_std += 1
                 segment_count_std_overlap += 1
 
         else:  # right == right_std
-            mappings += [(idx, idx_std, segment_count, segment_count_std,
-                          segment_count_overlap, segment_count_std_overlap)]
+            mappings += [
+                (
+                    idx,
+                    idx_std,
+                    segment_count,
+                    segment_count_std,
+                    segment_count_overlap,
+                    segment_count_std_overlap,
+                )
+            ]
 
             segment_count_overlap = 0
             segment_count_std_overlap = 0
 
             idx += 1
             if idx < len(offset_mapping):
                 right = offset_mapping[idx][1]
                 segment_count = 1
 
             idx_std += 1
             if idx_std < len(offset_mapping_std):
                 right_std = offset_mapping_std[idx_std][1]
                 segment_count_std = 1
 
-            while (idx + 1 < len(offset_mapping) and
-                   offset_mapping[idx + 1][1] == right):  # ignore overlapping tokens
+            while (
+                idx + 1 < len(offset_mapping) and offset_mapping[idx + 1][1] == right
+            ):  # ignore overlapping tokens
                 idx += 1
                 segment_count_overlap += 1
 
-            while (idx_std + 1 < len(offset_mapping_std) and
-                   offset_mapping_std[idx_std + 1][1] == right_std):  # ignore overlapping tokens
+            while (
+                idx_std + 1 < len(offset_mapping_std)
+                and offset_mapping_std[idx_std + 1][1] == right_std
+            ):  # ignore overlapping tokens
                 idx_std += 1
                 segment_count_std_overlap += 1
             continue
 
-    mappings += [(len(offset_mapping), len(offset_mapping_std), 1, 1, 0, 0)]  # validation segment
+    mappings += [
+        (len(offset_mapping), len(offset_mapping_std), 1, 1, 0, 0)
+    ]  # validation segment
 
     return mappings
 
 
-def get_tokenizer_depth_split_map(tokenizer: PreTrainedTokenizerBase,
-                                  depths: tuple) -> List[Dict[str, torch.LongTensor]]:
+def get_tokenizer_depth_split_map(
+    tokenizer: PreTrainedTokenizerBase, depths: tuple
+) -> List[Dict[str, torch.LongTensor]]:
     r"""
     Split individual token strings at specified depths, retokenize each resulting segment,
     keep only the first token of each segment (if there is one).
     Purpose is to provide targets for scattering probabilities when a single distribution requires a depth split.
         Args:
             tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 Tokenizer.
@@ -264,69 +303,92 @@
                 Tuple of depths at which tokens strings will be split.
 
         Returns:
             split_map (:obj:`List[Dict[str, torch.LongTensor]]`, `required`):
     """
     split_map = []
 
-    phrases = tokenizer.batch_decode(range(tokenizer.vocab_len))  # list of variable len strings (one per token)
+    phrases = tokenizer.batch_decode(
+        range(tokenizer.vocab_len)
+    )  # list of variable len strings (one per token)
 
     # first part of the phrase up to distance characters
-    split_phrases = [[phrase[:depths[0]] for phrase in phrases]]
-    for i in range(len(depths)-1):
+    split_phrases = [[phrase[: depths[0]] for phrase in phrases]]
+    for i in range(len(depths) - 1):
         # middle parts of the phrase from distance characters to end
-        split_phrases += [[phrase[depths[i]:depths[i+1]] for phrase in phrases]]
+        split_phrases += [[phrase[depths[i] : depths[i + 1]] for phrase in phrases]]
     # right part of the phrase from distance characters to end
-    split_phrases += [[phrase[depths[-1]:] for phrase in phrases]]
+    split_phrases += [[phrase[depths[-1] :] for phrase in phrases]]
 
-    for i, phrases in enumerate(split_phrases):  # loop through left, middle, right phrase collections
-        side_tokens = tokenizer(phrases)['input_ids']  # tokenize phrase collection
+    for i, phrases in enumerate(
+        split_phrases
+    ):  # loop through left, middle, right phrase collections
+        side_tokens = tokenizer(phrases)["input_ids"]  # tokenize phrase collection
         tokens_lens = [len(p) for p in side_tokens]  # get token lengths of each phrase
-        from_idx = [i for i, l in enumerate(tokens_lens) if l > 0]  # only non-zero len tokens list
-        first_tokens = [side_tokens[i][0] for i in from_idx]  # collect first tokens of each tokenized phrase
+        from_idx = [
+            i for i, l in enumerate(tokens_lens) if l > 0
+        ]  # only non-zero len tokens list
+        first_tokens = [
+            side_tokens[i][0] for i in from_idx
+        ]  # collect first tokens of each tokenized phrase
         # add dict for phrase collection, mapping from original index to first tokens of tokenized phrase substrings
-        split_map += [{'from': torch.tensor(from_idx, dtype=torch.long),
-                       'to': torch.tensor(first_tokens, dtype=torch.long)}]
+        split_map += [
+            {
+                "from": torch.tensor(from_idx, dtype=torch.long),
+                "to": torch.tensor(first_tokens, dtype=torch.long),
+            }
+        ]
 
     return split_map
 
 
-def split_probs(probs: torch.FloatTensor, split_map: List[Dict[str, torch.Tensor]]) -> torch.FloatTensor:
+def split_probs(
+    probs: torch.FloatTensor, split_map: List[Dict[str, torch.Tensor]]
+) -> torch.FloatTensor:
     r"""
     Split a given probability distribution over a tokenizer vocabulary, given a split_map
     of mappings from original tokens to target tokens at each depth of the split.
         Args:
             probs (:obj:`torch.FloatTensor`, `required`):
                 [vocab_size] Input probability distribution over a tokenizer vocabulary.
             split_map (:obj:`List[Dict[str, torch.Tensor]]`, `required`):
                 A split_map of mappings from original tokens to target tokens at each depth of the split.
 
         Returns:
             new_probs (:obj:`torch.FloatTensor`, `required`):
                 [splits, vocab_size] A new tensor with resultant probability distribution at each index
                 of the first dim, representing corresponding split depth.
     """
-    splits = len(split_map)  # how many parts to the depth split map, e.g. left, middle, right parts
+    splits = len(
+        split_map
+    )  # how many parts to the depth split map, e.g. left, middle, right parts
     vocab_size = probs.shape[0]  # retain input vocabulary size
-    new_probs = torch.zeros((splits, vocab_size)).to(probs.device)  # provision prob dist for each part
+    new_probs = torch.zeros((splits, vocab_size)).to(
+        probs.device
+    )  # provision prob dist for each part
 
     for pos in range(splits):  # loop through all parts of the split
-        from_idx = split_map[pos]['from']  # from original string token index
-        to_idx = split_map[pos]['to']  # to first token index of retokenized part string
-        new_probs[pos].scatter_add_(0, to_idx, probs[from_idx])  # transfer probabilities to new part distributions
+        from_idx = split_map[pos]["from"]  # from original string token index
+        to_idx = split_map[pos]["to"]  # to first token index of retokenized part string
+        new_probs[pos].scatter_add_(
+            0, to_idx, probs[from_idx]
+        )  # transfer probabilities to new part distributions
 
     return new_probs  # [splits, vocab_size]
 
 
-def align_tokenizer_sequences(probs: torch.FloatTensor, offset_mapping: List[tuple], offset_mapping_std: List[tuple],
-                              tokenizer: PreTrainedTokenizerBase,
-                              split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
-                              tokens: torch.LongTensor, tokens_std: torch.LongTensor) -> Tuple[torch.FloatTensor,
-                                                                                               List[tuple],
-                                                                                               torch.LongTensor]:
+def align_tokenizer_sequences(
+    probs: torch.FloatTensor,
+    offset_mapping: List[tuple],
+    offset_mapping_std: List[tuple],
+    tokenizer: PreTrainedTokenizerBase,
+    split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
+    tokens: torch.LongTensor,
+    tokens_std: torch.LongTensor,
+) -> Tuple[torch.FloatTensor, List[tuple], torch.LongTensor]:
     r"""
     Align an input tokenization distribution to standard tokenization segments by depth-splitting
     the input distribution at greedily chosen locations. Prepares the input distribution for mapping to a standard
     distribution.
         Args:
             probs (:obj:`torch.FloatTensor`, `required`):
                 [sequence_len, vocab_size] Input probability distribution over a tokenizer vocabulary.
@@ -350,64 +412,95 @@
             aligned_offset_mapping (:obj:`List[tuple]`, `required`):
                 Tokenizer aligned offset mappings for a specific sequence [(left_0, right_0), (left_1, right_1), ...].
             aligned_tokens (:obj:`torch.LongTensor`, `required`):
                 A sequence of aligned tokens produced by the source tokenizer.
     """
     aligned_tokens = []  # to store new aligned tokens
     aligned_probs = []  # to store new aligned probability distributions
-    aligned_offset_mapping = []  # to store new aligned offset mappings of aligned tokens
-    splits = get_tokenizer_alignment_splits(offset_mapping, offset_mapping_std)  # get necessary token split locations
+    aligned_offset_mapping = (
+        []
+    )  # to store new aligned offset mappings of aligned tokens
+    splits = get_tokenizer_alignment_splits(
+        offset_mapping, offset_mapping_std
+    )  # get necessary token split locations
 
     prev_idx = 0
     for idx in splits:  # each source token index that must be split
         depths = splits[idx]  # list of depths at which the token string must be split
         aligned_probs += [probs[prev_idx:idx]]  # retain preceding token probabilities
-        aligned_offset_mapping += offset_mapping[prev_idx:idx]  # retain preceding offset mappings
+        aligned_offset_mapping += offset_mapping[
+            prev_idx:idx
+        ]  # retain preceding offset mappings
         aligned_tokens += [tokens[prev_idx:idx]]  # retain preceding tokens
 
         if depths not in split_map_cache:
             # add depths split to cache to reuse in future (split map calc is relatively time-consuming)
             split_map_cache[depths] = get_tokenizer_depth_split_map(tokenizer, depths)
 
-        new_probs = split_probs(probs[idx], split_map_cache[depths])  # [splits, vocab_size] new split probabilities
+        new_probs = split_probs(
+            probs[idx], split_map_cache[depths]
+        )  # [splits, vocab_size] new split probabilities
         aligned_probs += [new_probs]
 
         text_idx = tokenizer.decode(tokens[idx])
 
         # === Left part ===
-        new_tokens = tokenizer(text_idx[:depths[0]], add_special_tokens=False, return_tensors='pt')['input_ids'][0]
+        new_tokens = tokenizer(
+            text_idx[: depths[0]], add_special_tokens=False, return_tensors="pt"
+        )["input_ids"][0]
         aligned_tokens += [new_tokens[:1]]
-        aligned_offset_mapping += [(offset_mapping[idx][0], offset_mapping[idx][0] + depths[0])]
+        aligned_offset_mapping += [
+            (offset_mapping[idx][0], offset_mapping[idx][0] + depths[0])
+        ]
 
         # === Middle parts ===
-        for d in range(len(depths)-1):
-            new_tokens = tokenizer(text_idx[depths[d]:depths[d+1]],
-                                   add_special_tokens=False, return_tensors='pt')['input_ids'][0]
+        for d in range(len(depths) - 1):
+            new_tokens = tokenizer(
+                text_idx[depths[d] : depths[d + 1]],
+                add_special_tokens=False,
+                return_tensors="pt",
+            )["input_ids"][0]
             aligned_tokens += [new_tokens[:1]]
-            aligned_offset_mapping += [(offset_mapping[idx][0] + depths[d], offset_mapping[idx][0] + depths[d+1])]
+            aligned_offset_mapping += [
+                (
+                    offset_mapping[idx][0] + depths[d],
+                    offset_mapping[idx][0] + depths[d + 1],
+                )
+            ]
 
         # == Right part ===
-        new_tokens = tokenizer(text_idx[depths[-1]:], add_special_tokens=False, return_tensors='pt')['input_ids'][0]
+        new_tokens = tokenizer(
+            text_idx[depths[-1] :], add_special_tokens=False, return_tensors="pt"
+        )["input_ids"][0]
         aligned_tokens += [new_tokens[:1]]
-        aligned_offset_mapping += [(offset_mapping[idx][0] + depths[-1], offset_mapping[idx][1])]
+        aligned_offset_mapping += [
+            (offset_mapping[idx][0] + depths[-1], offset_mapping[idx][1])
+        ]
 
         prev_idx = idx + 1
 
     aligned_probs += [probs[prev_idx:]]  # retain remainder of tokens probabilities
     aligned_tokens += [tokens[prev_idx:]]  # retain remainder of tokens
-    aligned_offset_mapping += offset_mapping[prev_idx:]  # retain remainder of offset mappings
-
-    aligned_probs = torch.cat(aligned_probs, dim=0)  # [sequence_len, vocab_size] assemble final probability tensor
-    aligned_tokens = torch.cat(aligned_tokens, dim=0).long()  # [sequence_len] assemble final token sequence
+    aligned_offset_mapping += offset_mapping[
+        prev_idx:
+    ]  # retain remainder of offset mappings
+
+    aligned_probs = torch.cat(
+        aligned_probs, dim=0
+    )  # [sequence_len, vocab_size] assemble final probability tensor
+    aligned_tokens = torch.cat(
+        aligned_tokens, dim=0
+    ).long()  # [sequence_len] assemble final token sequence
 
     return aligned_probs, aligned_offset_mapping, aligned_tokens
 
 
-def get_translation_map(from_tokenizer: PreTrainedTokenizerBase,
-                        to_tokenizer: PreTrainedTokenizerBase) -> Dict[str, Any]:
+def get_translation_map(
+    from_tokenizer: PreTrainedTokenizerBase, to_tokenizer: PreTrainedTokenizerBase
+) -> Dict[str, Any]:
     r"""
     Map individual token phrases from a tokenizer to another tokenizer.
         Args:
             from_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 From tokenizer.
             to_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 To tokenizer.
@@ -416,40 +509,50 @@
             translation_map (:obj:`Dict[str, Any]`, `required`):
                 Maps for each observed length, a source token to a token sequence of that length,
                 with source index to target indices.
     """
     set_vocab_len(from_tokenizer)
     set_vocab_len(to_tokenizer)
 
-    translation_map = {'lengths': {}}
-
-    phrases = from_tokenizer.batch_decode(range(from_tokenizer.vocab_len))  # tokens to strings
+    translation_map = {"lengths": {}}
 
-    to_tokens = to_tokenizer(phrases)['input_ids']  # convert single token from-phrases to to-tokenization
+    phrases = from_tokenizer.batch_decode(
+        range(from_tokenizer.vocab_len)
+    )  # tokens to strings
+
+    to_tokens = to_tokenizer(phrases)[
+        "input_ids"
+    ]  # convert single token from-phrases to to-tokenization
     to_tokens_lens = [len(p) for p in to_tokens]
     unique_lens = set(to_tokens_lens)
     max_len = max(unique_lens)
     counts = torch.zeros((max_len, to_tokenizer.vocab_len), dtype=torch.long)
 
     for l in unique_lens:  # each unique one-to-many mapping length
-        from_idx = [i for i, k in enumerate(to_tokens_lens) if k == l]  # find len l to-tokenizations
+        from_idx = [
+            i for i, k in enumerate(to_tokens_lens) if k == l
+        ]  # find len l to-tokenizations
         subset = [to_tokens[i] for i in from_idx]  # find len l to-tokenizations
         from_idx = torch.tensor(from_idx, dtype=torch.long)  # [subset_size]
         to_idx = torch.tensor(subset, dtype=torch.long)  # [subset_size, l]
-        translation_map['lengths'][l] = {'from': from_idx,
-                                         'to': to_idx}
+        translation_map["lengths"][l] = {"from": from_idx, "to": to_idx}
         # accumulate counts on tokens, to be used to divide probability mass over its channeled sequences
-        counts[:l, :].scatter_add_(1, to_idx.T, torch.ones((l, len(subset)), dtype=torch.long))
+        counts[:l, :].scatter_add_(
+            1, to_idx.T, torch.ones((l, len(subset)), dtype=torch.long)
+        )
 
-    translation_map['counts'] = counts
+    translation_map["counts"] = counts
     return translation_map
 
 
-def translate_one_to_many(probs_from: torch.FloatTensor, probs_to: torch.FloatTensor,
-                          translation_map: Dict[str, Any]) -> None:
+def translate_one_to_many(
+    probs_from: torch.FloatTensor,
+    probs_to: torch.FloatTensor,
+    translation_map: Dict[str, Any],
+) -> None:
     r"""
     Translate a single token probability distribution from a source tokenization to a
     sequence of probability distributions over a target tokenization.
         Args:
             probs_from (:obj:`torch.FloatTensor`, `required`):
                 [vocab_size] Input probability distribution over a from-tokenizer vocabulary.
             probs_to (:obj:`torch.FloatTensor`, `required`):
@@ -461,67 +564,97 @@
         Returns:
 
     """
     many_len = probs_to.shape[0]
 
     # === Unroll single distribution into std sequence ===
     for i in range(many_len):  # each unrolling step
-        for map_len in translation_map['lengths'].keys():  # each one-to-many mapping length available
+        for map_len in translation_map[
+            "lengths"
+        ].keys():  # each one-to-many mapping length available
             if map_len < i + 1:
                 continue  # skip unrolling steps not available in a shorter mapping length
-            from_idx = translation_map['lengths'][map_len]['from']
-            to_idx = translation_map['lengths'][map_len]['to'].T  # [map_len, subset_size_std]
-            probs_to[i, :].scatter_add_(0, to_idx[i, :], probs_from[from_idx])  # add probs in-place
-
-
-def translate_many_to_one(probs_from: torch.FloatTensor, probs_to: torch.FloatTensor,
-                          translation_map: Dict[str, Any]) -> None:
-    r"""
-        Translate a sequence of token probability distributions from a source tokenization to a
-        single token probability distribution over a target tokenization.
-            Args:
-                probs_from (:obj:`torch.FloatTensor`, `required`):
-                    [many, vocab_size] Input probability distributions over a from-tokenizer vocabulary.
-                probs_to (:obj:`torch.FloatTensor`, `required`):
-                    [vocab_size] Output probability distribution over a to-tokenizer vocabulary.
-                translation_map (:obj:`Dict[str, Any]`, `required`):
-                    Maps for each observed length, a source token to a token sequence of that length,
-                    with source index to target indices.
+            from_idx = translation_map["lengths"][map_len]["from"]
+            to_idx = translation_map["lengths"][map_len][
+                "to"
+            ].T  # [map_len, subset_size_std]
+            probs_to[i, :].scatter_add_(
+                0, to_idx[i, :], probs_from[from_idx]
+            )  # add probs in-place
+
+
+def translate_many_to_one(
+    probs_from: torch.FloatTensor,
+    probs_to: torch.FloatTensor,
+    translation_map: Dict[str, Any],
+) -> None:
+    r"""
+    Translate a sequence of token probability distributions from a source tokenization to a
+    single token probability distribution over a target tokenization.
+        Args:
+            probs_from (:obj:`torch.FloatTensor`, `required`):
+                [many, vocab_size] Input probability distributions over a from-tokenizer vocabulary.
+            probs_to (:obj:`torch.FloatTensor`, `required`):
+                [vocab_size] Output probability distribution over a to-tokenizer vocabulary.
+            translation_map (:obj:`Dict[str, Any]`, `required`):
+                Maps for each observed length, a source token to a token sequence of that length,
+                with source index to target indices.
 
-            Returns:
+        Returns:
 
-        """
+    """
     many_len = probs_from.shape[0]
     probs_from_copy = probs_from.clone()  # will modify from-probabilities
 
     # === Spread probability mass over realized sequences ===
-    counts = translation_map['counts']  # [max_len, vocab_size]
-    translation_max_len = counts.shape[0]  # maximum possible many-to-one length available in translation map
+    counts = translation_map["counts"]  # [max_len, vocab_size]
+    translation_max_len = counts.shape[
+        0
+    ]  # maximum possible many-to-one length available in translation map
 
     if many_len <= translation_max_len:
-        probs_from_copy /= counts[:many_len, :]  # divide probability mass by amount of paths crossing each token
+        probs_from_copy /= counts[
+            :many_len, :
+        ]  # divide probability mass by amount of paths crossing each token
     else:  # limit probs_from token depth to max_len
         probs_from_copy[:translation_max_len, :] /= counts
 
     # === Reverse map std token to source sequences, gather avg. sequence prob ===
-    for map_len in translation_map['lengths'].keys():  # mutually exclusive over std tokens
-        from_idx = translation_map['lengths'][map_len]['from']  # [subset_size_std] one std token
-        to_idx = translation_map['lengths'][map_len]['to'].T  # [map_len, subset_size_std] many server token seq
+    for map_len in translation_map[
+        "lengths"
+    ].keys():  # mutually exclusive over std tokens
+        from_idx = translation_map["lengths"][map_len][
+            "from"
+        ]  # [subset_size_std] one std token
+        to_idx = translation_map["lengths"][map_len][
+            "to"
+        ].T  # [map_len, subset_size_std] many server token seq
         if many_len < map_len:  # sequence beyond segment_count has min probability 0
             to_idx = to_idx[:many_len, :]  # [segment_count, subset_size_std]
-        server_seq_tokens = probs_from_copy.gather(1, to_idx)  # [map_len, subset_size_std] gather sequences
-        probs_to[from_idx] = server_seq_tokens.sum(dim=0) / map_len  # [subset_size_std] in-place average approx.
-
-
-def translate_tokenizer_probs(probs: torch.FloatTensor, probs_std: torch.FloatTensor,
-                              offset_mapping: List[tuple], offset_mapping_std: List[tuple],
-                              tokenizer: PreTrainedTokenizerBase, std_tokenizer: PreTrainedTokenizerBase,
-                              split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
-                              to_translation_map: Dict[str, Any], from_translation_map: Dict[str, Any],
-                              tokens: torch.LongTensor, tokens_std: torch.LongTensor) -> None:
+        server_seq_tokens = probs_from_copy.gather(
+            1, to_idx
+        )  # [map_len, subset_size_std] gather sequences
+        probs_to[from_idx] = (
+            server_seq_tokens.sum(dim=0) / map_len
+        )  # [subset_size_std] in-place average approx.
+
+
+def translate_tokenizer_probs(
+    probs: torch.FloatTensor,
+    probs_std: torch.FloatTensor,
+    offset_mapping: List[tuple],
+    offset_mapping_std: List[tuple],
+    tokenizer: PreTrainedTokenizerBase,
+    std_tokenizer: PreTrainedTokenizerBase,
+    split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
+    to_translation_map: Dict[str, Any],
+    from_translation_map: Dict[str, Any],
+    tokens: torch.LongTensor,
+    tokens_std: torch.LongTensor,
+) -> None:
     r"""
     Translates source token probability distributions to target probability distributions, by
     aligning segments through source token splits, then greedily performing one-to-one,
     one-to-many, many-to-one distribution mappings.
         Args:
             probs (:obj:`torch.FloatTensor`, `required`):
                 [sequence_len, vocab_size] Input probability distribution over a source tokenizer vocabulary.
@@ -550,49 +683,77 @@
                 Maps for each observed length, a source token to a token sequence of that length,
                 from target index to source indices.
 
         Returns:
 
     """
     # === Align tokenized sequences via source token splitting ===
-    result = align_tokenizer_sequences(probs, offset_mapping, offset_mapping_std,
-                                       tokenizer, split_map_cache, tokens.cpu(), tokens_std.cpu())
+    result = align_tokenizer_sequences(
+        probs,
+        offset_mapping,
+        offset_mapping_std,
+        tokenizer,
+        split_map_cache,
+        tokens.cpu(),
+        tokens_std.cpu(),
+    )
     aligned_probs, aligned_offset_mapping, aligned_tokens = result
 
     # === Get one-to-many / many-to-one mappings ===
-    mappings = get_tokenizer_sequence_mappings(aligned_offset_mapping, offset_mapping_std)
+    mappings = get_tokenizer_sequence_mappings(
+        aligned_offset_mapping, offset_mapping_std
+    )
 
     # === Perform probability mappings ===
-    for (right_idx, right_idx_std, segment_count_base, segment_count_std_base,
-         segment_count_overlap, segment_count_std_overlap) in mappings[1:]:  # don't map start token
-
-        segment_count = segment_count_base + segment_count_overlap  # calculate effective segments length
-        segment_count_std = segment_count_std_base + segment_count_std_overlap  # calculate effective segments length
+    for (
+        right_idx,
+        right_idx_std,
+        segment_count_base,
+        segment_count_std_base,
+        segment_count_overlap,
+        segment_count_std_overlap,
+    ) in mappings[
+        1:
+    ]:  # don't map start token
+        segment_count = (
+            segment_count_base + segment_count_overlap
+        )  # calculate effective segments length
+        segment_count_std = (
+            segment_count_std_base + segment_count_std_overlap
+        )  # calculate effective segments length
 
         # === One-to-many / one-to-one mapping ===
         if segment_count_base == 1:
-            start_idx_std = right_idx_std - segment_count_std  # calculate starting index
-
-            translate_one_to_many(aligned_probs[right_idx-1],
-                                  probs_std[start_idx_std:start_idx_std+segment_count_std],
-                                  to_translation_map)
+            start_idx_std = (
+                right_idx_std - segment_count_std
+            )  # calculate starting index
+
+            translate_one_to_many(
+                aligned_probs[right_idx - 1],
+                probs_std[start_idx_std : start_idx_std + segment_count_std],
+                to_translation_map,
+            )
 
         # === Many-to-one mapping ===
         elif segment_count_std_base == 1:  # many-to-one
             start_idx = right_idx - segment_count  # calculate starting index
 
-            translate_many_to_one(aligned_probs[start_idx:right_idx],
-                                  probs_std[right_idx_std-1],
-                                  from_translation_map)
+            translate_many_to_one(
+                aligned_probs[start_idx:right_idx],
+                probs_std[right_idx_std - 1],
+                from_translation_map,
+            )
 
         else:
-            print('Undefined mapping.')
+            print("Undefined mapping.")
 
 
-def get_top_probs(probs: torch.FloatTensor, tokenizer: PreTrainedTokenizerBase, amount: int = 10) -> str:
+def get_top_probs(
+    probs: torch.FloatTensor, tokenizer: PreTrainedTokenizerBase, amount: int = 10
+) -> str:
     r"""
     Constructs output string with top amount of highest probability token strings.
     Used to display the top probabilities.
         Args:
             probs (:obj:`torch.FloatTensor`, `required`):
                 [vocab_size] Probability distribution over a tokenizer vocabulary.
             tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
@@ -600,119 +761,147 @@
             amount: (:obj:`int`, `optional`):
                 Amount of top tokens to return
 
         Returns:
             string (:obj:`str`, `required`):
             Highest probability token strings, prob[token-string] ...
     """
-    string = ''
+    string = ""
 
-    vals, indices = probs.sort(dim=-1, descending=True)  # descending sort token probabilities
+    vals, indices = probs.sort(
+        dim=-1, descending=True
+    )  # descending sort token probabilities
 
     for i in range(amount):
-        string += '%.4f[%s] ' % (vals[i], tokenizer.decode(indices[i]))  # prob[token-string]
+        string += "%.4f[%s] " % (
+            vals[i],
+            tokenizer.decode(indices[i]),
+        )  # prob[token-string]
 
     return string
 
 
-def translate_logits_to_probs_std(logits: torch.FloatTensor,
-                                  offset_mapping: List[List[tuple]], offset_mapping_std: List[List[tuple]],
-                                  tokenizer: PreTrainedTokenizerBase, std_tokenizer: PreTrainedTokenizerBase,
-                                  split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
-                                  to_translation_map: Dict[str, Any], from_translation_map: Dict[str, Any],
-                                  tokens: torch.LongTensor, tokens_std: torch.LongTensor,
-                                  skip_equivalent: bool = True) -> torch.FloatTensor:
-    r"""
-        Translates source token logit scores to probability distributions over the standard tokenizer.
-            Args:
-                logits (:obj:`torch.FloatTensor`, `required`):
-                    [batch_size, sequence_len, vocab_size] Input source logits over a source tokenizer vocabulary.
-                offset_mapping (:obj:`List[List[tuple]]`, `required`):
-                    Batch of tokenizer offset mappings
-                    [[(left_0, right_0), (left_1, right_1), ...], ...].
-                offset_mapping_std (:obj:`List[List[tuple]]`, `required`):
-                    Batch of standard tokenizer offset mappings
-                    [[(left_0, right_0), (left_1, right_1), ...], ...].
-                tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
-                    Source tokenizer.
-                std_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
-                    Standard/target tokenizer.
-                split_map_cache (:obj:`Dict[tuple, List[Dict[str, torch.Tensor]]]`, `required`):
-                    A dictionary of depths keying split_maps of mappings from original tokens to
-                    target tokens at each depth of the split. Adds split_maps to cache for faster future recall.
-                tokens (:obj:`torch.LongTensor`, `required`):
-                    [batch_size, sequence_len] A sequence of tokens produced by the source tokenizer.
-                tokens_std (:obj:`torch.LongTensor`, `required`):
-                    [batch_size, std_sequence_len] A sequence of tokens produced by the standard tokenizer.
-                to_translation_map (:obj:`Dict[str, Any]`, `required`):
-                    Maps for each observed length, a source token to a token sequence of that length,
-                    with source index to target indices.
-                from_translation_map (:obj:`Dict[str, Any]`, `required`):
-                    Maps for each observed length, a source token to a token sequence of that length,
-                    from target index to source indices.
-                skip_equivalent (:obj:`bool`, `optional`):
-                    Skips translation if tokenizer and std_tokenizer are equivalent.
-
-            Returns:
-                probs_std (:obj:`torch.FloatTensor`, `required`):
-                    [batch_size, std_sequence_len, std_vocab_size] Output probability distribution over the
-                    standard tokenizer vocabulary.
-        """
+def translate_logits_to_probs_std(
+    logits: torch.FloatTensor,
+    offset_mapping: List[List[tuple]],
+    offset_mapping_std: List[List[tuple]],
+    tokenizer: PreTrainedTokenizerBase,
+    std_tokenizer: PreTrainedTokenizerBase,
+    split_map_cache: Dict[tuple, List[Dict[str, torch.Tensor]]],
+    to_translation_map: Dict[str, Any],
+    from_translation_map: Dict[str, Any],
+    tokens: torch.LongTensor,
+    tokens_std: torch.LongTensor,
+    skip_equivalent: bool = True,
+) -> torch.FloatTensor:
+    r"""
+    Translates source token logit scores to probability distributions over the standard tokenizer.
+        Args:
+            logits (:obj:`torch.FloatTensor`, `required`):
+                [batch_size, sequence_len, vocab_size] Input source logits over a source tokenizer vocabulary.
+            offset_mapping (:obj:`List[List[tuple]]`, `required`):
+                Batch of tokenizer offset mappings
+                [[(left_0, right_0), (left_1, right_1), ...], ...].
+            offset_mapping_std (:obj:`List[List[tuple]]`, `required`):
+                Batch of standard tokenizer offset mappings
+                [[(left_0, right_0), (left_1, right_1), ...], ...].
+            tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
+                Source tokenizer.
+            std_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
+                Standard/target tokenizer.
+            split_map_cache (:obj:`Dict[tuple, List[Dict[str, torch.Tensor]]]`, `required`):
+                A dictionary of depths keying split_maps of mappings from original tokens to
+                target tokens at each depth of the split. Adds split_maps to cache for faster future recall.
+            tokens (:obj:`torch.LongTensor`, `required`):
+                [batch_size, sequence_len] A sequence of tokens produced by the source tokenizer.
+            tokens_std (:obj:`torch.LongTensor`, `required`):
+                [batch_size, std_sequence_len] A sequence of tokens produced by the standard tokenizer.
+            to_translation_map (:obj:`Dict[str, Any]`, `required`):
+                Maps for each observed length, a source token to a token sequence of that length,
+                with source index to target indices.
+            from_translation_map (:obj:`Dict[str, Any]`, `required`):
+                Maps for each observed length, a source token to a token sequence of that length,
+                from target index to source indices.
+            skip_equivalent (:obj:`bool`, `optional`):
+                Skips translation if tokenizer and std_tokenizer are equivalent.
+
+        Returns:
+            probs_std (:obj:`torch.FloatTensor`, `required`):
+                [batch_size, std_sequence_len, std_vocab_size] Output probability distribution over the
+                standard tokenizer vocabulary.
+    """
     set_vocab_len(tokenizer)
     set_vocab_len(std_tokenizer)
 
     # === Check tokenizer equivalence / Skip if equivalent ===
     if skip_equivalent and check_tokenizer_equivalence(tokenizer, std_tokenizer):
-        logits = logits.to(torch.float).to('cpu')
+        logits = logits.to(torch.float).to("cpu")
         probs = torch.softmax(logits, dim=2)
         return probs
 
     # === Get shape sizes ===
     batch_size, sequence_len, vocab_size = logits.shape
     std_sequence_len = tokens_std.shape[-1]
     std_vocab_size = std_tokenizer.vocab_len
 
     if tokenizer.vocab_len < vocab_size:
-        logits = logits[..., :tokenizer.vocab_len]
+        logits = logits[..., : tokenizer.vocab_len]
         vocab_size = tokenizer.vocab_len
 
     # === Convert logits to probabilities ===
-    logits = logits.to(torch.float).to('cpu')
+    logits = logits.to(torch.float).to("cpu")
     probs = torch.softmax(logits, dim=2)  # [batch_size, sequence_len, vocab_size]
 
-    if vocab_size < tokenizer.vocab_len:  # fixes bug when model logits output is not full width
+    if (
+        vocab_size < tokenizer.vocab_len
+    ):  # fixes bug when model logits output is not full width
         padded_probs = torch.zeros((batch_size, sequence_len, tokenizer.vocab_len))
         padded_probs[..., :vocab_size] = probs
         probs = padded_probs
 
     # === Translate to probabilities over standard tokenizer ===
     probs_std = torch.zeros(batch_size, std_sequence_len, std_vocab_size)
     for b in range(batch_size):
-        probs_b = probs[b][-len(offset_mapping[b]):]  # remove left padding
-        tokens_b = tokens[b][-len(offset_mapping[b]):]  # remove left padding
-        translate_tokenizer_probs(probs_b, probs_std[b], offset_mapping[b], offset_mapping_std[b],
-                                  tokenizer, std_tokenizer,
-                                  split_map_cache, to_translation_map, from_translation_map,
-                                  tokens_b, tokens_std[b])
+        probs_b = probs[b][-len(offset_mapping[b]) :]  # remove left padding
+        tokens_b = tokens[b][-len(offset_mapping[b]) :]  # remove left padding
+        translate_tokenizer_probs(
+            probs_b,
+            probs_std[b],
+            offset_mapping[b],
+            offset_mapping_std[b],
+            tokenizer,
+            std_tokenizer,
+            split_map_cache,
+            to_translation_map,
+            from_translation_map,
+            tokens_b,
+            tokens_std[b],
+        )
 
     # === Correct excess probability mass (haircut) ===
     probs_std_sum = probs_std.sum(dim=-1)  # [batch_size, std_sequence_len]
-    over = (probs_std_sum > 1)
+    over = probs_std_sum > 1
     probs_std[over] /= probs_std_sum[over][:, None]
 
     # === Correct deficient probability mass (raise) ===
     probs_std_sum = probs_std.sum(dim=-1)  # [batch_size, std_sequence_len]
-    under = (probs_std_sum < 1)
-    probs_std[under] += ((1 - probs_std_sum[under]) / probs_std[under].shape[-1])[:, None]  # raise noise floor so sum 1
+    under = probs_std_sum < 1
+    probs_std[under] += ((1 - probs_std_sum[under]) / probs_std[under].shape[-1])[
+        :, None
+    ]  # raise noise floor so sum 1
 
     return probs_std  # [batch_size, std_sequence_len, std_vocab_size]
 
 
-def topk_token_phrases(logits: torch.Tensor, tokenizer: PreTrainedTokenizerBase,
-                       topk: int, ignore_index: int = -100) -> torch.Tensor:
+def topk_token_phrases(
+    logits: torch.Tensor,
+    tokenizer: PreTrainedTokenizerBase,
+    topk: int,
+    ignore_index: int = -100,
+) -> torch.Tensor:
     r"""
     Select topk tokenizer logits/phrases and include std_token_phrases counterparts (std_tokenization of token text)
     in topk_tensor output of shape [batch_size, (topk + 1), max_len], where max len of all phrase lists
     (with prob in front) is max_{b,k}(len([prob_k, tok_0_k, tok_1_k, ...])).
     The output topk_tensor also includes a floor_prob for each batch item. The floor probability is the
     mean probability of token phrases not captured in topk, required since the tokenizer vocab_size may
     not be known to the receiver.
@@ -740,59 +929,86 @@
                  [[prob_k=0_b=1, tok_0_k=0_b=1, tok_1_k=0_b=1, ..., ignore_index?],
                   [prob_k=1_b=1, tok_0_k=1_b=1, tok_1_k=1_b=1, ..., ignore_index?],
                   [...],
                   [prob_floor_b=1, ignore_index, ..., ignore_index]],
                  [...]]
     """
     # Get shape sizes
-    batch_size, vocab_size = logits.shape  # [batch_size, vocab_size] only last token prediction
+    (
+        batch_size,
+        vocab_size,
+    ) = logits.shape  # [batch_size, vocab_size] only last token prediction
 
     # Convert logits to probabilities
-    logits = logits.float()  # ensure further computations done in float32 for improved precision
+    logits = (
+        logits.float()
+    )  # ensure further computations done in float32 for improved precision
     probs = torch.softmax(logits, dim=1)  # [batch_size, vocab_size]
 
     # TopK phrase selection
-    topk_probs, topk_indices = torch.topk(probs, topk)  # topk probs and indices: [batch_size, topk]
+    topk_probs, topk_indices = torch.topk(
+        probs, topk
+    )  # topk probs and indices: [batch_size, topk]
 
     # === Calculate floor probability ===
     topk_pmass = topk_probs.sum(dim=-1)  # [batch_size] topk probability mass
-    remainder_pmass = torch.clamp(1 - topk_pmass, 1e-40, 1)  # [batch_size] remainder probability mass
+    remainder_pmass = torch.clamp(
+        1 - topk_pmass, 1e-40, 1
+    )  # [batch_size] remainder probability mass
     floor_probs = remainder_pmass / (vocab_size - topk)  # [batch_size]divide remainder
 
     # convert to list for faster iteration in list comprehension
     topk_probs_list = topk_probs.tolist()
     topk_indices_list = topk_indices.tolist()
     floor_probs_list = floor_probs.tolist()
 
     # === Construct topk phrases list ===
-    probs = []  # collect probability tensors with gradients attached (to be grafted into topk_tensor)
-    phrases = []  # form topk token phrases with prob prepend [prob, tok_0, tok_1, ... tok_n]
+    probs = (
+        []
+    )  # collect probability tensors with gradients attached (to be grafted into topk_tensor)
+    phrases = (
+        []
+    )  # form topk token phrases with prob prepend [prob, tok_0, tok_1, ... tok_n]
 
     for b in range(batch_size):
         # collect probability tensors with gradients attached (to be grafted into topk_tensor)
-        probs += [topk_probs[b], floor_probs[b]]  # [tensor(prob_k=0_b, prob_k=1_b, ...), tensor(prob_floor_b)]
+        probs += [
+            topk_probs[b],
+            floor_probs[b],
+        ]  # [tensor(prob_k=0_b, prob_k=1_b, ...), tensor(prob_floor_b)]
 
         # form topk token phrases with prob prepend [prob, tok_0, tok_1, ... tok_n]
-        phrases += [[prob] + tokenizer.std_token_phrases[i]
-                    for prob, i in zip(topk_probs_list[b], topk_indices_list[b])]  # [prob_k, tok_0_k, tok_1_k, ...]
+        phrases += [
+            [prob] + tokenizer.std_token_phrases[i]
+            for prob, i in zip(topk_probs_list[b], topk_indices_list[b])
+        ]  # [prob_k, tok_0_k, tok_1_k, ...]
 
         # also add prob_floor for batch item
         phrases += [[floor_probs_list[b]]]  # [prob_floor_b]
 
     # determine width of topk_tensor as max len of all phrase lists (with prob in front)
-    max_len = max([len(p) for p in phrases])  # max_{b,k}(len([prob_k, tok_0_k, tok_1_k, ...]))
+    max_len = max(
+        [len(p) for p in phrases]
+    )  # max_{b,k}(len([prob_k, tok_0_k, tok_1_k, ...]))
 
     # form single 2D tensor with all phrase and probs (typically to send to axon wire encoding)
-    topk_tensor = torch.tensor([p + [ignore_index] * (max_len - len(p))
-                                for p in phrases]).to(logits.device)  # [batch_size * (topk + 1), max_len]
+    topk_tensor = torch.tensor(
+        [p + [ignore_index] * (max_len - len(p)) for p in phrases]
+    ).to(
+        logits.device
+    )  # [batch_size * (topk + 1), max_len]
 
     # grafting probability tensors into first column to attach gradients
-    topk_tensor[:, 0] = torch.hstack(probs)  # tensor([prob_k=0_b, prob_k=1_b, ..., prob_floor_b])
-
-    topk_tensor = topk_tensor.reshape(batch_size, topk + 1, max_len)  # [batch_size, (topk + 1), max_len] reshaped
+    topk_tensor[:, 0] = torch.hstack(
+        probs
+    )  # tensor([prob_k=0_b, prob_k=1_b, ..., prob_floor_b])
+
+    topk_tensor = topk_tensor.reshape(
+        batch_size, topk + 1, max_len
+    )  # [batch_size, (topk + 1), max_len] reshaped
 
     return topk_tensor  # [batch_size, (topk + 1), max_len] (probability gradients attached in first column)
 
 
 def compact_topk_token_phrases(topk_tensor: torch.Tensor):
     r"""
     Compact 2D topk_tensor [batch_size, (topk + 1), max_len] by removing ignore_index padding, and also offset
@@ -819,24 +1035,34 @@
                 since 2 * topk + 1: topk x [probability, token sequence (at least one token)] +
                 floor probability (rest).
                 Content structure:
                     [prob_k=0_b=0, tok_0_k=0_b=0, tok_1_k=0_b=0, ..., prob_k=1_b=0, tok_0_k=1_b=0, ..., prob_floor_b=0,
                      prob_k=0_b=1, tok_0_k=0_b=1, tok_1_k=0_b=1, ..., prob_k=1_b=1, tok_0_k=1_b=1, ..., prob_floor_b=1,
                      ...]
     """
-    topk_tensor_offset = topk_tensor.clone()  # assume topk_tensor may be reused elsewhere so clone
-    topk_tensor_offset[:, :, 1:] += 2  # add 2 to token ids to preserve [0, 1] for probabilities (in first column)
-
-    flattened = topk_tensor_offset.flatten()  # [batch_size * (topk + 1) * max_len] 1D tensor
-    compact_topk = flattened[flattened > -1]  # remove ignore_index < -1 padding to compact content
+    topk_tensor_offset = (
+        topk_tensor.clone()
+    )  # assume topk_tensor may be reused elsewhere so clone
+    topk_tensor_offset[
+        :, :, 1:
+    ] += 2  # add 2 to token ids to preserve [0, 1] for probabilities (in first column)
+
+    flattened = (
+        topk_tensor_offset.flatten()
+    )  # [batch_size * (topk + 1) * max_len] 1D tensor
+    compact_topk = flattened[
+        flattened > -1
+    ]  # remove ignore_index < -1 padding to compact content
 
     return compact_topk  # [>= batch_size * (2 * topk + 1)]
 
 
-def unravel_topk_token_phrases(compact_topk: torch.Tensor, topk: int, ignore_index: int = -100) -> torch.Tensor:
+def unravel_topk_token_phrases(
+    compact_topk: torch.Tensor, topk: int, ignore_index: int = -100
+) -> torch.Tensor:
     r"""
     Unravel topk token phrases input_tensor from 1-D to [batch_size, (topk + 1), max_len] topk_tensor, which
     includes topk token probabilities (prob_k) + floor_prob in first column with gradients attached, with
     std_tokens in remaining columns with ignore_index padding.
         Args:
             compact_topk (:obj:`torch.Tensor`, `required`):
                 [sum_b(sum_k(len(phrase_k) + 1)_b)] Compacted 1-D tensor >= batch_size * (2 * topk + 1),
@@ -864,63 +1090,95 @@
                   [...],
                   [prob_floor_b=1, ignore_index, ..., ignore_index]],
                  [...]]
     """
 
     atol = 1e-6  # absolute tolerance
     # Find probability markers (per batch item: topk phrase probabilities + floor_prob)
-    prob_idx = torch.where((-atol < compact_topk) & (compact_topk < 1 + atol))[0]  # 0 <= prob <= 1 [batch_size * (topk + 1)], expect token_ids >= 2
-
-    batch_size = len(prob_idx) // (topk + 1)  # (batch_size * (topk + floor)) / (topk + floor)
-    assert batch_size * (topk + 1) == len(prob_idx), f'unravel_topk_token_phrases() probability marker failure: ' \
-                                                     f'{batch_size} * ({topk} + 1) != {len(prob_idx)}'  # decoding irregularity otherwise
-
-    probs = torch.clamp(compact_topk[prob_idx], 0, 1)  # [batch_size * (topk + 1)] ensure probabilities within [0, 1]
+    prob_idx = torch.where((-atol < compact_topk) & (compact_topk < 1 + atol))[
+        0
+    ]  # 0 <= prob <= 1 [batch_size * (topk + 1)], expect token_ids >= 2
+
+    batch_size = len(prob_idx) // (
+        topk + 1
+    )  # (batch_size * (topk + floor)) / (topk + floor)
+    assert batch_size * (topk + 1) == len(prob_idx), (
+        f"unravel_topk_token_phrases() probability marker failure: "
+        f"{batch_size} * ({topk} + 1) != {len(prob_idx)}"
+    )  # decoding irregularity otherwise
+
+    probs = torch.clamp(
+        compact_topk[prob_idx], 0, 1
+    )  # [batch_size * (topk + 1)] ensure probabilities within [0, 1]
     probs_sum = probs.reshape(batch_size, topk + 1).sum(dim=1)  # [batch_size]
-    assert torch.all((-atol < probs_sum) & (probs_sum < 1 + atol)), f'unravel_topk_token_phrases(): probs_sum not in [0, 1]'
+    assert torch.all(
+        (-atol < probs_sum) & (probs_sum < 1 + atol)
+    ), f"unravel_topk_token_phrases(): probs_sum not in [0, 1]"
 
     # Obtain phrase lengths and maximum phrase length
-    phrase_len = prob_idx[1:] - prob_idx[:-1]  # [batch_size * (topk + 1) - 1] length of each phrase
-    phrase_len = torch.cat((phrase_len, torch.tensor([1])))  # [batch_size * (topk + 1)] prob_floor is always len=1
-    max_len = phrase_len.max()  # determine width of topk_tensor as max len of all phrase lists (with prob in front)
+    phrase_len = (
+        prob_idx[1:] - prob_idx[:-1]
+    )  # [batch_size * (topk + 1) - 1] length of each phrase
+    phrase_len = torch.cat(
+        (phrase_len, torch.tensor([1]))
+    )  # [batch_size * (topk + 1)] prob_floor is always len=1
+    max_len = (
+        phrase_len.max()
+    )  # determine width of topk_tensor as max len of all phrase lists (with prob in front)
 
     # Initialize topk_tensor with ignore_index + 2, since decrement with 2 follows to remove token offset later
-    topk_tensor = torch.ones((batch_size * (topk + 1), max_len), device=compact_topk.device)
+    topk_tensor = torch.ones(
+        (batch_size * (topk + 1), max_len), device=compact_topk.device
+    )
     topk_tensor *= ignore_index + 2  # [batch_size * (topk + 1), max_len]
 
     # Insert phrases of each unique length as block into topk_tensor
     for unique_len in phrase_len.unique():
         if unique_len <= 1:
             continue  # skip probability column, will be added afterward
 
-        phrase_idx = torch.where(phrase_len == unique_len)[0]  # phrase indices where phrase_len is unique_len
+        phrase_idx = torch.where(phrase_len == unique_len)[
+            0
+        ]  # phrase indices where phrase_len is unique_len
         compact_idx = prob_idx[phrase_idx]  # indices in compact_topk
 
         # Create indexing block, add index for each phrase position, skip first (prob) position
-        block_idx = [compact_idx + position for position in range(1, unique_len)]  # incrementally add each position of phrase
+        block_idx = [
+            compact_idx + position for position in range(1, unique_len)
+        ]  # incrementally add each position of phrase
         # transpose .t() ensures correct interleaving of consecutive positions:
         # [[phrase_a_1, phrase_a_2, ..., phrase_a_n], [phrase_b_1, phrase_b_2, ..., phrase_b_n], ...]
-        block_idx = torch.vstack(block_idx).t().reshape(-1, unique_len - 1)  # [-1, unique_len - 1] for all phrases with unique_len
-
-        topk_tensor[phrase_idx, 1:unique_len] = compact_topk[block_idx]  # slice selected phrases and copy into topk_tensor
+        block_idx = (
+            torch.vstack(block_idx).t().reshape(-1, unique_len - 1)
+        )  # [-1, unique_len - 1] for all phrases with unique_len
+
+        topk_tensor[phrase_idx, 1:unique_len] = compact_topk[
+            block_idx
+        ]  # slice selected phrases and copy into topk_tensor
 
     topk_tensor -= 2  # remove token offset, overwrites probability column, replace probabilities below
 
     # grafting probability tensors into first column to attach gradients
     topk_tensor[:, 0] = probs  # tensor([prob_k=0_b, prob_k=1_b, ..., prob_floor_b])
 
-    topk_tensor = topk_tensor.reshape(batch_size, topk + 1, max_len)  # [batch_size, (topk + 1), max_len] reshaped
+    topk_tensor = topk_tensor.reshape(
+        batch_size, topk + 1, max_len
+    )  # [batch_size, (topk + 1), max_len] reshaped
 
     return topk_tensor  # [batch_size, (topk + 1), max_len]
 
 
-def phrase_cross_entropy(target_phrases: Union[List[List[int]], torch.Tensor],
-                         topk_tensor: torch.Tensor,
-                         ignore_index: int = -100, reduce=True, reduction='mean',
-                         vocab_size_min: int = 50257) -> Tuple[torch.Tensor, torch.Tensor]:
+def phrase_cross_entropy(
+    target_phrases: Union[List[List[int]], torch.Tensor],
+    topk_tensor: torch.Tensor,
+    ignore_index: int = -100,
+    reduce=True,
+    reduction="mean",
+    vocab_size_min: int = 50257,
+) -> Tuple[torch.Tensor, torch.Tensor]:
     r"""
     Calculates the cross entropy of a phrase prediction against a target phrase, so that this is a multi-token
     extension of typical cross entropy calculated for next token prediction.
         Args:
             target_phrases (:obj:`List[List[int]]`, `required`):
                 [batch_size, *] Target phrases in standard token sequence list.
             topk_tensor (:obj:`torch.Tensor`, `required`):
@@ -948,77 +1206,123 @@
         Returns:
             loss_val (:obj:`torch.Tensor`, `required`):
                 Validation cross entropy loss, either scalar if reduce or [batch_size].
             loss (:obj:`torch.Tensor`, `required`):
                 Phrase cross entropy loss, either scalar if reduce or [batch_size].
     """
 
-    batch_size, topk_p1, max_len = topk_tensor.shape  # [batch_size, (topk + 1), max_len]
+    (
+        batch_size,
+        topk_p1,
+        max_len,
+    ) = topk_tensor.shape  # [batch_size, (topk + 1), max_len]
     topk = topk_p1 - 1
 
-    topk_tokens = topk_tensor[:, :-1, 1:].round().int()  # [batch_size, topk, max_len - 1] Phrase tokens with ignore_index token for padding.
-    topk_probs = topk_tensor[:, :-1, 0]  # [batch_size, topk] Probabilities for each phrase in topk
-    floor_probs = topk_tensor[:, -1, 0]  # [batch_size] Floor probabilities as mean probability for non-topk tokens
-
-    topk_probs = torch.clamp(topk_probs, 0, 1)  # [batch_size, topk] ensure probabilities within [0, 1]
-    floor_probs = torch.clamp(floor_probs, 0, 1)  # [batch_size] ensure floor probabilities within [0, 1]
+    topk_tokens = (
+        topk_tensor[:, :-1, 1:].round().int()
+    )  # [batch_size, topk, max_len - 1] Phrase tokens with ignore_index token for padding.
+    topk_probs = topk_tensor[
+        :, :-1, 0
+    ]  # [batch_size, topk] Probabilities for each phrase in topk
+    floor_probs = topk_tensor[
+        :, -1, 0
+    ]  # [batch_size] Floor probabilities as mean probability for non-topk tokens
+
+    topk_probs = torch.clamp(
+        topk_probs, 0, 1
+    )  # [batch_size, topk] ensure probabilities within [0, 1]
+    floor_probs = torch.clamp(
+        floor_probs, 0, 1
+    )  # [batch_size] ensure floor probabilities within [0, 1]
 
     # === Ensure total probability is 1 ===
-    total_probs = topk_probs.sum(dim=-1) + max(0, vocab_size_min - topk) * floor_probs  # [batch_size] total probs
-    n_topk_probs = topk_probs / total_probs[:, None]  # [batch_size, topk] normalized topk_probs
+    total_probs = (
+        topk_probs.sum(dim=-1) + max(0, vocab_size_min - topk) * floor_probs
+    )  # [batch_size] total probs
+    n_topk_probs = (
+        topk_probs / total_probs[:, None]
+    )  # [batch_size, topk] normalized topk_probs
     n_floor_probs = floor_probs / total_probs  # [batch_size] normalized floor_probs
 
-    val_probs = torch.zeros(batch_size).to(topk_probs.device)  # accumulate probabilities when first tokens match
-    match_probs = torch.zeros(batch_size).to(topk_probs.device)  # accumulate probabilities when sub target matches phrase
+    val_probs = torch.zeros(batch_size).to(
+        topk_probs.device
+    )  # accumulate probabilities when first tokens match
+    match_probs = torch.zeros(batch_size).to(
+        topk_probs.device
+    )  # accumulate probabilities when sub target matches phrase
     for b in range(batch_size):
         target_phrase = target_phrases[b]
         if not isinstance(target_phrase, torch.Tensor):
             target_phrase = torch.tensor(target_phrases[b])
         if isinstance(target_phrase, torch.FloatTensor):
             target_phrase = target_phrase.round().int()
 
-        match = (topk_tokens[b, :, 0] == target_phrase[0].item())  # bool where first tokens match (validation token)
+        match = (
+            topk_tokens[b, :, 0] == target_phrase[0].item()
+        )  # bool where first tokens match (validation token)
         if match.sum() > 0:
             val_probs[b] = n_topk_probs[b, match].sum()  # accumulate all matches
         else:  # no matches
-            val_probs[b] = n_floor_probs[b]  # assume match is in non-topk tokens with avg floor_prob
+            val_probs[b] = n_floor_probs[
+                b
+            ]  # assume match is in non-topk tokens with avg floor_prob
 
         # === Integrate sub target matches ===
         check_len = min(max_len - 1, len(target_phrase))
         for c in range(1, check_len + 1):  # progressively increase sub target length
-            target = ignore_index * torch.ones(check_len, dtype=torch.int32).to(topk_tensor.device)  # [-100, ..., -100]
+            target = ignore_index * torch.ones(check_len, dtype=torch.int32).to(
+                topk_tensor.device
+            )  # [-100, ..., -100]
             target[:c] = target_phrase[:c]  # [tok0, tok1, ...tokc, -100, ..., -100]
 
             # Find sub target matches
-            match = (topk_tokens[b, :, :check_len] == target)
-            match_idx = torch.where(match.sum(dim=-1) == check_len)[0]  # phrase indices which match sub target
+            match = topk_tokens[b, :, :check_len] == target
+            match_idx = torch.where(match.sum(dim=-1) == check_len)[
+                0
+            ]  # phrase indices which match sub target
 
             if len(match_idx):  # at least one match
-                match_probs[b] += n_topk_probs[b, match_idx].sum()  # accumulate all matches
+                match_probs[b] += n_topk_probs[
+                    b, match_idx
+                ].sum()  # accumulate all matches
             else:  # no matches
-                match_probs[b] += n_floor_probs[b]  # assume match is in non-topk tokens with avg floor_prob
-
-    val_probs = torch.clamp(val_probs, 0, 1)  # [batch_size] ensure 0 <= total probability <= 1
-    loss_val = - torch.log(val_probs + 1e-40)  # [batch_size] calculate cross entropy loss
-
-    match_probs = torch.clamp(match_probs, 0, 1)  # [batch_size] ensure 0 <= total probability <= 1
-    loss = - torch.log(match_probs + 1e-40)  # [batch_size] calculate cross entropy loss
+                match_probs[b] += n_floor_probs[
+                    b
+                ]  # assume match is in non-topk tokens with avg floor_prob
+
+    val_probs = torch.clamp(
+        val_probs, 0, 1
+    )  # [batch_size] ensure 0 <= total probability <= 1
+    loss_val = -torch.log(
+        val_probs + 1e-40
+    )  # [batch_size] calculate cross entropy loss
+
+    match_probs = torch.clamp(
+        match_probs, 0, 1
+    )  # [batch_size] ensure 0 <= total probability <= 1
+    loss = -torch.log(match_probs + 1e-40)  # [batch_size] calculate cross entropy loss
 
     if reduce:
         if not hasattr(loss_val, reduction) or not hasattr(loss, reduction):
-            raise RuntimeError(f'phase_cross_entropy(): Reduction function {reduction} not found.')
+            raise RuntimeError(
+                f"phase_cross_entropy(): Reduction function {reduction} not found."
+            )
         loss_val = getattr(loss_val, reduction)()
         loss = getattr(loss, reduction)()
         if loss.numel() > 1:
-            raise ValueError(f'phase_cross_entropy(): Expected reduction to scalar, obtained {loss.shape} instead.')
+            raise ValueError(
+                f"phase_cross_entropy(): Expected reduction to scalar, obtained {loss.shape} instead."
+            )
 
     return loss_val, loss
 
 
-def topk_tokens_to_vocab_size(topk_tensor: torch.Tensor, vocab_size_std: int, vocab_size_min: int = 50257) -> torch.Tensor:
+def topk_tokens_to_vocab_size(
+    topk_tensor: torch.Tensor, vocab_size_std: int, vocab_size_min: int = 50257
+) -> torch.Tensor:
     r"""
     Convert topk_tokens first token probabilities into a standard logits tensor shape [batch_size, vocab_size_std].
         Args:
             topk_tensor (:obj:`torch.Tensor`, `required`):
                 [batch_size, (topk + 1), max_len] tensor includes topk token probabilities (prob_k) + floor_prob
                 in first column with gradients attached, with std_tokens in remaining columns with ignore_index padding.
                 Content structure:
@@ -1037,37 +1341,59 @@
                 Minimum server vocab_size expected, should set to nominal 50257,
                 used to prevent the floor_probs from being too large.
         Returns:
             logits (:obj:`torch.Tensor`, `required`):
                 [batch_size, vocab_size_std] Standard logits.
     """
 
-    batch_size, topk_p1, max_len = topk_tensor.shape  # [batch_size, (topk + 1), max_len]
+    (
+        batch_size,
+        topk_p1,
+        max_len,
+    ) = topk_tensor.shape  # [batch_size, (topk + 1), max_len]
     topk = topk_p1 - 1
 
-    topk_tokens = topk_tensor[:, :-1, 1].round().to(torch.int64)  # [batch_size, topk] first tokens
-    topk_probs = topk_tensor[:, :-1, 0]  # [batch_size, topk] Probabilities for each phrase in topk
-    floor_probs = topk_tensor[:, -1, 0]  # [batch_size] Floor probabilities as mean probability for non-topk tokens
-
-    topk_probs = torch.clamp(topk_probs, 0, 1)  # [batch_size, topk] ensure probabilities within [0, 1]
-    floor_probs = torch.clamp(floor_probs, 0, 1)  # [batch_size] ensure floor probabilities within [0, 1]
+    topk_tokens = (
+        topk_tensor[:, :-1, 1].round().to(torch.int64)
+    )  # [batch_size, topk] first tokens
+    topk_probs = topk_tensor[
+        :, :-1, 0
+    ]  # [batch_size, topk] Probabilities for each phrase in topk
+    floor_probs = topk_tensor[
+        :, -1, 0
+    ]  # [batch_size] Floor probabilities as mean probability for non-topk tokens
+
+    topk_probs = torch.clamp(
+        topk_probs, 0, 1
+    )  # [batch_size, topk] ensure probabilities within [0, 1]
+    floor_probs = torch.clamp(
+        floor_probs, 0, 1
+    )  # [batch_size] ensure floor probabilities within [0, 1]
 
     # === Ensure total probability is 1 ===
-    total_probs = topk_probs.sum(dim=-1) + max(0, vocab_size_min - topk) * floor_probs  # [batch_size] total probs
-    n_topk_probs = topk_probs / total_probs[:, None]  # [batch_size, topk] normalized topk_probs
+    total_probs = (
+        topk_probs.sum(dim=-1) + max(0, vocab_size_min - topk) * floor_probs
+    )  # [batch_size] total probs
+    n_topk_probs = (
+        topk_probs / total_probs[:, None]
+    )  # [batch_size, topk] normalized topk_probs
 
     # === Convert to logits tensor ===
     probs = torch.zeros((batch_size, vocab_size_std))  # [batch_size, vocab_size_std]
-    probs.scatter_add_(1, topk_tokens, n_topk_probs)  # accumulate token probabilities onto logits tensor
+    probs.scatter_add_(
+        1, topk_tokens, n_topk_probs
+    )  # accumulate token probabilities onto logits tensor
 
     return probs  # [batch_size, vocab_size_std]
 
 
-def check_tokenizer_equivalence(tokenizer_to_check: PreTrainedTokenizerBase,
-                                target_tokenizer: PreTrainedTokenizerBase) -> bool:
+def check_tokenizer_equivalence(
+    tokenizer_to_check: PreTrainedTokenizerBase,
+    target_tokenizer: PreTrainedTokenizerBase,
+) -> bool:
     r"""
     Is tokenizer_to_check equivalent to target_tokenizer?
         Args:
             tokenizer_to_check (:obj:`PreTrainedTokenizerBase`, `required`):
                 Tokenizer to check for equivalence.
             target_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 Target tokenizer to check equivalence against.
@@ -1077,15 +1403,17 @@
     """
     set_vocab_len(tokenizer_to_check)
     set_vocab_len(target_tokenizer)
 
     if tokenizer_to_check.vocab_len != target_tokenizer.vocab_len:
         return False
 
-    to_check_vocab = tokenizer_to_check.batch_decode(range(tokenizer_to_check.vocab_len))
+    to_check_vocab = tokenizer_to_check.batch_decode(
+        range(tokenizer_to_check.vocab_len)
+    )
     target_vocab = target_tokenizer.batch_decode(range(target_tokenizer.vocab_len))
 
     return to_check_vocab == target_vocab  # indexed tokenizer vocabularies should match
 
 
 def prune_tokens(inputs: torch.FloatTensor, prune_len: int = 1, margin: int = 3):
     r"""
@@ -1112,16 +1440,19 @@
         mask = torch.ones(seq_len, dtype=torch.bool)
         mask[rand_index] = False
         pruned_inputs.append(inputs[b, mask])
 
     return torch.stack(pruned_inputs)
 
 
-def pad_offsets(offsets_batch: List[List[tuple]], source_offsets_batch: List[List[List[Any]]],
-                pad_offsets_batch: List[List[List[Any]]]) -> List[List[List[Any]]]:
+def pad_offsets(
+    offsets_batch: List[List[tuple]],
+    source_offsets_batch: List[List[List[Any]]],
+    pad_offsets_batch: List[List[List[Any]]],
+) -> List[List[List[Any]]]:
     r"""
     Pads specific tuples in offsets_batch, selected by source_offsets_batch with
     associated paddings in pad_offsets_batch.
     Purpose is typically to add padding to align two tokenization offsets at special tokens.
         Args:
             offsets_batch (:obj:`List[List[tuple]]`, `required`):
                     Batch of full input tokenizer offset mappings to be used for alteration
@@ -1145,21 +1476,27 @@
         new_offsets = []
         pad = 0
 
         idx = 0
         for left, right in offsets_batch[b]:  # go through original offsets
             if idx < len(source_offsets_batch[b]):
                 source_left, source_right = source_offsets_batch[b][idx]
-                if left == source_left and right == source_right:  # matching offset found
+                if (
+                    left == source_left and right == source_right
+                ):  # matching offset found
                     pad_left, pad_right = pad_offsets_batch[b][idx]
-                    new_offsets += [(pad_left + pad, pad_right + pad)]  # replace offsets with padded + accum. pad
+                    new_offsets += [
+                        (pad_left + pad, pad_right + pad)
+                    ]  # replace offsets with padded + accum. pad
                     pad += pad_right - right
                     idx += 1
                     continue
-            new_offsets += [(left + pad, right + pad)]  # adjust original offsets w/ accum. pad
+            new_offsets += [
+                (left + pad, right + pad)
+            ]  # adjust original offsets w/ accum. pad
 
         new_offsets_batch += [new_offsets]
 
     return new_offsets_batch
 
 
 def find_offsets(string: str, substring: str) -> List[List[int]]:
@@ -1181,15 +1518,17 @@
     while idx != -1:  # found an instance
         offsets += [[idx, idx + len(substring)]]  # add offsets
         idx = string.find(substring, idx + len(substring))  # find next instance
 
     return offsets
 
 
-def replace_at_offsets(string: str, offsets: List[List[Any]]) -> Tuple[str, List[List[int]]]:
+def replace_at_offsets(
+    string: str, offsets: List[List[Any]]
+) -> Tuple[str, List[List[int]]]:
     r"""
     Replace indicated [left, right] offset positions with a new substring, by
     deleting [left, right] content and adding [left, left+len(substring)] substring,
     adjusting offsets incrementally.
     Assumes an incremental ordered, non-overlapping list of offsets, constructing
     the new string incrementally and recording new offsets.
         Args:
@@ -1202,15 +1541,15 @@
         Returns:
             new_string (:obj:`str`, `required`):
                 New string where replacements were made.
             new_offsets (:obj:`List[List[Any]]`, `required`):
                 New offsets where replacements are now located
                 [[left_0, right_0], [left_1, right_1], ...]
     """
-    new_string = ''
+    new_string = ""
     new_offsets = []
 
     prev = 0
     for left, right, substring in offsets:
         new_string += string[prev:left]  # retain preceding string
         new_left = len(new_string)  # advance index
 
@@ -1222,16 +1561,17 @@
         prev = right  # advance index
 
     new_string += string[prev:]
 
     return new_string, new_offsets
 
 
-def get_special_token_pairings(from_tokenizer: PreTrainedTokenizerBase,
-                               to_tokenizer: PreTrainedTokenizerBase) -> Dict[str, str]:
+def get_special_token_pairings(
+    from_tokenizer: PreTrainedTokenizerBase, to_tokenizer: PreTrainedTokenizerBase
+) -> Dict[str, str]:
     r"""
     Determines a prioritized matching of special token texts between two tokenizers.
     Purpose is to produce replacement pairs so special token test is correctly represented for target tokenizer.
         Args:
             from_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 From tokenizer.
             to_tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
@@ -1241,30 +1581,40 @@
             pairings (:obj:`Dict[str, str]`, `required`):
                 Prioritized dictionary of From_special_token_text -> To_special_token_text.
     """
     pairings = {}
 
     # some tokenizers e.g. GPT2 have the same text signifying BOS and EOS, while in other e.g. XGLM they differ
     # so prioritize EOS token first, since this seems to be the default context separator, e.g. XGLM, GerPT2, GPT2
-    if ('eos_token' in from_tokenizer.special_tokens_map) and ('eos_token' in to_tokenizer.special_tokens_map):
-        pairings[getattr(from_tokenizer, 'eos_token')] = getattr(to_tokenizer, 'eos_token')
+    if ("eos_token" in from_tokenizer.special_tokens_map) and (
+        "eos_token" in to_tokenizer.special_tokens_map
+    ):
+        pairings[getattr(from_tokenizer, "eos_token")] = getattr(
+            to_tokenizer, "eos_token"
+        )
 
     for special_token in from_tokenizer.special_tokens_map:
         if special_token in to_tokenizer.special_tokens_map:
-            if getattr(from_tokenizer, special_token) not in pairings:  # prevent priority overwrite
-                pairings[getattr(from_tokenizer, special_token)] = getattr(to_tokenizer, special_token)
+            if (
+                getattr(from_tokenizer, special_token) not in pairings
+            ):  # prevent priority overwrite
+                pairings[getattr(from_tokenizer, special_token)] = getattr(
+                    to_tokenizer, special_token
+                )
 
     return pairings
 
 
-def translate_special_token_text(text_batch: List[str], from_tokenizer: PreTrainedTokenizerBase,
-                                 to_tokenizer: PreTrainedTokenizerBase) -> Tuple[List[str],
-                                                                                 List[List[List[int]]],
-                                                                                 List[List[List[int]]],
-                                                                                 List[List[List[Any]]]]:
+def translate_special_token_text(
+    text_batch: List[str],
+    from_tokenizer: PreTrainedTokenizerBase,
+    to_tokenizer: PreTrainedTokenizerBase,
+) -> Tuple[
+    List[str], List[List[List[int]]], List[List[List[int]]], List[List[List[Any]]]
+]:
     r"""
     Translates special_token signifier text in from_tokenizer to to_tokenizer special_token text, for
     a given text_batch. Resulting to_text_batch can then be to_tokenized where special_tokens should
     map to its single corresponding token, despite signifier text difference compared to from_tokenizer.
         Args:
             text_batch (:obj:`List[str]`, `required`):
                 List of strings to translate special tokens for.
@@ -1295,22 +1645,32 @@
     pairings = get_special_token_pairings(from_tokenizer, to_tokenizer)
 
     for text in text_batch:
         from_offsets = []
         padding_offsets = []
         for token_string in pairings:
             offsets = find_offsets(text, token_string)  # find special-token locations
-            from_offsets += [[left, right, pairings[token_string]] for left, right in offsets]
-
-            pad_string = token_string if len(token_string) > len(pairings[token_string]) else pairings[token_string]
+            from_offsets += [
+                [left, right, pairings[token_string]] for left, right in offsets
+            ]
+
+            pad_string = (
+                token_string
+                if len(token_string) > len(pairings[token_string])
+                else pairings[token_string]
+            )
             padding_offsets += [[left, right, pad_string] for left, right in offsets]
 
         from_offsets = sorted(from_offsets)  # incrementally arrange locations
-        to_text, to_offsets = replace_at_offsets(text, from_offsets)  # replace special-token text
-        pad_text, padding_offsets = replace_at_offsets(text, padding_offsets)  # pad special-token text locations
+        to_text, to_offsets = replace_at_offsets(
+            text, from_offsets
+        )  # replace special-token text
+        pad_text, padding_offsets = replace_at_offsets(
+            text, padding_offsets
+        )  # pad special-token text locations
 
         to_text_batch += [to_text]
         from_offsets_batch += [[[left, right] for left, right, _ in from_offsets]]
         to_offsets_batch += [to_offsets]
         pad_offsets_batch += [padding_offsets]
 
     return to_text_batch, from_offsets_batch, to_offsets_batch, pad_offsets_batch
@@ -1321,18 +1681,22 @@
     Sets the tokenizer.vocab_len if unset, to store the real vocabulary size according to the vocab or encoder.
         Args:
             tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 Tokenizer to set vocab_len for.
         Returns:
 
     """
-    if not hasattr(tokenizer, 'vocab_len'):
-        if hasattr(tokenizer, 'vocab'):  # use independent vocab_len when tokenizer.vocab_size != len(tokenizer.vocab)
+    if not hasattr(tokenizer, "vocab_len"):
+        if hasattr(
+            tokenizer, "vocab"
+        ):  # use independent vocab_len when tokenizer.vocab_size != len(tokenizer.vocab)
             tokenizer.vocab_len = len(tokenizer.vocab)
-        elif hasattr(tokenizer, 'encoder'):  # tokenizers like facebook/opt-* has encoder=vocab
+        elif hasattr(
+            tokenizer, "encoder"
+        ):  # tokenizers like facebook/opt-* has encoder=vocab
             tokenizer.vocab_len = len(tokenizer.encoder)
         else:  # revert to vocab_size
             tokenizer.vocab_len = tokenizer.vocab_size
 
 
 def set_whitespace_preserving(tokenizer: PreTrainedTokenizerBase):
     r"""
@@ -1340,18 +1704,18 @@
     or not like BERT-style.
         Args:
             tokenizer (:obj:`PreTrainedTokenizerBase`, `required`):
                 Tokenizer to set vocab_len for.
         Returns:
 
     """
-    if not hasattr(tokenizer, 'whitespace_preserving'):
-        space_token = tokenizer(' ', add_special_tokens=False)['input_ids']
+    if not hasattr(tokenizer, "whitespace_preserving"):
+        space_token = tokenizer(" ", add_special_tokens=False)["input_ids"]
         space_text = tokenizer.decode(space_token)
-        if space_text == ' ':
+        if space_text == " ":
             tokenizer.whitespace_preserving = True
         else:
             tokenizer.whitespace_preserving = False
 
 
 def set_std_token_phrases(tokenizer, std_tokenizer):
     r"""
@@ -1364,24 +1728,30 @@
             std_tokenizer(:obj:`PreTrainedTokenizerBase`, `required`):
                 Standard bittensor tokenizer to convert to.
 
         Returns:
 
     """
     # === Tokenizer phrases to memory ===
-    if not hasattr(tokenizer, 'phrases'):
+    if not hasattr(tokenizer, "phrases"):
         if tokenizer.whitespace_preserving:
-            tokenizer.phrases = tokenizer.batch_decode(range(tokenizer.vocab_len))  # server tokens to strings
+            tokenizer.phrases = tokenizer.batch_decode(
+                range(tokenizer.vocab_len)
+            )  # server tokens to strings
         else:
-            tokenizer.phrases = [' ' + phrase for phrase in
-                                 tokenizer.batch_decode(range(tokenizer.vocab_len))]  # server tokens to strings
+            tokenizer.phrases = [
+                " " + phrase
+                for phrase in tokenizer.batch_decode(range(tokenizer.vocab_len))
+            ]  # server tokens to strings
 
-    if not hasattr(tokenizer, 'std_token_phrases'):
+    if not hasattr(tokenizer, "std_token_phrases"):
         # Retokenize phrases to new tokenizer
-        tokenizer.std_token_phrases = std_tokenizer(tokenizer.phrases)['input_ids']  # [topk, max_len] convert phrases to tokens sequences
+        tokenizer.std_token_phrases = std_tokenizer(tokenizer.phrases)[
+            "input_ids"
+        ]  # [topk, max_len] convert phrases to tokens sequences
 
 
 def prep_tokenizer(tokenizer, std_tokenizer=None):
     tokenizer.padding_side = "left"  # Generative default expects most recent token on right-hand side with padding on left. https://github.com/huggingface/transformers/pull/10552
     # tokenizer.add_prefix_space = False
     # tokenizer.add_special_tokens({'bos_token': "[BOS]"}) # A special token representing the beginning of a sentence.
     # tokenizer.add_special_tokens({'eos_token': "[EOS]"}) # A special token representing the end of a sentence.
```

### Comparing `bittensor-5.3.1/bittensor/utils/weight_utils.py` & `bittensor-5.3.2/bittensor/utils/weight_utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -20,205 +20,237 @@
 import torch
 import bittensor
 from typing import Tuple, List
 
 U32_MAX = 4294967295
 U16_MAX = 65535
 
-def normalize_max_weight(  x: torch.FloatTensor, limit:float = 0.1 ) -> 'torch.FloatTensor':
-    r""" Normalizes the tensor x so that sum(x) = 1 and the max value is not greater than the limit.
-        Args:
-            x (:obj:`torch.FloatTensor`):
-                Tensor to be max_value normalized.
-            limit: float:
-                Max value after normalization.
-        Returns:
-            y (:obj:`torch.FloatTensor`):
-                Normalized x tensor.
+
+def normalize_max_weight(
+    x: torch.FloatTensor, limit: float = 0.1
+) -> "torch.FloatTensor":
+    r"""Normalizes the tensor x so that sum(x) = 1 and the max value is not greater than the limit.
+    Args:
+        x (:obj:`torch.FloatTensor`):
+            Tensor to be max_value normalized.
+        limit: float:
+            Max value after normalization.
+    Returns:
+        y (:obj:`torch.FloatTensor`):
+            Normalized x tensor.
     """
-    epsilon = 1e-7 #For numerical stability after normalization
+    epsilon = 1e-7  # For numerical stability after normalization
 
-    weights =  x.clone()
+    weights = x.clone()
     values, _ = torch.sort(weights)
 
-    if x.sum() == 0 or len(x)*limit <= 1:
-        return torch.ones_like(x)/x.size(0)
+    if x.sum() == 0 or len(x) * limit <= 1:
+        return torch.ones_like(x) / x.size(0)
     else:
-        estimation = values/values.sum()
+        estimation = values / values.sum()
 
         if estimation.max() <= limit:
-            return weights/weights.sum()
+            return weights / weights.sum()
 
         # Find the cumlative sum and sorted tensor
-        cumsum = torch.cumsum(estimation,0)
+        cumsum = torch.cumsum(estimation, 0)
 
         # Determine the index of cutoff
-        estimation_sum = torch.tensor([(len(values)-i-1)*estimation[i] for i in range(len(values))])
-        n_values = (estimation/(estimation_sum+cumsum+epsilon)<limit).sum()
+        estimation_sum = torch.tensor(
+            [(len(values) - i - 1) * estimation[i] for i in range(len(values))]
+        )
+        n_values = (estimation / (estimation_sum + cumsum + epsilon) < limit).sum()
 
         # Determine the cutoff based on the index
-        cutoff_scale = (limit*cumsum[n_values-1]-epsilon)/(1-(limit*(len(estimation)-n_values)))
-        cutoff= cutoff_scale*values.sum()
+        cutoff_scale = (limit * cumsum[n_values - 1] - epsilon) / (
+            1 - (limit * (len(estimation) - n_values))
+        )
+        cutoff = cutoff_scale * values.sum()
 
         # Applying the cutoff
         weights[weights > cutoff] = cutoff
 
-        y = weights/weights.sum()
+        y = weights / weights.sum()
 
         return y
 
-def convert_weight_uids_and_vals_to_tensor( n: int, uids: List[int], weights: List[int] ) -> 'torch.FloatTensor':
-    r""" Converts weights and uids from chain representation into a torch tensor (inverse operation from convert_weights_and_uids_for_emit)
-        Args:
-            n: int:
-                number of neurons on network.
-            uids (:obj:`List[int],`):
-                Tensor of uids as destinations for passed weights.
-            weights (:obj:`List[int],`):
-                Tensor of weights.
-        Returns:
-            row_weights ( torch.FloatTensor ):
-                Converted row weights.
+
+def convert_weight_uids_and_vals_to_tensor(
+    n: int, uids: List[int], weights: List[int]
+) -> "torch.FloatTensor":
+    r"""Converts weights and uids from chain representation into a torch tensor (inverse operation from convert_weights_and_uids_for_emit)
+    Args:
+        n: int:
+            number of neurons on network.
+        uids (:obj:`List[int],`):
+            Tensor of uids as destinations for passed weights.
+        weights (:obj:`List[int],`):
+            Tensor of weights.
+    Returns:
+        row_weights ( torch.FloatTensor ):
+            Converted row weights.
     """
-    row_weights = torch.zeros( [ n ], dtype=torch.float32 )
-    for uid_j, wij in list(zip( uids, weights )):
-        row_weights[ uid_j ] = float( wij )  # assumes max-upscaled values (w_max = U16_MAX).
+    row_weights = torch.zeros([n], dtype=torch.float32)
+    for uid_j, wij in list(zip(uids, weights)):
+        row_weights[uid_j] = float(
+            wij
+        )  # assumes max-upscaled values (w_max = U16_MAX).
     row_sum = row_weights.sum()
     if row_sum > 0:
         row_weights /= row_sum  # normalize
     return row_weights
 
-def convert_bond_uids_and_vals_to_tensor( n: int, uids: List[int], bonds: List[int] ) -> 'torch.LongTensor':
-    r""" Converts bond and uids from chain representation into a torch tensor.
-        Args:
-            n: int:
-                number of neurons on network.
-            uids (:obj:`List[int],`):
-                Tensor of uids as destinations for passed bonds.
-            bonds (:obj:`List[int],`):
-                Tensor of bonds.
-        Returns:
-            row_bonds ( torch.FloatTensor ):
-                Converted row bonds.
+
+def convert_bond_uids_and_vals_to_tensor(
+    n: int, uids: List[int], bonds: List[int]
+) -> "torch.LongTensor":
+    r"""Converts bond and uids from chain representation into a torch tensor.
+    Args:
+        n: int:
+            number of neurons on network.
+        uids (:obj:`List[int],`):
+            Tensor of uids as destinations for passed bonds.
+        bonds (:obj:`List[int],`):
+            Tensor of bonds.
+    Returns:
+        row_bonds ( torch.FloatTensor ):
+            Converted row bonds.
     """
-    row_bonds = torch.zeros( [ n ], dtype=torch.int64 )
-    for uid_j, bij in list(zip( uids, bonds )):
-        row_bonds[ uid_j ] = int( bij )
+    row_bonds = torch.zeros([n], dtype=torch.int64)
+    for uid_j, bij in list(zip(uids, bonds)):
+        row_bonds[uid_j] = int(bij)
     return row_bonds
 
-def convert_weights_and_uids_for_emit( uids: torch.LongTensor, weights: torch.FloatTensor ) -> Tuple[List[int], List[int]]:
-    r""" Converts weights into integer u32 representation that sum to MAX_INT_WEIGHT.
-        Args:
-            uids (:obj:`torch.LongTensor,`):
-                Tensor of uids as destinations for passed weights.
-            weights (:obj:`torch.FloatTensor,`):
-                Tensor of weights.
-        Returns:
-            weight_uids (List[int]):
-                Uids as a list.
-            weight_vals (List[int]):
-                Weights as a list.
+
+def convert_weights_and_uids_for_emit(
+    uids: torch.LongTensor, weights: torch.FloatTensor
+) -> Tuple[List[int], List[int]]:
+    r"""Converts weights into integer u32 representation that sum to MAX_INT_WEIGHT.
+    Args:
+        uids (:obj:`torch.LongTensor,`):
+            Tensor of uids as destinations for passed weights.
+        weights (:obj:`torch.FloatTensor,`):
+            Tensor of weights.
+    Returns:
+        weight_uids (List[int]):
+            Uids as a list.
+        weight_vals (List[int]):
+            Weights as a list.
     """
     # Checks.
     weights = weights.tolist()
     uids = uids.tolist()
     if min(weights) < 0:
-        raise ValueError('Passed weight is negative cannot exist on chain {}'.format(weights))
+        raise ValueError(
+            "Passed weight is negative cannot exist on chain {}".format(weights)
+        )
     if min(uids) < 0:
-        raise ValueError('Passed uid is negative cannot exist on chain {}'.format(uids))
+        raise ValueError("Passed uid is negative cannot exist on chain {}".format(uids))
     if len(uids) != len(weights):
-        raise ValueError('Passed weights and uids must have the same length, got {} and {}'.format(len(uids), len(weights)))
+        raise ValueError(
+            "Passed weights and uids must have the same length, got {} and {}".format(
+                len(uids), len(weights)
+            )
+        )
     if sum(weights) == 0:
-        return [],[] # Nothing to set on chain.
+        return [], []  # Nothing to set on chain.
     else:
         max_weight = float(max(weights))
-        weights = [float(value) / max_weight for value in weights]  # max-upscale values (max_weight = 1).
+        weights = [
+            float(value) / max_weight for value in weights
+        ]  # max-upscale values (max_weight = 1).
 
     weight_vals = []
     weight_uids = []
     for i, (weight_i, uid_i) in enumerate(list(zip(weights, uids))):
-        uint16_val = round(float(weight_i) * int(U16_MAX))  # convert to int representation.
+        uint16_val = round(
+            float(weight_i) * int(U16_MAX)
+        )  # convert to int representation.
 
         # Filter zeros
-        if uint16_val != 0: # Filter zeros
-            weight_vals.append( uint16_val )
-            weight_uids.append( uid_i )
+        if uint16_val != 0:  # Filter zeros
+            weight_vals.append(uint16_val)
+            weight_uids.append(uid_i)
 
     return weight_uids, weight_vals
 
 
 def process_weights_for_netuid(
-        uids,
-        weights: torch.Tensor,
-        netuid: int,
-        subtensor: 'bittensor.subtensor',
-        metagraph: 'bittensor.metagraph' = None,
-    ) -> torch.FloatTensor:
-    bittensor.logging.debug( 'process_weights_for_netuid()' )
-    bittensor.logging.debug( 'weights', weights )
-    bittensor.logging.debug( 'netuid', netuid )
-    bittensor.logging.debug( 'subtensor', subtensor )
-    bittensor.logging.debug( 'metagraph', metagraph )
+    uids,
+    weights: torch.Tensor,
+    netuid: int,
+    subtensor: "bittensor.subtensor",
+    metagraph: "bittensor.metagraph" = None,
+) -> torch.FloatTensor:
+    bittensor.logging.debug("process_weights_for_netuid()")
+    bittensor.logging.debug("weights", weights)
+    bittensor.logging.debug("netuid", netuid)
+    bittensor.logging.debug("subtensor", subtensor)
+    bittensor.logging.debug("metagraph", metagraph)
 
     # Get latest metagraph from chain if metagraph is None.
     if metagraph == None:
-        metagraph = subtensor.metagraph( netuid )
+        metagraph = subtensor.metagraph(netuid)
 
     # Cast weights to floats.
-    if not isinstance( weights, torch.FloatTensor ):
-        weights = weights.type( torch.float32 )
+    if not isinstance(weights, torch.FloatTensor):
+        weights = weights.type(torch.float32)
 
     # Network configuration parameters from an subtensor.
     # These parameters determine the range of acceptable weights for each neuron.
-    quantile = subtensor.validator_exclude_quantile( netuid = netuid )
-    min_allowed_weights = subtensor.min_allowed_weights( netuid = netuid )
-    max_weight_limit = subtensor.max_weight_limit( netuid = netuid )
-    bittensor.logging.debug( 'quantile', quantile )
-    bittensor.logging.debug( 'min_allowed_weights', min_allowed_weights )
-    bittensor.logging.debug( 'max_weight_limit', max_weight_limit )
+    quantile = subtensor.validator_exclude_quantile(netuid=netuid)
+    min_allowed_weights = subtensor.min_allowed_weights(netuid=netuid)
+    max_weight_limit = subtensor.max_weight_limit(netuid=netuid)
+    bittensor.logging.debug("quantile", quantile)
+    bittensor.logging.debug("min_allowed_weights", min_allowed_weights)
+    bittensor.logging.debug("max_weight_limit", max_weight_limit)
 
     # Find all non zero weights.
-    non_zero_weight_idx = torch.argwhere( weights > 0 ).squeeze( dim = 1 )
-    non_zero_weight_uids = uids[ non_zero_weight_idx ]
-    non_zero_weights = weights[ non_zero_weight_idx ]
+    non_zero_weight_idx = torch.argwhere(weights > 0).squeeze(dim=1)
+    non_zero_weight_uids = uids[non_zero_weight_idx]
+    non_zero_weights = weights[non_zero_weight_idx]
     if non_zero_weights.numel() == 0 or metagraph.n < min_allowed_weights:
-        bittensor.logging.warning( 'No non-zero weights returning all ones.' )
-        final_weights = torch.ones( ( metagraph.n ) ).to( metagraph.n ) / metagraph.n
-        bittensor.logging.debug( 'final_weights', final_weights )
-        return torch.tensor( list( range( len( final_weights ) ) ) ), final_weights
+        bittensor.logging.warning("No non-zero weights returning all ones.")
+        final_weights = torch.ones((metagraph.n)).to(metagraph.n) / metagraph.n
+        bittensor.logging.debug("final_weights", final_weights)
+        return torch.tensor(list(range(len(final_weights)))), final_weights
 
     elif non_zero_weights.numel() < min_allowed_weights:
-        bittensor.logging.warning( 'No non-zero weights less then min allowed weight, returning all ones.' )
+        bittensor.logging.warning(
+            "No non-zero weights less then min allowed weight, returning all ones."
+        )
         # ( const ): Should this be torch.zeros( ( metagraph.n ) ) to reset everyone to build up weight?
-        weights = torch.ones( ( metagraph.n ) ).to( metagraph.n ) * 1e-5 # creating minimum even non-zero weights
+        weights = (
+            torch.ones((metagraph.n)).to(metagraph.n) * 1e-5
+        )  # creating minimum even non-zero weights
         weights[non_zero_weight_idx] += non_zero_weights
-        bittensor.logging.debug( 'final_weights', weights )
+        bittensor.logging.debug("final_weights", weights)
         normalized_weights = bittensor.utils.weight_utils.normalize_max_weight(
-            x = weights,
-            limit = max_weight_limit
+            x=weights, limit=max_weight_limit
         )
-        return torch.tensor( list( range( len( normalized_weights ) ) ) ), normalized_weights
+        return torch.tensor(list(range(len(normalized_weights)))), normalized_weights
 
-    bittensor.logging.debug( 'non_zero_weights', non_zero_weights )
+    bittensor.logging.debug("non_zero_weights", non_zero_weights)
 
     # Compute the exclude quantile and find the weights in the lowest quantile
-    max_exclude = max( 0,len( non_zero_weights ) - min_allowed_weights) / len( non_zero_weights )
-    exclude_quantile = min([ quantile , max_exclude ])
-    lowest_quantile = non_zero_weights.quantile( exclude_quantile )
-    bittensor.logging.debug( 'max_exclude', max_exclude )
-    bittensor.logging.debug( 'exclude_quantile', exclude_quantile )
-    bittensor.logging.debug( 'lowest_quantile', lowest_quantile )
+    max_exclude = max(0, len(non_zero_weights) - min_allowed_weights) / len(
+        non_zero_weights
+    )
+    exclude_quantile = min([quantile, max_exclude])
+    lowest_quantile = non_zero_weights.quantile(exclude_quantile)
+    bittensor.logging.debug("max_exclude", max_exclude)
+    bittensor.logging.debug("exclude_quantile", exclude_quantile)
+    bittensor.logging.debug("lowest_quantile", lowest_quantile)
 
     # Exclude all weights below the allowed quantile.
     non_zero_weight_uids = non_zero_weight_uids[lowest_quantile <= non_zero_weights]
-    non_zero_weights = non_zero_weights[ lowest_quantile <= non_zero_weights ]
-    bittensor.logging.debug( 'non_zero_weight_uids', non_zero_weight_uids )
-    bittensor.logging.debug( 'non_zero_weights', non_zero_weights )
+    non_zero_weights = non_zero_weights[lowest_quantile <= non_zero_weights]
+    bittensor.logging.debug("non_zero_weight_uids", non_zero_weight_uids)
+    bittensor.logging.debug("non_zero_weights", non_zero_weights)
 
     # Normalize weights and return.
     normalized_weights = bittensor.utils.weight_utils.normalize_max_weight(
-        x = non_zero_weights,
-        limit = max_weight_limit
+        x=non_zero_weights, limit=max_weight_limit
     )
-    bittensor.logging.debug( 'final_weights', normalized_weights )
+    bittensor.logging.debug("final_weights", normalized_weights)
 
     return non_zero_weight_uids, normalized_weights
```

### Comparing `bittensor-5.3.1/bittensor.egg-info/PKG-INFO` & `bittensor-5.3.2/bittensor.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: bittensor
-Version: 5.3.1
+Version: 5.3.2
 Summary: bittensor
 Home-page: https://github.com/opentensor/bittensor
 Author: bittensor.com
 Author-email: 
 License: MIT
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Developers
@@ -437,14 +437,17 @@
 # Send a prompt to this endpoint
 dendrite.forward( roles = ['user'], messages = ['what are you?'] )
 ```
 
 ## Release
 The release manager should follow the instructions of the [RELEASE_GUIDELINES.md](./RELEASE_GUIDELINES.md) document.
 
+## Contributions
+Please review the [contributing guide](./contrib/CONTRIBUTING.md) for more information before making a pull request.
+
 ## License
 The MIT License (MIT)
 Copyright © 2021 Yuma Rao
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
 The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
```

### Comparing `bittensor-5.3.1/bittensor.egg-info/SOURCES.txt` & `bittensor-5.3.2/bittensor.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `bittensor-5.3.1/bittensor.egg-info/requires.txt` & `bittensor-5.3.2/bittensor.egg-info/requires.txt`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 ansible_vault==2.1
 argparse==1.4.0
 base58==2.0.1
 backoff==2.1.0
-bittensor-config==0.0.0
-bittensor-wallet==0.0.4
+bittensor-config<1.0.0,>=0.0.1
+bittensor-wallet<1.0.0,>=0.0.5
 cryptography==41.0.0
 datasets==2.12.0
 fuzzywuzzy==0.18.0
 grpcio==1.42.0
 grpcio-tools==1.42.0
 hypothesis==6.47.4
 idna<3,>=2.5
```

### Comparing `bittensor-5.3.1/setup.py` & `bittensor-5.3.2/setup.py`

 * *Files 14% similar despite different names*

```diff
@@ -24,64 +24,66 @@
 import os
 import pathlib
 
 
 def read_requirements(path):
     with pathlib.Path(path).open() as requirements_txt:
         return [
-            str(requirement)
-            for requirement
-            in parse_requirements(requirements_txt)
+            str(requirement) for requirement in parse_requirements(requirements_txt)
         ]
 
-requirements = read_requirements('requirements/prod.txt')
-extra_requirements_dev = read_requirements('requirements/dev.txt')
-extra_requirements_cubit = read_requirements('requirements/cubit.txt')
+
+requirements = read_requirements("requirements/prod.txt")
+extra_requirements_dev = read_requirements("requirements/dev.txt")
+extra_requirements_cubit = read_requirements("requirements/cubit.txt")
 
 here = path.abspath(path.dirname(__file__))
 
-with open(path.join(here, 'README.md'), encoding='utf-8') as f:
+with open(path.join(here, "README.md"), encoding="utf-8") as f:
     long_description = f.read()
 
 
 # loading version from setup.py
-with codecs.open(os.path.join(here, 'bittensor/__init__.py'), encoding='utf-8') as init_file:
-    version_match = re.search(r"^__version__ = ['\"]([^'\"]*)['\"]", init_file.read(), re.M)
+with codecs.open(
+    os.path.join(here, "bittensor/__init__.py"), encoding="utf-8"
+) as init_file:
+    version_match = re.search(
+        r"^__version__ = ['\"]([^'\"]*)['\"]", init_file.read(), re.M
+    )
     version_string = version_match.group(1)
 
 setup(
-    name='bittensor',
+    name="bittensor",
     version=version_string,
-    description='bittensor',
+    description="bittensor",
     long_description=long_description,
-    long_description_content_type='text/markdown',
-    url='https://github.com/opentensor/bittensor',
-    author='bittensor.com',
+    long_description_content_type="text/markdown",
+    url="https://github.com/opentensor/bittensor",
+    author="bittensor.com",
     packages=find_packages(),
     include_package_data=True,
-    author_email='',
-    license='MIT',
-    python_requires='>=3.8',
+    author_email="",
+    license="MIT",
+    python_requires=">=3.8",
     install_requires=requirements,
     extras_require={
-        'dev': extra_requirements_dev,
+        "dev": extra_requirements_dev,
     },
-    scripts=['bin/btcli'],
+    scripts=["bin/btcli"],
     classifiers=[
-        'Development Status :: 3 - Alpha',
-        'Intended Audience :: Developers',
-        'Topic :: Software Development :: Build Tools',
-
+        "Development Status :: 3 - Alpha",
+        "Intended Audience :: Developers",
+        "Topic :: Software Development :: Build Tools",
         # Pick your license as you wish
-        'License :: OSI Approved :: MIT License',
-        'Programming Language :: Python :: 3 :: Only',
-        'Programming Language :: Python :: 3.8',
-        'Programming Language :: Python :: 3.9',
-        'Programming Language :: Python :: 3.10',
-        'Topic :: Scientific/Engineering',
-        'Topic :: Scientific/Engineering :: Mathematics',
-        'Topic :: Scientific/Engineering :: Artificial Intelligence',
-        'Topic :: Software Development',
-        'Topic :: Software Development :: Libraries',
-        'Topic :: Software Development :: Libraries :: Python Modules',
+        "License :: OSI Approved :: MIT License",
+        "Programming Language :: Python :: 3 :: Only",
+        "Programming Language :: Python :: 3.8",
+        "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
+        "Topic :: Scientific/Engineering",
+        "Topic :: Scientific/Engineering :: Mathematics",
+        "Topic :: Scientific/Engineering :: Artificial Intelligence",
+        "Topic :: Software Development",
+        "Topic :: Software Development :: Libraries",
+        "Topic :: Software Development :: Libraries :: Python Modules",
     ],
 )
```

### Comparing `bittensor-5.3.1/tests/__init__.py` & `bittensor-5.3.2/tests/__init__.py`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -11,8 +11,8 @@
 # The above copyright notice and this permission notice shall be included in all copies or substantial portions of
 # the Software.
 
 # THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
-# DEALINGS IN THE SOFTWARE.
+# DEALINGS IN THE SOFTWARE.
```

### Comparing `bittensor-5.3.1/tests/helpers/__init__.py` & `bittensor-5.3.2/tests/helpers/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -11,8 +11,15 @@
 
 # THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
 # THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
-from .helpers import _get_mock_coldkey, _get_mock_hotkey, _get_mock_keypair, _get_mock_wallet, CLOSE_IN_VALUE, MockConsole
+from .helpers import (
+    _get_mock_coldkey,
+    _get_mock_hotkey,
+    _get_mock_keypair,
+    _get_mock_wallet,
+    CLOSE_IN_VALUE,
+    MockConsole,
+)
```

### Comparing `bittensor-5.3.1/tests/helpers/helpers.py` & `bittensor-5.3.2/tests/helpers/helpers.py`

 * *Files 13% similar despite different names*

```diff
@@ -32,139 +32,139 @@
     """Returns a mock wallet object."""
 
     mock_wallet = _get_mock_wallet()
 
     return mock_wallet
 
 
-class CLOSE_IN_VALUE():
+class CLOSE_IN_VALUE:
     value: Union[float, int, Balance]
     tolerance: Union[float, int, Balance]
 
-    def __init__(self, value: Union[float, int, Balance], tolerance: Union[float, int, Balance] = 0.0) -> None:
+    def __init__(
+        self,
+        value: Union[float, int, Balance],
+        tolerance: Union[float, int, Balance] = 0.0,
+    ) -> None:
         self.value = value
         self.tolerance = tolerance
 
     def __eq__(self, __o: Union[float, int, Balance]) -> bool:
         # True if __o \in [value - tolerance, value + tolerance]
         # or if value \in [__o - tolerance, __o + tolerance]
-        return ((self.value - self.tolerance) <= __o and __o <= (self.value + self.tolerance)) or \
-                ((__o - self.tolerance) <= self.value and self.value <= (__o + self.tolerance))
-
-
+        return (
+            (self.value - self.tolerance) <= __o
+            and __o <= (self.value + self.tolerance)
+        ) or (
+            (__o - self.tolerance) <= self.value
+            and self.value <= (__o + self.tolerance)
+        )
 
 
 def get_mock_neuron(**kwargs) -> NeuronInfo:
     """
     Returns a mock neuron with the given kwargs overriding the default values.
     """
 
-    mock_neuron_d = dict({
-                "netuid": -1, # mock netuid
-                "axon_info": axon_info(
-                    block = 0,
-                    version = 1,
-                    ip = 0,
-                    port = 0,
-                    ip_type = 0,
-                    protocol = 0,
-                    placeholder1 = 0,
-                    placeholder2 = 0
-                ),
-                "prometheus_info": PrometheusInfo(
-                    block = 0,
-                    version = 1,
-                    ip = 0,
-                    port = 0,
-                    ip_type = 0
-                ),
-                "validator_permit": True,
-                "uid":1,
-                "hotkey":'some_hotkey',
-                "coldkey":'some_coldkey',
-                "active":0,
-                "last_update":0,
-                "stake": {
-                    "some_coldkey": 1e12
-                },
-                "total_stake":1e12,
-                "rank":0.0,
-                "trust":0.0,
-                "consensus":0.0,
-                "validator_trust": 0.0,
-                "incentive":0.0,
-                "dividends":0.0,
-                "emission":0.0,
-                "bonds":[],
-                "weights":[],
-                "stake_dict": {},
-                "pruning_score": 0.0,
-                "is_null":False
-            })
-
-    mock_neuron_d.update(kwargs) # update with kwargs
+    mock_neuron_d = dict(
+        {
+            "netuid": -1,  # mock netuid
+            "axon_info": axon_info(
+                block=0,
+                version=1,
+                ip=0,
+                port=0,
+                ip_type=0,
+                protocol=0,
+                placeholder1=0,
+                placeholder2=0,
+            ),
+            "prometheus_info": PrometheusInfo(
+                block=0, version=1, ip=0, port=0, ip_type=0
+            ),
+            "validator_permit": True,
+            "uid": 1,
+            "hotkey": "some_hotkey",
+            "coldkey": "some_coldkey",
+            "active": 0,
+            "last_update": 0,
+            "stake": {"some_coldkey": 1e12},
+            "total_stake": 1e12,
+            "rank": 0.0,
+            "trust": 0.0,
+            "consensus": 0.0,
+            "validator_trust": 0.0,
+            "incentive": 0.0,
+            "dividends": 0.0,
+            "emission": 0.0,
+            "bonds": [],
+            "weights": [],
+            "stake_dict": {},
+            "pruning_score": 0.0,
+            "is_null": False,
+        }
+    )
 
-    if kwargs.get('stake') is None and kwargs.get('coldkey') is not None:
-        mock_neuron_d['stake'] = { kwargs.get('coldkey'): 1e12 }
+    mock_neuron_d.update(kwargs)  # update with kwargs
 
-    if kwargs.get('total_stake') is None:
-        mock_neuron_d['total_stake'] = sum(mock_neuron_d['stake'].values())
+    if kwargs.get("stake") is None and kwargs.get("coldkey") is not None:
+        mock_neuron_d["stake"] = {kwargs.get("coldkey"): 1e12}
 
-    mock_neuron = NeuronInfo._neuron_dict_to_namespace(
-        mock_neuron_d
-    )
+    if kwargs.get("total_stake") is None:
+        mock_neuron_d["total_stake"] = sum(mock_neuron_d["stake"].values())
+
+    mock_neuron = NeuronInfo._neuron_dict_to_namespace(mock_neuron_d)
 
     return mock_neuron
 
-def get_mock_neuron_by_uid( uid: int, **kwargs ) -> NeuronInfo:
+
+def get_mock_neuron_by_uid(uid: int, **kwargs) -> NeuronInfo:
     return get_mock_neuron(
-        uid = uid,
-        hotkey = _get_mock_hotkey(uid),
-        coldkey = _get_mock_coldkey(uid),
-        **kwargs
+        uid=uid, hotkey=_get_mock_hotkey(uid), coldkey=_get_mock_coldkey(uid), **kwargs
     )
 
+
 class MockStatus:
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         pass
 
     def start(self):
         pass
 
     def stop(self):
         pass
 
+
 class MockConsole:
     """
     Mocks the console object for status and print.
     Captures the last print output as a string.
     """
+
     captured_print = None
 
     def status(self, *args, **kwargs):
         return MockStatus()
 
     def print(self, *args, **kwargs):
-        console = Console(width = 1000, no_color=True, markup=False) # set width to 1000 to avoid truncation
+        console = Console(
+            width=1000, no_color=True, markup=False
+        )  # set width to 1000 to avoid truncation
         console.begin_capture()
         console.print(*args, **kwargs)
         self.captured_print = console.end_capture()
 
     def clear(self, *args, **kwargs):
         pass
 
     @staticmethod
     def remove_rich_syntax(text: str) -> str:
         """
         Removes rich syntax from the given text.
         Removes markup and ansi syntax.
         """
-        output_no_syntax = Text.from_ansi(
-            Text.from_markup(
-                text
-            ).plain
-        ).plain
+        output_no_syntax = Text.from_ansi(Text.from_markup(text).plain).plain
 
-        return output_no_syntax
+        return output_no_syntax
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_cli.py` & `bittensor-5.3.2/tests/integration_tests/test_cli.py`

 * *Files 1% similar despite different names*

```diff
@@ -26,50 +26,41 @@
 import random
 
 import pytest
 from substrateinterface.base import Keypair
 
 import bittensor
 from bittensor.utils.balance import Balance
-from tests.helpers import MockConsole, _get_mock_keypair, _get_mock_wallet as generate_wallet
+from tests.helpers import (
+    MockConsole,
+    _get_mock_keypair,
+    _get_mock_wallet as generate_wallet,
+)
 from bittensor._subtensor.subtensor_mock import MockSubtensor
 
 
-_subtensor_mock: MockSubtensor = bittensor.subtensor( network = 'mock', _mock = True )
+_subtensor_mock: MockSubtensor = bittensor.subtensor(network="mock", _mock=True)
+
 
 def setUpModule():
     _subtensor_mock.reset()
 
-    _subtensor_mock.create_subnet(
-        netuid = 1
-    )
-
-    _subtensor_mock.create_subnet(
-        netuid = 2
-    )
-
-    _subtensor_mock.create_subnet(
-        netuid = 3
-    )
+    _subtensor_mock.create_subnet(netuid=1)
+
+    _subtensor_mock.create_subnet(netuid=2)
+
+    _subtensor_mock.create_subnet(netuid=3)
 
     # Set diff 0
-    _subtensor_mock.set_difficulty(
-        netuid = 1,
-        difficulty = 0
-    )
-
-    _subtensor_mock.set_difficulty(
-        netuid = 2,
-        difficulty = 0
-    )
-
-    _subtensor_mock.set_difficulty(
-        netuid = 3,
-        difficulty = 0
-    )
+    _subtensor_mock.set_difficulty(netuid=1, difficulty=0)
+
+    _subtensor_mock.set_difficulty(netuid=2, difficulty=0)
+
+    _subtensor_mock.set_difficulty(netuid=3, difficulty=0)
+
 
 class TestCLIWithNetworkAndConfig(unittest.TestCase):
     def setUp(self):
         self._config = TestCLIWithNetworkAndConfig.construct_config()
 
     @property
     def config(self):
@@ -91,15 +82,14 @@
         bittensor.wallet.add_defaults(defaults)
         bittensor.dataset.add_defaults(defaults)
         bittensor.logging.add_defaults(defaults)
         bittensor.prometheus.add_defaults(defaults)
 
         return defaults
 
-        
     def test_overview(self):
         config = self.config
         config.wallet.path = "/tmp/test_cli_test_overview"
         config.wallet.name = "mock_wallet"
         config.command = "overview"
         config.no_prompt = True
         config.all = False
@@ -143,15 +133,15 @@
 
         for netuid, wallet in mock_registrations:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=netuid,
                 coldkey=wallet.coldkey.ss58_address,
                 hotkey=wallet.hotkey.ss58_address,
             )
-            
+
         def mock_get_wallet(*args, **kwargs):
             hk = kwargs.get("hotkey")
             name_ = kwargs.get("name")
 
             if not hk and kwargs.get("config"):
                 hk = kwargs.get("config").wallet.hotkey
             if not name_ and kwargs.get("config"):
@@ -198,15 +188,14 @@
                         self.assertEqual(occurrences, expected)
 
                     # Check that unregistered hotkeys are not printed.
                     for wallet in mock_wallets:
                         if wallet not in [w for _, w in mock_registrations]:
                             self.assertNotIn(wallet.hotkey_str, output_no_syntax)
 
-    
     def test_overview_not_in_first_subnet(self):
         config = self.config
         config.wallet.path = "/tmp/test_cli_test_overview"
         config.wallet.name = "mock_wallet"
         config.command = "overview"
         config.no_prompt = True
         config.all = False
@@ -236,15 +225,14 @@
             # No registrations in subnet 1 or 2
             (3, mock_wallets[4])  # hk4 is on netuid 3
         ]
 
         # Register each wallet to it's subnet
         print("Registering mock wallets to subnets...")
 
-       
         for netuid, wallet in mock_registrations:
             print(
                 "Registering wallet {} to subnet {}".format(wallet.hotkey_str, netuid)
             )
             _ = _subtensor_mock.force_register_neuron(
                 netuid=netuid,
                 coldkey=wallet.coldkey.ss58_address,
@@ -302,15 +290,14 @@
                         self.assertEqual(occurrences, expected)
 
                     # Check that unregistered hotkeys are not printed.
                     for wallet in mock_wallets:
                         if wallet not in [w for _, w in mock_registrations]:
                             self.assertNotIn(wallet.hotkey_str, output_no_syntax)
 
-    
     def test_overview_no_wallet(self):
         # Mock IO for wallet
         with patch(
             "bittensor.Wallet.coldkeypub_file",
             MagicMock(exists_on_device=MagicMock(return_value=False)),
         ):
             bittensor.subtensor.register = MagicMock(return_value=True)
@@ -320,133 +307,122 @@
             config.no_prompt = True
             config.all = False
             config.netuid = []  # Don't set, so it tries all networks.
 
             cli = bittensor.cli(config)
             cli.run()
 
-    
     def test_overview_with_hotkeys_config(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.hotkeys = ["some_hotkey"]
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_without_hotkeys_config(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_with_sort_by_config(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.wallet.sort_by = "rank"
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_with_sort_by_bad_column_name(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.wallet.sort_by = "totallynotmatchingcolumnname"
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_without_sort_by_config(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_with_sort_order_config(self):
         config = self.config
         config.command = "overview"
         config.wallet.sort_order = "desc"  # Set descending sort order
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_with_sort_order_config_bad_sort_type(self):
         config = self.config
         config.command = "overview"
         config.wallet.sort_order = "nowaythisshouldmatchanyorderingchoice"
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_without_sort_order_config(self):
         config = self.config
         config.command = "overview"
         # Don't specify sort_order in config
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_with_width_config(self):
         config = self.config
         config.command = "overview"
         config.width = 100
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_without_width_config(self):
         config = self.config
         config.command = "overview"
         # Don't specify width in config
         config.no_prompt = True
         config.all = False
         config.netuid = []  # Don't set, so it tries all networks.
 
         cli = bittensor.cli(config)
         cli.run()
 
-    
     def test_overview_all(self):
         config = self.config
         config.command = "overview"
         config.no_prompt = True
         config.netuid = []  # Don't set, so it tries all networks.
 
         config.all = True
@@ -481,23 +457,22 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them stakes
 
-       
         for wallet in mock_wallets:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkey.ss58_address,
                 stake=mock_stakes[wallet.hotkey_str].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -525,15 +500,14 @@
                 )
                 self.assertAlmostEqual(
                     stake.tao,
                     mock_stakes[wallet.hotkey_str].tao - config.amount,
                     places=4,
                 )
 
-    
     def test_unstake_with_all_hotkeys(self):
         config = self.config
         config.command = "unstake"
         config.no_prompt = True
         config.amount = 5.0
         config.wallet.name = "fake_wallet"
         # Notice wallet.hotkeys not specified
@@ -557,23 +531,23 @@
                 hotkey_str=hk,
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(list(mock_stakes.keys()))
         ]
 
         # Register mock wallets and give them stakes
-       
+
         for wallet in mock_wallets:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkey.ss58_address,
                 stake=mock_stakes[wallet.hotkey_str].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -635,23 +609,23 @@
                 hotkey_str=hk,
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(list(mock_stakes.keys()))
         ]
 
         # Register mock wallets and give them stakes
-       
+
         for wallet in mock_wallets:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkey.ss58_address,
                 stake=mock_stakes[wallet.hotkey_str].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -721,24 +695,24 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(list(mock_stakes.keys()))
         ]
 
         # Register mock wallets and give them stakes
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkey.ss58_address,
                 stake=mock_stakes[wallet.hotkey_str].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -774,16 +748,15 @@
                     )  # Add a small buffer for fp errors
 
                     if wallet.hotkey_str == "hk1":
                         # hk1 should not have been unstaked because it was already below max_stake
                         self.assertAlmostEqual(
                             stake.tao, mock_stakes[wallet.hotkey_str].tao, places=4
                         )
-    
-    
+
     def test_stake_with_specific_hotkeys(self):
         config = self.config
         config.command = "stake"
         config.no_prompt = True
         config.amount = 5.0
         config.wallet.name = "fake_wallet"
         config.hotkeys = ["hk0", "hk1", "hk2"]
@@ -803,28 +776,27 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkey.ss58_address,
             )
-            
+
         success, err = _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -848,15 +820,14 @@
             for wallet in mock_wallets:
                 stake = _subtensor_mock.get_stake_for_coldkey_and_hotkey(
                     hotkey_ss58=wallet.hotkey.ss58_address,
                     coldkey_ss58=wallet.coldkey.ss58_address,
                 )
                 self.assertAlmostEqual(stake.tao, config.amount, places=4)
 
-    
     def test_stake_with_all_hotkeys(self):
         config = self.config
         config.command = "stake"
         config.no_prompt = True
         config.amount = 5.0
         config.wallet.name = "fake_wallet"
         # Notice wallet.hotkeys is not specified
@@ -878,29 +849,28 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(mock_hotkeys)
         ]
 
         # Register mock wallets and give them no stake
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
             )
-            
+
         # Set the coldkey balance
         success, err = _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -976,29 +946,28 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(mock_hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
             )
-            
+
         # Set the coldkey balance
         _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1082,15 +1051,15 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             if wallet.hotkey_str == "hk1":
                 # Set the stake for hk1
                 _ = _subtensor_mock.force_register_neuron(
                     netuid=1,
                     hotkey=wallet.hotkey.ss58_address,
@@ -1099,20 +1068,19 @@
                 )
             else:
                 _ = _subtensor_mock.force_register_neuron(
                     netuid=1,
                     hotkey=wallet.hotkey.ss58_address,
                     coldkey=wallet.coldkeypub.ss58_address,
                 )
-                
+
         _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1191,28 +1159,27 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
             )
-            
+
         _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1284,28 +1251,27 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             print("Registering mock wallet {}".format(wallet.hotkey_str))
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
             )
-            
+
         _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1372,27 +1338,26 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
             )
-            
+
         _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1467,28 +1432,27 @@
                 hotkey=_get_mock_keypair(idx + 100, self.id()),
             )
             for idx, hk in enumerate(config.hotkeys)
         ]
 
         # Register mock wallets and give them balances
         print("Registering mock wallets...")
-       
+
         for wallet in mock_wallets:
             _ = _subtensor_mock.force_register_neuron(
                 netuid=1,
                 hotkey=wallet.hotkey.ss58_address,
                 coldkey=wallet.coldkeypub.ss58_address,
                 stake=mock_stakes[wallet.hotkey_str].rao,  # More than max_stake
             )
-            
+
         success, err = _subtensor_mock.force_set_balance(
-            ss58_address=mock_coldkey_kp.ss58_address,
-            balance=mock_balance.rao,
+            ss58_address=mock_coldkey_kp.ss58_address, balance=mock_balance.rao
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             if kwargs.get("hotkey"):
                 for wallet in mock_wallets:
                     if wallet.hotkey_str == kwargs.get("hotkey"):
                         return wallet
@@ -1535,16 +1499,15 @@
             )
 
             # Check that the balance is the same
             balance = _subtensor_mock.get_balance(
                 address=wallet.coldkeypub.ss58_address
             )
             self.assertAlmostEqual(balance.tao, mock_balance.tao, places=4)
-    
-    
+
     def test_nominate(self):
         config = self.config
         config.command = "nominate"
         config.no_prompt = True
         config.wallet.name = "w0"
         config.hotkey = "hk0"
 
@@ -1561,15 +1524,15 @@
         # Register mock wallet and give it a balance
         _ = _subtensor_mock.force_register_neuron(
             netuid=1,
             hotkey=mock_wallet.hotkey.ss58_address,
             coldkey=mock_wallet.coldkey.ss58_address,
             balance=mock_balance.rao,
         )
-        
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             hk = kwargs.get("hotkey")
             name_ = kwargs.get("name")
 
             if not hk and kwargs.get("config"):
@@ -1598,17 +1561,15 @@
         config.command = "delegate"
         config.no_prompt = True
         config.amount = 5.0
         config.wallet.name = "w1"
 
         mock_balances: Dict[str, bittensor.Balance] = {
             # All have more than 5.0 stake
-            "w0": {
-                "hk0": bittensor.Balance.from_float(10.0),
-            },
+            "w0": {"hk0": bittensor.Balance.from_float(10.0)},
             "w1": {"hk1": bittensor.Balance.from_float(11.1)},
         }
 
         mock_stake = bittensor.Balance.from_float(5.0)
 
         mock_wallets = []
         for idx, wallet_name in enumerate(list(mock_balances.keys())):
@@ -1621,34 +1582,31 @@
                     hotkey=_get_mock_keypair(idx * 100 + idx_hk, self.id()),
                 )
                 mock_wallets.append(wallet)
 
         # Set hotkey to be the hotkey from the other wallet
         config.delegate_ss58key: str = mock_wallets[0].hotkey.ss58_address
 
-       
         # Register mock wallets and give them balance
         _ = _subtensor_mock.force_register_neuron(
             netuid=1,
             hotkey=mock_wallets[0].hotkey.ss58_address,
             coldkey=mock_wallets[0].coldkey.ss58_address,
             balance=mock_balances["w0"]["hk0"].rao,
             stake=mock_stake.rao,  # Needs set stake to be a validator
         )
-        
+
         # Give w1 some balance
         success, err = _subtensor_mock.force_set_balance(
             ss58_address=mock_wallets[1].coldkey.ss58_address,
             balance=mock_balances["w1"]["hk1"].rao,
         )
-        
+
         # Make the first wallet a delegate
-        success = _subtensor_mock.nominate(
-            wallet=mock_wallets[0],
-        )
+        success = _subtensor_mock.nominate(wallet=mock_wallets[0])
         self.assertTrue(success)
 
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             hk = kwargs.get("hotkey")
             name_ = kwargs.get("name")
@@ -1676,27 +1634,24 @@
             # Check the stake
             stake = _subtensor_mock.get_stake_for_coldkey_and_hotkey(
                 hotkey_ss58=mock_wallets[0].hotkey.ss58_address,
                 coldkey_ss58=mock_wallets[1].coldkey.ss58_address,
             )
             self.assertAlmostEqual(stake.tao, config.amount, places=4)
 
-    
     def test_undelegate_stake(self):
         config = self.config
         config.command = "undelegate"
         config.no_prompt = True
         config.amount = 5.0
         config.wallet.name = "w1"
 
         mock_balances: Dict[str, bittensor.Balance] = {
             # All have more than 5.0 stake
-            "w0": {
-                "hk0": bittensor.Balance.from_float(10.0),
-            },
+            "w0": {"hk0": bittensor.Balance.from_float(10.0)},
             "w1": {"hk1": bittensor.Balance.from_float(11.1)},
         }
 
         mock_stake = bittensor.Balance.from_float(5.0)
         mock_delegated = bittensor.Balance.from_float(6.0)
 
         mock_wallets = []
@@ -1718,25 +1673,23 @@
         _ = _subtensor_mock.force_register_neuron(
             netuid=1,
             hotkey=mock_wallets[0].hotkey.ss58_address,
             coldkey=mock_wallets[0].coldkey.ss58_address,
             balance=mock_balances["w0"]["hk0"].rao,
             stake=mock_stake.rao,  # Needs set stake to be a validator
         )
-        
+
         # Give w1 some balance
         success, err = _subtensor_mock.force_set_balance(
             ss58_address=mock_wallets[1].coldkey.ss58_address,
             balance=mock_balances["w1"]["hk1"].rao,
         )
-        
+
         # Make the first wallet a delegate
-        success = _subtensor_mock.nominate(
-            wallet=mock_wallets[0],
-        )
+        success = _subtensor_mock.nominate(wallet=mock_wallets[0])
         self.assertTrue(success)
 
         # Stake to the delegate
         success = _subtensor_mock.delegate(
             wallet=mock_wallets[1],
             delegate_ss58=mock_wallets[0].hotkey.ss58_address,
             amount=mock_delegated,
@@ -1782,15 +1735,14 @@
                 hotkey_ss58=mock_wallets[0].hotkey.ss58_address,
                 coldkey_ss58=mock_wallets[1].coldkey.ss58_address,
             )
             self.assertAlmostEqual(
                 stake.tao, mock_delegated.tao - config.amount, places=4
             )
 
-    
     def test_transfer(self):
         config = self.config
         config.command = "transfer"
         config.no_prompt = True
         config.amount = 3.2
         config.wallet.name = "w1"
 
@@ -1808,21 +1760,21 @@
             )
             mock_wallets.append(wallet)
 
         # Set dest to w0
         config.dest = mock_wallets[0].coldkey.ss58_address
 
         # Give w0 and w1 balance
-       
+
         for wallet in mock_wallets:
             success, err = _subtensor_mock.force_set_balance(
                 ss58_address=wallet.coldkey.ss58_address,
                 balance=mock_balances[wallet.name].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             name_ = kwargs.get("name")
 
             if not name_ and kwargs.get("config"):
                 name_ = kwargs.get("config").wallet.name
@@ -1850,15 +1802,14 @@
             balance = _subtensor_mock.get_balance(
                 address=mock_wallets[1].coldkey.ss58_address
             )
             self.assertAlmostEqual(
                 balance.tao, mock_balances["w1"].tao - config.amount, places=4
             )  # no fees
 
-    
     def test_transfer_not_enough_balance(self):
         config = self.config
         config.command = "transfer"
         config.no_prompt = True
         config.amount = 3.2
         config.wallet.name = "w1"
 
@@ -1878,21 +1829,21 @@
             )
             mock_wallets.append(wallet)
 
         # Set dest to w0
         config.dest = mock_wallets[0].coldkey.ss58_address
 
         # Give w0 and w1 balance
-       
+
         for wallet in mock_wallets:
             success, err = _subtensor_mock.force_set_balance(
                 ss58_address=wallet.coldkey.ss58_address,
                 balance=mock_balances[wallet.name].rao,
             )
-            
+
         cli = bittensor.cli(config)
 
         def mock_get_wallet(*args, **kwargs):
             name_ = kwargs.get("name")
 
             if not name_ and kwargs.get("config"):
                 name_ = kwargs.get("config").wallet.name
@@ -1931,27 +1882,22 @@
             balance = _subtensor_mock.get_balance(
                 address=mock_wallets[1].coldkey.ss58_address
             )
             self.assertAlmostEqual(
                 balance.tao, mock_balances["w1"].tao, places=4
             )  # did not transfer
 
-    
     def test_register(self):
         config = self.config
         config.command = "register"
         config.subtensor.register.num_processes = 1
         config.subtensor.register.update_interval = 50_000
         config.no_prompt = True
 
-        mock_wallet = generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
 
         with patch("bittensor.wallet", return_value=mock_wallet) as mock_create_wallet:
             with patch(
                 "bittensor._subtensor.extrinsics.registration.POWSolution.is_stale",
@@ -1962,65 +1908,55 @@
                 with pytest.raises(MockException):
                     cli = bittensor.cli(config)
                     cli.run()
                     mock_create_wallet.assert_called_once()
 
                 self.assertEqual(mock_is_stale.call_count, 1)
 
-    
     def test_recycle_register(self):
         config = self.config
         config.command = "recycle_register"
         config.no_prompt = True
 
-        mock_wallet = generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         # Give the wallet some balance for burning
         success, err = _subtensor_mock.force_set_balance(
             ss58_address=mock_wallet.coldkeypub.ss58_address,
             balance=bittensor.Balance.from_float(200.0),
         )
-        
+
         with patch("bittensor.wallet", return_value=mock_wallet) as mock_create_wallet:
             cli = bittensor.cli(config)
             cli.run()
             mock_create_wallet.assert_called_once()
 
             # Verify that the wallet was registered
             subtensor = bittensor.subtensor(config)
             registered = subtensor.is_hotkey_registered_on_subnet(
                 hotkey_ss58=mock_wallet.hotkey.ss58_address, netuid=1
             )
 
             self.assertTrue(registered)
 
-    
     def test_stake(self):
         amount_to_stake: Balance = Balance.from_tao(0.5)
         config = self.config
         config.no_prompt = True
         config.command = "stake"
         config.amount = amount_to_stake.tao
         config.stake_all = False
         config.wallet._mock = True
         config.use_password = False
         config.model = "core_server"
         config.hotkey = "hk0"
 
         subtensor = bittensor.subtensor(config)
 
-        mock_wallet = generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         # Register the hotkey and give it some balance
         _subtensor_mock.force_register_neuron(
             netuid=1,
             hotkey=mock_wallet.hotkey.ss58_address,
             coldkey=mock_wallet.coldkey.ss58_address,
             balance=(
@@ -2042,27 +1978,24 @@
             new_stake = subtensor.get_stake_for_coldkey_and_hotkey(
                 hotkey_ss58=mock_wallet.hotkey.ss58_address,
                 coldkey_ss58=mock_wallet.coldkey.ss58_address,
             )
 
             self.assertGreater(new_stake, old_stake)
 
-    
     def test_metagraph(self):
         config = self.config
         config.wallet.name = "metagraph_testwallet"
         config.command = "metagraph"
         config.no_prompt = True
 
         # Add some neurons to the metagraph
         mock_nn = []
 
-        def register_mock_neuron(
-            i: int
-        ) -> int:
+        def register_mock_neuron(i: int) -> int:
             mock_nn.append(
                 SimpleNamespace(
                     hotkey=_get_mock_keypair(i + 100, self.id()).ss58_address,
                     coldkey=_get_mock_keypair(i, self.id()).ss58_address,
                     balance=Balance.from_rao(random.randint(0, 2**45)).rao,
                     stake=Balance.from_rao(random.randint(0, 2**45)).rao,
                 )
@@ -2072,22 +2005,19 @@
                 hotkey=mock_nn[i].hotkey,
                 coldkey=mock_nn[i].coldkey,
                 balance=mock_nn[i].balance,
                 stake=mock_nn[i].stake,
             )
             return uid
 
-       
         for i in range(5):
-            _ = register_mock_neuron(
-                i
-            )
+            _ = register_mock_neuron(i)
 
         _subtensor_mock.neurons_lite(netuid=config.netuid)
-            
+
         cli = bittensor.cli(config)
 
         mock_console = MockConsole()
         with patch("bittensor.__console__", mock_console):
             cli.run()
 
         # Check that the overview was printed.
@@ -2100,15 +2030,14 @@
         self.assertIn(
             str(len(nn) - 1), output_no_syntax
         )  # Check that the number of neurons is output
         # Check each uid is in the output
         for neuron in nn:
             self.assertIn(str(neuron.uid), output_no_syntax)
 
-    
     def test_set_weights(self):
         config = self.config
         config.wallet.name = "set_weights_testwallet"
         config.no_prompt = True
         config.uids = [1, 2, 3, 4]
         config.weights = [0.25, 0.25, 0.25, 0.25]
         config.n_words = 12
@@ -2122,15 +2051,14 @@
         cli.run()
 
         # Now set the weights
         config.command = "set_weights"
         cli.config = config
         cli.run()
 
-    
     def test_inspect(self):
         config = self.config
         config.wallet.name = "inspect_testwallet"
         config.no_prompt = True
         config.n_words = 12
         config.use_password = False
         config.overwrite_coldkey = True
@@ -2151,56 +2079,39 @@
         cli.config = config
         cli.run()
 
         cli.config.command = "list"
         cli.config = config
         cli.run()
 
+
 class TestCLIWithNetworkUsingArgs(unittest.TestCase):
     """
     Test the CLI by passing args directly to the bittensor.cli factory
     """
-    
+
     def test_list_delegates(self):
         cli = bittensor.cli(
-            args=[
-                "list_delegates",
-                "--subtensor.network",
-                "mock",  # Mock network
-            ]
+            args=["list_delegates", "--subtensor.network", "mock"]  # Mock network
         )
         cli.run()
 
-    
     def test_list_subnets(self):
         cli = bittensor.cli(
-            args=[
-                "list_subnets",
-                "--subtensor.network",
-                "mock",  # Mock network
-            ]
+            args=["list_subnets", "--subtensor.network", "mock"]  # Mock network
         )
         cli.run()
 
     def test_delegate(self):
         """
         Test delegate add command
         """
-        mock_wallet = generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
-        delegate_wallet = generate_wallet(
-            hotkey = _get_mock_keypair(
-                100 + 1, self.id()
-            )
-        )
+        mock_wallet = generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
+        delegate_wallet = generate_wallet(hotkey=_get_mock_keypair(100 + 1, self.id()))
 
-       
         # register the wallet
         _ = _subtensor_mock.force_register_neuron(
             netuid=1,
             hotkey=mock_wallet.hotkey.ss58_address,
             coldkey=mock_wallet.coldkey.ss58_address,
         )
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_cli_no_network.py` & `bittensor-5.3.2/tests/integration_tests/test_cli_no_network.py`

 * *Files 19% similar despite different names*

```diff
@@ -39,25 +39,28 @@
             "total_stake": bittensor.Balance.from_rao(0),
             "nominators": [],
             "owner_ss58": "",
             "take": 0.18,
             "validator_permits": [],
             "registrations": [],
             "return_per_1000": bittensor.Balance.from_rao(0),
-            "total_daily_return": bittensor.Balance.from_rao(0)
+            "total_daily_return": bittensor.Balance.from_rao(0),
         }
-        cls._patched_subtensor = patch('bittensor._subtensor.subtensor_mock.MockSubtensor.__new__', new=MagicMock(
-            return_value=MagicMock(
-                get_subnets=MagicMock(return_value=[1]), # Mock subnet 1 ONLY.
-                block=10_000,
-                get_delegates=MagicMock(return_value=[
-                    bittensor.DelegateInfo( **mock_delegate_info )
-                ]),
-            )
-        ))
+        cls._patched_subtensor = patch(
+            "bittensor._subtensor.subtensor_mock.MockSubtensor.__new__",
+            new=MagicMock(
+                return_value=MagicMock(
+                    get_subnets=MagicMock(return_value=[1]),  # Mock subnet 1 ONLY.
+                    block=10_000,
+                    get_delegates=MagicMock(
+                        return_value=[bittensor.DelegateInfo(**mock_delegate_info)]
+                    ),
+                )
+            ),
+        )
         cls._patched_subtensor.start()
 
     @classmethod
     def tearDownClass(cls) -> None:
         cls._patched_subtensor.stop()
 
     def setUp(self):
@@ -69,60 +72,59 @@
         return copy_
 
     @staticmethod
     def construct_config():
         defaults = bittensor.Config()
 
         defaults.netuid = 1
-        bittensor.subtensor.add_defaults( defaults )
-        defaults.subtensor.network = 'mock'
+        bittensor.subtensor.add_defaults(defaults)
+        defaults.subtensor.network = "mock"
         defaults.no_version_checking = True
-        bittensor.axon.add_defaults( defaults )
-        bittensor.wallet.add_defaults( defaults )
-        bittensor.dataset.add_defaults( defaults )
+        bittensor.axon.add_defaults(defaults)
+        bittensor.wallet.add_defaults(defaults)
+        bittensor.dataset.add_defaults(defaults)
 
         return defaults
 
     def test_check_configs(self):
         config = self.config
         config.no_prompt = True
         config.model = "core_server"
         config.dest = "no_prompt"
         config.amount = 1
         config.mnemonic = "this is a mnemonic"
         config.seed = None
-        config.uids = [1,2,3]
+        config.uids = [1, 2, 3]
         config.weights = [0.25, 0.25, 0.25, 0.25]
         config.no_version_checking = True
-        config.ss58_address = bittensor.Keypair.create_from_seed( b'0' * 32 ).ss58_address
+        config.ss58_address = bittensor.Keypair.create_from_seed(b"0" * 32).ss58_address
         config.public_key_hex = None
         config.proposal_hash = ""
 
         cli = bittensor.cli
 
         # Get argparser
         parser = cli.__create_parser__()
         # Get all commands from argparser
-        commands = [
-            command for command in parser._actions[1].choices
-        ]
+        commands = [command for command in parser._actions[1].choices]
 
         def ask_response(prompt: str) -> Any:
             if "delegate index" in prompt:
                 return 0
             elif "wallet name" in prompt:
                 return "mock"
             elif "hotkey" in prompt:
                 return "mock"
-        with patch('rich.prompt.Prompt.ask', ask_response):
+
+        with patch("rich.prompt.Prompt.ask", ask_response):
             for cmd in commands:
                 config.command = cmd
                 cli.check_config(config)
 
-    def test_new_coldkey( self ):
+    def test_new_coldkey(self):
         config = self.config
         config.wallet.name = "new_coldkey_testwallet"
 
         config.command = "new_coldkey"
         config.amount = 1
         config.dest = "no_prompt"
         config.model = "core_server"
@@ -130,796 +132,1011 @@
         config.use_password = False
         config.no_prompt = True
         config.overwrite_coldkey = True
 
         cli = bittensor.cli(config)
         cli.run()
 
-    def test_new_hotkey( self ):
+    def test_new_hotkey(self):
         config = self.config
         config.wallet.name = "new_hotkey_testwallet"
         config.command = "new_hotkey"
         config.amount = 1
         config.dest = "no_prompt"
         config.model = "core_server"
         config.n_words = 12
         config.use_password = False
         config.no_prompt = True
         config.overwrite_hotkey = True
 
-
         cli = bittensor.cli(config)
         cli.run()
 
-    def test_regen_coldkey( self ):
+    def test_regen_coldkey(self):
         config = self.config
         config.wallet.name = "regen_coldkey_testwallet"
         config.command = "regen_coldkey"
         config.amount = 1
         config.dest = "no_prompt"
         config.model = "core_server"
         config.mnemonic = "faculty decade seven jelly gospel axis next radio grain radio remain gentle"
         config.seed = None
         config.n_words = 12
         config.use_password = False
         config.no_prompt = True
         config.overwrite_coldkey = True
 
-
         cli = bittensor.cli(config)
         cli.run()
 
-    def test_regen_coldkeypub( self ):
+    def test_regen_coldkeypub(self):
         config = self.config
         config.wallet.name = "regen_coldkeypub_testwallet"
         config.command = "regen_coldkeypub"
         config.ss58_address = "5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
         config.public_key = None
         config.use_password = False
         config.no_prompt = True
         config.overwrite_coldkeypub = True
 
-
         cli = bittensor.cli(config)
         cli.run()
 
-    def test_regen_hotkey( self ):
+    def test_regen_hotkey(self):
         config = self.config
         config.wallet.name = "regen_hotkey_testwallet"
         config.command = "regen_hotkey"
         config.amount = 1
         config.model = "core_server"
         config.mnemonic = "faculty decade seven jelly gospel axis next radio grain radio remain gentle"
         config.seed = None
         config.n_words = 12
         config.use_password = False
         config.no_prompt = True
         config.overwrite_hotkey = True
 
-
         cli = bittensor.cli(config)
         cli.run()
 
-    def test_list( self ):
+    def test_list(self):
         # Mock IO for wallet
-        with patch('bittensor.wallet', side_effect=[MagicMock(
-            coldkeypub_file=MagicMock(
-                exists_on_device=MagicMock(
-                    return_value=True # Wallet exists
+        with patch(
+            "bittensor.wallet",
+            side_effect=[
+                MagicMock(
+                    coldkeypub_file=MagicMock(
+                        exists_on_device=MagicMock(return_value=True),  # Wallet exists
+                        is_encrypted=MagicMock(
+                            return_value=False  # Wallet is not encrypted
+                        ),
+                    ),
+                    coldkeypub=MagicMock(
+                        ss58_address=bittensor.Keypair.create_from_mnemonic(
+                            bittensor.Keypair.generate_mnemonic()
+                        ).ss58_address
+                    ),
                 ),
-                is_encrypted=MagicMock(
-                    return_value=False # Wallet is not encrypted
+                MagicMock(
+                    hotkey_file=MagicMock(
+                        exists_on_device=MagicMock(return_value=True),  # Wallet exists
+                        is_encrypted=MagicMock(
+                            return_value=False  # Wallet is not encrypted
+                        ),
+                    ),
+                    hotkey=MagicMock(
+                        ss58_address=bittensor.Keypair.create_from_mnemonic(
+                            bittensor.Keypair.generate_mnemonic()
+                        ).ss58_address
+                    ),
                 ),
-            ),
-            coldkeypub=MagicMock(
-                ss58_address=bittensor.Keypair.create_from_mnemonic(
-                        bittensor.Keypair.generate_mnemonic()
-                ).ss58_address
-            )
-        ),
-        MagicMock(
-            hotkey_file=MagicMock(
-                exists_on_device=MagicMock(
-                    return_value=True # Wallet exists
-                ),
-                is_encrypted=MagicMock(
-                    return_value=False # Wallet is not encrypted
-                ),
-            ),
-            hotkey=MagicMock(
-                ss58_address=bittensor.Keypair.create_from_mnemonic(
-                        bittensor.Keypair.generate_mnemonic()
-                ).ss58_address
-            )
-        )]):
+            ],
+        ):
             config = self.config
-            config.wallet.path = 'tmp/walletpath'
-            config.wallet.name = 'mock_wallet'
+            config.wallet.path = "tmp/walletpath"
+            config.wallet.name = "mock_wallet"
             config.no_prompt = True
             config.command = "list"
 
-
             cli = bittensor.cli(config)
-            with patch('os.walk', side_effect=[iter(
-                    [('/tmp/walletpath', ['mock_wallet'], [])] # 1 wallet dir
-            ),
-            iter(
-                [('/tmp/walletpath/mock_wallet/hotkeys', [], ['hk0'])] # 1 hotkey file
-            )]):
+            with patch(
+                "os.walk",
+                side_effect=[
+                    iter([("/tmp/walletpath", ["mock_wallet"], [])]),  # 1 wallet dir
+                    iter(
+                        [
+                            ("/tmp/walletpath/mock_wallet/hotkeys", [], ["hk0"])
+                        ]  # 1 hotkey file
+                    ),
+                ],
+            ):
                 cli.run()
 
-    def test_list_no_wallet( self ):
+    def test_list_no_wallet(self):
         # Mock IO for wallet
-        with patch('bittensor.Wallet.coldkeypub_file', MagicMock(
-            exists_on_device=MagicMock(
-                return_value=False # Wallet doesn't exist
-            )
-        )):
+        with patch(
+            "bittensor.Wallet.coldkeypub_file",
+            MagicMock(
+                exists_on_device=MagicMock(return_value=False)  # Wallet doesn't exist
+            ),
+        ):
             config = self.config
-            config.wallet.path = '/tmp/test_cli_test_list_no_wallet'
+            config.wallet.path = "/tmp/test_cli_test_list_no_wallet"
             config.no_prompt = True
             config.command = "list"
 
-
             cli = bittensor.cli(config)
             # This shouldn't raise an error anymore
             cli.run()
 
     def test_btcli_help(self):
         """
         Verify the correct help text is output when the --help flag is passed
         """
         with pytest.raises(SystemExit) as pytest_wrapped_e:
-            with patch('argparse.ArgumentParser._print_message', return_value=None) as mock_print_message:
-                args = [
-                    '--help'
-                ]
+            with patch(
+                "argparse.ArgumentParser._print_message", return_value=None
+            ) as mock_print_message:
+                args = ["--help"]
                 bittensor.cli(args=args).run()
 
         # Should try to print help
         mock_print_message.assert_called_once()
 
         call_args = mock_print_message.call_args
         args, _ = call_args
         help_out = args[0]
 
         # Expected help output even if parser isn't working well
         ## py3.6-3.9 or py3.10+
-        assert 'optional arguments' in help_out or 'options' in help_out
+        assert "optional arguments" in help_out or "options" in help_out
         # Expected help output if all commands are listed
-        assert 'positional arguments' in help_out
+        assert "positional arguments" in help_out
         # Verify that cli is printing the help message for
         # Get argparser
         parser = bittensor.cli.__create_parser__()
         # Get all commands from argparser
-        commands = [
-            command for command in parser._actions[1].choices
-        ]
+        commands = [command for command in parser._actions[1].choices]
         # Verify that all commands are listed in the help message, AND
         # Verify there are no duplicate commands
         ##  Listed twice. Once in the positional arguments and once in the optional arguments
         for command in commands:
-            pat = re.compile(rf'\n\s+({command})[^\S\r\n]+\w')
+            pat = re.compile(rf"\n\s+({command})[^\S\r\n]+\w")
             matches = pat.findall(help_out)
-            self.assertGreaterEqual( len(matches), 1, f"Command {command} not found in help output")
-            self.assertLess( len(matches), 2, f"Duplicate command {command} in help output")
+            self.assertGreaterEqual(
+                len(matches), 1, f"Command {command} not found in help output"
+            )
+            self.assertLess(
+                len(matches), 2, f"Duplicate command {command} in help output"
+            )
 
     def test_register_cuda_use_cuda_flag(self):
-            class ExitEarlyException(Exception):
-                """Raised by mocked function to exit early"""
-                pass
-
-            base_args = [
-                "register",
-                "--wallet.path", "tmp/walletpath",
-                "--wallet.name", "mock",
-                "--wallet.hotkey", "hk0",
-                "--no_prompt",
-                "--cuda.dev_id", "0",
-                "--network", "mock"
-            ]
-            bittensor.subtensor.check_config = MagicMock(return_value = True)
-            with patch('torch.cuda.is_available', return_value=True):
-                with patch('bittensor.Subtensor.get_subnets', return_value = [1]):
-                    with patch('bittensor.Subtensor.subnet_exists', side_effect=lambda netuid: netuid == 1):
-                        with patch('bittensor.Subtensor.register', side_effect=ExitEarlyException):
-                            # Should be able to set true without argument
-                            args = base_args + [
-                                "--subtensor.register.cuda.use_cuda", # should be True without any arugment
-                            ]
-                            with pytest.raises(ExitEarlyException):
-                                cli = bittensor.cli(args=args)
-                                cli.run()
+        class ExitEarlyException(Exception):
+            """Raised by mocked function to exit early"""
 
-                            assert cli.config.subtensor.register.cuda.get('use_cuda') == True # should be None
+            pass
 
-                            # Should be able to set to false with no argument
+        base_args = [
+            "register",
+            "--wallet.path",
+            "tmp/walletpath",
+            "--wallet.name",
+            "mock",
+            "--wallet.hotkey",
+            "hk0",
+            "--no_prompt",
+            "--cuda.dev_id",
+            "0",
+            "--network",
+            "mock",
+        ]
+        bittensor.subtensor.check_config = MagicMock(return_value=True)
+        with patch("torch.cuda.is_available", return_value=True):
+            with patch("bittensor.Subtensor.get_subnets", return_value=[1]):
+                with patch(
+                    "bittensor.Subtensor.subnet_exists",
+                    side_effect=lambda netuid: netuid == 1,
+                ):
+                    with patch(
+                        "bittensor.Subtensor.register", side_effect=ExitEarlyException
+                    ):
+                        # Should be able to set true without argument
+                        args = base_args + [
+                            "--subtensor.register.cuda.use_cuda",  # should be True without any arugment
+                        ]
+                        with pytest.raises(ExitEarlyException):
+                            cli = bittensor.cli(args=args)
+                            cli.run()
+
+                        assert (
+                            cli.config.subtensor.register.cuda.get("use_cuda") == True
+                        )  # should be None
+
+                        # Should be able to set to false with no argument
+                        args = base_args + [
+                            "--subtensor.register.cuda.no_cuda",
+                        ]
+                        with pytest.raises(ExitEarlyException):
+                            cli = bittensor.cli(args=args)
+                            cli.run()
 
-                            args = base_args + [
-                                "--subtensor.register.cuda.no_cuda",
-                            ]
-                            with pytest.raises(ExitEarlyException):
-                                cli = bittensor.cli(args=args)
-                                cli.run()
+                        assert cli.config.subtensor.register.cuda.use_cuda == False
 
-                            assert cli.config.subtensor.register.cuda.use_cuda == False
 
 class MockException(Exception):
     pass
 
 
 class TestEmptyArgs(unittest.TestCase):
     """
     Test that the CLI doesn't crash when no args are passed
     """
+
     _patched_subtensor = None
 
     @classmethod
     def setUpClass(cls) -> None:
-        cls._patched_subtensor = patch('bittensor._subtensor.subtensor_mock.MockSubtensor.__new__', new=MagicMock(
-        ))
+        cls._patched_subtensor = patch(
+            "bittensor._subtensor.subtensor_mock.MockSubtensor.__new__", new=MagicMock()
+        )
         cls._patched_subtensor.start()
 
     @classmethod
     def tearDownClass(cls) -> None:
         cls._patched_subtensor.stop()
-    
-    @patch('rich.prompt.PromptBase.ask', side_effect=MockException)
+
+    @patch("rich.prompt.PromptBase.ask", side_effect=MockException)
     def test_command_no_args(self, patched_prompt_ask):
         # Get argparser
         parser = bittensor.cli.__create_parser__()
         # Get all commands from argparser
-        commands = [
-            command for command in parser._actions[1].choices
-        ]
+        commands = [command for command in parser._actions[1].choices]
 
         # Test that each command can be run with no args
         for command in commands:
             try:
-                bittensor.cli(args=[
-                    command
-                ]).run()
+                bittensor.cli(args=[command]).run()
             except MockException:
-                pass # Expected exception
+                pass  # Expected exception
 
             # Should not raise any other exceptions
-        
+
 
 class TestCLIDefaultsNoNetwork(unittest.TestCase):
     _patched_subtensor = None
 
     @classmethod
     def setUpClass(cls) -> None:
         mock_delegate_info = {
             "hotkey_ss58": "",
             "total_stake": bittensor.Balance.from_rao(0),
             "nominators": [],
             "owner_ss58": "",
-            "take": 0.18, 
+            "take": 0.18,
             "validator_permits": [],
-            "registrations": [], 
-            "return_per_1000": bittensor.Balance.from_rao(0), 
-            "total_daily_return": bittensor.Balance.from_rao(0)
+            "registrations": [],
+            "return_per_1000": bittensor.Balance.from_rao(0),
+            "total_daily_return": bittensor.Balance.from_rao(0),
         }
-        cls._patched_subtensor = patch('bittensor._subtensor.subtensor_mock.MockSubtensor.__new__', new=MagicMock(
-            return_value=MagicMock(
-                get_subnets=MagicMock(return_value=[1]), # Mock subnet 1 ONLY.
-                block=10_000,
-                get_delegates=MagicMock(return_value=[
-                    bittensor.DelegateInfo( **mock_delegate_info )
-                ]),
-            )
-        ))
+        cls._patched_subtensor = patch(
+            "bittensor._subtensor.subtensor_mock.MockSubtensor.__new__",
+            new=MagicMock(
+                return_value=MagicMock(
+                    get_subnets=MagicMock(return_value=[1]),  # Mock subnet 1 ONLY.
+                    block=10_000,
+                    get_delegates=MagicMock(
+                        return_value=[bittensor.DelegateInfo(**mock_delegate_info)]
+                    ),
+                )
+            ),
+        )
         cls._patched_subtensor.start()
 
     @classmethod
     def tearDownClass(cls) -> None:
         cls._patched_subtensor.stop()
 
     def test_inspect_prompt_wallet_name(self):
         # Patch command to exit early
-        with patch('bittensor._cli.commands.inspect.InspectCommand.run', return_value=None):
-
+        with patch(
+            "bittensor._cli.commands.inspect.InspectCommand.run", return_value=None
+        ):
             # Test prompt happens when no wallet name is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'inspect',
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "inspect",
                         # '--wallet.name', 'mock',
-                    ])
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called_once()
 
             # Test NO prompt happens when wallet name is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'inspect',
-                        '--wallet.name', 'coolwalletname',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "inspect",
+                        "--wallet.name",
+                        "coolwalletname",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
             # Test NO prompt happens when wallet name 'default' is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'inspect',
-                        '--wallet.name', 'default',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "inspect",
+                        "--wallet.name",
+                        "default",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_overview_prompt_wallet_name(self):
         # Patch command to exit early
-        with patch('bittensor._cli.commands.overview.OverviewCommand.run', return_value=None):
-
+        with patch(
+            "bittensor._cli.commands.overview.OverviewCommand.run", return_value=None
+        ):
             # Test prompt happens when no wallet name is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'overview',
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "overview",
                         # '--wallet.name', 'mock',
-                        '--netuid', '1'
-                    ])
+                        "--netuid",
+                        "1",
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called_once()
 
             # Test NO prompt happens when wallet name is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'overview',
-                        '--wallet.name', 'coolwalletname',
-                        '--netuid', '1',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "overview",
+                        "--wallet.name",
+                        "coolwalletname",
+                        "--netuid",
+                        "1",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
             # Test NO prompt happens when wallet name 'default' is passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=[
-                        'overview',
-                        '--wallet.name', 'default',
-                        '--netuid', '1',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=[
+                        "overview",
+                        "--wallet.name",
+                        "default",
+                        "--netuid",
+                        "1",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_stake_prompt_wallet_name_and_hotkey_name(self):
         base_args = [
-            'stake',
-            '--all',
+            "stake",
+            "--all",
         ]
         # Patch command to exit early
-        with patch('bittensor._cli.commands.stake.StakeCommand.run', return_value=None):
-
-            # Test prompt happens when 
+        with patch("bittensor._cli.commands.stake.StakeCommand.run", return_value=None):
+            # Test prompt happens when
             # - wallet name IS NOT passed, AND
             # - hotkey name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         # '--wallet.name', 'mock',
-                        #'--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                        #'--wallet.hotkey', 'mock_hotkey',
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 2, msg="Prompt should have been called twice")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    2,
+                    msg="Prompt should have been called twice",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in [val for val in kwargs0.values()]]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in [val for val in kwargs0.values()]
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
                 args1, kwargs1 = mock_ask_prompt.call_args_list[1]
-                combined_args_kwargs1 = [arg for arg in args1] + [val for val in kwargs1.values()]
+                combined_args_kwargs1 = [arg for arg in args1] + [
+                    val for val in kwargs1.values()
+                ]
                 # check that prompt was called for hotkey
 
                 self.assertTrue(
-                    any(filter(lambda x: 'hotkey' in x.lower(), combined_args_kwargs1)),
-                    msg=f"Prompt should have been called for hotkey: {combined_args_kwargs1}"
+                    any(filter(lambda x: "hotkey" in x.lower(), combined_args_kwargs1)),
+                    msg=f"Prompt should have been called for hotkey: {combined_args_kwargs1}",
                 )
 
-            # Test prompt happens when 
+            # Test prompt happens when
             # - wallet name IS NOT passed, AND
             # - hotkey name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         #'--wallet.name', 'mock',
-                        '--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                        "--wallet.hotkey",
+                        "mock_hotkey",
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
-            # Test prompt happens when 
+            # Test prompt happens when
             # - wallet name IS passed, AND
             # - hotkey name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'mock',
-                        #'--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "mock",
+                        #'--wallet.hotkey', 'mock_hotkey',
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for hotkey
                 self.assertTrue(
-                    any(filter(lambda x: 'hotkey' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs0}"
+                    any(filter(lambda x: "hotkey" in x.lower(), combined_args_kwargs0)),
+                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs0}",
                 )
 
-
             # Test NO prompt happens when
             # - wallet name IS passed, AND
             # - hotkey name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'coolwalletname',
-                        '--wallet.hotkey', 'coolwalletname_hotkey',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "coolwalletname",
+                        "--wallet.hotkey",
+                        "coolwalletname_hotkey",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
             # Test NO prompt happens when
             # - wallet name 'default' IS passed, AND
             # - hotkey name 'default' IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'default',
-                        '--wallet.hotkey', 'default',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "default",
+                        "--wallet.hotkey",
+                        "default",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_unstake_prompt_wallet_name_and_hotkey_name(self):
         base_args = [
-            'unstake',
-            '--all',
+            "unstake",
+            "--all",
         ]
         # Patch command to exit early
-        with patch('bittensor._cli.commands.unstake.UnStakeCommand.run', return_value=None):
-
-            # Test prompt happens when 
+        with patch(
+            "bittensor._cli.commands.unstake.UnStakeCommand.run", return_value=None
+        ):
+            # Test prompt happens when
             # - wallet name IS NOT passed, AND
             # - hotkey name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         # '--wallet.name', 'mock',
-                        #'--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                        #'--wallet.hotkey', 'mock_hotkey',
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 2, msg="Prompt should have been called twice")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    2,
+                    msg="Prompt should have been called twice",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
                 args1, kwargs1 = mock_ask_prompt.call_args_list[1]
-                combined_args_kwargs1 = [arg for arg in args1] + [val for val in kwargs1.values()]
+                combined_args_kwargs1 = [arg for arg in args1] + [
+                    val for val in kwargs1.values()
+                ]
                 # check that prompt was called for hotkey
                 self.assertTrue(
-                    any(filter(lambda x: 'hotkey' in x.lower(), combined_args_kwargs1)),
-                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs1}"
+                    any(filter(lambda x: "hotkey" in x.lower(), combined_args_kwargs1)),
+                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs1}",
                 )
 
-            # Test prompt happens when 
+            # Test prompt happens when
             # - wallet name IS NOT passed, AND
             # - hotkey name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         #'--wallet.name', 'mock',
-                        '--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                        "--wallet.hotkey",
+                        "mock_hotkey",
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
-            # Test prompt happens when 
+            # Test prompt happens when
             # - wallet name IS passed, AND
             # - hotkey name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock', 'mock_hotkey']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock", "mock_hotkey"]
 
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'mock',
-                        #'--wallet.hotkey', 'mock_hotkey', 
-                    ])
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "mock",
+                        #'--wallet.hotkey', 'mock_hotkey',
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for hotkey
                 self.assertTrue(
-                    any(filter(lambda x: 'hotkey' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs0}"
+                    any(filter(lambda x: "hotkey" in x.lower(), combined_args_kwargs0)),
+                    msg=f"Prompt should have been called for hotkey {combined_args_kwargs0}",
                 )
 
-
             # Test NO prompt happens when
             # - wallet name IS passed, AND
             # - hotkey name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'coolwalletname',
-                        '--wallet.hotkey', 'coolwalletname_hotkey',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "coolwalletname",
+                        "--wallet.hotkey",
+                        "coolwalletname_hotkey",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
             # Test NO prompt happens when
             # - wallet name 'default' IS passed, AND
             # - hotkey name 'default' IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'default',
-                        '--wallet.hotkey', 'default',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "default",
+                        "--wallet.hotkey",
+                        "default",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_delegate_prompt_wallet_name(self):
-        base_args = [
-            'delegate',
-            '--all',
-            '--delegate_ss58key', _get_mock_coldkey(0)
-        ]
+        base_args = ["delegate", "--all", "--delegate_ss58key", _get_mock_coldkey(0)]
         # Patch command to exit early
-        with patch('bittensor._cli.commands.delegates.DelegateStakeCommand.run', return_value=None):
-
-            # Test prompt happens when 
+        with patch(
+            "bittensor._cli.commands.delegates.DelegateStakeCommand.run",
+            return_value=None,
+        ):
+            # Test prompt happens when
             # - wallet name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         # '--wallet.name', 'mock',
-                    ])
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
             # Test NO prompt happens when
             # - wallet name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'coolwalletname',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "coolwalletname",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_undelegate_prompt_wallet_name(self):
-        base_args = [
-            'undelegate',
-            '--all',
-            '--delegate_ss58key', _get_mock_coldkey(0)
-        ]
+        base_args = ["undelegate", "--all", "--delegate_ss58key", _get_mock_coldkey(0)]
         # Patch command to exit early
-        with patch('bittensor._cli.commands.delegates.DelegateUnstakeCommand.run', return_value=None):
-
-            # Test prompt happens when 
+        with patch(
+            "bittensor._cli.commands.delegates.DelegateUnstakeCommand.run",
+            return_value=None,
+        ):
+            # Test prompt happens when
             # - wallet name IS NOT passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                mock_ask_prompt.side_effect = ['mock']
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                mock_ask_prompt.side_effect = ["mock"]
 
-                cli = bittensor.cli(args=base_args + [
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
                         # '--wallet.name', 'mock',
-                    ])
+                    ]
+                )
                 cli.run()
 
                 # Prompt happened
                 mock_ask_prompt.assert_called()
-                self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                self.assertEqual(
+                    mock_ask_prompt.call_count,
+                    1,
+                    msg="Prompt should have been called ONCE",
+                )
                 args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
+                combined_args_kwargs0 = [arg for arg in args0] + [
+                    val for val in kwargs0.values()
+                ]
                 # check that prompt was called for wallet name
                 self.assertTrue(
-                    any(filter(lambda x: 'wallet name' in x.lower(), combined_args_kwargs0)),
-                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}"
+                    any(
+                        filter(
+                            lambda x: "wallet name" in x.lower(), combined_args_kwargs0
+                        )
+                    ),
+                    msg=f"Prompt should have been called for wallet name: {combined_args_kwargs0}",
                 )
 
             # Test NO prompt happens when
             # - wallet name IS passed
-            with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                cli = bittensor.cli(args=base_args + [
-                        '--wallet.name', 'coolwalletname',
-                    ])
+            with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                cli = bittensor.cli(
+                    args=base_args
+                    + [
+                        "--wallet.name",
+                        "coolwalletname",
+                    ]
+                )
                 cli.run()
 
                 # NO prompt happened
                 mock_ask_prompt.assert_not_called()
 
     def test_delegate_prompt_hotkey(self):
         # Tests when
         # - wallet name IS passed, AND
         # - delegate hotkey IS NOT passed
         base_args = [
-            'delegate',
-            '--all',
-            '--wallet.name', 'mock', 
+            "delegate",
+            "--all",
+            "--wallet.name",
+            "mock",
         ]
 
         delegate_ss58 = _get_mock_coldkey(0)
-        with patch('bittensor._cli.commands.delegates.show_delegates'):
-            with patch('bittensor.Subtensor.get_delegates', return_value=[
-                bittensor.DelegateInfo(
-                    hotkey_ss58=delegate_ss58, # return delegate with mock coldkey
-                    total_stake=bittensor.Balance.from_float(0.1),
-                    nominators=[],
-                    owner_ss58='',
-                    take=0.18,
-                    validator_permits=[],
-                    registrations=[],
-                    return_per_1000=bittensor.Balance.from_float(0.1),
-                    total_daily_return=bittensor.Balance.from_float(0.1)
-                )
-            ]):
+        with patch("bittensor._cli.commands.delegates.show_delegates"):
+            with patch(
+                "bittensor.Subtensor.get_delegates",
+                return_value=[
+                    bittensor.DelegateInfo(
+                        hotkey_ss58=delegate_ss58,  # return delegate with mock coldkey
+                        total_stake=bittensor.Balance.from_float(0.1),
+                        nominators=[],
+                        owner_ss58="",
+                        take=0.18,
+                        validator_permits=[],
+                        registrations=[],
+                        return_per_1000=bittensor.Balance.from_float(0.1),
+                        total_daily_return=bittensor.Balance.from_float(0.1),
+                    )
+                ],
+            ):
                 # Patch command to exit early
-                with patch('bittensor._cli.commands.delegates.DelegateStakeCommand.run', return_value=None):
-
-                    # Test prompt happens when 
+                with patch(
+                    "bittensor._cli.commands.delegates.DelegateStakeCommand.run",
+                    return_value=None,
+                ):
+                    # Test prompt happens when
                     # - delegate hotkey IS NOT passed
-                    with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                        mock_ask_prompt.side_effect = ['0'] # select delegate with mock coldkey
-
-                        cli = bittensor.cli(args=base_args + [
+                    with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                        mock_ask_prompt.side_effect = [
+                            "0"
+                        ]  # select delegate with mock coldkey
+
+                        cli = bittensor.cli(
+                            args=base_args
+                            + [
                                 # '--delegate_ss58key', delegate_ss58,
-                            ])
+                            ]
+                        )
                         cli.run()
 
                         # Prompt happened
                         mock_ask_prompt.assert_called()
-                        self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                        self.assertEqual(
+                            mock_ask_prompt.call_count,
+                            1,
+                            msg="Prompt should have been called ONCE",
+                        )
                         args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                        combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
-                        # check that prompt was called for delegate hotkey 
+                        combined_args_kwargs0 = [arg for arg in args0] + [
+                            val for val in kwargs0.values()
+                        ]
+                        # check that prompt was called for delegate hotkey
                         self.assertTrue(
-                            any(filter(lambda x: 'delegate' in x.lower(), combined_args_kwargs0)),
-                            msg=f"Prompt should have been called for delegate: {combined_args_kwargs0}"
+                            any(
+                                filter(
+                                    lambda x: "delegate" in x.lower(),
+                                    combined_args_kwargs0,
+                                )
+                            ),
+                            msg=f"Prompt should have been called for delegate: {combined_args_kwargs0}",
                         )
 
                     # Test NO prompt happens when
                     # - delegate hotkey IS passed
-                    with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                        cli = bittensor.cli(args=base_args + [
-                                '--delegate_ss58key', delegate_ss58,
-                            ])
+                    with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                        cli = bittensor.cli(
+                            args=base_args
+                            + [
+                                "--delegate_ss58key",
+                                delegate_ss58,
+                            ]
+                        )
                         cli.run()
 
                         # NO prompt happened
                         mock_ask_prompt.assert_not_called()
 
     def test_undelegate_prompt_hotkey(self):
         # Tests when
         # - wallet name IS passed, AND
         # - delegate hotkey IS NOT passed
         base_args = [
-            'undelegate',
-            '--all',
-            '--wallet.name', 'mock', 
+            "undelegate",
+            "--all",
+            "--wallet.name",
+            "mock",
         ]
 
         delegate_ss58 = _get_mock_coldkey(0)
-        with patch('bittensor._cli.commands.delegates.show_delegates'):
-            with patch('bittensor.Subtensor.get_delegates', return_value=[
-                bittensor.DelegateInfo(
-                    hotkey_ss58=delegate_ss58, # return delegate with mock coldkey
-                    total_stake=bittensor.Balance.from_float(0.1),
-                    nominators=[],
-                    owner_ss58='',
-                    take=0.18,
-                    validator_permits=[],
-                    registrations=[],
-                    return_per_1000=bittensor.Balance.from_float(0.1),
-                    total_daily_return=bittensor.Balance.from_float(0.1)
-                )
-            ]):
+        with patch("bittensor._cli.commands.delegates.show_delegates"):
+            with patch(
+                "bittensor.Subtensor.get_delegates",
+                return_value=[
+                    bittensor.DelegateInfo(
+                        hotkey_ss58=delegate_ss58,  # return delegate with mock coldkey
+                        total_stake=bittensor.Balance.from_float(0.1),
+                        nominators=[],
+                        owner_ss58="",
+                        take=0.18,
+                        validator_permits=[],
+                        registrations=[],
+                        return_per_1000=bittensor.Balance.from_float(0.1),
+                        total_daily_return=bittensor.Balance.from_float(0.1),
+                    )
+                ],
+            ):
                 # Patch command to exit early
-                with patch('bittensor._cli.commands.delegates.DelegateUnstakeCommand.run', return_value=None):
-
-                    # Test prompt happens when 
+                with patch(
+                    "bittensor._cli.commands.delegates.DelegateUnstakeCommand.run",
+                    return_value=None,
+                ):
+                    # Test prompt happens when
                     # - delegate hotkey IS NOT passed
-                    with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                        mock_ask_prompt.side_effect = ['0'] # select delegate with mock coldkey
-
-                        cli = bittensor.cli(args=base_args + [
+                    with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                        mock_ask_prompt.side_effect = [
+                            "0"
+                        ]  # select delegate with mock coldkey
+
+                        cli = bittensor.cli(
+                            args=base_args
+                            + [
                                 # '--delegate_ss58key', delegate_ss58,
-                            ])
+                            ]
+                        )
                         cli.run()
 
                         # Prompt happened
                         mock_ask_prompt.assert_called()
-                        self.assertEqual(mock_ask_prompt.call_count, 1, msg="Prompt should have been called ONCE")
+                        self.assertEqual(
+                            mock_ask_prompt.call_count,
+                            1,
+                            msg="Prompt should have been called ONCE",
+                        )
                         args0, kwargs0 = mock_ask_prompt.call_args_list[0]
-                        combined_args_kwargs0 = [arg for arg in args0] + [val for val in kwargs0.values()]
-                        # check that prompt was called for delegate hotkey 
+                        combined_args_kwargs0 = [arg for arg in args0] + [
+                            val for val in kwargs0.values()
+                        ]
+                        # check that prompt was called for delegate hotkey
                         self.assertTrue(
-                            any(filter(lambda x: 'delegate' in x.lower(), combined_args_kwargs0)),
-                            msg=f"Prompt should have been called for delegate: {combined_args_kwargs0}"
+                            any(
+                                filter(
+                                    lambda x: "delegate" in x.lower(),
+                                    combined_args_kwargs0,
+                                )
+                            ),
+                            msg=f"Prompt should have been called for delegate: {combined_args_kwargs0}",
                         )
 
                     # Test NO prompt happens when
                     # - delegate hotkey IS passed
-                    with patch('rich.prompt.Prompt.ask') as mock_ask_prompt:
-                        cli = bittensor.cli(args=base_args + [
-                                '--delegate_ss58key', delegate_ss58,
-                            ])
+                    with patch("rich.prompt.Prompt.ask") as mock_ask_prompt:
+                        cli = bittensor.cli(
+                            args=base_args
+                            + [
+                                "--delegate_ss58key",
+                                delegate_ss58,
+                            ]
+                        )
                         cli.run()
 
                         # NO prompt happened
                         mock_ask_prompt.assert_not_called()
 
 
-
 if __name__ == "__main__":
-    unittest.main()
+    unittest.main()
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_ipfs.py` & `bittensor-5.3.2/tests/integration_tests/test_ipfs.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,24 +1,31 @@
 import bittensor
 import json
 
+
 def test_ipfs_init():
     ipfs = bittensor.Ipfs()
 
-    assert ipfs.cat == 'http://global.ipfs.opentensor.ai/api/v0/cat'
-    assert ipfs.node_get == 'http://global.ipfs.opentensor.ai/api/v0/object/get'
-    assert ipfs.ipns_resolve == 'http://global.ipfs.opentensor.ai/api/v0/name/resolve'
-
-    assert ipfs.mountain_hash == 'QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX'
-    assert ipfs.latest_neurons_ipns == 'k51qzi5uqu5di1eoe0o91g32tbfsgikva6mvz0jw0414zhxzhiakana67shoh7'
-    assert ipfs.historical_neurons_ipns == 'k51qzi5uqu5dhf5yxm3kqw9hyrv28q492p3t32s23059z911a23l30ai6ziceh'
+    assert ipfs.cat == "http://global.ipfs.opentensor.ai/api/v0/cat"
+    assert ipfs.node_get == "http://global.ipfs.opentensor.ai/api/v0/object/get"
+    assert ipfs.ipns_resolve == "http://global.ipfs.opentensor.ai/api/v0/name/resolve"
+
+    assert ipfs.mountain_hash == "QmSdDg6V9dgpdAFtActs75Qfc36qJtm9y8a7yrQ1rHm7ZX"
+    assert (
+        ipfs.latest_neurons_ipns
+        == "k51qzi5uqu5di1eoe0o91g32tbfsgikva6mvz0jw0414zhxzhiakana67shoh7"
+    )
+    assert (
+        ipfs.historical_neurons_ipns
+        == "k51qzi5uqu5dhf5yxm3kqw9hyrv28q492p3t32s23059z911a23l30ai6ziceh"
+    )
 
     assert ipfs.refresh_corpus == False
 
+
 def test_retrieve_directory():
     ipfs = bittensor.Ipfs()
 
-    directory = ipfs.retrieve_directory(ipfs.node_get, (('arg', ipfs.mountain_hash),))
+    directory = ipfs.retrieve_directory(ipfs.node_get, (("arg", ipfs.mountain_hash),))
     folder_list = json.loads(directory.text)
     assert directory.status_code == 200
     assert len(folder_list) > 1
-
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_metagraph_integration.py` & `bittensor-5.3.2/tests/integration_tests/test_metagraph_integration.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,28 +17,24 @@
 # DEALINGS IN THE SOFTWARE.
 
 import bittensor
 import torch
 import pytest
 from bittensor._subtensor.subtensor_mock import MockSubtensor
 
-_subtensor_mock: MockSubtensor = bittensor.subtensor( network = 'mock', _mock = True )
+_subtensor_mock: MockSubtensor = bittensor.subtensor(network="mock", _mock=True)
+
 
 def setUpModule():
     _subtensor_mock.reset()
 
-    _subtensor_mock.create_subnet(
-        netuid = 3
-    )
+    _subtensor_mock.create_subnet(netuid=3)
 
     # Set diff 0
-    _subtensor_mock.set_difficulty(
-        netuid = 3,
-        difficulty = 0
-    )
+    _subtensor_mock.set_difficulty(netuid=3, difficulty=0)
 
 
 class TestMetagraph:
     def setup_method(self):
         self.sub = bittensor.subtensor(_mock=True)
         self.metagraph = bittensor.metagraph(netuid=3, network="mock")
 
@@ -59,32 +55,32 @@
         self.metagraph.save()
         self.metagraph.load()
         self.metagraph.save()
 
     def test_state_dict(self):
         self.metagraph.load()
         state = self.metagraph.state_dict()
-        assert 'version' in state
-        assert 'n' in state
-        assert 'block' in state
-        assert 'stake' in state
-        assert 'total_stake' in state
-        assert 'ranks' in state
-        assert 'trust' in state
-        assert 'consensus' in state
-        assert 'validator_trust' in state
-        assert 'incentive' in state
-        assert 'emission' in state
-        assert 'dividends' in state
-        assert 'active' in state
-        assert 'last_update' in state
-        assert 'validator_permit' in state
-        assert 'weights' in state
-        assert 'bonds' in state
-        assert 'uids' in state
+        assert "version" in state
+        assert "n" in state
+        assert "block" in state
+        assert "stake" in state
+        assert "total_stake" in state
+        assert "ranks" in state
+        assert "trust" in state
+        assert "consensus" in state
+        assert "validator_trust" in state
+        assert "incentive" in state
+        assert "emission" in state
+        assert "dividends" in state
+        assert "active" in state
+        assert "last_update" in state
+        assert "validator_permit" in state
+        assert "weights" in state
+        assert "bonds" in state
+        assert "uids" in state
 
     def test_properties(self):
         metagraph = self.metagraph
         metagraph.hotkeys
         metagraph.coldkeys
         metagraph.addresses
         metagraph.validator_trust
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_priority_thread_pool.py` & `bittensor-5.3.2/tests/integration_tests/test_priority_thread_pool.py`

 * *Files 9% similar despite different names*

```diff
@@ -14,23 +14,25 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 import bittensor
 import unittest
 
+
 class TestPriorityThreadPool(unittest.TestCase):
     @classmethod
     def setUpClass(cls) -> None:
         cls.priority_pool = bittensor.prioritythreadpool(max_workers=1)
-        
+
     def test_priority_thread_pool(self):
         save = []
-        def save_number(number,save):
+
+        def save_number(number, save):
             save += [number]
+
         with self.priority_pool:
             for x in range(10):
-                self.priority_pool.submit(save_number, x,save,priority=x)
+                self.priority_pool.submit(save_number, x, save, priority=x)
 
         assert save[0] == 0
         assert save[1] == 9
-
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_prometheus.py` & `bittensor-5.3.2/tests/integration_tests/test_prometheus.py`

 * *Files 25% similar despite different names*

```diff
@@ -2,37 +2,43 @@
 
 import pytest
 import unittest
 from unittest.mock import MagicMock, patch
 from bittensor._subtensor.subtensor_mock import MockSubtensor
 from tests.helpers import _get_mock_wallet
 
-_subtensor_mock: MockSubtensor = bittensor.subtensor( network = 'mock', _mock = True )
+_subtensor_mock: MockSubtensor = bittensor.subtensor(network="mock", _mock=True)
+
 
 def setUpModule():
     _subtensor_mock.reset()
 
-    _subtensor_mock.create_subnet(
-        netuid = 3
-    )
-
-    _subtensor_mock.set_difficulty(
-        netuid = 3,
-        difficulty = 0
-    )
+    _subtensor_mock.create_subnet(netuid=3)
 
-class TestPrometheus(unittest.TestCase):
+    _subtensor_mock.set_difficulty(netuid=3, difficulty=0)
 
+
+class TestPrometheus(unittest.TestCase):
     def setUp(self):
-        self.subtensor = bittensor.subtensor(network = 'mock')
+        self.subtensor = bittensor.subtensor(network="mock")
         self.wallet = _get_mock_wallet()
 
     def test_init_prometheus_success(self):
-        with patch.object(self.subtensor, '_do_serve_prometheus', return_value = (True, None)):
-            with patch("prometheus_client.start_http_server"): 
-                self.assertTrue( bittensor.prometheus(wallet = self.wallet, subtensor = self.subtensor, netuid=3) )
+        with patch.object(
+            self.subtensor, "_do_serve_prometheus", return_value=(True, None)
+        ):
+            with patch("prometheus_client.start_http_server"):
+                self.assertTrue(
+                    bittensor.prometheus(
+                        wallet=self.wallet, subtensor=self.subtensor, netuid=3
+                    )
+                )
 
     def test_init_prometheus_failed(self):
-        with patch.object(self.subtensor, '_do_serve_prometheus', return_value = (False, 'Mock failure')):
-            with patch("prometheus_client.start_http_server"): 
+        with patch.object(
+            self.subtensor, "_do_serve_prometheus", return_value=(False, "Mock failure")
+        ):
+            with patch("prometheus_client.start_http_server"):
                 with pytest.raises(Exception):
-                    bittensor.prometheus(wallet = self.wallet, subtensor = self.subtensor, netuid=3)
+                    bittensor.prometheus(
+                        wallet=self.wallet, subtensor=self.subtensor, netuid=3
+                    )
```

### Comparing `bittensor-5.3.1/tests/integration_tests/test_subtensor_integration.py` & `bittensor-5.3.2/tests/integration_tests/test_subtensor_integration.py`

 * *Files 6% similar despite different names*

```diff
@@ -24,477 +24,609 @@
 from types import SimpleNamespace
 
 import bittensor
 import pytest
 from bittensor.utils.balance import Balance
 from substrateinterface import Keypair
 from bittensor._subtensor.subtensor_mock import MockSubtensor
-from tests.helpers import _get_mock_hotkey, _get_mock_coldkey, MockConsole, _get_mock_keypair, _get_mock_wallet
+from tests.helpers import (
+    _get_mock_hotkey,
+    _get_mock_coldkey,
+    MockConsole,
+    _get_mock_keypair,
+    _get_mock_wallet,
+)
+
 
 class TestSubtensor(unittest.TestCase):
     _mock_console_patcher = None
     _mock_subtensor: MockSubtensor
     subtensor: MockSubtensor
 
     def setUp(self):
         self.wallet = _get_mock_wallet(
-            hotkey = _get_mock_keypair(0, self.id()),
-            coldkey = _get_mock_keypair(1, self.id())
+            hotkey=_get_mock_keypair(0, self.id()),
+            coldkey=_get_mock_keypair(1, self.id()),
         )
         self.balance = Balance.from_tao(1000)
-        self.mock_neuron = MagicMock() # NOTE: this might need more sophistication
-        self.subtensor = bittensor.subtensor( network = 'mock' ) # own instance per test
+        self.mock_neuron = MagicMock()  # NOTE: this might need more sophistication
+        self.subtensor = bittensor.subtensor(network="mock")  # own instance per test
 
     @classmethod
     def setUpClass(cls) -> None:
         # mock rich console status
         mock_console = MockConsole()
-        cls._mock_console_patcher = patch('bittensor.__console__', mock_console)
+        cls._mock_console_patcher = patch("bittensor.__console__", mock_console)
         cls._mock_console_patcher.start()
 
         # Keeps the same mock network for all tests. This stops the network from being re-setup for each test.
-        cls._mock_subtensor = bittensor.subtensor( network = 'mock' )
+        cls._mock_subtensor = bittensor.subtensor(network="mock")
 
         cls._do_setup_subnet()
 
     @classmethod
     def _do_setup_subnet(cls):
         # reset the mock subtensor
         cls._mock_subtensor.reset()
         # Setup the mock subnet 3
-        cls._mock_subtensor.create_subnet(
-            netuid = 3
-        )
+        cls._mock_subtensor.create_subnet(netuid=3)
 
     @classmethod
     def tearDownClass(cls) -> None:
         cls._mock_console_patcher.stop()
 
-    def test_network_overrides( self ):
-        """ Tests that the network overrides the chain_endpoint.
-        """
+    def test_network_overrides(self):
+        """Tests that the network overrides the chain_endpoint."""
         # Argument importance: chain_endpoint (arg) > network (arg) > config.subtensor.chain_endpoint > config.subtensor.network
         config0 = bittensor.subtensor.config()
-        config0.subtensor.network = 'finney'
-        config0.subtensor.chain_endpoint = 'wss://finney.subtensor.io' # Should not match bittensor.__finney_entrypoint__
+        config0.subtensor.network = "finney"
+        config0.subtensor.chain_endpoint = "wss://finney.subtensor.io"  # Should not match bittensor.__finney_entrypoint__
         assert config0.subtensor.chain_endpoint != bittensor.__finney_entrypoint__
 
         config1 = bittensor.subtensor.config()
-        config1.subtensor.network = 'local'
+        config1.subtensor.network = "local"
         config1.subtensor.chain_endpoint = None
 
         # Mock network calls
-        with patch('substrateinterface.SubstrateInterface.connect_websocket'):
-            with patch('substrateinterface.SubstrateInterface.reload_type_registry'):
+        with patch("substrateinterface.SubstrateInterface.connect_websocket"):
+            with patch("substrateinterface.SubstrateInterface.reload_type_registry"):
                 # Choose arg over config
-                sub0 = bittensor.subtensor( config = config0, chain_endpoint = 'wss://fin.subtensor.io' )
-                self.assertEqual(sub0.chain_endpoint, 'wss://fin.subtensor.io', msg='Explicit chain_endpoint arg should override config.chain_endpoint')
+                sub0 = bittensor.subtensor(
+                    config=config0, chain_endpoint="wss://fin.subtensor.io"
+                )
+                self.assertEqual(
+                    sub0.chain_endpoint,
+                    "wss://fin.subtensor.io",
+                    msg="Explicit chain_endpoint arg should override config.chain_endpoint",
+                )
 
                 # Choose network arg over config
-                sub1 = bittensor.subtensor( config = config1, network = 'local' )
-                self.assertEqual(sub1.chain_endpoint, bittensor.__local_entrypoint__, msg='Explicit network arg should override config.network')
+                sub1 = bittensor.subtensor(config=config1, network="local")
+                self.assertEqual(
+                    sub1.chain_endpoint,
+                    bittensor.__local_entrypoint__,
+                    msg="Explicit network arg should override config.network",
+                )
 
                 # Choose chain_endpoint config over network config
-                sub2 = bittensor.subtensor( config = config0 )
-                self.assertEqual(sub2.chain_endpoint, config0.subtensor.chain_endpoint, msg='config.chain_endpoint should override choice derived from config.network')
+                sub2 = bittensor.subtensor(config=config0)
+                self.assertEqual(
+                    sub2.chain_endpoint,
+                    config0.subtensor.chain_endpoint,
+                    msg="config.chain_endpoint should override choice derived from config.network",
+                )
 
-                sub3 = bittensor.subtensor( config = config1 )
+                sub3 = bittensor.subtensor(config=config1)
                 # Should pick local instead of finney (default)
                 assert sub3.network == "local"
                 assert sub3.chain_endpoint == bittensor.__local_entrypoint__
 
-    def test_get_current_block( self ):
+    def test_get_current_block(self):
         block = self.subtensor.get_current_block()
-        assert (type(block) == int)
+        assert type(block) == int
 
-    def test_unstake( self ):
-        self.subtensor._do_unstake = MagicMock(return_value = True)
+    def test_unstake(self):
+        self.subtensor._do_unstake = MagicMock(return_value=True)
 
         self.subtensor.substrate.get_payment_info = MagicMock(
-            return_value = { 'partialFee': 100 }
+            return_value={"partialFee": 100}
         )
 
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
 
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            success= self.subtensor.unstake(self.wallet,
-                                amount = 200
-                                )
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            success = self.subtensor.unstake(self.wallet, amount=200)
             self.assertTrue(success, msg="Unstake should succeed")
 
-    def test_unstake_inclusion( self ):
-        self.subtensor._do_unstake = MagicMock(return_value = True)
-        
+    def test_unstake_inclusion(self):
+        self.subtensor._do_unstake = MagicMock(return_value=True)
+
         self.subtensor.substrate.get_payment_info = MagicMock(
-            return_value = { 'partialFee': 100 }
+            return_value={"partialFee": 100}
         )
 
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
 
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            success= self.subtensor.unstake(self.wallet,
-                                amount = 200,
-                                wait_for_inclusion = True
-                                )
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            success = self.subtensor.unstake(
+                self.wallet, amount=200, wait_for_inclusion=True
+            )
             self.assertTrue(success, msg="Unstake should succeed")
 
-    def test_unstake_failed( self ):
-        self.subtensor._do_unstake = MagicMock(return_value = False)
-        
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
-
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            fail = self.subtensor.unstake(self.wallet,
-                                amount = 200,
-                                wait_for_inclusion = True
-                                )
+    def test_unstake_failed(self):
+        self.subtensor._do_unstake = MagicMock(return_value=False)
+
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
+
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            fail = self.subtensor.unstake(
+                self.wallet, amount=200, wait_for_inclusion=True
+            )
             self.assertFalse(fail, msg="Unstake should fail")
 
     def test_stake(self):
-        self.subtensor._do_stake = MagicMock(return_value = True)
+        self.subtensor._do_stake = MagicMock(return_value=True)
 
         self.subtensor.substrate.get_payment_info = MagicMock(
-            return_value = { 'partialFee': 100 }
+            return_value={"partialFee": 100}
         )
 
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
 
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            with patch('bittensor.Subtensor.get_hotkey_owner', return_value=self.wallet.coldkeypub.ss58_address):
-                success= self.subtensor.add_stake(self.wallet,
-                                    amount = 200
-                                    )
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            with patch(
+                "bittensor.Subtensor.get_hotkey_owner",
+                return_value=self.wallet.coldkeypub.ss58_address,
+            ):
+                success = self.subtensor.add_stake(self.wallet, amount=200)
                 self.assertTrue(success, msg="Stake should succeed")
 
     def test_stake_inclusion(self):
-        self.subtensor._do_stake = MagicMock(return_value = True)
+        self.subtensor._do_stake = MagicMock(return_value=True)
 
         self.subtensor.substrate.get_payment_info = MagicMock(
-            return_value = { 'partialFee': 100 }
+            return_value={"partialFee": 100}
         )
-        
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
-
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            with patch('bittensor.Subtensor.get_hotkey_owner', return_value=self.wallet.coldkeypub.ss58_address):
-                success= self.subtensor.add_stake(self.wallet,
-                                    amount = 200,
-                                    wait_for_inclusion = True
-                                    )
+
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
+
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            with patch(
+                "bittensor.Subtensor.get_hotkey_owner",
+                return_value=self.wallet.coldkeypub.ss58_address,
+            ):
+                success = self.subtensor.add_stake(
+                    self.wallet, amount=200, wait_for_inclusion=True
+                )
                 self.assertTrue(success, msg="Stake should succeed")
 
-    def test_stake_failed( self ):
-        self.subtensor._do_stake = MagicMock(return_value = False)
+    def test_stake_failed(self):
+        self.subtensor._do_stake = MagicMock(return_value=False)
 
         self.subtensor.substrate.get_payment_info = MagicMock(
-            return_value = { 'partialFee': 100 }
+            return_value={"partialFee": 100}
         )
 
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_balance = MagicMock(return_value = Balance.from_rao(0))
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_balance = MagicMock(return_value=Balance.from_rao(0))
 
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        with patch('bittensor.Subtensor.get_stake_for_coldkey_and_hotkey', return_value=Balance.from_tao(500)):
-            with patch('bittensor.Subtensor.get_hotkey_owner', return_value=self.wallet.coldkeypub.ss58_address):
-                fail = self.subtensor.add_stake(self.wallet,
-                                    amount = 200,
-                                    wait_for_inclusion = True
-                                    )
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        with patch(
+            "bittensor.Subtensor.get_stake_for_coldkey_and_hotkey",
+            return_value=Balance.from_tao(500),
+        ):
+            with patch(
+                "bittensor.Subtensor.get_hotkey_owner",
+                return_value=self.wallet.coldkeypub.ss58_address,
+            ):
+                fail = self.subtensor.add_stake(
+                    self.wallet, amount=200, wait_for_inclusion=True
+                )
                 self.assertFalse(fail, msg="Stake should fail")
 
-    def test_transfer( self ):
+    def test_transfer(self):
         fake_coldkey = _get_mock_coldkey(1)
-        
-        self.subtensor._do_transfer = MagicMock(return_value = (True, '0x', None))
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
-        success= self.subtensor.transfer(self.wallet,
-                            fake_coldkey,
-                            amount = 200,
-                            )
+
+        self.subtensor._do_transfer = MagicMock(return_value=(True, "0x", None))
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
+        success = self.subtensor.transfer(
+            self.wallet,
+            fake_coldkey,
+            amount=200,
+        )
         self.assertTrue(success, msg="Transfer should succeed")
 
-    def test_transfer_inclusion( self ):
+    def test_transfer_inclusion(self):
         fake_coldkey = _get_mock_coldkey(1)
-        self.subtensor._do_transfer = MagicMock(return_value = (True, '0x', None))
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
-
-        success = self.subtensor.transfer(self.wallet,
-                            fake_coldkey,
-                            amount = 200,
-                            wait_for_inclusion = True
-                            )
+        self.subtensor._do_transfer = MagicMock(return_value=(True, "0x", None))
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
+
+        success = self.subtensor.transfer(
+            self.wallet, fake_coldkey, amount=200, wait_for_inclusion=True
+        )
         self.assertTrue(success, msg="Transfer should succeed")
 
-    def test_transfer_failed(self ):
+    def test_transfer_failed(self):
         fake_coldkey = _get_mock_coldkey(1)
-        self.subtensor._do_transfer = MagicMock(return_value = (False, None, 'Mock failure message'))
+        self.subtensor._do_transfer = MagicMock(
+            return_value=(False, None, "Mock failure message")
+        )
 
-        fail= self.subtensor.transfer(self.wallet,
-                            fake_coldkey,
-                            amount = 200,
-                            wait_for_inclusion = True
-                            )
+        fail = self.subtensor.transfer(
+            self.wallet, fake_coldkey, amount=200, wait_for_inclusion=True
+        )
         self.assertFalse(fail, msg="Transfer should fail")
 
-    def test_transfer_invalid_dest(self ):
+    def test_transfer_invalid_dest(self):
         fake_coldkey = _get_mock_coldkey(1)
 
-        fail = self.subtensor.transfer(self.wallet,
-                            fake_coldkey[:-1], # invalid dest
-                            amount = 200,
-                            wait_for_inclusion = True
-                            )
+        fail = self.subtensor.transfer(
+            self.wallet,
+            fake_coldkey[:-1],  # invalid dest
+            amount=200,
+            wait_for_inclusion=True,
+        )
         self.assertFalse(fail, msg="Transfer should fail because of invalid dest")
 
-    def test_transfer_dest_as_bytes(self ):
+    def test_transfer_dest_as_bytes(self):
         fake_coldkey = _get_mock_coldkey(1)
-        self.subtensor._do_transfer = MagicMock(return_value = (True, '0x', None))
+        self.subtensor._do_transfer = MagicMock(return_value=(True, "0x", None))
 
-        self.subtensor.register = MagicMock(return_value = True)
-        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(return_value = self.mock_neuron)
-        self.subtensor.get_balance = MagicMock(return_value = self.balance)
+        self.subtensor.register = MagicMock(return_value=True)
+        self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+            return_value=self.mock_neuron
+        )
+        self.subtensor.get_balance = MagicMock(return_value=self.balance)
 
         dest_as_bytes: bytes = Keypair(fake_coldkey).public_key
-        success = self.subtensor.transfer(self.wallet,
-                            dest_as_bytes, # invalid dest
-                            amount = 200,
-                            wait_for_inclusion = True
-                            )
+        success = self.subtensor.transfer(
+            self.wallet,
+            dest_as_bytes,  # invalid dest
+            amount=200,
+            wait_for_inclusion=True,
+        )
         self.assertTrue(success, msg="Transfer should succeed")
 
-    def test_set_weights( self ):
+    def test_set_weights(self):
         chain_weights = [0]
-        class success():
+
+        class success:
             def __init__(self):
                 self.is_success = True
+
             def process_events(self):
                 return True
 
+        self.subtensor._do_set_weights = MagicMock(return_value=(True, None))
 
-        self.subtensor._do_set_weights = MagicMock(return_value = (True, None))
-
-        success= self.subtensor.set_weights(wallet=self.wallet,
-                            netuid = 3,
-                            uids=[1],
-                            weights=chain_weights,
-                            )
+        success = self.subtensor.set_weights(
+            wallet=self.wallet,
+            netuid=3,
+            uids=[1],
+            weights=chain_weights,
+        )
         assert success == True
 
-    def test_set_weights_inclusion( self ):
+    def test_set_weights_inclusion(self):
         chain_weights = [0]
-        self.subtensor._do_set_weights = MagicMock(return_value = (True, None))
+        self.subtensor._do_set_weights = MagicMock(return_value=(True, None))
 
-        success = self.subtensor.set_weights(wallet=self.wallet,
-                            netuid = 1,
-                            uids=[1],
-                            weights=chain_weights,
-                            wait_for_inclusion = True
-                            )
+        success = self.subtensor.set_weights(
+            wallet=self.wallet,
+            netuid=1,
+            uids=[1],
+            weights=chain_weights,
+            wait_for_inclusion=True,
+        )
         assert success == True
 
-    def test_set_weights_failed( self ):
+    def test_set_weights_failed(self):
         chain_weights = [0]
-        self.subtensor._do_set_weights = MagicMock(return_value = (False, 'Mock failure message'))
+        self.subtensor._do_set_weights = MagicMock(
+            return_value=(False, "Mock failure message")
+        )
 
         fail = self.subtensor.set_weights(
             wallet=self.wallet,
-            netuid = 3,
+            netuid=3,
             uids=[1],
             weights=chain_weights,
-            wait_for_inclusion = True
+            wait_for_inclusion=True,
         )
         assert fail == False
 
-    def test_get_balance( self ):
+    def test_get_balance(self):
         fake_coldkey = _get_mock_coldkey(0)
-        balance= self.subtensor.get_balance(address=fake_coldkey)
+        balance = self.subtensor.get_balance(address=fake_coldkey)
         assert type(balance) == bittensor.utils.balance.Balance
 
-    def test_get_balances( self ):
+    def test_get_balances(self):
         balances = self.subtensor.get_balances()
         assert type(balances) == dict
         for i in balances:
             assert type(balances[i]) == bittensor.utils.balance.Balance
 
-    def test_get_uid_by_hotkey_on_subnet( self ):
+    def test_get_uid_by_hotkey_on_subnet(self):
         mock_coldkey_kp = _get_mock_keypair(0, self.id())
         mock_hotkey_kp = _get_mock_keypair(100, self.id())
 
         # Register on subnet 3
         mock_uid = self.subtensor.force_register_neuron(
-            netuid = 3,
-            hotkey = mock_hotkey_kp.ss58_address,
-            coldkey = mock_coldkey_kp.ss58_address,
+            netuid=3,
+            hotkey=mock_hotkey_kp.ss58_address,
+            coldkey=mock_coldkey_kp.ss58_address,
         )
 
-        uid = self.subtensor.get_uid_for_hotkey_on_subnet(mock_hotkey_kp.ss58_address, netuid = 3)
-        self.assertIsInstance(uid, int, msg="get_uid_for_hotkey_on_subnet should return an int")
-        self.assertEqual(uid, mock_uid, msg="get_uid_for_hotkey_on_subnet should return the correct uid")
+        uid = self.subtensor.get_uid_for_hotkey_on_subnet(
+            mock_hotkey_kp.ss58_address, netuid=3
+        )
+        self.assertIsInstance(
+            uid, int, msg="get_uid_for_hotkey_on_subnet should return an int"
+        )
+        self.assertEqual(
+            uid,
+            mock_uid,
+            msg="get_uid_for_hotkey_on_subnet should return the correct uid",
+        )
 
-    def test_is_hotkey_registered( self ):
+    def test_is_hotkey_registered(self):
         mock_coldkey_kp = _get_mock_keypair(0, self.id())
         mock_hotkey_kp = _get_mock_keypair(100, self.id())
 
         # Register on subnet 3
         _ = self.subtensor.force_register_neuron(
-            netuid = 3,
-            hotkey = mock_hotkey_kp.ss58_address,
-            coldkey = mock_coldkey_kp.ss58_address,
+            netuid=3,
+            hotkey=mock_hotkey_kp.ss58_address,
+            coldkey=mock_coldkey_kp.ss58_address,
+        )
+
+        registered = self.subtensor.is_hotkey_registered(
+            mock_hotkey_kp.ss58_address, netuid=3
         )
-        
-        registered = self.subtensor.is_hotkey_registered(mock_hotkey_kp.ss58_address, netuid = 3)
         self.assertTrue(registered, msg="Hotkey should be registered")
 
-    def test_is_hotkey_registered_not_registered( self ):
+    def test_is_hotkey_registered_not_registered(self):
         mock_hotkey_kp = _get_mock_keypair(100, self.id())
 
         # Do not register on subnet 3
 
-        registered = self.subtensor.is_hotkey_registered(mock_hotkey_kp.ss58_address, netuid = 3)
+        registered = self.subtensor.is_hotkey_registered(
+            mock_hotkey_kp.ss58_address, netuid=3
+        )
         self.assertFalse(registered, msg="Hotkey should not be registered")
 
-    def test_registration_multiprocessed_already_registered( self ):
+    def test_registration_multiprocessed_already_registered(self):
         workblocks_before_is_registered = random.randint(5, 10)
         # return False each work block but return True after a random number of blocks
-        is_registered_return_values = [False for _ in range(workblocks_before_is_registered)] + [True] + [True, False]
+        is_registered_return_values = (
+            [False for _ in range(workblocks_before_is_registered)]
+            + [True]
+            + [True, False]
+        )
         # this should pass the initial False check in the subtensor class and then return True because the neuron is already registered
 
         mock_neuron = MagicMock()
         mock_neuron.is_null = True
 
-        with patch('bittensor.Subtensor.difficulty'):
+        with patch("bittensor.Subtensor.difficulty"):
             # patch solution queue to return None
-            with patch('multiprocessing.queues.Queue.get', return_value=None) as mock_queue_get:
+            with patch(
+                "multiprocessing.queues.Queue.get", return_value=None
+            ) as mock_queue_get:
                 # patch time queue get to raise Empty exception
-                with patch('multiprocessing.queues.Queue.get_nowait', side_effect=QueueEmpty) as mock_queue_get_nowait:
-
+                with patch(
+                    "multiprocessing.queues.Queue.get_nowait", side_effect=QueueEmpty
+                ) as mock_queue_get_nowait:
                     wallet = _get_mock_wallet(
-                        hotkey = _get_mock_keypair(0, self.id()),
-                        coldkey = _get_mock_keypair(1, self.id())
+                        hotkey=_get_mock_keypair(0, self.id()),
+                        coldkey=_get_mock_keypair(1, self.id()),
+                    )
+                    self.subtensor.is_hotkey_registered = MagicMock(
+                        side_effect=is_registered_return_values
                     )
-                    self.subtensor.is_hotkey_registered = MagicMock( side_effect=is_registered_return_values )
 
-                    self.subtensor.difficulty= MagicMock(return_value=1)
-                    self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock( side_effect=mock_neuron )
-                    self.subtensor._do_pow_register = MagicMock(return_value = (True, None))
+                    self.subtensor.difficulty = MagicMock(return_value=1)
+                    self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+                        side_effect=mock_neuron
+                    )
+                    self.subtensor._do_pow_register = MagicMock(
+                        return_value=(True, None)
+                    )
 
-                    with patch('bittensor.__console__.status') as mock_set_status:
+                    with patch("bittensor.__console__.status") as mock_set_status:
                         # Need to patch the console status to avoid opening a parallel live display
                         mock_set_status.__enter__ = MagicMock(return_value=True)
                         mock_set_status.__exit__ = MagicMock(return_value=True)
 
                         # should return True
-                        assert self.subtensor.register(wallet=wallet, netuid = 3, num_processes=3, update_interval=5 ) == True
+                        assert (
+                            self.subtensor.register(
+                                wallet=wallet,
+                                netuid=3,
+                                num_processes=3,
+                                update_interval=5,
+                            )
+                            == True
+                        )
 
                     # calls until True and once again before exiting subtensor class
                     # This assertion is currently broken when difficulty is too low
-                    assert self.subtensor.is_hotkey_registered.call_count == workblocks_before_is_registered + 2
+                    assert (
+                        self.subtensor.is_hotkey_registered.call_count
+                        == workblocks_before_is_registered + 2
+                    )
 
-    def test_registration_partly_failed( self ):
-        do_pow_register_mock = MagicMock( side_effect = [(False, 'Failed'), (False, 'Failed'), (True, None)])
+    def test_registration_partly_failed(self):
+        do_pow_register_mock = MagicMock(
+            side_effect=[(False, "Failed"), (False, "Failed"), (True, None)]
+        )
 
         def is_registered_side_effect(*args, **kwargs):
             nonlocal do_pow_register_mock
             return do_pow_register_mock.call_count < 3
 
-        current_block = [i for i in range(0,100)]
+        current_block = [i for i in range(0, 100)]
 
-        with patch('bittensor.Subtensor.get_neuron_for_pubkey_and_subnet', return_value = bittensor.NeuronInfo._null_neuron()):
-            with patch('bittensor.Subtensor.difficulty'):
+        with patch(
+            "bittensor.Subtensor.get_neuron_for_pubkey_and_subnet",
+            return_value=bittensor.NeuronInfo._null_neuron(),
+        ):
+            with patch("bittensor.Subtensor.difficulty"):
                 wallet = _get_mock_wallet(
-                    hotkey = _get_mock_keypair(0, self.id()),
-                    coldkey = _get_mock_keypair(1, self.id())
+                    hotkey=_get_mock_keypair(0, self.id()),
+                    coldkey=_get_mock_keypair(1, self.id()),
                 )
 
-                self.subtensor.is_hotkey_registered = MagicMock(side_effect=is_registered_side_effect)
+                self.subtensor.is_hotkey_registered = MagicMock(
+                    side_effect=is_registered_side_effect
+                )
 
                 self.subtensor.difficulty = MagicMock(return_value=1)
                 self.subtensor.get_current_block = MagicMock(side_effect=current_block)
                 self.subtensor._do_pow_register = do_pow_register_mock
 
                 # should return True
-                self.assertTrue( self.subtensor.register(wallet=wallet, netuid = 3, num_processes=3, update_interval=5), msg="Registration should succeed" )
+                self.assertTrue(
+                    self.subtensor.register(
+                        wallet=wallet, netuid=3, num_processes=3, update_interval=5
+                    ),
+                    msg="Registration should succeed",
+                )
 
-    def test_registration_failed( self ):
+    def test_registration_failed(self):
         is_registered_return_values = [False for _ in range(100)]
-        current_block = [i for i in range(0,100)]
+        current_block = [i for i in range(0, 100)]
         mock_neuron = MagicMock()
         mock_neuron.is_null = True
 
-        with patch('bittensor._subtensor.extrinsics.registration.create_pow', return_value=None) as mock_create_pow:
+        with patch(
+            "bittensor._subtensor.extrinsics.registration.create_pow", return_value=None
+        ) as mock_create_pow:
             wallet = _get_mock_wallet(
-                hotkey = _get_mock_keypair(0, self.id()),
-                coldkey = _get_mock_keypair(1, self.id())
+                hotkey=_get_mock_keypair(0, self.id()),
+                coldkey=_get_mock_keypair(1, self.id()),
             )
 
-            self.subtensor.is_hotkey_registered = MagicMock(side_effect=is_registered_return_values)
+            self.subtensor.is_hotkey_registered = MagicMock(
+                side_effect=is_registered_return_values
+            )
 
             self.subtensor.get_current_block = MagicMock(side_effect=current_block)
-            self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock( return_value=mock_neuron )
-            self.subtensor.substrate.get_block_hash = MagicMock( return_value = '0x' + '0' * 64 )
-            self.subtensor._do_pow_register = MagicMock(return_value = (False, 'Failed'))
+            self.subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(
+                return_value=mock_neuron
+            )
+            self.subtensor.substrate.get_block_hash = MagicMock(
+                return_value="0x" + "0" * 64
+            )
+            self.subtensor._do_pow_register = MagicMock(return_value=(False, "Failed"))
 
             # should return True
-            self.assertIsNot( self.subtensor.register(wallet=wallet, netuid = 3 ), True, msg="Registration should fail" )
-            self.assertEqual( mock_create_pow.call_count, 3 )
+            self.assertIsNot(
+                self.subtensor.register(wallet=wallet, netuid=3),
+                True,
+                msg="Registration should fail",
+            )
+            self.assertEqual(mock_create_pow.call_count, 3)
 
-    def test_registration_stale_then_continue( self ):
+    def test_registration_stale_then_continue(self):
         # verifty that after a stale solution, the solve will continue without exiting
 
         class ExitEarly(Exception):
             pass
 
-        mock_is_stale = MagicMock(
-            side_effect = [True, False]
-        )
+        mock_is_stale = MagicMock(side_effect=[True, False])
 
-        mock_do_pow_register = MagicMock(
-            side_effect = ExitEarly()
-        )
+        mock_do_pow_register = MagicMock(side_effect=ExitEarly())
 
         mock_subtensor_self = MagicMock(
-            neuron_for_pubkey = MagicMock( return_value = MagicMock(is_null = True) ), # not registered
-            _do_pow_register = mock_do_pow_register,
+            neuron_for_pubkey=MagicMock(
+                return_value=MagicMock(is_null=True)
+            ),  # not registered
+            _do_pow_register=mock_do_pow_register,
             substrate=MagicMock(
-                get_block_hash = MagicMock( return_value = '0x' + '0'*64 ),
-            )
+                get_block_hash=MagicMock(return_value="0x" + "0" * 64),
+            ),
         )
 
         mock_wallet = MagicMock()
 
-        mock_create_pow = MagicMock(
-            return_value = MagicMock(
-                is_stale = mock_is_stale
-            )
-        )
+        mock_create_pow = MagicMock(return_value=MagicMock(is_stale=mock_is_stale))
 
-        with patch('bittensor.Subtensor.get_neuron_for_pubkey_and_subnet', return_value=bittensor.NeuronInfo._null_neuron() ):
-            with patch('bittensor._subtensor.extrinsics.registration.create_pow', mock_create_pow):
+        with patch(
+            "bittensor.Subtensor.get_neuron_for_pubkey_and_subnet",
+            return_value=bittensor.NeuronInfo._null_neuron(),
+        ):
+            with patch(
+                "bittensor._subtensor.extrinsics.registration.create_pow",
+                mock_create_pow,
+            ):
                 # should create a pow and check if it is stale
                 # then should create a new pow and check if it is stale
                 # then should enter substrate and exit early because of test
                 with pytest.raises(ExitEarly):
-                    bittensor.Subtensor.register( mock_subtensor_self, mock_wallet, netuid = 3 )
-                self.assertEqual( mock_create_pow.call_count, 2, msg="must try another pow after stale" )
-                self.assertEqual( mock_is_stale.call_count, 2 )
-                self.assertEqual( mock_do_pow_register.call_count, 1, msg="only tries to submit once, then exits" )
+                    bittensor.Subtensor.register(
+                        mock_subtensor_self, mock_wallet, netuid=3
+                    )
+                self.assertEqual(
+                    mock_create_pow.call_count,
+                    2,
+                    msg="must try another pow after stale",
+                )
+                self.assertEqual(mock_is_stale.call_count, 2)
+                self.assertEqual(
+                    mock_do_pow_register.call_count,
+                    1,
+                    msg="only tries to submit once, then exits",
+                )
+
 
 # # This test was flaking, please check to_defaults before reactiving the test
 # def _test_defaults_to_finney():
 #     sub = bittensor.subtensor()
 #     assert sub.network == 'finney'
 #     assert sub.chain_endpoint == bittensor.__finney_entrypoint__
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_axon.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_axon.py`

 * *Files 22% similar despite different names*

```diff
@@ -24,66 +24,71 @@
 from unittest.mock import MagicMock
 
 import bittensor
 from bittensor.utils.test_utils import get_random_unused_port
 
 from tests.helpers import _get_mock_wallet, _get_mock_keypair
 
+
 def gen_nonce():
     return f"{time.monotonic_ns()}"
 
+
 def sign_v2(sender_wallet, receiver_wallet):
     nonce, receptor_uid = gen_nonce(), str(uuid.uuid1())
     sender_hotkey = sender_wallet.hotkey.ss58_address
     receiver_hotkey = receiver_wallet.hotkey.ss58_address
     message = f"{nonce}.{sender_hotkey}.{receiver_hotkey}.{receptor_uid}"
     signature = f"0x{sender_wallet.hotkey.sign(message).hex()}"
     return ".".join([nonce, sender_hotkey, signature, receptor_uid])
 
+
 def sign(sender_wallet, receiver_wallet, receiver_version):
     return sign_v2(sender_wallet, receiver_wallet)
 
+
 def is_port_in_use(port):
     import socket
+
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
-        val = s.connect_ex(('localhost', port))
+        val = s.connect_ex(("localhost", port))
         if val == 0:
             return True
         else:
             return False
 
+
 class TestAxon(unittest.TestCase):
     @classmethod
     def setUpClass(cls) -> None:
         cls.wallet = wallet = _get_mock_wallet(
-            coldkey = _get_mock_keypair(0, cls.__name__),
-            hotkey= _get_mock_keypair(100 + 0, cls.__name__),
+            coldkey=_get_mock_keypair(0, cls.__name__),
+            hotkey=_get_mock_keypair(100 + 0, cls.__name__),
         )
 
-        cls.axon = bittensor.axon( wallet = wallet, metagraph = None )
+        cls.axon = bittensor.axon(wallet=wallet, metagraph=None)
 
         cls.sender_wallet = _get_mock_wallet(
-            coldkey = _get_mock_keypair(1, cls.__name__),
-            hotkey= _get_mock_keypair(100 + 1, cls.__name__),
+            coldkey=_get_mock_keypair(1, cls.__name__),
+            hotkey=_get_mock_keypair(100 + 1, cls.__name__),
         )
 
-
     def test_axon_start(self):
         mock_wallet = MagicMock(
             spec=bittensor.Wallet,
             coldkey=MagicMock(),
             coldkeypub=MagicMock(
                 # mock ss58 address
                 ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
             ),
             hotkey=MagicMock(
                 ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
             ),
         )
-        axon = bittensor.axon( wallet = mock_wallet, metagraph = None )
+        axon = bittensor.axon(wallet=mock_wallet, metagraph=None)
         axon.start()
         assert axon.server._state.stage == grpc._server._ServerStage.STARTED
 
     def test_axon_stop(self):
         mock_wallet = MagicMock(
             spec=bittensor.Wallet,
             coldkey=MagicMock(),
@@ -91,19 +96,19 @@
                 # mock ss58 address
                 ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
             ),
             hotkey=MagicMock(
                 ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
             ),
         )
-        axon = bittensor.axon( wallet = mock_wallet, metagraph = None )
+        axon = bittensor.axon(wallet=mock_wallet, metagraph=None)
         axon.start()
-        time.sleep( 1 )
+        time.sleep(1)
         axon.stop()
-        time.sleep( 1 )
+        time.sleep(1)
         assert axon.server._state.stage == grpc._server._ServerStage.STOPPED
 
     def test_sign_v2(self):
         sign_v2(self.sender_wallet, self.wallet)
 
     def test_axon_is_destroyed(self):
         mock_wallet = MagicMock(
@@ -115,48 +120,49 @@
             ),
             hotkey=MagicMock(
                 ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
             ),
         )
 
         port = get_random_unused_port()
-        assert is_port_in_use( port ) == False
-        axon = bittensor.axon ( wallet = mock_wallet, metagraph = None, port = port )
-        assert is_port_in_use( port ) == True
+        assert is_port_in_use(port) == False
+        axon = bittensor.axon(wallet=mock_wallet, metagraph=None, port=port)
+        assert is_port_in_use(port) == True
         axon.start()
-        assert is_port_in_use( port ) == True
+        assert is_port_in_use(port) == True
         axon.stop()
-        assert is_port_in_use( port ) == False
+        assert is_port_in_use(port) == False
         axon.__del__()
-        assert is_port_in_use( port ) == False
+        assert is_port_in_use(port) == False
 
         port = get_random_unused_port()
-        assert is_port_in_use( port ) == False
-        axon2 = bittensor.axon ( wallet = mock_wallet, metagraph = None, port = port )
-        assert is_port_in_use( port ) == True
+        assert is_port_in_use(port) == False
+        axon2 = bittensor.axon(wallet=mock_wallet, metagraph=None, port=port)
+        assert is_port_in_use(port) == True
         axon2.start()
-        assert is_port_in_use( port ) == True
+        assert is_port_in_use(port) == True
         axon2.__del__()
-        assert is_port_in_use( port ) == False
+        assert is_port_in_use(port) == False
 
         port_3 = get_random_unused_port()
-        assert is_port_in_use( port_3 ) == False
-        axonA = bittensor.axon ( wallet = mock_wallet, metagraph = None, port = port_3 )
-        assert is_port_in_use( port_3 ) == True
-        axonB = bittensor.axon ( wallet = mock_wallet, metagraph = None, port = port_3 )
+        assert is_port_in_use(port_3) == False
+        axonA = bittensor.axon(wallet=mock_wallet, metagraph=None, port=port_3)
+        assert is_port_in_use(port_3) == True
+        axonB = bittensor.axon(wallet=mock_wallet, metagraph=None, port=port_3)
         assert axonA.server != axonB.server
-        assert is_port_in_use( port_3 ) == True
+        assert is_port_in_use(port_3) == True
         axonA.start()
-        assert is_port_in_use( port_3 ) == True
+        assert is_port_in_use(port_3) == True
         axonB.start()
-        assert is_port_in_use( port_3 ) == True
+        assert is_port_in_use(port_3) == True
         axonA.__del__()
-        assert is_port_in_use( port ) == False
+        assert is_port_in_use(port) == False
         axonB.__del__()
-        assert is_port_in_use( port ) == False
+        assert is_port_in_use(port) == False
+
 
 # test external axon args
 class TestExternalAxon(unittest.TestCase):
     """
     Tests the external axon config flags
     `--axon.external_port` and `--axon.external_ip`
     Need to verify the external config is used when broadcasting to the network
@@ -165,176 +171,223 @@
     Also test the default behaviour when no external axon config is provided
     (should use the internal axon config, like usual)
     """
 
     def test_external_ip_not_set_dont_use_internal_ip(self):
         # Verify that not setting the external ip arg will NOT default to the internal axon ip
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_config = bittensor.axon.config()
         mock_wallet = MagicMock(
             spec=bittensor.Wallet,
             coldkey=MagicMock(),
             coldkeypub=MagicMock(
                 # mock ss58 address
                 ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
             ),
             hotkey=MagicMock(
                 ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
             ),
         )
-        axon = bittensor.axon ( wallet = mock_wallet, metagraph = None, ip = 'fake_ip', server = mock_server, config = mock_config )
-        assert axon.external_ip != axon.ip # should be different
-        assert (axon.external_ip is None) or (axon.external_ip == bittensor.utils.networking.get_external_ip()) # should be None OR default from bittensor.utils
+        axon = bittensor.axon(
+            wallet=mock_wallet,
+            metagraph=None,
+            ip="fake_ip",
+            server=mock_server,
+            config=mock_config,
+        )
+        assert axon.external_ip != axon.ip  # should be different
+        assert (axon.external_ip is None) or (
+            axon.external_ip == bittensor.utils.networking.get_external_ip()
+        )  # should be None OR default from bittensor.utils
 
     def test_external_port_not_set_use_internal_port(self):
         # Verify that not setting the external port arg will default to the internal axon port
         mock_config = bittensor.axon.config()
 
         mock_wallet = mock.MagicMock(
-            hotkey = mock.MagicMock(
-                ss58_address = 'fake_hotkey_address',
-                spec = bittensor.Keypair
+            hotkey=mock.MagicMock(
+                ss58_address="fake_hotkey_address", spec=bittensor.Keypair
             ),
-            spec = bittensor.Wallet
+            spec=bittensor.Wallet,
         )
 
-        with mock.patch('bittensor.wallet') as mock_create_wallet:
+        with mock.patch("bittensor.wallet") as mock_create_wallet:
             mock_create_wallet.return_value = mock_wallet
-            axon = bittensor.axon ( wallet = mock_wallet, metagraph = None, port = 1234, config=mock_config )
+            axon = bittensor.axon(
+                wallet=mock_wallet, metagraph=None, port=1234, config=mock_config
+            )
             assert axon.external_port == axon.port
 
     def test_external_port_set_full_address_internal(self):
         internal_port = 1234
         external_port = 5678
         mock_wallet = mock.MagicMock(
-            hotkey = mock.MagicMock(
-                ss58_address = 'fake_hotkey_address',
-                spec = bittensor.Keypair
+            hotkey=mock.MagicMock(
+                ss58_address="fake_hotkey_address", spec=bittensor.Keypair
             ),
-            spec = bittensor.Wallet
+            spec=bittensor.Wallet,
         )
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_config = bittensor.axon.config()
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, port = internal_port, external_port = external_port, server = mock_server, config = mock_config )
+        _ = bittensor.axon(
+            wallet=mock_wallet,
+            metagraph=None,
+            port=internal_port,
+            external_port=external_port,
+            server=mock_server,
+            config=mock_config,
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address0 = args[0]
 
-        assert f'{internal_port}' in full_address0 and f':{external_port}' not in full_address0
+        assert (
+            f"{internal_port}" in full_address0
+            and f":{external_port}" not in full_address0
+        )
 
         mock_add_insecure_port.reset_mock()
 
         # Test using config
         mock_config = bittensor.axon.config()
 
         mock_config.axon.port = internal_port
         mock_config.axon.external_port = external_port
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, config = mock_config, server = mock_server )
+        _ = bittensor.axon(
+            wallet=mock_wallet, metagraph=None, config=mock_config, server=mock_server
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address0 = args[0]
 
-        assert f'{internal_port}' in full_address0, f'{internal_port} was not found in {full_address0}'
-        assert f':{external_port}' not in full_address0, f':{external_port} was found in {full_address0}'
+        assert (
+            f"{internal_port}" in full_address0
+        ), f"{internal_port} was not found in {full_address0}"
+        assert (
+            f":{external_port}" not in full_address0
+        ), f":{external_port} was found in {full_address0}"
 
     def test_external_ip_set_full_address_internal(self):
-        internal_ip = 'fake_ip_internal'
-        external_ip = 'fake_ip_external'
+        internal_ip = "fake_ip_internal"
+        external_ip = "fake_ip_external"
 
         mock_wallet = mock.MagicMock(
-            hotkey = mock.MagicMock(
-                ss58_address = 'fake_hotkey_address',
-                spec = bittensor.Keypair
+            hotkey=mock.MagicMock(
+                ss58_address="fake_hotkey_address", spec=bittensor.Keypair
             ),
-            spec = bittensor.Wallet
+            spec=bittensor.Wallet,
         )
 
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_config = bittensor.axon.config()
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, ip=internal_ip, external_ip=external_ip, server=mock_server, config=mock_config )
+        _ = bittensor.axon(
+            wallet=mock_wallet,
+            metagraph=None,
+            ip=internal_ip,
+            external_ip=external_ip,
+            server=mock_server,
+            config=mock_config,
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address0 = args[0]
 
-        assert f'{internal_ip}' in full_address0 and f'{external_ip}' not in full_address0
+        assert (
+            f"{internal_ip}" in full_address0 and f"{external_ip}" not in full_address0
+        )
 
         mock_add_insecure_port.reset_mock()
 
         # Test using config
         mock_config = bittensor.axon.config()
         mock_config.axon.external_ip = external_ip
         mock_config.axon.ip = internal_ip
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, config=mock_config, server=mock_server )
+        _ = bittensor.axon(
+            wallet=mock_wallet, metagraph=None, config=mock_config, server=mock_server
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address0 = args[0]
 
-        assert f'{internal_ip}' in full_address0, f'{internal_ip} was not found in {full_address0}'
-        assert f'{external_ip}' not in full_address0, f'{external_ip} was found in {full_address0}'
+        assert (
+            f"{internal_ip}" in full_address0
+        ), f"{internal_ip} was not found in {full_address0}"
+        assert (
+            f"{external_ip}" not in full_address0
+        ), f"{external_ip} was found in {full_address0}"
 
     def test_external_ip_port_set_full_address_internal(self):
-        internal_ip = 'fake_ip_internal'
-        external_ip = 'fake_ip_external'
+        internal_ip = "fake_ip_internal"
+        external_ip = "fake_ip_external"
         internal_port = 1234
         external_port = 5678
 
         mock_wallet = mock.MagicMock(
-            hotkey = mock.MagicMock(
-                ss58_address = 'fake_hotkey_address',
-                spec = bittensor.Keypair
+            hotkey=mock.MagicMock(
+                ss58_address="fake_hotkey_address", spec=bittensor.Keypair
             ),
-            spec = bittensor.Wallet
+            spec=bittensor.Wallet,
         )
 
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_config = bittensor.axon.config()
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, ip=internal_ip, external_ip=external_ip, port=internal_port, external_port=external_port, server=mock_server, config=mock_config )
+        _ = bittensor.axon(
+            wallet=mock_wallet,
+            metagraph=None,
+            ip=internal_ip,
+            external_ip=external_ip,
+            port=internal_port,
+            external_port=external_port,
+            server=mock_server,
+            config=mock_config,
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address0 = args[0]
 
-        assert f'{internal_ip}:{internal_port}' == full_address0 and f'{external_ip}:{external_port}' != full_address0
+        assert (
+            f"{internal_ip}:{internal_port}" == full_address0
+            and f"{external_ip}:{external_port}" != full_address0
+        )
 
         mock_add_insecure_port.reset_mock()
 
         # Test using config
         mock_config = bittensor.axon.config()
 
         mock_config.axon.ip = internal_ip
         mock_config.axon.external_ip = external_ip
         mock_config.axon.port = internal_port
         mock_config.axon.external_port = external_port
 
-        _ = bittensor.axon( wallet = mock_wallet, metagraph = None, config=mock_config, server=mock_server )
+        _ = bittensor.axon(
+            wallet=mock_wallet, metagraph=None, config=mock_config, server=mock_server
+        )
 
         mock_add_insecure_port.assert_called_once()
         args, _ = mock_add_insecure_port.call_args
         full_address1 = args[0]
 
-        assert f'{internal_ip}:{internal_port}' == full_address1, f'{internal_ip}:{internal_port} is not eq to {full_address1}'
-        assert f'{external_ip}:{external_port}' != full_address1, f'{external_ip}:{external_port} is eq to {full_address1}'
+        assert (
+            f"{internal_ip}:{internal_port}" == full_address1
+        ), f"{internal_ip}:{internal_port} is not eq to {full_address1}"
+        assert (
+            f"{external_ip}:{external_port}" != full_address1
+        ), f"{external_ip}:{external_port} is eq to {full_address1}"
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_balance.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_balance.py`

 * *Files 18% similar despite different names*

```diff
@@ -24,20 +24,31 @@
 from hypothesis import strategies as st
 
 from tests.helpers import CLOSE_IN_VALUE
 
 """
 Test the Balance class
 """
-valid_tao_numbers_strategy = st.one_of(st.integers(max_value=21_000_000, min_value=-21_000_000), st.floats(allow_infinity=False, allow_nan=False, allow_subnormal=False, max_value=21_000_000.00, min_value=-21_000_000.00))
+valid_tao_numbers_strategy = st.one_of(
+    st.integers(max_value=21_000_000, min_value=-21_000_000),
+    st.floats(
+        allow_infinity=False,
+        allow_nan=False,
+        allow_subnormal=False,
+        max_value=21_000_000.00,
+        min_value=-21_000_000.00,
+    ),
+)
+
 
 def remove_zero_filter(x):
     """Remove zero and rounded to zero from the list of valid numbers"""
     return int(x * pow(10, 9)) != 0
 
+
 class TestBalance(unittest.TestCase):
     @given(balance=valid_tao_numbers_strategy)
     def test_balance_init(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         if isinstance(balance, int):
             assert balance_.rao == balance
         elif isinstance(balance, float):
@@ -59,15 +70,17 @@
             rao2_ = int(balance2 * pow(10, 9))
 
         sum_ = balance_ + balance2_
         assert isinstance(sum_, Balance)
         assert CLOSE_IN_VALUE(sum_.rao, 5) == rao_ + rao2_
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_add_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_add_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
@@ -82,30 +95,36 @@
     @given(balance=valid_tao_numbers_strategy)
     def test_balance_eq_other_not_balance(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         rao2_: int
         # convert balance2 to rao. This assumes balance2 is a rao value
         rao2_ = int(balance_.rao)
 
-        self.assertEqual(CLOSE_IN_VALUE(rao2_, 5), balance_, msg=f"Balance {balance_} is not equal to {rao2_}")
+        self.assertEqual(
+            CLOSE_IN_VALUE(rao2_, 5),
+            balance_,
+            msg=f"Balance {balance_} is not equal to {rao2_}",
+        )
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_radd_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_radd_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = int(balance2)
 
-        sum_ =  balance2_ + balance_ # This is an radd
+        sum_ = balance2_ + balance_  # This is an radd
         assert isinstance(sum_, Balance)
         assert CLOSE_IN_VALUE(sum_.rao, 5) == rao2_ + rao_
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
     def test_balance_sub(self, balance: Union[int, float], balance2: Union[int, float]):
         balance_ = Balance(balance)
         balance2_ = Balance(balance2)
@@ -121,44 +140,48 @@
             rao2_ = int(balance2 * pow(10, 9))
 
         diff_ = balance_ - balance2_
         assert isinstance(diff_, Balance)
         assert CLOSE_IN_VALUE(diff_.rao, 5) == rao_ - rao2_
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_sub_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_sub_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = int(balance2)
 
-        diff_ =  balance_ - balance2_
+        diff_ = balance_ - balance2_
         assert isinstance(diff_, Balance)
         assert CLOSE_IN_VALUE(diff_.rao, 5) == rao_ - rao2_
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_rsub_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_rsub_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = int(balance2)
 
-        diff_ =  balance2_ - balance_ # This is an rsub
+        diff_ = balance2_ - balance_  # This is an rsub
         assert isinstance(diff_, Balance)
         assert CLOSE_IN_VALUE(diff_.rao, 5) == rao2_ - rao_
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
     def test_balance_mul(self, balance: Union[int, float], balance2: Union[int, float]):
         balance_ = Balance(balance)
         balance2_ = Balance(balance2)
@@ -170,46 +193,67 @@
         if isinstance(balance2, int):
             rao2_ = balance2
         elif isinstance(balance2, float):
             rao2_ = int(balance2 * pow(10, 9))
 
         prod_ = balance_ * balance2_
         assert isinstance(prod_, Balance)
-        self.assertAlmostEqual(prod_.rao, rao_ * rao2_, 9, msg="{} * {} == {} != {} * {} == {}".format(balance_, balance2_, prod_.rao, rao_, balance2, rao_ * balance2))
+        self.assertAlmostEqual(
+            prod_.rao,
+            rao_ * rao2_,
+            9,
+            msg="{} * {} == {} != {} * {} == {}".format(
+                balance_, balance2_, prod_.rao, rao_, balance2, rao_ * balance2
+            ),
+        )
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_mul_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_mul_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
 
         prod_ = balance_ * balance2_
         assert isinstance(prod_, Balance)
         self.assertAlmostEqual(prod_.rao, int(rao_ * balance2), delta=20)
 
     @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy)
-    def test_balance_rmul_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    def test_balance_rmul_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
 
-        prod_ =  balance2_ * balance_ # This is an rmul
+        prod_ = balance2_ * balance_  # This is an rmul
         assert isinstance(prod_, Balance)
-        self.assertAlmostEqual(prod_.rao, int(balance2 * rao_), delta=20, msg=f"{balance2_} * {balance_} = {prod_} != {balance2} * {rao_} == {balance2 * rao_}")
-
-    @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy.filter(remove_zero_filter)) # Avoid zero division
-    def test_balance_truediv(self, balance: Union[int, float], balance2: Union[int, float]):
+        self.assertAlmostEqual(
+            prod_.rao,
+            int(balance2 * rao_),
+            delta=20,
+            msg=f"{balance2_} * {balance_} = {prod_} != {balance2} * {rao_} == {balance2 * rao_}",
+        )
+
+    @given(
+        balance=valid_tao_numbers_strategy,
+        balance2=valid_tao_numbers_strategy.filter(remove_zero_filter),
+    )  # Avoid zero division
+    def test_balance_truediv(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = Balance(balance2)
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
@@ -217,51 +261,83 @@
         if isinstance(balance2, int):
             rao2_ = balance2
         elif isinstance(balance2, float):
             rao2_ = int(balance2 * pow(10, 9))
 
         quot_ = balance_ / balance2_
         assert isinstance(quot_, Balance)
-        self.assertAlmostEqual(quot_.rao, int(rao_ / rao2_), delta=2, msg=f"{balance_} / {balance2_} = {quot_} != {rao_} / {rao2_} == {int(rao_ / rao2_)}")
-
-    @given(balance=valid_tao_numbers_strategy,  balance2=valid_tao_numbers_strategy.filter(remove_zero_filter))
-    def test_balance_truediv_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+        self.assertAlmostEqual(
+            quot_.rao,
+            int(rao_ / rao2_),
+            delta=2,
+            msg=f"{balance_} / {balance2_} = {quot_} != {rao_} / {rao2_} == {int(rao_ / rao2_)}",
+        )
+
+    @given(
+        balance=valid_tao_numbers_strategy,
+        balance2=valid_tao_numbers_strategy.filter(remove_zero_filter),
+    )
+    def test_balance_truediv_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = balance2
 
         quot_ = balance_ / balance2_
-        self.assertAlmostEqual(quot_.rao, int(rao_ / rao2_), delta=10, msg="{} / {} = {} != {}".format(balance_, balance2_, quot_.rao, int(rao_ / rao2_)))
-
-    @given(balance=valid_tao_numbers_strategy.filter(remove_zero_filter), balance2=valid_tao_numbers_strategy) # This is a filter to avoid division by zero
-    def test_balance_rtruediv_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+        self.assertAlmostEqual(
+            quot_.rao,
+            int(rao_ / rao2_),
+            delta=10,
+            msg="{} / {} = {} != {}".format(
+                balance_, balance2_, quot_.rao, int(rao_ / rao2_)
+            ),
+        )
+
+    @given(
+        balance=valid_tao_numbers_strategy.filter(remove_zero_filter),
+        balance2=valid_tao_numbers_strategy,
+    )  # This is a filter to avoid division by zero
+    def test_balance_rtruediv_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = balance2
 
-        quot_ =  balance2_ / balance_ # This is an rtruediv
+        quot_ = balance2_ / balance_  # This is an rtruediv
         assert isinstance(quot_, Balance)
-        self.assertAlmostEqual(quot_.rao, int(rao2_ / rao_), delta=5, msg="{} / {} = {}".format(balance2_, balance_, quot_))
-
-    @given(balance=valid_tao_numbers_strategy, balance2=valid_tao_numbers_strategy.filter(remove_zero_filter)) # Avoid zero division
-    def test_balance_floordiv(self, balance: Union[int, float], balance2: Union[int, float]):
+        self.assertAlmostEqual(
+            quot_.rao,
+            int(rao2_ / rao_),
+            delta=5,
+            msg="{} / {} = {}".format(balance2_, balance_, quot_),
+        )
+
+    @given(
+        balance=valid_tao_numbers_strategy,
+        balance2=valid_tao_numbers_strategy.filter(remove_zero_filter),
+    )  # Avoid zero division
+    def test_balance_floordiv(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = Balance(balance2)
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
@@ -271,45 +347,62 @@
         elif isinstance(balance2, float):
             rao2_ = int(balance2 * pow(10, 9))
 
         quot_ = balance_ // balance2_
         assert isinstance(quot_, Balance)
         assert CLOSE_IN_VALUE(quot_.rao, 5) == rao_ // rao2_
 
-    @given(balance=valid_tao_numbers_strategy,  balance2=valid_tao_numbers_strategy.filter(remove_zero_filter))
-    def test_balance_floordiv_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+    @given(
+        balance=valid_tao_numbers_strategy,
+        balance2=valid_tao_numbers_strategy.filter(remove_zero_filter),
+    )
+    def test_balance_floordiv_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = balance2
 
         quot_ = balance_ // balance2_
         assert isinstance(quot_, Balance)
-        self.assertAlmostEqual(quot_.rao, rao_ // rao2_, delta=5, msg="{} // {} = {} != {}".format(balance_, balance2_, quot_.rao, rao_ // rao2_))
-
-    @given(balance=valid_tao_numbers_strategy.filter(remove_zero_filter), balance2=valid_tao_numbers_strategy) # This is a filter to avoid division by zero
-    def test_balance_rfloordiv_other_not_balance(self, balance: Union[int, float], balance2: Union[int, float]):
+        self.assertAlmostEqual(
+            quot_.rao,
+            rao_ // rao2_,
+            delta=5,
+            msg="{} // {} = {} != {}".format(
+                balance_, balance2_, quot_.rao, rao_ // rao2_
+            ),
+        )
+
+    @given(
+        balance=valid_tao_numbers_strategy.filter(remove_zero_filter),
+        balance2=valid_tao_numbers_strategy,
+    )  # This is a filter to avoid division by zero
+    def test_balance_rfloordiv_other_not_balance(
+        self, balance: Union[int, float], balance2: Union[int, float]
+    ):
         balance_ = Balance(balance)
         balance2_ = balance2
         rao_: int
         rao2_: int
         if isinstance(balance, int):
             rao_ = balance
         elif isinstance(balance, float):
             rao_ = int(balance * pow(10, 9))
         # assume balance2 is a rao value
         rao2_ = balance2
 
-        quot_ =  balance2_ // balance_ # This is an rfloordiv
+        quot_ = balance2_ // balance_  # This is an rfloordiv
         assert isinstance(quot_, Balance)
         self.assertAlmostEqual(quot_.rao, rao2_ // rao_, delta=5)
 
     @given(balance=valid_tao_numbers_strategy)
     def test_balance_not_eq_none(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         assert not balance_ == None
@@ -317,15 +410,15 @@
     @given(balance=valid_tao_numbers_strategy)
     def test_balance_neq_none(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         assert balance_ != None
 
     def test_balance_init_from_invalid_value(self):
         with pytest.raises(TypeError):
-            Balance('invalid not a number')
+            Balance("invalid not a number")
 
     @given(balance=valid_tao_numbers_strategy)
     def test_balance_add_invalid_type(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         with pytest.raises(NotImplementedError):
             _ = balance_ + ""
 
@@ -351,8 +444,8 @@
     def test_balance_eq_invalid_type(self, balance: Union[int, float]):
         balance_ = Balance(balance)
         with pytest.raises(NotImplementedError):
             balance_ == ""
 
 
 if __name__ == "__main__":
-    unittest.main()
+    unittest.main()
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_config.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_config.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,14 +19,15 @@
 from sys import prefix
 import argparse
 import pytest
 from unittest.mock import MagicMock
 
 import bittensor
 
+
 def test_prefix():
     # Test the use of prefixes to instantiate all of the bittensor objects.
     parser = argparse.ArgumentParser()
 
     mock_wallet = MagicMock(
         spec=bittensor.Wallet,
         coldkey=MagicMock(),
@@ -35,72 +36,77 @@
             ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
         ),
         hotkey=MagicMock(
             ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
         ),
     )
 
-    #bittensor.dendrite.add_args( parser)
-    #bittensor.dendrite.add_args( parser, prefix = 'second' )
+    # bittensor.dendrite.add_args( parser)
+    # bittensor.dendrite.add_args( parser, prefix = 'second' )
 
-    bittensor.logging.add_args( parser )
-    bittensor.logging.add_args( parser, prefix = 'second' )
+    bittensor.logging.add_args(parser)
+    bittensor.logging.add_args(parser, prefix="second")
 
-    bittensor.wallet.add_args( parser )
-    bittensor.wallet.add_args( parser, prefix = 'second' )
+    bittensor.wallet.add_args(parser)
+    bittensor.wallet.add_args(parser, prefix="second")
 
-    bittensor.subtensor.add_args( parser )
-    bittensor.subtensor.add_args( parser, prefix = 'second'  )
+    bittensor.subtensor.add_args(parser)
+    bittensor.subtensor.add_args(parser, prefix="second")
 
-    #bittensor.metagraph.add_args( parser )
-    #bittensor.metagraph.add_args( parser, prefix = 'second' )
+    # bittensor.metagraph.add_args( parser )
+    # bittensor.metagraph.add_args( parser, prefix = 'second' )
 
-    bittensor.dataset.add_args( parser )
-    bittensor.dataset.add_args( parser, prefix = 'second' )
+    bittensor.dataset.add_args(parser)
+    bittensor.dataset.add_args(parser, prefix="second")
 
-    bittensor.axon.add_args( parser )
-    bittensor.axon.add_args( parser, prefix = 'second' )
+    bittensor.axon.add_args(parser)
+    bittensor.axon.add_args(parser, prefix="second")
 
-    #bittensor.wandb.add_args( parser )
-    #bittensor.wandb.add_args( parser, prefix = 'second' )
+    # bittensor.wandb.add_args( parser )
+    # bittensor.wandb.add_args( parser, prefix = 'second' )
 
     # Test with argv=[]
-    config_non_strict = bittensor.config( parser, strict=False, args=[] )
-    config_strict = bittensor.config( parser, strict=True, args=[] )
+    config_non_strict = bittensor.config(parser, strict=False, args=[])
+    config_strict = bittensor.config(parser, strict=True, args=[])
 
-    #bittensor.dendrite( config_strict ).__del__()
-    #bittensor.dendrite( config_non_strict ).__del__()
-    #bittensor.dendrite( config_strict.second ).__del__()
-    #bittensor.dendrite( config_non_strict.second ).__del__()
-
-    bittensor.axon( metagraph=None, wallet=mock_wallet, config=config_strict ).stop()
-    bittensor.axon( metagraph=None, wallet=mock_wallet, config=config_non_strict ).stop()
-    bittensor.axon( metagraph=None, wallet=mock_wallet, config=config_strict.second ).stop()
-    bittensor.axon( metagraph=None, wallet=mock_wallet, config=config_non_strict.second ).stop()
-
-    #bittensor.metagraph( config_strict )
-    #bittensor.metagraph( config_non_strict )
-    #bittensor.metagraph( config_strict.second )
-    #bittensor.metagraph( config_non_strict.second )
-
-    bittensor.wallet( config_strict )
-    bittensor.wallet( config_non_strict )
-    bittensor.wallet( config_strict.second )
-    bittensor.wallet( config_non_strict.second )
-
-    bittensor.logging( config_strict )
-    bittensor.logging( config_non_strict )
-    bittensor.logging( config_strict.second )
-    bittensor.logging( config_non_strict.second )
+    # bittensor.dendrite( config_strict ).__del__()
+    # bittensor.dendrite( config_non_strict ).__del__()
+    # bittensor.dendrite( config_strict.second ).__del__()
+    # bittensor.dendrite( config_non_strict.second ).__del__()
+
+    bittensor.axon(metagraph=None, wallet=mock_wallet, config=config_strict).stop()
+    bittensor.axon(metagraph=None, wallet=mock_wallet, config=config_non_strict).stop()
+    bittensor.axon(
+        metagraph=None, wallet=mock_wallet, config=config_strict.second
+    ).stop()
+    bittensor.axon(
+        metagraph=None, wallet=mock_wallet, config=config_non_strict.second
+    ).stop()
+
+    # bittensor.metagraph( config_strict )
+    # bittensor.metagraph( config_non_strict )
+    # bittensor.metagraph( config_strict.second )
+    # bittensor.metagraph( config_non_strict.second )
+
+    bittensor.wallet(config_strict)
+    bittensor.wallet(config_non_strict)
+    bittensor.wallet(config_strict.second)
+    bittensor.wallet(config_non_strict.second)
+
+    bittensor.logging(config_strict)
+    bittensor.logging(config_non_strict)
+    bittensor.logging(config_strict.second)
+    bittensor.logging(config_non_strict.second)
 
     # This is the only place we call bittensor.wandb() outside of neuron code.
     # It fails because we don't have a key set up for this.
     # TODO: Actually test bittensor.wandb
-    #bittensor.wandb( config_strict )
-    #bittensor.wandb( config_non_strict )
-    #bittensor.wandb( config_strict.second )
-    #bittensor.wandb( config_non_strict.second )
+    # bittensor.wandb( config_strict )
+    # bittensor.wandb( config_non_strict )
+    # bittensor.wandb( config_strict.second )
+    # bittensor.wandb( config_non_strict.second )
+
 
-if __name__  == "__main__":
+if __name__ == "__main__":
     # test_loaded_config()
     # test_strict()
-    test_prefix()
+    test_prefix()
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_metagraph.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_metagraph.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,27 +14,26 @@
 # THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 # OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 # DEALINGS IN THE SOFTWARE.
 
 import bittensor
 import unittest
 
-_subtensor_mock = bittensor.subtensor( network = 'mock', _mock = True )
-    
+_subtensor_mock = bittensor.subtensor(network="mock", _mock=True)
+
+
 class TestMetagraph(unittest.TestCase):
     def setUp(self) -> None:
         global _subtensor_mock
         _subtensor_mock.reset()
 
-        _subtensor_mock.create_subnet(
-            netuid = 999
-        )
+        _subtensor_mock.create_subnet(netuid=999)
 
     def test_metagraph(self):
         global _subtensor_mock
-        metagraph = _subtensor_mock.metagraph( netuid = 999 )
+        metagraph = _subtensor_mock.metagraph(netuid=999)
 
         assert metagraph.netuid == 999
         assert metagraph.n == 0
         assert len(metagraph.hotkeys) == 0
         assert len(metagraph.coldkeys) == 0
-        assert len(metagraph.uids) == 0
+        assert len(metagraph.uids) == 0
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_subtensor.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_subtensor.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 # The MIT License (MIT)
 # Copyright © 2022 Opentensor Foundation
 
 # Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
 # documentation files (the “Software”), to deal in the Software without restriction, including without limitation
 # the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
 # and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
@@ -19,37 +18,34 @@
 import unittest.mock as mock
 from unittest.mock import MagicMock
 import pytest
 
 import bittensor
 import unittest
 
+
 class TestSubtensorWithExternalAxon(unittest.TestCase):
     """
     Test the subtensor with external axon in the config
     """
 
     def test_serve_axon_with_external_ip_set(self):
-        internal_ip: str = 'this is an internal ip'
-        external_ip: str = 'this is an external ip'
+        internal_ip: str = "this is an internal ip"
+        external_ip: str = "this is an external ip"
 
-        mock_serve_axon = MagicMock(
-            return_value=True
-        )
+        mock_serve_axon = MagicMock(return_value=True)
 
         mock_subtensor = MagicMock(
             spec=bittensor.Subtensor,
             # serve=mock_serve,
-            serve_axon=mock_serve_axon
+            serve_axon=mock_serve_axon,
         )
 
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_grpc_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_grpc_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_wallet = MagicMock(
             spec=bittensor.Wallet,
             coldkey=MagicMock(),
             coldkeypub=MagicMock(
                 # mock ss58 address
                 ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
@@ -62,48 +58,40 @@
         mock_config = bittensor.axon.config()
         mock_axon_with_external_ip_set = bittensor.axon(
             wallet=mock_wallet,
             metagraph=None,
             ip=internal_ip,
             external_ip=external_ip,
             server=mock_grpc_server,
-            config=mock_config
+            config=mock_config,
         )
 
         mock_subtensor.serve_axon(
-            netuid=-1,
-            axon=mock_axon_with_external_ip_set,
-            use_upnpc=False,
+            netuid=-1, axon=mock_axon_with_external_ip_set, use_upnpc=False
         )
 
         mock_serve_axon.assert_called_once()
 
         # verify that the axon is served to the network with the external ip
         _, kwargs = mock_serve_axon.call_args
-        axon_info = kwargs['axon'].info()
+        axon_info = kwargs["axon"].info()
         self.assertEqual(axon_info.ip, external_ip)
 
     def test_serve_axon_with_external_port_set(self):
-        external_ip: str = 'this is an external ip'
+        external_ip: str = "this is an external ip"
 
         internal_port: int = 1234
         external_port: int = 5678
 
-        mock_serve = MagicMock(
-            return_value=True
-        )
+        mock_serve = MagicMock(return_value=True)
 
-        mock_serve_axon = MagicMock(
-            return_value=True
-        )
+        mock_serve_axon = MagicMock(return_value=True)
 
         mock_subtensor = MagicMock(
-            spec=bittensor.Subtensor,
-            serve=mock_serve,
-            serve_axon=mock_serve_axon,
+            spec=bittensor.Subtensor, serve=mock_serve, serve_axon=mock_serve_axon
         )
 
         mock_wallet = MagicMock(
             spec=bittensor.Wallet,
             coldkey=MagicMock(),
             coldkeypub=MagicMock(
                 # mock ss58 address
@@ -111,100 +99,99 @@
             ),
             hotkey=MagicMock(
                 ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
             ),
         )
 
         mock_add_insecure_port = mock.MagicMock(return_value=None)
-        mock_grpc_server = mock.MagicMock(
-            add_insecure_port=mock_add_insecure_port
-        )
+        mock_grpc_server = mock.MagicMock(add_insecure_port=mock_add_insecure_port)
 
         mock_config = bittensor.axon.config()
 
         mock_axon_with_external_port_set = bittensor.axon(
             wallet=mock_wallet,
             metagraph=None,
             port=internal_port,
             external_port=external_port,
             server=mock_grpc_server,
-            config=mock_config
+            config=mock_config,
         )
 
-        with mock.patch('bittensor.utils.networking.get_external_ip', return_value=external_ip):
+        with mock.patch(
+            "bittensor.utils.networking.get_external_ip", return_value=external_ip
+        ):
             # mock the get_external_ip function to return the external ip
             mock_subtensor.serve_axon(
-                netuid=-1,
-                axon=mock_axon_with_external_port_set,
-                use_upnpc=False,
+                netuid=-1, axon=mock_axon_with_external_port_set, use_upnpc=False
             )
 
         mock_serve_axon.assert_called_once()
         # verify that the axon is served to the network with the external port
         _, kwargs = mock_serve_axon.call_args
-        axon_info = kwargs['axon'].info()
+        axon_info = kwargs["axon"].info()
         self.assertEqual(axon_info.port, external_port)
 
+
 class ExitEarly(Exception):
     """Mock exception to exit early from the called code"""
+
     pass
 
 
 class TestStakeMultiple(unittest.TestCase):
     """
     Test the stake_multiple function
     """
 
     def test_stake_multiple(self):
         mock_amount: bittensor.Balance = bittensor.Balance.from_tao(1.0)
 
         mock_wallet = MagicMock(
-                        spec=bittensor.Wallet,
-                        coldkey=MagicMock(),
-                        coldkeypub=MagicMock(
-                            # mock ss58 address
-                            ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
-                        ),
-                        hotkey=MagicMock(
-                            ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
-                        ),
-                    )
-
-        mock_hotkey_ss58s = [
-            "5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
-        ]
-
-        mock_amounts = [
-            mock_amount # more than 1000 RAO
-        ]
+            spec=bittensor.Wallet,
+            coldkey=MagicMock(),
+            coldkeypub=MagicMock(
+                # mock ss58 address
+                ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
+            ),
+            hotkey=MagicMock(
+                ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
+            ),
+        )
+
+        mock_hotkey_ss58s = ["5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"]
+
+        mock_amounts = [mock_amount]  # more than 1000 RAO
 
         mock_neuron = MagicMock(
-            is_null = False,
+            is_null=False,
         )
 
-        mock_do_stake = MagicMock(
-            side_effect=ExitEarly
-        )
+        mock_do_stake = MagicMock(side_effect=ExitEarly)
 
         mock_subtensor = MagicMock(
             spec=bittensor.Subtensor,
             network="mock_net",
-            get_balance=MagicMock(return_value=bittensor.Balance.from_tao(mock_amount.tao + 20.0)), # enough balance to stake
+            get_balance=MagicMock(
+                return_value=bittensor.Balance.from_tao(mock_amount.tao + 20.0)
+            ),  # enough balance to stake
             get_neuron_for_pubkey_and_subnet=MagicMock(return_value=mock_neuron),
-            _do_stake=mock_do_stake
+            _do_stake=mock_do_stake,
         )
 
         with pytest.raises(ExitEarly):
             bittensor.Subtensor.add_stake_multiple(
                 mock_subtensor,
                 wallet=mock_wallet,
                 hotkey_ss58s=mock_hotkey_ss58s,
                 amounts=mock_amounts,
             )
 
             mock_do_stake.assert_called_once()
             # args, kwargs
             _, kwargs = mock_do_stake.call_args
-            self.assertAlmostEqual(kwargs['ammount'], mock_amount.rao, delta=1.0 * 1e9) # delta of 1.0 TAO
+            self.assertAlmostEqual(
+                kwargs["ammount"], mock_amount.rao, delta=1.0 * 1e9
+            )  # delta of 1.0 TAO
+
 
-if __name__ == '__main__':
-    unittest.main()
+if __name__ == "__main__":
+    unittest.main()
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/test_synapse.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/test_synapse.py`

 * *Files 12% similar despite different names*

```diff
@@ -17,108 +17,127 @@
 # DEALINGS IN THE SOFTWARE.
 import bittensor
 import torch
 import unittest
 from unittest.mock import MagicMock
 
 
-class MockTextPromptingSynapse( bittensor.TextPromptingSynapse ):
-    def forward( self, messages ):
+class MockTextPromptingSynapse(bittensor.TextPromptingSynapse):
+    def forward(self, messages):
         return messages
 
-    def multi_forward( self, messages ):
+    def multi_forward(self, messages):
         return messages
 
-    def backward( self, messages, response, rewards ):
+    def backward(self, messages, response, rewards):
         return messages, response, rewards
 
-    def priority( self, call: bittensor.SynapseCall ) -> float:
+    def priority(self, call: bittensor.SynapseCall) -> float:
         return 0.0
 
-    def blacklist( self, call: bittensor.SynapseCall ) -> bool:
+    def blacklist(self, call: bittensor.SynapseCall) -> bool:
         return False
 
+
 def test_create_text_prompting():
     mock_wallet = MagicMock(
         spec=bittensor.Wallet,
         coldkey=MagicMock(),
         coldkeypub=MagicMock(
             # mock ss58 address
             ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
         ),
         hotkey=MagicMock(
             ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
         ),
     )
-    axon = bittensor.axon( wallet = mock_wallet, metagraph = None )
-    synapse = MockTextPromptingSynapse( axon = axon )
+    axon = bittensor.axon(wallet=mock_wallet, metagraph=None)
+    synapse = MockTextPromptingSynapse(axon=axon)
+
 
 # @unittest.skip("This is for convenience of testing without violating DRY too much")
 def get_synapse():
     mock_wallet = MagicMock(
         spec=bittensor.Wallet,
         coldkey=MagicMock(),
         coldkeypub=MagicMock(
             # mock ss58 address
             ss58_address="5DD26kC2kxajmwfbbZmVmxhrY9VeeyR1Gpzy9i8wxLUg6zxm"
         ),
         hotkey=MagicMock(
             ss58_address="5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg"
         ),
     )
-    axon = bittensor.axon( wallet = mock_wallet, metagraph = None )
-    return MockTextPromptingSynapse( axon = axon )
+    axon = bittensor.axon(wallet=mock_wallet, metagraph=None)
+    return MockTextPromptingSynapse(axon=axon)
 
 
 def test_text_prompting_synapse_forward():
     synapse = get_synapse()
-    messages = ['test message']
-    response = synapse.forward( messages )
+    messages = ["test message"]
+    response = synapse.forward(messages)
     assert response == messages
 
+
 def test_text_prompting_synapse_multi_forward():
     synapse = get_synapse()
-    messages = ['test message'] * 10
-    responses = synapse.multi_forward( messages )
+    messages = ["test message"] * 10
+    responses = synapse.multi_forward(messages)
     assert responses == messages
 
+
 def test_text_prompting_synapse_backward():
     synapse = get_synapse()
-    messages = ['test message']
-    response = ['test response']
+    messages = ["test message"]
+    response = ["test response"]
     rewards = torch.tensor([1.0])
-    output = synapse.backward( messages, response, rewards )
+    output = synapse.backward(messages, response, rewards)
     assert len(output) == 3
     assert messages == output[0]
     assert response == output[1]
     assert torch.all(torch.eq(rewards, output[2]))
 
+
 def test_text_prompting_synapse_blacklist():
     synapse = get_synapse()
     request = bittensor.proto.ForwardTextPromptingRequest()
 
     # Mock the signature checking of the context.
     context = MagicMock()
     context.invocation_metadata.return_value = {}
     synapse.axon = MagicMock()
     synapse.axon.auth_interceptor = MagicMock()
-    synapse.axon.auth_interceptor.parse_signature.return_value = (None, None, "5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg", None)
+    synapse.axon.auth_interceptor.parse_signature.return_value = (
+        None,
+        None,
+        "5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg",
+        None,
+    )
 
-    call = bittensor._synapse.text_prompting.synapse.SynapseForward( synapse, request, synapse.forward, context = context )
-    blacklist = synapse.blacklist( call )
+    call = bittensor._synapse.text_prompting.synapse.SynapseForward(
+        synapse, request, synapse.forward, context=context
+    )
+    blacklist = synapse.blacklist(call)
     assert blacklist == False
 
+
 def test_text_prompting_synapse_priority():
     synapse = get_synapse()
     request = bittensor.proto.ForwardTextPromptingRequest()
 
     # Mock the signature checking of the context.
     context = MagicMock()
     context.invocation_metadata.return_value = {}
     synapse.axon = MagicMock()
     synapse.axon.auth_interceptor = MagicMock()
-    synapse.axon.auth_interceptor.parse_signature.return_value = (None, None, "5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg", None)
+    synapse.axon.auth_interceptor.parse_signature.return_value = (
+        None,
+        None,
+        "5CtstubuSoVLJGCXkiWRNKrrGg2DVBZ9qMs2qYTLsZR4q1Wg",
+        None,
+    )
 
-    call = bittensor._synapse.text_prompting.synapse.SynapseForward( synapse, request, synapse.forward, context = context )
-    priority = synapse.priority( call )
+    call = bittensor._synapse.text_prompting.synapse.SynapseForward(
+        synapse, request, synapse.forward, context=context
+    )
+    priority = synapse.priority(call)
     assert priority == 0.0
-
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_network_utils.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_network_utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -5,125 +5,178 @@
 import requests
 import urllib
 import pytest
 import miniupnpc
 
 from bittensor.utils.networking import UPNPCException, upnpc_create_port_map
 
+
 def test_int_to_ip_zero():
     assert utils.networking.int_to_ip(0) == "0.0.0.0"
     assert utils.networking.ip_to_int("0.0.0.0") == 0
     assert utils.networking.ip__str__(4, "0.0.0.0", 8888) == "/ipv4/0.0.0.0:8888"
 
+
 def test_int_to_ip_range():
     for i in range(10):
         assert utils.networking.int_to_ip(i) == "0.0.0." + str(i)
         assert utils.networking.ip_to_int("0.0.0." + str(i)) == i
-        assert utils.networking.ip__str__(4, "0.0.0."+ str(i), 8888) == "/ipv4/0.0.0." + str(i) + ":8888"
+        assert (
+            utils.networking.ip__str__(4, "0.0.0." + str(i), 8888)
+            == "/ipv4/0.0.0." + str(i) + ":8888"
+        )
+
 
 def test_int_to_ip4_max():
     assert utils.networking.int_to_ip(4294967295) == "255.255.255.255"
-    assert utils.networking.ip_to_int( "255.255.255.255") == 4294967295
-    assert utils.networking.ip__str__(4, "255.255.255.255", 8888) == "/ipv4/255.255.255.255:8888"
+    assert utils.networking.ip_to_int("255.255.255.255") == 4294967295
+    assert (
+        utils.networking.ip__str__(4, "255.255.255.255", 8888)
+        == "/ipv4/255.255.255.255:8888"
+    )
+
 
 def test_int_to_ip6_zero():
     assert utils.networking.int_to_ip(4294967296) == "::1:0:0"
     assert utils.networking.ip_to_int("::1:0:0") == 4294967296
     assert utils.networking.ip__str__(6, "::1:0:0", 8888) == "/ipv6/::1:0:0:8888"
 
+
 def test_int_to_ip6_range():
     for i in range(10):
         assert utils.networking.int_to_ip(4294967296 + i) == "::1:0:" + str(i)
         assert utils.networking.ip_to_int("::1:0:" + str(i)) == 4294967296 + i
-        assert utils.networking.ip__str__(6, "::1:0:" + str(i), 8888) == "/ipv6/::1:0:" + str(i) + ":8888"
+        assert (
+            utils.networking.ip__str__(6, "::1:0:" + str(i), 8888)
+            == "/ipv6/::1:0:" + str(i) + ":8888"
+        )
+
 
 def test_int_to_ip6_max():
     max_val = 340282366920938463463374607431768211455
-    assert utils.networking.int_to_ip(max_val) == 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
-    assert utils.networking.ip_to_int('ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff') == max_val
-    assert utils.networking.ip__str__(6, "ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff", 8888) == "/ipv6/ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff:8888"
+    assert (
+        utils.networking.int_to_ip(max_val) == "ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff"
+    )
+    assert (
+        utils.networking.ip_to_int("ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff") == max_val
+    )
+    assert (
+        utils.networking.ip__str__(6, "ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff", 8888)
+        == "/ipv6/ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff:8888"
+    )
+
 
 def test_int_to_ip6_overflow():
     overflow = 340282366920938463463374607431768211455 + 1
     try:
         utils.networking.int_to_ip(overflow)
     except:
         assert True
 
+
 def test_int_to_ip6_underflow():
     underflow = -1
     try:
         utils.networking.int_to_ip(underflow)
     except:
         assert True
 
+
 def test_get_external_ip():
     assert utils.networking.get_external_ip()
 
+
 def test_get_external_ip_os_broken():
-    class fake():
+    class fake:
         def readline(self):
             return 1
+
     def mock_call():
         return fake()
 
-    with mock.patch.object(os, 'popen', new=mock_call):
+    with mock.patch.object(os, "popen", new=mock_call):
         assert utils.networking.get_external_ip()
 
+
 def test_get_external_ip_os_request_urllib_broken():
-    class fake():
+    class fake:
         def readline(self):
             return 1
+
     def mock_call():
         return fake()
 
-    class fake_s():
+    class fake_s:
         def text(self):
             return 1
+
     def mock_call_two():
         return fake_s()
 
-    class fake_a():
+    class fake_a:
         def urlopen(self):
             return 1
 
-
-    with mock.patch.object(os, 'popen', new=mock_call):
-        with mock.patch.object(requests, 'get', new=mock_call_two):
-            urllib.request= MagicMock(return_value = fake_a())
+    with mock.patch.object(os, "popen", new=mock_call):
+        with mock.patch.object(requests, "get", new=mock_call_two):
+            urllib.request = MagicMock(return_value=fake_a())
             with pytest.raises(Exception):
                 assert utils.networking.get_external_ip()
 
+
 def returnNoPortMapping():
     return None
 
-@mock.patch('miniupnpc.UPnP')
+
+@mock.patch("miniupnpc.UPnP")
 def test_upnpc_create_port_map(mocked_upnp):
     port = 65535
-    mocked_upnp.discover = MagicMock(return_value = 1)
-    mocked_upnp.selectgid = MagicMock(return_value = 1)
-    mocked_upnp.lanaddr = MagicMock(return_value = '127.0.0.1')
-    mocked_upnp.selectigd = MagicMock(return_value = '127.0.0.1')
-    mocked_upnp.statusinfo = MagicMock(return_value = '200')
-    mocked_upnp.connectiontype = MagicMock(return_value = 'some_type')
+    mocked_upnp.discover = MagicMock(return_value=1)
+    mocked_upnp.selectgid = MagicMock(return_value=1)
+    mocked_upnp.lanaddr = MagicMock(return_value="127.0.0.1")
+    mocked_upnp.selectigd = MagicMock(return_value="127.0.0.1")
+    mocked_upnp.statusinfo = MagicMock(return_value="200")
+    mocked_upnp.connectiontype = MagicMock(return_value="some_type")
     mocked_upnp.getspecificportmapping = returnNoPortMapping
 
     with pytest.raises(UPNPCException):
         upnpc_create_port_map(port=port)
 
-@pytest.mark.parametrize("url, expected", [
-    ("wss://exampleendpoint:9944", "wss://exampleendpoint:9944"),
-    ("ws://exampleendpoint:9944", "ws://exampleendpoint:9944"),
-    ("exampleendpoint:9944", "ws://exampleendpoint:9944"), # should add ws:// not wss://
-    ("ws://exampleendpoint", "ws://exampleendpoint"), # should not add port if not specified
-    ("wss://exampleendpoint", "wss://exampleendpoint"), # should not add port if not specified
-    ("exampleendpoint", "ws://exampleendpoint"), # should not add port if not specified
-    ("exampleendpointwithws://:9944", "ws://exampleendpointwithws://:9944"), # should only care about the front
-    ("exampleendpointwithwss://:9944", "ws://exampleendpointwithwss://:9944"), # should only care about the front
-])
+
+@pytest.mark.parametrize(
+    "url, expected",
+    [
+        ("wss://exampleendpoint:9944", "wss://exampleendpoint:9944"),
+        ("ws://exampleendpoint:9944", "ws://exampleendpoint:9944"),
+        (
+            "exampleendpoint:9944",
+            "ws://exampleendpoint:9944",
+        ),  # should add ws:// not wss://
+        (
+            "ws://exampleendpoint",
+            "ws://exampleendpoint",
+        ),  # should not add port if not specified
+        (
+            "wss://exampleendpoint",
+            "wss://exampleendpoint",
+        ),  # should not add port if not specified
+        (
+            "exampleendpoint",
+            "ws://exampleendpoint",
+        ),  # should not add port if not specified
+        (
+            "exampleendpointwithws://:9944",
+            "ws://exampleendpointwithws://:9944",
+        ),  # should only care about the front
+        (
+            "exampleendpointwithwss://:9944",
+            "ws://exampleendpointwithwss://:9944",
+        ),  # should only care about the front
+    ],
+)
 def test_format(url: str, expected: str):
     assert utils.networking.get_formatted_ws_endpoint_url(url) == expected
 
 
 if __name__ == "__main__":
     test_get_external_ip()
-    test_upnpc_create_port_map()
+    test_upnpc_create_port_map()
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_utils.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -27,542 +27,659 @@
 from bittensor._subtensor.subtensor_mock import MockSubtensor
 
 from tests.helpers import _get_mock_wallet as _generate_wallet, _get_mock_keypair
 
 
 @fixture(scope="function")
 def setup_chain():
-
     operating_system = "OSX" if platform == "darwin" else "Linux"
     path = "./bin/chain/{}/node-subtensor".format(operating_system)
     logger.info(path)
     if not path:
-        logger.error("make sure the NODE_SUBTENSOR_BIN env var is set and points to the node-subtensor binary")
+        logger.error(
+            "make sure the NODE_SUBTENSOR_BIN env var is set and points to the node-subtensor binary"
+        )
         sys.exit()
 
     # Select a port
     port = select_port()
 
     # Delete existing wallets
-    #subprocess.Popen(["rm", '-r', '~/.bittensor/wallets/*testwallet'], close_fds=True, shell=False)
+    # subprocess.Popen(["rm", '-r', '~/.bittensor/wallets/*testwallet'], close_fds=True, shell=False)
 
     # Purge chain first
-    subprocess.Popen([path, 'purge-chain', '--dev', '-y'], close_fds=True, shell=False)
-    proc = subprocess.Popen([path, '--dev', '--port', str(port+1), '--ws-port', str(port), '--rpc-port', str(port + 2), '--tmp'], close_fds=True, shell=False)
+    subprocess.Popen([path, "purge-chain", "--dev", "-y"], close_fds=True, shell=False)
+    proc = subprocess.Popen(
+        [
+            path,
+            "--dev",
+            "--port",
+            str(port + 1),
+            "--ws-port",
+            str(port),
+            "--rpc-port",
+            str(port + 2),
+            "--tmp",
+        ],
+        close_fds=True,
+        shell=False,
+    )
 
     # Wait 4 seconds for the node to come up
     time.sleep(4)
 
     yield port
 
     # Wait 4 seconds for the node to come up
     time.sleep(4)
 
     # Kill process
     os.system("kill %i" % proc.pid)
 
+
 @pytest.fixture(scope="session", autouse=True)
 def initialize_tests():
     # Kill any running process before running tests
     os.system("pkill node-subtensor")
 
+
 def select_port():
     port = random.randrange(1000, 65536, 5)
     return port
 
-def setup_subtensor( port:int ):
+
+def setup_subtensor(port: int):
     chain_endpoint = "localhost:{}".format(port)
     subtensor = bittensor.subtensor(
-        chain_endpoint = chain_endpoint,
+        chain_endpoint=chain_endpoint,
     )
     return subtensor, port
 
+
 def construct_config():
     defaults = bittensor.Config()
-    bittensor.subtensor.add_defaults( defaults )
-    bittensor.dendrite.add_defaults( defaults )
-    bittensor.axon.add_defaults( defaults )
-    bittensor.wallet.add_defaults( defaults )
-    bittensor.dataset.add_defaults( defaults )
+    bittensor.subtensor.add_defaults(defaults)
+    bittensor.dendrite.add_defaults(defaults)
+    bittensor.axon.add_defaults(defaults)
+    bittensor.wallet.add_defaults(defaults)
+    bittensor.dataset.add_defaults(defaults)
 
     return defaults
 
+
 def test_unbiased_topk():
-    input_tensor = torch.FloatTensor([1., 2., 3., 4., 5., 6., 7., 8., 9., 10.])
+    input_tensor = torch.FloatTensor(
+        [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
+    )
     topk = bittensor.utils.unbiased_topk(input_tensor, 2)
-    assert torch.all(torch.eq(topk[0], torch.Tensor([10., 9.])))
+    assert torch.all(torch.eq(topk[0], torch.Tensor([10.0, 9.0])))
     assert torch.all(torch.eq(topk[1], torch.Tensor([9, 8])))
 
+
 class TestRegistrationHelpers(unittest.TestCase):
     def test_create_seal_hash(self):
-        block_and_hotkey_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
+        block_and_hotkey_hash = (
+            "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+        )
         block_and_hotkey_hash_bytes = bytes.fromhex(block_and_hotkey_hash[2:])
         nonce = 10
-        seal_hash = bittensor.utils.registration._create_seal_hash(block_and_hotkey_hash_bytes, nonce)
-        self.assertEqual(seal_hash, b'\xc5\x01B6"\xa8\xa5FDPK\xe49\xad\xdat\xbb:\x87d\x13/\x86\xc6:I8\x9b\x88\xf0\xc20')
+        seal_hash = bittensor.utils.registration._create_seal_hash(
+            block_and_hotkey_hash_bytes, nonce
+        )
+        self.assertEqual(
+            seal_hash,
+            b'\xc5\x01B6"\xa8\xa5FDPK\xe49\xad\xdat\xbb:\x87d\x13/\x86\xc6:I8\x9b\x88\xf0\xc20',
+        )
 
     def test_seal_meets_difficulty(self):
-        block_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
+        block_hash = (
+            "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+        )
         nonce = 10
-        limit = int(math.pow(2,256))- 1
-        nonce_bytes = nonce.to_bytes(8, 'little')
-        block_bytes = block_hash.encode('utf-8')[2:]
+        limit = int(math.pow(2, 256)) - 1
+        nonce_bytes = nonce.to_bytes(8, "little")
+        block_bytes = block_hash.encode("utf-8")[2:]
         pre_seal = nonce_bytes + block_bytes
-        seal = hashlib.sha256( bytearray(pre_seal) ).digest()
+        seal = hashlib.sha256(bytearray(pre_seal)).digest()
 
         difficulty = 1
-        meets = bittensor.utils.registration._seal_meets_difficulty( seal, difficulty, limit )
+        meets = bittensor.utils.registration._seal_meets_difficulty(
+            seal, difficulty, limit
+        )
         assert meets == True
 
         difficulty = 10
-        meets = bittensor.utils.registration._seal_meets_difficulty( seal, difficulty, limit )
+        meets = bittensor.utils.registration._seal_meets_difficulty(
+            seal, difficulty, limit
+        )
         assert meets == False
 
     def test_solve_for_difficulty_fast(self):
-        block_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
+        block_hash = (
+            "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+        )
         subtensor = MagicMock()
-        subtensor.get_current_block = MagicMock( return_value=1 )
-        subtensor.difficulty = MagicMock( return_value=1 )
+        subtensor.get_current_block = MagicMock(return_value=1)
+        subtensor.difficulty = MagicMock(return_value=1)
         subtensor.substrate = MagicMock()
-        subtensor.get_block_hash = MagicMock( return_value=block_hash )
-        subtensor.is_hotkey_registered = MagicMock( return_value=False )
+        subtensor.get_block_hash = MagicMock(return_value=block_hash)
+        subtensor.is_hotkey_registered = MagicMock(return_value=False)
         wallet = MagicMock(
-            hotkey = Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
+            hotkey=Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
         )
         num_proc: int = 1
-        limit = int(math.pow(2,256))- 1
+        limit = int(math.pow(2, 256)) - 1
 
-        solution = bittensor.utils.registration._solve_for_difficulty_fast( subtensor, wallet, netuid = -1, num_processes=num_proc )
+        solution = bittensor.utils.registration._solve_for_difficulty_fast(
+            subtensor, wallet, netuid=-1, num_processes=num_proc
+        )
         seal = solution.seal
 
         assert bittensor.utils.registration._seal_meets_difficulty(seal, 1, limit)
 
-        subtensor.difficulty = MagicMock( return_value=10 )
-        solution = bittensor.utils.registration._solve_for_difficulty_fast( subtensor, wallet, netuid = -1, num_processes=num_proc )
+        subtensor.difficulty = MagicMock(return_value=10)
+        solution = bittensor.utils.registration._solve_for_difficulty_fast(
+            subtensor, wallet, netuid=-1, num_processes=num_proc
+        )
         seal = solution.seal
         assert bittensor.utils.registration._seal_meets_difficulty(seal, 10, limit)
 
     def test_solve_for_difficulty_fast_registered_already(self):
         # tests if the registration stops after the first block of nonces
         for _ in range(10):
             workblocks_before_is_registered = random.randint(1, 4)
             # return False each work block but return True after a random number of blocks
-            is_registered_return_values = [False for _ in range(workblocks_before_is_registered)] + [True] + [False, False]
+            is_registered_return_values = (
+                [False for _ in range(workblocks_before_is_registered)]
+                + [True]
+                + [False, False]
+            )
 
-            block_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
+            block_hash = (
+                "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+            )
             subtensor = MagicMock()
-            subtensor.get_current_block = MagicMock( return_value=1 )
-            subtensor.difficulty = MagicMock( return_value=int(1e10)) # set high to make solving take a long time
+            subtensor.get_current_block = MagicMock(return_value=1)
+            subtensor.difficulty = MagicMock(
+                return_value=int(1e10)
+            )  # set high to make solving take a long time
             subtensor.substrate = MagicMock()
-            subtensor.get_block_hash = MagicMock( return_value=block_hash )
-            subtensor.is_hotkey_registered = MagicMock( side_effect=is_registered_return_values )
+            subtensor.get_block_hash = MagicMock(return_value=block_hash)
+            subtensor.is_hotkey_registered = MagicMock(
+                side_effect=is_registered_return_values
+            )
             wallet = MagicMock(
-                hotkey = Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
+                hotkey=Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
             )
 
             # all arugments should return None to indicate an early return
-            solution = bittensor.utils.registration._solve_for_difficulty_fast( subtensor, wallet, netuid = -1, num_processes = 1, update_interval = 1000)
+            solution = bittensor.utils.registration._solve_for_difficulty_fast(
+                subtensor, wallet, netuid=-1, num_processes=1, update_interval=1000
+            )
 
             assert solution is None
             # called every time until True
-            assert subtensor.is_hotkey_registered.call_count == workblocks_before_is_registered + 1
+            assert (
+                subtensor.is_hotkey_registered.call_count
+                == workblocks_before_is_registered + 1
+            )
 
     def test_solve_for_difficulty_fast_missing_hash(self):
-        block_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
+        block_hash = (
+            "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+        )
         subtensor = MagicMock()
-        subtensor.get_current_block = MagicMock( return_value=1 )
-        subtensor.difficulty = MagicMock( return_value=1 )
+        subtensor.get_current_block = MagicMock(return_value=1)
+        subtensor.difficulty = MagicMock(return_value=1)
         subtensor.substrate = MagicMock()
-        subtensor.get_block_hash = MagicMock( side_effect= [None, None] + [block_hash]*20)
-        subtensor.is_hotkey_registered = MagicMock( return_value=False )
+        subtensor.get_block_hash = MagicMock(
+            side_effect=[None, None] + [block_hash] * 20
+        )
+        subtensor.is_hotkey_registered = MagicMock(return_value=False)
         wallet = MagicMock(
-            hotkey = Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
+            hotkey=Keypair.create_from_mnemonic(Keypair.generate_mnemonic()),
         )
         num_proc: int = 1
-        limit = int(math.pow(2,256))- 1
+        limit = int(math.pow(2, 256)) - 1
 
-        solution = bittensor.utils.registration._solve_for_difficulty_fast( subtensor, wallet, netuid = -1, num_processes=num_proc )
+        solution = bittensor.utils.registration._solve_for_difficulty_fast(
+            subtensor, wallet, netuid=-1, num_processes=num_proc
+        )
         seal = solution.seal
         assert bittensor.utils.registration._seal_meets_difficulty(seal, 1, limit)
-        subtensor.difficulty = MagicMock( return_value=10 )
-        solution = bittensor.utils.registration._solve_for_difficulty_fast( subtensor, wallet, netuid = -1, num_processes=num_proc )
+        subtensor.difficulty = MagicMock(return_value=10)
+        solution = bittensor.utils.registration._solve_for_difficulty_fast(
+            subtensor, wallet, netuid=-1, num_processes=num_proc
+        )
         seal = solution.seal
         assert bittensor.utils.registration._seal_meets_difficulty(seal, 10, limit)
 
     def test_registration_diff_pack_unpack_under_32_bits(self):
-        fake_diff = pow(2, 31)# this is under 32 bits
+        fake_diff = pow(2, 31)  # this is under 32 bits
 
-        mock_diff = multiprocessing.Array('Q', [0, 0], lock=True) # [high, low]
+        mock_diff = multiprocessing.Array("Q", [0, 0], lock=True)  # [high, low]
         bittensor.utils.registration._registration_diff_pack(fake_diff, mock_diff)
-        assert bittensor.utils.registration._registration_diff_unpack(mock_diff) == fake_diff
+        assert (
+            bittensor.utils.registration._registration_diff_unpack(mock_diff)
+            == fake_diff
+        )
 
     def test_registration_diff_pack_unpack_over_32_bits(self):
-        mock_diff = multiprocessing.Array('Q', [0, 0], lock=True) # [high, low]
-        fake_diff = pow(2, 32) * pow(2, 4) # this should be too large if the bit shift is wrong (32 + 4 bits)
+        mock_diff = multiprocessing.Array("Q", [0, 0], lock=True)  # [high, low]
+        fake_diff = pow(2, 32) * pow(
+            2, 4
+        )  # this should be too large if the bit shift is wrong (32 + 4 bits)
         bittensor.utils.registration._registration_diff_pack(fake_diff, mock_diff)
-        assert bittensor.utils.registration._registration_diff_unpack(mock_diff) == fake_diff
+        assert (
+            bittensor.utils.registration._registration_diff_unpack(mock_diff)
+            == fake_diff
+        )
 
     def test_hash_block_with_hotkey(self):
-        block_hash = "0xc444e4205857add79a0427401aa2518d11e85f32377eff9a946d180a54697459"
+        block_hash = (
+            "0xc444e4205857add79a0427401aa2518d11e85f32377eff9a946d180a54697459"
+        )
         block_hash_bytes = bytes.fromhex(block_hash[2:])
 
-        hotkey_pubkey_hex = "0xba3189e99e75b6097cd94a5ecc771016b83c8432d35d14a03ab731b07112f559"
+        hotkey_pubkey_hex = (
+            "0xba3189e99e75b6097cd94a5ecc771016b83c8432d35d14a03ab731b07112f559"
+        )
         hotkey_bytes = bytes.fromhex(hotkey_pubkey_hex[2:])
 
-        expected_hash_hex = '0x7869b61229641b33a355dc34d4ef48f8d82166635237f9f10bcb215b8cb48161'
+        expected_hash_hex = (
+            "0x7869b61229641b33a355dc34d4ef48f8d82166635237f9f10bcb215b8cb48161"
+        )
         expected_hash = bytes.fromhex(expected_hash_hex[2:])
 
-        result_hash = bittensor.utils.registration._hash_block_with_hotkey(block_hash_bytes, hotkey_bytes)
+        result_hash = bittensor.utils.registration._hash_block_with_hotkey(
+            block_hash_bytes, hotkey_bytes
+        )
         self.assertEqual(result_hash, expected_hash)
 
     def test_update_curr_block(self):
         curr_block, curr_block_num, curr_diff = _SolverBase.create_shared_memory()
 
         block_number: int = 1
-        block_bytes = bytes.fromhex('9dda24e4199df410e18a43044b3069078f796922b0247b8749aecb577b09bd59')
+        block_bytes = bytes.fromhex(
+            "9dda24e4199df410e18a43044b3069078f796922b0247b8749aecb577b09bd59"
+        )
         diff: int = 1
-        hotkey_bytes = bytes.fromhex('0'*64)
+        hotkey_bytes = bytes.fromhex("0" * 64)
         lock: Union[multiprocessing.Lock, MagicMock] = MagicMock()
 
-        bittensor.utils.registration._update_curr_block(curr_diff, curr_block, curr_block_num, block_number, block_bytes, diff, hotkey_bytes, lock)
+        bittensor.utils.registration._update_curr_block(
+            curr_diff,
+            curr_block,
+            curr_block_num,
+            block_number,
+            block_bytes,
+            diff,
+            hotkey_bytes,
+            lock,
+        )
 
         self.assertEqual(curr_block_num.value, block_number)
         self.assertEqual(curr_diff[0], diff >> 32)
         self.assertEqual(curr_diff[1], diff & 0xFFFFFFFF)
 
-        hash_of_block_and_hotkey = bittensor.utils.registration._hash_block_with_hotkey(block_bytes, hotkey_bytes)
-        self.assertEqual(curr_block[:], [int(byte_) for byte_ in hash_of_block_and_hotkey])
+        hash_of_block_and_hotkey = bittensor.utils.registration._hash_block_with_hotkey(
+            block_bytes, hotkey_bytes
+        )
+        self.assertEqual(
+            curr_block[:], [int(byte_) for byte_ in hash_of_block_and_hotkey]
+        )
 
     def test_solve_for_nonce_block(self):
         nonce_start = 0
         nonce_end = 10_000
-        block_and_hotkey_hash_bytes = bytes.fromhex('9dda24e4199df410e18a43044b3069078f796922b0247b8749aecb577b09bd59')
+        block_and_hotkey_hash_bytes = bytes.fromhex(
+            "9dda24e4199df410e18a43044b3069078f796922b0247b8749aecb577b09bd59"
+        )
 
-        limit = limit = int(math.pow(2,256)) - 1
+        limit = limit = int(math.pow(2, 256)) - 1
         block_number = 1
 
         difficulty = 1
-        result = bittensor.utils.registration._solve_for_nonce_block(nonce_start, nonce_end, block_and_hotkey_hash_bytes, difficulty, limit, block_number)
+        result = bittensor.utils.registration._solve_for_nonce_block(
+            nonce_start,
+            nonce_end,
+            block_and_hotkey_hash_bytes,
+            difficulty,
+            limit,
+            block_number,
+        )
 
         self.assertIsNotNone(result)
         self.assertEqual(result.block_number, block_number)
         self.assertEqual(result.difficulty, difficulty)
 
         # Make sure seal meets difficulty
-        self.assertTrue(bittensor.utils.registration._seal_meets_difficulty(result.seal, difficulty, limit))
+        self.assertTrue(
+            bittensor.utils.registration._seal_meets_difficulty(
+                result.seal, difficulty, limit
+            )
+        )
 
         # Test with a higher difficulty
         difficulty = 10
-        result = bittensor.utils.registration._solve_for_nonce_block(nonce_start, nonce_end, block_and_hotkey_hash_bytes, difficulty, limit, block_number)
+        result = bittensor.utils.registration._solve_for_nonce_block(
+            nonce_start,
+            nonce_end,
+            block_and_hotkey_hash_bytes,
+            difficulty,
+            limit,
+            block_number,
+        )
 
         self.assertIsNotNone(result)
         self.assertEqual(result.block_number, block_number)
         self.assertEqual(result.difficulty, difficulty)
 
         # Make sure seal meets difficulty
-        self.assertTrue(bittensor.utils.registration._seal_meets_difficulty(result.seal, difficulty, limit))
+        self.assertTrue(
+            bittensor.utils.registration._seal_meets_difficulty(
+                result.seal, difficulty, limit
+            )
+        )
+
 
 class TestSS58Utils(unittest.TestCase):
     def test_is_valid_ss58_address(self):
         keypair = bittensor.Keypair.create_from_mnemonic(
-            bittensor.Keypair.generate_mnemonic(
-                words=12
-            ), ss58_format=bittensor.__ss58_format__
+            bittensor.Keypair.generate_mnemonic(words=12),
+            ss58_format=bittensor.__ss58_format__,
         )
         good_address = keypair.ss58_address
-        bad_address = good_address[:-1] + 'a'
+        bad_address = good_address[:-1] + "a"
         assert bittensor.utils.is_valid_ss58_address(good_address)
         assert not bittensor.utils.is_valid_ss58_address(bad_address)
 
     def test_is_valid_ss58_address_legacy(self):
         keypair = bittensor.Keypair.create_from_mnemonic(
-            bittensor.Keypair.generate_mnemonic(
-                words=12
-            ), ss58_format=42 # should be fine for legacy ss58
+            bittensor.Keypair.generate_mnemonic(words=12),
+            ss58_format=42,  # should be fine for legacy ss58
         )
         good_address = keypair.ss58_address
-        bad_address = good_address[:-1] + 'a'
+        bad_address = good_address[:-1] + "a"
         assert bittensor.utils.is_valid_ss58_address(good_address)
         assert not bittensor.utils.is_valid_ss58_address(bad_address)
 
     def test_is_valid_ed25519_pubkey(self):
         keypair = bittensor.Keypair.create_from_mnemonic(
-            bittensor.Keypair.generate_mnemonic(
-                words=12
-            ), ss58_format=bittensor.__ss58_format__
+            bittensor.Keypair.generate_mnemonic(words=12),
+            ss58_format=bittensor.__ss58_format__,
         )
         good_pubkey = keypair.public_key.hex()
-        bad_pubkey = good_pubkey[:-1] # needs to be 64 chars
+        bad_pubkey = good_pubkey[:-1]  # needs to be 64 chars
         assert bittensor.utils.is_valid_ed25519_pubkey(good_pubkey)
         assert not bittensor.utils.is_valid_ed25519_pubkey(bad_pubkey)
 
         # Test with bytes
         good_pubkey = keypair.public_key
-        bad_pubkey = good_pubkey[:-1] # needs to be 32 bytes
+        bad_pubkey = good_pubkey[:-1]  # needs to be 32 bytes
         assert bittensor.utils.is_valid_ed25519_pubkey(good_pubkey)
         assert not bittensor.utils.is_valid_ed25519_pubkey(bad_pubkey)
 
 
 class TestUpdateCurrentBlockDuringRegistration(unittest.TestCase):
     def test_check_for_newest_block_and_update_same_block(self):
         # if the block is the same, the function should return the same block number
         subtensor = MagicMock()
         current_block_num: int = 1
-        subtensor.get_current_block = MagicMock( return_value=current_block_num )
-        mock_hotkey_bytes = bytes.fromhex('0'*63 + '1')
+        subtensor.get_current_block = MagicMock(return_value=current_block_num)
+        mock_hotkey_bytes = bytes.fromhex("0" * 63 + "1")
 
-        self.assertEqual(bittensor.utils.registration._check_for_newest_block_and_update(
-            subtensor,
-            -1, # netuid
-            current_block_num, # current block number is the same as the new block number
-            mock_hotkey_bytes, # mock hotkey bytes
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-        ), current_block_num)
+        self.assertEqual(
+            bittensor.utils.registration._check_for_newest_block_and_update(
+                subtensor,
+                -1,  # netuid
+                current_block_num,  # current block number is the same as the new block number
+                mock_hotkey_bytes,  # mock hotkey bytes
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+            ),
+            current_block_num,
+        )
 
     def test_check_for_newest_block_and_update_new_block(self):
         # if the block is new, the function should return the new block_number
-        mock_block_hash = '0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'
-        mock_hotkey_bytes = bytes.fromhex('0'*63 + '1')
+        mock_block_hash = (
+            "0xba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+        )
+        mock_hotkey_bytes = bytes.fromhex("0" * 63 + "1")
 
         current_block_num: int = 1
         current_diff: int = 0
 
-        mock_substrate = MagicMock(
-        )
+        mock_substrate = MagicMock()
         subtensor = MagicMock(
-            get_block_hash=MagicMock(
-                return_value=mock_block_hash
-            ),
+            get_block_hash=MagicMock(return_value=mock_block_hash),
             substrate=mock_substrate,
-            difficulty=MagicMock(return_value=current_diff + 1), # new diff
+            difficulty=MagicMock(return_value=current_diff + 1),  # new diff
         )
-        subtensor.get_current_block = MagicMock( return_value=current_block_num + 1 ) # new block
+        subtensor.get_current_block = MagicMock(
+            return_value=current_block_num + 1
+        )  # new block
 
         mock_update_curr_block = MagicMock()
 
         mock_solvers = [
-            MagicMock(
-                newBlockEvent=MagicMock(
-                    set=MagicMock()
-                )
-        ),
-        MagicMock(
-            newBlockEvent=MagicMock(
-                set=MagicMock()
-            )
-        )]
+            MagicMock(newBlockEvent=MagicMock(set=MagicMock())),
+            MagicMock(newBlockEvent=MagicMock(set=MagicMock())),
+        ]
 
         mock_curr_stats = MagicMock(
             block_number=current_block_num,
-            block_hash=b'',
+            block_hash=b"",
             difficulty=0,
         )
 
-        self.assertEqual(bittensor.utils.registration._check_for_newest_block_and_update(
-            subtensor,
-            -1, # netuid
-            MagicMock(),
-            mock_hotkey_bytes,
-            MagicMock(),
-            MagicMock(),
-            MagicMock(),
-            mock_update_curr_block,
-            MagicMock(),
-            mock_solvers,
-            mock_curr_stats,
-        ), current_block_num + 1)
+        self.assertEqual(
+            bittensor.utils.registration._check_for_newest_block_and_update(
+                subtensor,
+                -1,  # netuid
+                MagicMock(),
+                mock_hotkey_bytes,
+                MagicMock(),
+                MagicMock(),
+                MagicMock(),
+                mock_update_curr_block,
+                MagicMock(),
+                mock_solvers,
+                mock_curr_stats,
+            ),
+            current_block_num + 1,
+        )
 
         # check that the update_curr_block function was called
         mock_update_curr_block.assert_called_once()
 
         # check that the solvers got the event
         for solver in mock_solvers:
             solver.newBlockEvent.set.assert_called_once()
 
         # check the stats were updated
         self.assertEqual(mock_curr_stats.block_number, current_block_num + 1)
         self.assertEqual(mock_curr_stats.block_hash, mock_block_hash)
         self.assertEqual(mock_curr_stats.difficulty, current_diff + 1)
 
+
 class TestGetBlockWithRetry(unittest.TestCase):
     class MockException(Exception):
         pass
 
     def test_get_block_with_retry_network_error_exit(self):
         mock_subtensor = MagicMock(
             get_current_block=MagicMock(return_value=1),
             difficulty=MagicMock(return_value=1),
-            get_block_hash=MagicMock(side_effect=self.MockException('network error'))
+            get_block_hash=MagicMock(side_effect=self.MockException("network error")),
         )
         with pytest.raises(self.MockException):
             # this should raise an exception because the network error is retried only 3 times
             bittensor.utils.registration._get_block_with_retry(mock_subtensor, -1)
 
     def test_get_block_with_retry_network_error_no_error(self):
         mock_subtensor = MagicMock(
             get_current_block=MagicMock(return_value=1),
             difficulty=MagicMock(return_value=1),
             substrate=MagicMock(
-                get_block_hash=MagicMock(return_value=b'ba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279')
-            )
+                get_block_hash=MagicMock(
+                    return_value=b"ba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+                )
+            ),
         )
 
         # this should not raise an exception because there is no error
         bittensor.utils.registration._get_block_with_retry(mock_subtensor, -1)
 
     def test_get_block_with_retry_network_error_none_twice(self):
         # Should retry twice then succeed on the third try
         tries = 0
+
         def block_none_twice(block_hash: bytes):
             nonlocal tries
             if tries == 1:
                 return block_hash
             else:
                 tries += 1
                 return None
 
-
         mock_subtensor = MagicMock(
             get_current_block=MagicMock(return_value=1),
             difficulty=MagicMock(return_value=1),
             substrate=MagicMock(
-                get_block_hash=MagicMock(side_effect=block_none_twice(b'ba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279'))
-            )
+                get_block_hash=MagicMock(
+                    side_effect=block_none_twice(
+                        b"ba7ea4eb0b16dee271dbef5911838c3f359fcf598c74da65a54b919b68b67279"
+                    )
+                )
+            ),
         )
 
         # this should not raise an exception because there is no error on the third try
         bittensor.utils.registration._get_block_with_retry(mock_subtensor, -1)
+
+
 class TestPOWNotStale(unittest.TestCase):
     def test_pow_not_stale_same_block_number(self):
-        mock_subtensor = MagicMock(
-            get_current_block=MagicMock(return_value=1),
-        )
+        mock_subtensor = MagicMock(get_current_block=MagicMock(return_value=1))
         mock_solution = bittensor.utils.registration.POWSolution(
-            block_number= 1, # 3 less than current block number
-            nonce= 1,
-            difficulty= 1,
-            seal= b'',
+            block_number=1,  # 3 less than current block number
+            nonce=1,
+            difficulty=1,
+            seal=b"",
         )
 
         assert not mock_solution.is_stale(mock_subtensor)
 
     def test_pow_not_stale_diff_block_number(self):
-        mock_subtensor = MagicMock(
-            get_current_block=MagicMock(return_value=2),
-        )
+        mock_subtensor = MagicMock(get_current_block=MagicMock(return_value=2))
         mock_solution = bittensor.utils.registration.POWSolution(
-            block_number= 1, # 1 less than current block number
-            nonce= 1,
-            difficulty= 1,
-            seal= b'',
+            block_number=1,  # 1 less than current block number
+            nonce=1,
+            difficulty=1,
+            seal=b"",
         )
 
         assert not mock_solution.is_stale(mock_subtensor)
 
-        mock_subtensor = MagicMock(
-            get_current_block=MagicMock(return_value=3),
-        )
+        mock_subtensor = MagicMock(get_current_block=MagicMock(return_value=3))
         mock_solution = bittensor.utils.registration.POWSolution(
-            block_number= 1, # 2 less than current block number
-            nonce= 1,
-            difficulty= 1,
-            seal= b'',
+            block_number=1,  # 2 less than current block number
+            nonce=1,
+            difficulty=1,
+            seal=b"",
         )
 
         assert not mock_solution.is_stale(mock_subtensor)
 
-        mock_subtensor = MagicMock(
-            get_current_block=MagicMock(return_value=4),
-        )
+        mock_subtensor = MagicMock(get_current_block=MagicMock(return_value=4))
         mock_solution = bittensor.utils.registration.POWSolution(
-            block_number= 1, # 3 less than current block number
-            nonce= 1,
-            difficulty= 1,
-            seal= b'',
+            block_number=1,  # 3 less than current block number
+            nonce=1,
+            difficulty=1,
+            seal=b"",
         )
 
         assert not mock_solution.is_stale(mock_subtensor)
 
     def test_pow_not_stale_diff_block_number_too_old(self):
-        mock_subtensor = MagicMock(
-            get_current_block=MagicMock(return_value=5),
-        )
+        mock_subtensor = MagicMock(get_current_block=MagicMock(return_value=5))
         mock_solution = bittensor.utils.registration.POWSolution(
-            block_number= 1, # 4 less than current block number
-            nonce= 1,
-            difficulty= 1,
-            seal= b'',
+            block_number=1,  # 4 less than current block number
+            nonce=1,
+            difficulty=1,
+            seal=b"",
         )
 
         assert mock_solution.is_stale(mock_subtensor)
 
+
 class TestPOWCalled(unittest.TestCase):
-    def setUp(self) -> None: 
+    def setUp(self) -> None:
         # Setup mock subnet
         self._subtensor = bittensor.subtensor(_mock=True)
 
-        self._subtensor.create_subnet(
-            netuid = 99
-        )
+        self._subtensor.create_subnet(netuid=99)
 
     def test_pow_called_for_cuda(self):
         class MockException(Exception):
             pass
+
         mock_pow_register_call = MagicMock(side_effect=MockException)
 
         mock_subtensor = bittensor.subtensor(_mock=True)
-        mock_subtensor.get_neuron_for_pubkey_and_subnet=MagicMock(is_null=True)
+        mock_subtensor.get_neuron_for_pubkey_and_subnet = MagicMock(is_null=True)
         mock_subtensor._do_pow_register = mock_pow_register_call
 
         mock_wallet = SimpleNamespace(
             hotkey=bittensor.Keypair.create_from_seed(
-                '0x' + '0' * 64, ss58_format=bittensor.__ss58_format__
+                "0x" + "0" * 64, ss58_format=bittensor.__ss58_format__
             ),
-            coldkeypub=SimpleNamespace(
-                ss58_address=''
-            )
+            coldkeypub=SimpleNamespace(ss58_address=""),
         )
 
         mock_pow_is_stale = MagicMock(return_value=False)
 
         mock_result = MagicMock(
-            spec = bittensor.utils.registration.POWSolution,
+            spec=bittensor.utils.registration.POWSolution,
             block_number=1,
             nonce=random.randint(0, pow(2, 32)),
             difficulty=1,
-            seal=b'\x00' * 64,
+            seal=b"\x00" * 64,
             is_stale=mock_pow_is_stale,
         )
 
-        with patch('torch.cuda.is_available', return_value=True) as mock_cuda_available:
+        with patch("torch.cuda.is_available", return_value=True) as mock_cuda_available:
             with patch(
-                'bittensor._subtensor.extrinsics.registration.create_pow',
-                return_value=mock_result
+                "bittensor._subtensor.extrinsics.registration.create_pow",
+                return_value=mock_result,
             ) as mock_create_pow:
                 # Should exit early
                 with pytest.raises(MockException):
-                    mock_subtensor.register(mock_wallet, netuid=99, cuda=True, prompt=False)
+                    mock_subtensor.register(
+                        mock_wallet, netuid=99, cuda=True, prompt=False
+                    )
 
                 mock_pow_is_stale.assert_called_once()
                 mock_create_pow.assert_called_once()
                 mock_cuda_available.assert_called_once()
 
                 call0 = mock_pow_is_stale.call_args
                 _, kwargs = call0
-                assert kwargs['subtensor'] == mock_subtensor
+                assert kwargs["subtensor"] == mock_subtensor
 
                 mock_pow_register_call.assert_called_once()
                 _, kwargs = mock_pow_register_call.call_args
-                kwargs['pow_result'].nonce == mock_result.nonce
+                kwargs["pow_result"].nonce == mock_result.nonce
 
 
 class TestCUDASolverRun(unittest.TestCase):
     def test_multi_cuda_run_updates_nonce_start(self):
         class MockException(Exception):
             pass
 
@@ -578,280 +695,322 @@
             stopEvent=MagicMock(is_set=MagicMock(return_value=False)),
             newBlockEvent=MagicMock(is_set=MagicMock(return_value=False)),
             finished_queue=MagicMock(put=MagicMock()),
             limit=10000,
             proc_num=0,
         )
 
-
-        with patch('bittensor.utils.registration._solve_for_nonce_block_cuda',
-            side_effect=[None, MockException] # first call returns mocked no solution, second call raises exception
+        with patch(
+            "bittensor.utils.registration._solve_for_nonce_block_cuda",
+            side_effect=[
+                None,
+                MockException,
+            ],  # first call returns mocked no solution, second call raises exception
         ) as mock_solve_for_nonce_block_cuda:
-
             # Should exit early
             with pytest.raises(MockException):
                 _CUDASolver.run(mock_solver_self)
             mock_solve_for_nonce_block_cuda.assert_called()
             calls = mock_solve_for_nonce_block_cuda.call_args_list
-            self.assertEqual(len(calls), 2, f"solve_for_nonce_block_cuda was called {len(calls)}. Expected 2") # called only twice
+            self.assertEqual(
+                len(calls),
+                2,
+                f"solve_for_nonce_block_cuda was called {len(calls)}. Expected 2",
+            )  # called only twice
 
             # args, kwargs
             args_call_0, _ = calls[0]
-            initial_nonce_start: int = args_call_0[0] # fist arg should be nonce_start
+            initial_nonce_start: int = args_call_0[0]  # fist arg should be nonce_start
             self.assertIsInstance(initial_nonce_start, int)
 
             args_call_1, _ = calls[1]
-            nonce_start_after_iteration: int = args_call_1[0] # first arg should be nonce_start
+            nonce_start_after_iteration: int = args_call_1[
+                0
+            ]  # first arg should be nonce_start
             self.assertIsInstance(nonce_start_after_iteration, int)
 
             # verify nonce_start is updated after each iteration
-            self.assertNotEqual(nonce_start_after_iteration, initial_nonce_start, "nonce_start was not updated after iteration")
+            self.assertNotEqual(
+                nonce_start_after_iteration,
+                initial_nonce_start,
+                "nonce_start was not updated after iteration",
+            )
             ## Should incerase by the number of nonces tried == TPB * update_interval
-            self.assertEqual(nonce_start_after_iteration, (initial_nonce_start + update_interval * TPB) % nonce_limit,  "nonce_start was not updated by the correct amount")
+            self.assertEqual(
+                nonce_start_after_iteration,
+                (initial_nonce_start + update_interval * TPB) % nonce_limit,
+                "nonce_start was not updated by the correct amount",
+            )
+
 
 @ddt
 class TestExplorerURL(unittest.TestCase):
     network_map: Dict[str, str] = {
         "nakamoto": "https://polkadot.js.org/apps/?rpc=wss://archivelb.nakamoto.opentensor.ai:9943#/explorer",
         "example": "https://polkadot.js.org/apps/?rpc=wss://example.example.com#/explorer",
         "nobunaga": "https://polkadot.js.org/apps/?rpc=wss://nobunaga.bittensor.com:9943#/explorer",
         # "bad": None # no explorer for this network
     }
 
     @data(
-        ("nobunaga", "https://polkadot.js.org/apps/?rpc=wss://nobunaga.bittensor.com:9943#/explorer"),
-        ("nakamoto", "https://polkadot.js.org/apps/?rpc=wss://archivelb.nakamoto.opentensor.ai:9943#/explorer"),
-        ("example", "https://polkadot.js.org/apps/?rpc=wss://example.example.com#/explorer"),
+        (
+            "nobunaga",
+            "https://polkadot.js.org/apps/?rpc=wss://nobunaga.bittensor.com:9943#/explorer",
+        ),
+        (
+            "nakamoto",
+            "https://polkadot.js.org/apps/?rpc=wss://archivelb.nakamoto.opentensor.ai:9943#/explorer",
+        ),
+        (
+            "example",
+            "https://polkadot.js.org/apps/?rpc=wss://example.example.com#/explorer",
+        ),
         ("bad", None),
         ("", None),
-        ("networknamewithoutexplorer", None)
+        ("networknamewithoutexplorer", None),
     )
     @unpack
-    def test_get_explorer_root_url_by_network_from_map(self, network: str, expected: str) -> str:
-        self.assertEqual(bittensor.utils.get_explorer_root_url_by_network_from_map(network, self.network_map), expected)
+    def test_get_explorer_root_url_by_network_from_map(
+        self, network: str, expected: str
+    ) -> str:
+        self.assertEqual(
+            bittensor.utils.get_explorer_root_url_by_network_from_map(
+                network, self.network_map
+            ),
+            expected,
+        )
 
     @data(
-        ("nobunaga", "0x123", "https://polkadot.js.org/apps/?rpc=wss://nobunaga.bittensor.com:9943#/explorer/query/0x123"),
-        ("example", "0x123", "https://polkadot.js.org/apps/?rpc=wss://example.example.com#/explorer/query/0x123"),
+        (
+            "nobunaga",
+            "0x123",
+            "https://polkadot.js.org/apps/?rpc=wss://nobunaga.bittensor.com:9943#/explorer/query/0x123",
+        ),
+        (
+            "example",
+            "0x123",
+            "https://polkadot.js.org/apps/?rpc=wss://example.example.com#/explorer/query/0x123",
+        ),
         ("bad", "0x123", None),
         ("", "0x123", None),
-        ("networknamewithoutexplorer", "0x123", None)
+        ("networknamewithoutexplorer", "0x123", None),
     )
     @unpack
-    def test_get_explorer_url_for_network_by_network_and_block_hash(self, network: str, block_hash: str, expected: str) -> str:
-        self.assertEqual(bittensor.utils.get_explorer_url_for_network(network, block_hash, self.network_map), expected)
+    def test_get_explorer_url_for_network_by_network_and_block_hash(
+        self, network: str, block_hash: str, expected: str
+    ) -> str:
+        self.assertEqual(
+            bittensor.utils.get_explorer_url_for_network(
+                network, block_hash, self.network_map
+            ),
+            expected,
+        )
 
 
 class TestWalletReregister(unittest.TestCase):
     _mock_subtensor: MockSubtensor
 
     def setUp(self):
-        self.subtensor = bittensor.subtensor( network = 'mock' ) # own instance per test
+        self.subtensor = bittensor.subtensor(network="mock")  # own instance per test
 
     @classmethod
     def setUpClass(cls) -> None:
         # Keeps the same mock network for all tests. This stops the network from being re-setup for each test.
-        cls._mock_subtensor = bittensor.subtensor( network = 'mock' )
+        cls._mock_subtensor = bittensor.subtensor(network="mock")
 
         cls._do_setup_subnet()
 
     @classmethod
     def _do_setup_subnet(cls):
         # reset the mock subtensor
         cls._mock_subtensor.reset()
         # Setup the mock subnet 3
-        cls._mock_subtensor.create_subnet(
-            netuid = 3
-        )
+        cls._mock_subtensor.create_subnet(netuid=3)
 
     def test_wallet_reregister_reregister_false(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
-        
-        with patch('bittensor._subtensor.extrinsics.registration.register_extrinsic', side_effect=MockException) as mock_register:
-            with pytest.raises(SystemExit): # should exit because it's not registered
+
+        with patch(
+            "bittensor._subtensor.extrinsics.registration.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
+            with pytest.raises(SystemExit):  # should exit because it's not registered
                 bittensor.utils.reregister(
-                    wallet = mock_wallet,
-                    subtensor = self._mock_subtensor,
-                    netuid = 3,
-                    reregister = False,
+                    wallet=mock_wallet,
+                    subtensor=self._mock_subtensor,
+                    netuid=3,
+                    reregister=False,
                 )
 
-            mock_register.assert_not_called() # should not call register
+            mock_register.assert_not_called()  # should not call register
 
     def test_wallet_reregister_reregister_false_and_registered_already(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
 
         self._mock_subtensor.force_register_neuron(
-            netuid = 3,
-            hotkey = mock_wallet.hotkey.ss58_address,
-            coldkey = mock_wallet.coldkeypub.ss58_address,
-        )
-        self.assertTrue(self._mock_subtensor.is_hotkey_registered_on_subnet(
-            netuid = 3,
-            hotkey_ss58 = mock_wallet.hotkey.ss58_address,
-        ))
-        
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
+            netuid=3,
+            hotkey=mock_wallet.hotkey.ss58_address,
+            coldkey=mock_wallet.coldkeypub.ss58_address,
+        )
+        self.assertTrue(
+            self._mock_subtensor.is_hotkey_registered_on_subnet(
+                netuid=3,
+                hotkey_ss58=mock_wallet.hotkey.ss58_address,
+            )
+        )
+
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
             bittensor.utils.reregister(
-                wallet = mock_wallet,
-                subtensor = self._mock_subtensor,
-                netuid = 3,
-                reregister = False,
-            ) # Should not exit because it's registered
+                wallet=mock_wallet,
+                subtensor=self._mock_subtensor,
+                netuid=3,
+                reregister=False,
+            )  # Should not exit because it's registered
 
-            mock_register.assert_not_called() # should not call register
+            mock_register.assert_not_called()  # should not call register
 
     def test_wallet_reregister_reregister_true_and_registered_already(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
 
         self._mock_subtensor.force_register_neuron(
-            netuid = 3,
-            hotkey = mock_wallet.hotkey.ss58_address,
-            coldkey = mock_wallet.coldkeypub.ss58_address,
-        )
-        self.assertTrue(self._mock_subtensor.is_hotkey_registered_on_subnet(
-            netuid = 3,
-            hotkey_ss58 = mock_wallet.hotkey.ss58_address,
-        ))
-        
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
-            bittensor.utils.reregister(
-                wallet = mock_wallet,
-                subtensor = self._mock_subtensor,
-                netuid = 3,
-                reregister = True,
-            ) # Should not exit because it's registered
+            netuid=3,
+            hotkey=mock_wallet.hotkey.ss58_address,
+            coldkey=mock_wallet.coldkeypub.ss58_address,
+        )
+        self.assertTrue(
+            self._mock_subtensor.is_hotkey_registered_on_subnet(
+                netuid=3,
+                hotkey_ss58=mock_wallet.hotkey.ss58_address,
+            )
+        )
 
-            mock_register.assert_not_called() # should not call register
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
+            bittensor.utils.reregister(
+                wallet=mock_wallet,
+                subtensor=self._mock_subtensor,
+                netuid=3,
+                reregister=True,
+            )  # Should not exit because it's registered
 
+            mock_register.assert_not_called()  # should not call register
 
     def test_wallet_reregister_no_params(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
-        
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
+
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
             # Should be able to set without argument
             with pytest.raises(MockException):
                 bittensor.utils.reregister(
-                    wallet = mock_wallet,
-                    subtensor = self._mock_subtensor,
-                    netuid = 3,
-                    reregister = True,
+                    wallet=mock_wallet,
+                    subtensor=self._mock_subtensor,
+                    netuid=3,
+                    reregister=True,
                     # didn't pass any register params
                 )
 
-            mock_register.assert_called_once() # should call register once
+            mock_register.assert_called_once()  # should call register once
 
     def test_wallet_reregister_use_cuda_flag_true(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
-        
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
+
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
             # Should be able to set without argument
             with pytest.raises(MockException):
                 bittensor.utils.reregister(
-                    wallet = mock_wallet,
-                    subtensor = self._mock_subtensor,
-                    netuid = 3,
-                    dev_id = 0,
-                    cuda = True,
-                    reregister = True,
+                    wallet=mock_wallet,
+                    subtensor=self._mock_subtensor,
+                    netuid=3,
+                    dev_id=0,
+                    cuda=True,
+                    reregister=True,
                 )
 
             call_args = mock_register.call_args
             _, kwargs = call_args
 
             mock_register.assert_called_once()
-            self.assertIn('cuda', kwargs)
-            self.assertEqual(kwargs['cuda'], True) 
+            self.assertIn("cuda", kwargs)
+            self.assertEqual(kwargs["cuda"], True)
 
     def test_wallet_reregister_use_cuda_flag_false(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
-        
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
+
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
             # Should be able to set without argument
             with pytest.raises(MockException):
                 bittensor.utils.reregister(
-                    wallet = mock_wallet,
-                    subtensor = self._mock_subtensor,
-                    netuid = 3,
-                    dev_id = 0,
-                    cuda = False,
-                    reregister = True,
+                    wallet=mock_wallet,
+                    subtensor=self._mock_subtensor,
+                    netuid=3,
+                    dev_id=0,
+                    cuda=False,
+                    reregister=True,
                 )
 
             call_args = mock_register.call_args
             _, kwargs = call_args
 
             mock_register.assert_called_once()
-            self.assertEqual(kwargs['cuda'], False)
+            self.assertEqual(kwargs["cuda"], False)
 
     def test_wallet_reregister_cuda_arg_not_specified_should_be_false(self):
-        mock_wallet = _generate_wallet(
-            hotkey = _get_mock_keypair(
-                100, self.id()
-            )
-        )
+        mock_wallet = _generate_wallet(hotkey=_get_mock_keypair(100, self.id()))
 
         class MockException(Exception):
             pass
 
-        with patch('bittensor._subtensor.subtensor_impl.register_extrinsic', side_effect=MockException) as mock_register:
+        with patch(
+            "bittensor._subtensor.subtensor_impl.register_extrinsic",
+            side_effect=MockException,
+        ) as mock_register:
             # Should be able to set without argument
             with pytest.raises(MockException):
                 bittensor.utils.reregister(
-                    wallet = mock_wallet,
-                    subtensor = self._mock_subtensor,
-                    netuid = 3,
-                    dev_id = 0,
-                    reregister = True,
+                    wallet=mock_wallet,
+                    subtensor=self._mock_subtensor,
+                    netuid=3,
+                    dev_id=0,
+                    reregister=True,
                 )
 
             call_args = mock_register.call_args
             _, kwargs = call_args
 
             mock_register.assert_called_once()
-            self.assertEqual(kwargs['cuda'], False) # should be False by default
+            self.assertEqual(kwargs["cuda"], False)  # should be False by default
 
 
 if __name__ == "__main__":
     unittest.main()
```

### Comparing `bittensor-5.3.1/tests/unit_tests/bittensor_tests/utils/test_weight_utils.py` & `bittensor-5.3.2/tests/unit_tests/bittensor_tests/utils/test_weight_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,88 +1,92 @@
 import torch
 import bittensor.utils.weight_utils as weight_utils
 import pytest
 import random
 
+
 def test_convert_weight_and_uids():
     uids = torch.tensor(list(range(10)))
     weights = torch.rand(10)
-    weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+    weight_utils.convert_weights_and_uids_for_emit(uids, weights)
 
     # min weight < 0
     weights[5] = -1
     with pytest.raises(ValueError) as pytest_wrapped_e:
-        weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+        weight_utils.convert_weights_and_uids_for_emit(uids, weights)
 
     # min uid < 0
     weights[5] = 0
     uids[3] = -1
     with pytest.raises(ValueError) as pytest_wrapped_e:
-        weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+        weight_utils.convert_weights_and_uids_for_emit(uids, weights)
 
     # len(uids) != len(weights)
     uids[3] = 3
     with pytest.raises(ValueError) as pytest_wrapped_e:
-        weight_utils.convert_weights_and_uids_for_emit( uids, weights[1:] )
+        weight_utils.convert_weights_and_uids_for_emit(uids, weights[1:])
 
     # sum(weights) == 0
     weights = torch.zeros(10)
-    weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+    weight_utils.convert_weights_and_uids_for_emit(uids, weights)
 
     # test for overflow and underflow
-    for _ in range (5):
+    for _ in range(5):
         uids = torch.tensor(list(range(10)))
         weights = torch.rand(10)
-        weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+        weight_utils.convert_weights_and_uids_for_emit(uids, weights)
+
 
 def test_normalize_with_max_weight():
     weights = torch.rand(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.01 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.01)
     assert wn.max() <= 0.01
 
     weights = torch.zeros(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.01 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.01)
     assert wn.max() <= 0.01
 
     weights = torch.rand(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.02 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.02)
     assert wn.max() <= 0.02
 
     weights = torch.zeros(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.02 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.02)
     assert wn.max() <= 0.02
 
     weights = torch.rand(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.03 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.03)
     assert wn.max() <= 0.03
 
     weights = torch.zeros(1000)
-    wn = weight_utils.normalize_max_weight( weights, limit = 0.03 )
+    wn = weight_utils.normalize_max_weight(weights, limit=0.03)
     assert wn.max() <= 0.03
 
     # Check for Limit
     limit = 0.001
     weights = torch.rand(2000)
     w = weights / weights.sum()
-    wn = weight_utils.normalize_max_weight( weights, limit = limit )
-    assert (w.max() >= limit and (limit - wn.max()).abs() < 0.001) or (w.max() < limit and wn.max() < limit)
+    wn = weight_utils.normalize_max_weight(weights, limit=limit)
+    assert (w.max() >= limit and (limit - wn.max()).abs() < 0.001) or (
+        w.max() < limit and wn.max() < limit
+    )
 
     # Check for Zeros
     limit = 0.01
     weights = torch.zeros(2000)
-    wn = weight_utils.normalize_max_weight( weights, limit = limit )
-    assert wn.max() == 1/2000
+    wn = weight_utils.normalize_max_weight(weights, limit=limit)
+    assert wn.max() == 1 / 2000
 
     # Check for Ordering after normalization
     weights = torch.rand(100)
-    wn = weight_utils.normalize_max_weight( weights, limit = 1 )
-    assert torch.equal(wn,weights/weights.sum())
+    wn = weight_utils.normalize_max_weight(weights, limit=1)
+    assert torch.equal(wn, weights / weights.sum())
 
     # Check for eplison changes
     eplison = 0.01
-    weights,_ = torch.sort(torch.rand(100))
-    x = weights/weights.sum()
-    limit  = x[-10]
-    change = eplison*limit
-    y = weight_utils.normalize_max_weight(x, limit=limit-change)
-    z = weight_utils.normalize_max_weight(x, limit=limit+change)
-    assert (y-z).abs().sum() < eplison
+    weights, _ = torch.sort(torch.rand(100))
+    x = weights / weights.sum()
+    limit = x[-10]
+    change = eplison * limit
+    y = weight_utils.normalize_max_weight(x, limit=limit - change)
+    z = weight_utils.normalize_max_weight(x, limit=limit + change)
+    assert (y - z).abs().sum() < eplison
```

