# Comparing `tmp/lamini-0.0.19-28-py3-none-any.whl.zip` & `tmp/lamini-0.0.20-29-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,42 @@
-Zip file size: 38051 bytes, number of entries: 40
--rw-r--r--  2.0 unx      585 b- defN 23-Jul-26 20:37 llama/__init__.py
--rw-r--r--  2.0 unx      703 b- defN 23-Jul-26 20:37 llama/error/error.py
--rw-r--r--  2.0 unx      616 b- defN 23-Jul-26 20:37 llama/metrics/compare_equal_metric.py
--rw-r--r--  2.0 unx      104 b- defN 23-Jul-26 20:37 llama/metrics/metric.py
--rw-r--r--  2.0 unx    17855 b- defN 23-Jul-26 20:37 llama/program/builder.py
--rw-r--r--  2.0 unx      765 b- defN 23-Jul-26 20:37 llama/program/function.py
--rw-r--r--  2.0 unx     1882 b- defN 23-Jul-26 20:37 llama/program/program.py
--rw-r--r--  2.0 unx     2656 b- defN 23-Jul-26 20:37 llama/program/value.py
--rw-r--r--  2.0 unx      737 b- defN 23-Jul-26 20:37 llama/program/operations/batch_llama_operation.py
--rw-r--r--  2.0 unx     1028 b- defN 23-Jul-26 20:37 llama/program/operations/call_operation.py
--rw-r--r--  2.0 unx     1218 b- defN 23-Jul-26 20:37 llama/program/operations/feedback_operation.py
--rw-r--r--  2.0 unx      505 b- defN 23-Jul-26 20:37 llama/program/operations/get_argument_operation.py
--rw-r--r--  2.0 unx      618 b- defN 23-Jul-26 20:37 llama/program/operations/get_element_operation.py
--rw-r--r--  2.0 unx      632 b- defN 23-Jul-26 20:37 llama/program/operations/get_field_operation.py
--rw-r--r--  2.0 unx      615 b- defN 23-Jul-26 20:37 llama/program/operations/llama_operation.py
--rw-r--r--  2.0 unx      514 b- defN 23-Jul-26 20:37 llama/program/operations/metric_operation.py
--rw-r--r--  2.0 unx      755 b- defN 23-Jul-26 20:37 llama/program/operations/return_operation.py
--rw-r--r--  2.0 unx      286 b- defN 23-Jul-26 20:37 llama/program/operations/train_operation.py
--rw-r--r--  2.0 unx     4780 b- defN 23-Jul-26 20:37 llama/program/util/api_actions.py
--rw-r--r--  2.0 unx     1105 b- defN 23-Jul-26 20:37 llama/program/util/config.py
--rw-r--r--  2.0 unx     6472 b- defN 23-Jul-26 20:37 llama/program/util/run_ai.py
--rw-r--r--  2.0 unx     1121 b- defN 23-Jul-26 20:37 llama/program/util/type_to_dict.py
--rw-r--r--  2.0 unx      391 b- defN 23-Jul-26 20:37 llama/prompts/blank_prompt.py
--rw-r--r--  2.0 unx      285 b- defN 23-Jul-26 20:37 llama/prompts/general_prompt.py
--rw-r--r--  2.0 unx     3729 b- defN 23-Jul-26 20:37 llama/prompts/prompt.py
--rw-r--r--  2.0 unx      344 b- defN 23-Jul-26 20:37 llama/prompts/qa_prompt.py
--rw-r--r--  2.0 unx     6223 b- defN 23-Jul-26 20:37 llama/runners/basic_model_runner.py
--rw-r--r--  2.0 unx     5003 b- defN 23-Jul-26 20:37 llama/runners/question_answer_runner.py
--rw-r--r--  2.0 unx    11678 b- defN 23-Jul-26 20:37 llama/tools/augmenters.py
--rw-r--r--  2.0 unx      205 b- defN 23-Jul-26 20:37 llama/tools/embedding.py
--rw-r--r--  2.0 unx     7982 b- defN 23-Jul-26 20:37 llama/tools/filters.py
--rw-r--r--  2.0 unx      215 b- defN 23-Jul-26 20:37 llama/tools/json_to_object.py
--rw-r--r--  2.0 unx     2293 b- defN 23-Jul-26 20:37 llama/types/base_specification.py
--rw-r--r--  2.0 unx      178 b- defN 23-Jul-26 20:37 llama/types/context.py
--rw-r--r--  2.0 unx     1707 b- defN 23-Jul-26 20:37 llama/types/type.py
--rw-r--r--  2.0 unx    11340 b- defN 23-Jul-26 20:37 lamini-0.0.19.dist-info/LICENSE
--rw-r--r--  2.0 unx    13597 b- defN 23-Jul-26 20:37 lamini-0.0.19.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jul-26 20:37 lamini-0.0.19.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-Jul-26 20:37 lamini-0.0.19.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3494 b- defN 23-Jul-26 20:37 lamini-0.0.19.dist-info/RECORD
-40 files, 114314 bytes uncompressed, 32413 bytes compressed:  71.6%
+Zip file size: 38128 bytes, number of entries: 40
+-rw-r--r--  2.0 unx      585 b- defN 23-Jul-27 02:15 llama/__init__.py
+-rw-r--r--  2.0 unx      703 b- defN 23-Jul-27 02:15 llama/error/error.py
+-rw-r--r--  2.0 unx      616 b- defN 23-Jul-27 02:15 llama/metrics/compare_equal_metric.py
+-rw-r--r--  2.0 unx      104 b- defN 23-Jul-27 02:15 llama/metrics/metric.py
+-rw-r--r--  2.0 unx    18089 b- defN 23-Jul-27 02:15 llama/program/builder.py
+-rw-r--r--  2.0 unx      765 b- defN 23-Jul-27 02:15 llama/program/function.py
+-rw-r--r--  2.0 unx     1882 b- defN 23-Jul-27 02:15 llama/program/program.py
+-rw-r--r--  2.0 unx     2656 b- defN 23-Jul-27 02:15 llama/program/value.py
+-rw-r--r--  2.0 unx      737 b- defN 23-Jul-27 02:15 llama/program/operations/batch_llama_operation.py
+-rw-r--r--  2.0 unx     1028 b- defN 23-Jul-27 02:15 llama/program/operations/call_operation.py
+-rw-r--r--  2.0 unx     1218 b- defN 23-Jul-27 02:15 llama/program/operations/feedback_operation.py
+-rw-r--r--  2.0 unx      505 b- defN 23-Jul-27 02:15 llama/program/operations/get_argument_operation.py
+-rw-r--r--  2.0 unx      618 b- defN 23-Jul-27 02:15 llama/program/operations/get_element_operation.py
+-rw-r--r--  2.0 unx      632 b- defN 23-Jul-27 02:15 llama/program/operations/get_field_operation.py
+-rw-r--r--  2.0 unx      615 b- defN 23-Jul-27 02:15 llama/program/operations/llama_operation.py
+-rw-r--r--  2.0 unx      514 b- defN 23-Jul-27 02:15 llama/program/operations/metric_operation.py
+-rw-r--r--  2.0 unx      755 b- defN 23-Jul-27 02:15 llama/program/operations/return_operation.py
+-rw-r--r--  2.0 unx      286 b- defN 23-Jul-27 02:15 llama/program/operations/train_operation.py
+-rw-r--r--  2.0 unx     4780 b- defN 23-Jul-27 02:15 llama/program/util/api_actions.py
+-rw-r--r--  2.0 unx     1105 b- defN 23-Jul-27 02:15 llama/program/util/config.py
+-rw-r--r--  2.0 unx     6472 b- defN 23-Jul-27 02:15 llama/program/util/run_ai.py
+-rw-r--r--  2.0 unx     1121 b- defN 23-Jul-27 02:15 llama/program/util/type_to_dict.py
+-rw-r--r--  2.0 unx      391 b- defN 23-Jul-27 02:15 llama/prompts/blank_prompt.py
+-rw-r--r--  2.0 unx      285 b- defN 23-Jul-27 02:15 llama/prompts/general_prompt.py
+-rw-r--r--  2.0 unx     3729 b- defN 23-Jul-27 02:15 llama/prompts/prompt.py
+-rw-r--r--  2.0 unx      344 b- defN 23-Jul-27 02:15 llama/prompts/qa_prompt.py
+-rw-r--r--  2.0 unx     6254 b- defN 23-Jul-27 02:15 llama/runners/basic_model_runner.py
+-rw-r--r--  2.0 unx     5005 b- defN 23-Jul-27 02:15 llama/runners/question_answer_runner.py
+-rw-r--r--  2.0 unx    11678 b- defN 23-Jul-27 02:15 llama/tools/augmenters.py
+-rw-r--r--  2.0 unx      205 b- defN 23-Jul-27 02:15 llama/tools/embedding.py
+-rw-r--r--  2.0 unx     7982 b- defN 23-Jul-27 02:15 llama/tools/filters.py
+-rw-r--r--  2.0 unx      215 b- defN 23-Jul-27 02:15 llama/tools/json_to_object.py
+-rw-r--r--  2.0 unx     2293 b- defN 23-Jul-27 02:15 llama/types/base_specification.py
+-rw-r--r--  2.0 unx      178 b- defN 23-Jul-27 02:15 llama/types/context.py
+-rw-r--r--  2.0 unx     1707 b- defN 23-Jul-27 02:15 llama/types/type.py
+-rw-r--r--  2.0 unx    11340 b- defN 23-Jul-27 02:16 lamini-0.0.20.dist-info/LICENSE
+-rw-r--r--  2.0 unx    13597 b- defN 23-Jul-27 02:16 lamini-0.0.20.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-27 02:16 lamini-0.0.20.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-Jul-27 02:16 lamini-0.0.20.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3494 b- defN 23-Jul-27 02:16 lamini-0.0.20.dist-info/RECORD
+40 files, 114581 bytes uncompressed, 32490 bytes compressed:  71.6%
```

## zipnote {}

```diff
@@ -99,23 +99,23 @@
 
 Filename: llama/types/context.py
 Comment: 
 
 Filename: llama/types/type.py
 Comment: 
 
-Filename: lamini-0.0.19.dist-info/LICENSE
+Filename: lamini-0.0.20.dist-info/LICENSE
 Comment: 
 
-Filename: lamini-0.0.19.dist-info/METADATA
+Filename: lamini-0.0.20.dist-info/METADATA
 Comment: 
 
-Filename: lamini-0.0.19.dist-info/WHEEL
+Filename: lamini-0.0.20.dist-info/WHEEL
 Comment: 
 
-Filename: lamini-0.0.19.dist-info/top_level.txt
+Filename: lamini-0.0.20.dist-info/top_level.txt
 Comment: 
 
-Filename: lamini-0.0.19.dist-info/RECORD
+Filename: lamini-0.0.20.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## llama/program/builder.py

```diff
@@ -43,27 +43,32 @@
 
 
 class Builder:
     """Build a program for execution by the Llama large language model engine."""
 
     def __init__(
         self,
-        id: str,
-        model_name: str = None,
+        id: str = "default_dataset",
+        model_name: Optional[str] = None,
         prompt: Optional[BasePrompt] = None,
-        config={},
+        key: Optional[str] = None,
+        config: dict = {},
     ):
         self.id = id
         self.program = Program(self, id, prompt)
         self.current_function = self.program.main
         self.value_cache = {}
         self.model_name = model_name
         self.prompt = prompt
         self.training_job_id = None
-        edit_config(config)
+        self.key = key
+        self.config = config
+        if self.key is not None:
+            self.config.update({"production": {"key": self.key}})
+        edit_config(self.config)
 
     def __call__(self, input, output_type, *args, **kwargs):
         """Inference with the LLM. input can be a single value or a list of values."""
         # Reset program
         self.program = Program(self, self.id, self.prompt)
         self.current_function = self.program.main
         if isinstance(input, list):
@@ -188,15 +193,15 @@
             kwargs.get("peft_args", {}),
             templates,
         )
         training_job_id = results["job_id"]
         self.training_job_id = training_job_id
 
         if kwargs.get("verbose", False):
-            print(f"job id: {training_job_id}")
+            print(f"job id: {self.training_job_id}")
         # wait until data part is done
         results = self.get_training_job_status(training_job_id)
         return results
 
     def get_inference_job_status(self, job_id: str):
         """Get the status of a batch inference job."""
         if job_id is None:
```

## llama/runners/basic_model_runner.py

```diff
@@ -1,50 +1,55 @@
 from typing import List, Union
 from llama import Type, Context, LLMEngine
 import jsonlines
 import pandas as pd
 
 from llama.prompts.blank_prompt import BlankPrompt
 
+
 class Input(Type):
     input: str = Context(" ")
 
+
 class Output(Type):
     output: str = Context(" ")
 
+
 class BasicModelRunner:
     """A class for running and training a model with a blank prompt (string in, string out)"""
 
     def __init__(self, model_name: str = "EleutherAI/pythia-410m-deduped", config={}):
         self.model_name = model_name
         self.prompt = BlankPrompt()
-        self.llm = LLMEngine("basic_model_runner",
-                             model_name=model_name,
-                             config=config,
-                             prompt=self.prompt,
-                            )
+        self.llm = LLMEngine(
+            "basic_model_runner",
+            model_name=model_name,
+            config=config,
+            prompt=self.prompt,
+        )
         self.job_id = None
         self.data = []
+        self.evaluation = None
 
     def __call__(self, inputs: Union[str, List[str]]) -> str:
         """Call the model runner on prompt"""
         # Alternative way to run it:
         # output = self.llm(self.prompt.input(input=input_string), self.prompt.output)
 
         if isinstance(inputs, list):
             print("Running batch job on %d number of inputs" % len(inputs))
             input_objects = [Input(input=i) for i in inputs]
         else:
             # Singleton
             input_objects = Input(input=inputs)
-            output_objects = self.llm(
-                input=input_objects,
-                output_type=Output,
-                model_name=self.model_name,
-            )
+        output_objects = self.llm(
+            input=input_objects,
+            output_type=Output,
+            model_name=self.model_name,
+        )
         if isinstance(output_objects, list):
             outputs = [o.output for o in output_objects]
             return [{"input": i, "output": o} for i, o in zip(inputs, outputs)]
         else:
             return output_objects.output
 
     def get_keys(self, data_keys):
@@ -61,22 +66,27 @@
     def load_data(self, data, verbose: bool = False):
         """
         Load a list of json objects with input-output keys into the LLM
         Each object must have 'input' and 'output' as keys.
         """
         # Get keys
         if not isinstance(data, list) and not isinstance(data[0], dict):
-            raise ValueError("Data must be a list of dicts with keys 'input' and 'output'")
-        
+            raise ValueError(
+                "Data must be a list of dicts with keys 'input' and 'output'"
+            )
+
         data_keys = data[0].keys()
         keys = self.get_keys(data_keys)
 
         try:
             input_output_objects = [
-                [Input(input=d[keys[0]]), Output(output=d[keys[1]]) if keys[1] else Output(output="") ]
+                [
+                    Input(input=d[keys[0]]),
+                    Output(output=d[keys[1]]) if keys[1] else Output(output=""),
+                ]
                 for d in data
             ]
         except KeyError:
             raise ValueError("Each object must have 'input' and 'output' as keys")
         self.data.extend(input_output_objects)
         if verbose:
             print("Sample added data: %s" % str(input_output_objects[0]))
@@ -102,15 +112,18 @@
         data_keys = df.columns
         keys = self.get_keys(data_keys)
 
         input_output_objects = []
         try:
             for _, row in df.iterrows():
                 input_output_objects.append(
-                    [Input(input=row[keys[0]]), Output(output=row[keys[1]]) if keys[1] else Output(output="") ]
+                    [
+                        Input(input=row[keys[0]]),
+                        Output(output=row[keys[1]]) if keys[1] else Output(output=""),
+                    ]
                 )
         except KeyError:
             raise ValueError("Each object must have 'input' and 'output' as keys")
         self.data.extend(input_output_objects)
 
         if verbose:
             print("Sample added data: %s" % str(input_output_objects[0]))
@@ -126,44 +139,37 @@
         self.load_data_from_dataframe(df, verbose=verbose)
 
     def clear_data(self):
         """Clear the data from the LLM"""
         self.llm.clear_data()
         self.data = []
 
-    def train(
-        self,
-        verbose: bool = False,
-        finetune_args={},
-        limit=500
-    ):
+    def train(self, verbose: bool = False, finetune_args={}, limit=500):
         """
         Train the LLM on added data. This function blocks until training is complete.
         """
         if len(self.data) < 10:
             raise Exception("Submit at least 10 data pairs to train")
         if len(self.data) > limit:
             data = self.data[:limit]
         else:
             data = self.data
         self.llm.save_data(data)
 
-        final_status = self.llm.train(
-            verbose=verbose,
-            finetune_args=finetune_args
-        )
+        final_status = self.llm.train(verbose=verbose, finetune_args=finetune_args)
         try:
             self.model_name = final_status["model_name"]
             self.job_id = final_status["job_id"]
-            self.llm = LLMEngine("basic_model_runner", model_name=self.model_name)
             self.llm.clear_data()
         except KeyError:
             raise Exception("Training failed")
-    
+
     def evaluate(self) -> List:
         """Get evaluation results"""
-        return self.llm.evaluate()
+        self.evaluation = self.llm.evaluate()
+        return self.evaluation
 
     def get_eval_results(self) -> List:
         if self.job_id is None:
             raise Exception("Must train before getting results (no job id))")
-        return self.llm.eval(self.job_id)
+        self.evaluation = self.llm.eval(self.job_id)
+        return self.evaluation
```

## llama/runners/question_answer_runner.py

```diff
@@ -15,15 +15,17 @@
 
 
 class QuestionAnswerModel:
     """A class for running and training a question answering model"""
 
     def __init__(self, model_name: str = "EleutherAI/pythia-410m-deduped", config={}):
         self.model_name = model_name
-        self.llm = LLMEngine("question_answer_runner", model_name=model_name, config=config)
+        self.llm = LLMEngine(
+            "question_answer_runner", model_name=model_name, config=config
+        )
         self.question_answer = []
         self.job_id = None
         self.evaluation_results = None
 
     def get_answer(self, question: str) -> str:
         """Get answer to a single question"""
         question_object = Question(question=question)
@@ -44,15 +46,14 @@
             output_type=Answer,
             model_name=self.model_name,
             task="question_answer",
         )
         answers = [a.answer for a in answer_objects]
         return [{"question": q, "answer": a} for q, a in zip(questions, answers)]
 
-
     def load_question_answer(self, data):
         """
         Load a list of json objects with question answer keys into the LLM
         Each object must have 'question' and 'answer' as keys.
         """
         try:
             question_answer_objects = [
@@ -102,38 +103,43 @@
 
     def train(
         self,
         verbose: bool = False,
         finetune_args={},
         enable_peft=False,
         peft_args={},
-        limit=500
+        limit=500,
     ):
         """
         Train the LLM on added data. This function blocks until training is complete.
         """
         if len(self.question_answer) < 10:
             raise Exception("Submit at least 10 question answer pairs to train")
         if len(self.question_answer) > limit:
             qa_pairs = self.question_answer[:limit]
         else:
             qa_pairs = self.question_answer
         self.llm.save_data(qa_pairs)
 
-        final_status = self.llm.train(task="question_answer", verbose=verbose, finetune_args=finetune_args, enable_peft=enable_peft, peft_args=peft_args)
+        final_status = self.llm.train(
+            task="question_answer",
+            verbose=verbose,
+            finetune_args=finetune_args,
+            enable_peft=enable_peft,
+            peft_args=peft_args,
+        )
         try:
             self.model_name = final_status["model_name"]
             self.job_id = final_status["job_id"]
-            self.llm = LLMEngine("question_answer_runner", model_name=self.model_name)
             self.llm.clear_data()
         except KeyError:
             raise Exception("Training failed")
 
         return final_status
-    
+
     def evaluate(self) -> List:
         """Get evaluation results"""
         self.evaluation_results = self.llm.evaluate()
         return self.evaluation_results
 
     def get_eval_results(self) -> List:
         if self.job_id is None:
```

## Comparing `lamini-0.0.19.dist-info/LICENSE` & `lamini-0.0.20.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `lamini-0.0.19.dist-info/METADATA` & `lamini-0.0.20.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: lamini
-Version: 0.0.19
+Version: 0.0.20
 Summary: Build on large language models faster
 Author-email: PowerML <info@powerml.co>
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `lamini-0.0.19.dist-info/RECORD` & `lamini-0.0.20.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 llama/__init__.py,sha256=iGMmmrQleGF-pJahQBAetxWlJ9KoCuB-d3LepSxvMKs,585
 llama/error/error.py,sha256=oACWv3ZcZO2H4Rwj1BR9DfDyd-CJqQ1WcffbMj2cAoc,703
 llama/metrics/compare_equal_metric.py,sha256=u-DhSye5IpiR1yLlTvaF6MHvApr306PBSR1NYKzaDm8,616
 llama/metrics/metric.py,sha256=RT-VeKlNhXrouFoOIKH42dB3OCqT18TMxct_bNr6TCg,104
-llama/program/builder.py,sha256=ybyZxxGKPMYjtok-wjyBJNBhSRXU0pZpA9q67odGrVo,17855
+llama/program/builder.py,sha256=hGMxUZCbE4OmZsG6CfFNyyWOJaffX0-9Px6rjE8jeXY,18089
 llama/program/function.py,sha256=ozpku_T8JQ90AdWKQcv0O1XZVFX9wgcxo9x8t8q3UZk,765
 llama/program/program.py,sha256=ulV6nCejhSXaLlT6OlJHHjkJMN-iCz9OT9F-5PGBhcw,1882
 llama/program/value.py,sha256=a3p2A6QgzRi7QkAl_FZgXsJGy7wKuBx8bpFYTquUFNM,2656
 llama/program/operations/batch_llama_operation.py,sha256=CQj3gD5Rp_HQrEUY0_H35qaZNfoDsnAOASuWankobY4,737
 llama/program/operations/call_operation.py,sha256=Zbl32tkaVIHd_bOTb8NfzXkrXsg3_aaDahX6DO6Sb74,1028
 llama/program/operations/feedback_operation.py,sha256=l4EiiF3961JTknWhXGb64Boe06OnSekgliej2onQxZM,1218
 llama/program/operations/get_argument_operation.py,sha256=Ee-skGuclfOngoY8rC9ABq8o9zM_xKiqCS_kYekx6aQ,505
@@ -20,21 +20,21 @@
 llama/program/util/config.py,sha256=iha-Twi5a6FisTbLTXtcYWvHxrS_DWvRFsEOUjnbEVk,1105
 llama/program/util/run_ai.py,sha256=80NMpE3qUQ5yNGLjEu9HD962DX0WsMvIQw1lg5bUxj4,6472
 llama/program/util/type_to_dict.py,sha256=nkSKgzqcGvoYMwCiRT1nbADnFE_1giaq_7VNOJdju_Q,1121
 llama/prompts/blank_prompt.py,sha256=jSoAbqDitnpzrfbg46l3vfvM6wfwxnXSxrpSTd0Fwx8,391
 llama/prompts/general_prompt.py,sha256=kANKipkdW4yP01bdWF0naboQGCcXJkZOieubiSaCv5Y,285
 llama/prompts/prompt.py,sha256=7mZSK4nPpZhTwEUMKLTgA39JJ2pqxQT-jeaUmSQ4cD0,3729
 llama/prompts/qa_prompt.py,sha256=kpYZVo2pZdLQfc_2S6PC5cBsk9cs8YN-ycQUsp6HZKk,344
-llama/runners/basic_model_runner.py,sha256=LKS9UyPIUhIiKiRkkLzR2A17zuU7onJvjjl3NtuP_aE,6223
-llama/runners/question_answer_runner.py,sha256=FTTdJrvMCf9xK9-HETRnDFXy7paFKbrx9qChiLGs7zA,5003
+llama/runners/basic_model_runner.py,sha256=jgAyqAubM9WJcpMNQ6hBVVTiaY7AY7e7EKdJBDNyNT4,6254
+llama/runners/question_answer_runner.py,sha256=-xmbf3BF--7lNv3YPiLF5Lb_1sSun9d0oBiMYTRELYs,5005
 llama/tools/augmenters.py,sha256=bsd9rC0lgn5vHU1cnFAbG7sJcbFwcITGNhTtqhoov7U,11678
 llama/tools/embedding.py,sha256=WofHn3HfReaXqv8HaczgYpsOf98v2hGa7bprTNadVW0,205
 llama/tools/filters.py,sha256=hkqrCc2z65UZ_E9pow0pCe5BKmLdbkCjl36ovN6B_aM,7982
 llama/tools/json_to_object.py,sha256=4WyzMJlREXCv1EhB7Eo2FJZo52Wvk2lZwXt-DF2WOBI,215
 llama/types/base_specification.py,sha256=Esws0xNRORDx2tXBeMrWtRyoQgtj6qSGxH1I_xLwnfA,2293
 llama/types/context.py,sha256=giTdF_Zmo-sp3PD66doy46juCQdfTQMDanWyYyOduxo,178
 llama/types/type.py,sha256=D1n3cW1ukcbYdg0nPPNmTVwui0Z54WjTSlr5lz60u6k,1707
-lamini-0.0.19.dist-info/LICENSE,sha256=-alRIf0b5B1SavU0njHUTAanPUn6GHxH9a2Q_ACz1HM,11340
-lamini-0.0.19.dist-info/METADATA,sha256=pYp2SxgKQ2leHE8c2KljsfwlNsidhCG9GKxVApiXcKk,13597
-lamini-0.0.19.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
-lamini-0.0.19.dist-info/top_level.txt,sha256=vXIfhTMeFFl71QrVVrWCJGS0tzlBB5vynlR-iGsCqZ4,6
-lamini-0.0.19.dist-info/RECORD,,
+lamini-0.0.20.dist-info/LICENSE,sha256=-alRIf0b5B1SavU0njHUTAanPUn6GHxH9a2Q_ACz1HM,11340
+lamini-0.0.20.dist-info/METADATA,sha256=nf_bKU58j1hwHzG_Sj7RSVOAaL9MRdgx9VTMXPzYNLM,13597
+lamini-0.0.20.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
+lamini-0.0.20.dist-info/top_level.txt,sha256=vXIfhTMeFFl71QrVVrWCJGS0tzlBB5vynlR-iGsCqZ4,6
+lamini-0.0.20.dist-info/RECORD,,
```

